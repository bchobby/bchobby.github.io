<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>数据倾斜和数据倾斜的解决方案 - 编程爱好者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="数据倾斜和数据倾斜的解决方案" />
<meta property="og:description" content="1、什么是数据倾斜 Hadoop能够进行对海量数据进行批处理的核心，在于它的分布式思想，也就是多台服务器（节点）组成集群，进行分布式的数据处理。
举个例子，假如要处理一个10亿数据的表格，我的集群由10个节点组成，一台服务器处理这10亿数据需要10个小时，现在我将10亿条数据平均的分配到不同的节点上，每台节点负责处理1亿条数据，那么原本需要10个小时完成的工作，现在只需要1个小时即可。
而以上只是理想情况，实际上分配到每台节点的数据量并不是均匀的，当大量的数据分配到某一个节点时（假设5亿条），那么原本只需要1小时完成的工作，变成了其中9个节点不到1小时就完成了工作，而分配到了5亿数据的节点，花了5个小时才完成。
从最终结果来看，就是这个处理10亿数据的任务，集群花了5个小时才最终得出结果。大量的数据集中到了一台或者几台机器上计算，这些数据的计算速度远远低于平均计算速度，导致整个计算过程过慢，这种情况就是发生了数据倾斜。
2、数据倾斜的表现 2.1、MapReduce任务 主要表现在Reuduce阶段卡在99.99%，一直99.99%不能结束。
有一个多几个Reuduce卡住；各种container报错OOM；读写的数据量极大，至少远远超过其它正常的Reuduce。伴随着数据倾斜，会出现任务被kill等各种诡异的表现。 2.2、Spark任务 绝大多数task执行得都非常快，但个别task执行的极慢；
单个Executor执行时间特别久，整体任务卡在某个stage不能结束；
Executor lost，OOM，Shuffle过程出错；
正常运行的任务突然失败；
用SparkStreaming做实时算法时候，一直会有 executor 出现 OOM 的错误，但是其余的executor内存使用率却很低。
3、发生数据倾斜的原因 正常的数据分布理论上都是倾斜的，就是我们所说的二八原理：80%的财富集中在20%的人手中, 80%的用户只使用20%的功能 , 20%的用户贡献了80%的访问量 , 不同的数据字段可能的数据倾斜一般有两种情况：
唯一值非常少，极少数值有非常多的记录值（唯一值少于几千）；
唯一值比较多，这个字段的某些值有远远多于其他值的记录数，但是它的占比也小于百分之一或千分之一。
可以理解为：
数据频率倾斜——某一个区域数据要远远大于其他区域；数据大小倾斜——部分记录的大小远远大于平均值。 无论是MR还是Spark任务进行计算的时候，都会触发 Shuffle 动作，一旦触发，所有相同key的值就会拉到一个或几个节点上，就容易发生单个节点处理数据量爆增的情况 。
Shuffle 的中文含义是“洗牌”，其原理在这里不展开说，但通过下面这张图，你能了解到它的对数据进行了什么样的处理。
3.1、key 分布不均匀 某些key的数量过于集中，存在大量相同值的数据；存在大量异常值或空值。 3.2、业务数据本身的特性 例如某个分公司或某个城市订单量大幅提升几十倍甚至几百倍，对该城市的订单统计聚合时，容易发生数据倾斜。
3.3、某些 SQL 语句本身就有数据倾斜 两个表中关联字段存在大量空值，或是关联字段的数据不统一，例如在A表中值是大写，B表中值是小写等情况。
4、触发数据倾斜的SQL操作 关键词情况后果join其中一个表较小，但是key集中分发到某一个或几个Reduce/Stage的数据远高于平均值大表与大表，但是分桶的判断字段0值或空值过多这些空值都由一个Reduce/Stage处理，非常慢group bygroup by维度过小，某值的数量过多处理某值的Reduce/Stage非常耗时count distinct某特殊值过多处理此特殊值的Reduce/Stage非常耗时 5、数据倾斜的解决方案 首先排除过滤倾斜key，ETL预处理这种治标不治本的方法，然后详细来讲解各种不同的处理方式。
5.1、参数调整 5.1.1、通用优化：提高 shuffle 并行度 Spark的shuffle并行度默认值是200，建议根据服务器的情况进行调整。一般是集群cpu总和的2-3倍。当发生数据倾斜的时候，适当增大并行度，可以将原本被分配到同一个Task的不同Key分配到不同Task。
set spark.sql.shuffle.partitions= [num_tasks] 5.1.1.1、原理 5.1.1.2、缺点 它没有从根本上改变数据倾斜的本质和问题，只是说尽可能地去缓解和减轻 shuffle reduce task 的数据压力，以及数据倾斜的问题。。
5.1.2、map 端聚合，启动负载均衡 适用范围： group by 造成的数据倾斜。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bchobby.github.io/posts/0aebf838b5e42bccfc8042d7c35f7f18/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-09-20T15:06:29+08:00" />
<meta property="article:modified_time" content="2023-09-20T15:06:29+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程爱好者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程爱好者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">数据倾斜和数据倾斜的解决方案</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="1_0"></a>1、什么是数据倾斜</h2> 
<p><code>Hadoop</code>能够进行对海量数据进行批处理的核心，在于它的<strong>分布式思想</strong>，也就是多台服务器（节点）组成集群，进行<strong>分布式的数据处理</strong>。</p> 
<p>举个例子，假如要处理一个<strong>10亿数据的表格</strong>，我的集群由10个节点组成，<strong>一台服务器处理这10亿数据需要10个小时</strong>，现在我将10亿条数据平均的分配到不同的节点上，<strong>每台节点负责处理1亿条数据，那么原本需要10个小时完成的工作，现在只需要1个小时即可</strong>。</p> 
<p>而以上只是理想情况，<strong>实际上分配到每台节点的数据量并不是均匀的</strong>，当大量的数据分配到某一个节点时（假设5亿条），那么原本只需要1小时完成的工作，变成了其中9个节点不到1小时就完成了工作，而分配到了5亿数据的节点，花了5个小时才完成。</p> 
<p>从最终结果来看，就是这个处理10亿数据的任务，集群花了5个小时才最终得出结果。大量的数据集中到了一台或者几台机器上计算，这些数据的计算速度远远低于平均计算速度，导致整个计算过程过慢，<strong>这种情况就是发生了数据倾斜</strong>。</p> 
<p><img src="https://images2.imgbox.com/2c/8c/cNha72du_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="2_13"></a>2、数据倾斜的表现</h2> 
<h3><a id="21MapReduce_15"></a>2.1、<code>MapReduce</code>任务</h3> 
<p>主要表现在<code>Reuduce</code>阶段卡在99.99%，一直99.99%不能结束。</p> 
<ul><li>有一个多几个<code>Reuduce</code>卡住；</li><li>各种<code>container</code>报错<code>OOM</code>；</li><li>读写的数据量极大，至少远远超过其它正常的<code>Reuduce</code>。伴随着数据倾斜，会出现任务被kill等各种诡异的表现。</li></ul> 
<h3><a id="22Spark_23"></a>2.2、<code>Spark</code>任务</h3> 
<ul><li> <p>绝大多数<code>task</code>执行得都非常快，但个别<code>task</code>执行的极慢；</p> </li><li> <p>单个<code>Executor</code>执行时间特别久，整体任务卡在某个<code>stage</code>不能结束；</p> </li><li> <p><code>Executor lost</code>，<code>OOM</code>，<code>Shuffle</code>过程出错；</p> </li><li> <p>正常运行的任务突然失败；</p> </li><li> <p>用<code>SparkStreaming</code>做实时算法时候，<strong>一直会有</strong> <strong><code>executor</code></strong> <strong>出现</strong> <strong><code>OOM</code></strong> <strong>的错误</strong>，但是其余的<code>executor</code>内存使用率却很低。</p> </li></ul> 
<h2><a id="3_32"></a>3、发生数据倾斜的原因</h2> 
<p>正常的数据分布理论上都是倾斜的，就是我们所说的二八原理：80%的财富集中在20%的人手中, 80%的用户只使用20%的功能 , 20%的用户贡献了80%的访问量 , 不同的数据字段可能的数据倾斜一般有两种情况：</p> 
<ul><li> <p>唯一值非常少，极少数值有非常多的记录值（唯一值少于几千）；</p> </li><li> <p>唯一值比较多，这个字段的某些值有远远多于其他值的记录数，但是它的占比也小于百分之一或千分之一。</p> </li></ul> 
<p>可以理解为：</p> 
<ul><li>数据频率倾斜——某一个区域数据要远远大于其他区域；</li><li>数据大小倾斜——部分记录的大小远远大于平均值。</li></ul> 
<p>无论是<code>MR</code>还是<code>Spark</code>任务进行计算的时候，都会触发 <strong><code>Shuffle</code></strong> 动作，一旦触发，<strong>所有相同key的值就会拉到一个或几个节点上，就容易发生单个节点处理数据量爆增的情况</strong> <strong>。</strong></p> 
<p><strong><code>Shuffle</code></strong> 的中文含义是“洗牌”，其原理在这里不展开说，但通过下面这张图，你能了解到它的对数据进行了什么样的处理。</p> 
<p><img src="https://images2.imgbox.com/5a/c1/lKrikA5l_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="31key__53"></a>3.1、<strong><code>key</code></strong> <strong>分布不均匀</strong></h3> 
<ul><li>某些<code>key</code>的数量过于集中，存在大量相同值的数据；</li><li>存在大量异常值或空值。</li></ul> 
<h3><a id="32_58"></a>3.2、<strong>业务数据本身的特性</strong></h3> 
<p>例如某个分公司或某个城市订单量大幅提升几十倍甚至几百倍，对该城市的订单统计聚合时，容易发生数据倾斜。</p> 
<h3><a id="33_SQL__62"></a>3.3、<strong>某些</strong> <strong><code>SQL</code></strong> <strong>语句本身就有数据倾斜</strong></h3> 
<p>两个表中关联字段存在大量空值，或是关联字段的数据不统一，例如在<code>A</code>表中值是大写，<code>B</code>表中值是小写等情况。</p> 
<h2><a id="4SQL_66"></a>4、触发数据倾斜的SQL操作</h2> 
<table><thead><tr><th></th><th></th><th></th></tr></thead><tbody><tr><td>关键词</td><td>情况</td><td>后果</td></tr><tr><td><code>join</code></td><td>其中一个表较小，但是<code>key</code>集中</td><td>分发到某一个或几个<code>Reduce/Stage</code>的数据远高于平均值</td></tr><tr><td></td><td>大表与大表，但是分桶的判断字段0值或空值过多</td><td>这些空值都由一个<code>Reduce/Stage</code>处理，非常慢</td></tr><tr><td><code>group by</code></td><td><code>group by</code>维度过小，某值的数量过多</td><td>处理某值的<code>Reduce/Stage</code>非常耗时</td></tr><tr><td><code>count distinct</code></td><td>某特殊值过多</td><td>处理此特殊值的<code>Reduce/Stage</code>非常耗时</td></tr></tbody></table> 
<h2><a id="5_77"></a>5、数据倾斜的解决方案</h2> 
<p>首先排除过滤倾斜<code>key</code>，<code>ETL</code>预处理这种治标不治本的方法，然后详细来讲解各种不同的处理方式。</p> 
<h3><a id="51_81"></a>5.1、<strong>参数调整</strong></h3> 
<h4><a id="511_shuffle__83"></a>5.1.1、<strong>通用优化：提高</strong> <strong><code>shuffle</code></strong> <strong>并行度</strong></h4> 
<p>Spark的<code>shuffle</code>并行度默认值是200，建议根据服务器的情况进行调整。一般是集群<code>cpu</code>总和的2-3倍。当发生数据倾斜的时候，适当增大并行度，可以将原本被分配到同一个<code>Task</code>的不同<code>Key</code>分配到不同<code>Task</code>。</p> 
<pre><code class="prism language-bash"><span class="token builtin class-name">set</span> <span class="token assign-left variable">spark.sql.shuffle.partitions</span><span class="token operator">=</span> <span class="token punctuation">[</span>num_tasks<span class="token punctuation">]</span>
</code></pre> 
<h5><a id="5111_91"></a>5.1.1.1、原理</h5> 
<p><img src="https://images2.imgbox.com/53/7f/dbEOVU4X_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="5112_96"></a>5.1.1.2、缺点</h5> 
<p>它没有从根本上改变数据倾斜的本质和问题，只是说尽可能地去<strong>缓解和减轻</strong> <strong><code>shuffle reduce task</code></strong> <strong>的数据压力</strong>，以及数据倾斜的问题。。</p> 
<h4><a id="512map__100"></a>5.1.2、<strong><code>map</code></strong> <strong>端聚合，启动负载均衡</strong></h4> 
<p>适用范围： <strong><code>group by</code></strong> <strong>造成的数据倾斜</strong>。</p> 
<p>数据倾斜时负载均衡，当选项设定为<code>true</code>，它使计算变成了<strong>两个</strong> <strong><code>mapreduce</code></strong>，先在第一个中在<code>shuffle</code> 过程 <code>partition</code> 时随机给 <code>key</code> 打标记，使每个<code>key</code>随机均匀分布到各个 <code>reduce</code>上计算，但是这样只能完成部分计算，因为相同<code>key</code>没有分配到相同<code>reduce</code>上，所以需要第二次的<code>mapreduce</code>,这次就回归正常 <code>shuffle</code>，但是数据分布不均匀的问题在第一次<code>mapreduce</code>已经有了很大的改善。</p> 
<pre><code class="prism language-bash"><span class="token comment"># 在map中会做部分聚集操作，效率更高但需要更多的内存</span>
<span class="token builtin class-name">set</span> <span class="token assign-left variable">hive.map.aggr</span><span class="token operator">=</span>true<span class="token punctuation">;</span> 
<span class="token comment"># 默认false，数据倾斜时负载均衡</span>
<span class="token builtin class-name">set</span> <span class="token assign-left variable">hive.groupby.skewindata</span><span class="token operator">=</span>true<span class="token punctuation">;</span> 
</code></pre> 
<h4><a id="513Reduce_Join_Map_Join_113"></a>5.1.3、<code>Reduce Join</code> 改为<code>Map Join</code></h4> 
<p>适用范围：<strong>小表</strong> <strong><code>Join</code></strong> <strong>大表</strong>。</p> 
<pre><code class="prism language-bash"><span class="token comment"># hive是否自动根据文件量大小，选择将common join转成map join 。</span>
<span class="token builtin class-name">set</span> hive.auto.convert.join <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span> 
<span class="token comment"># 大表小表判断的阈值，如果表的大小小于该值25Mb，则会被判定为小表。</span>
<span class="token comment"># 则会被加载到内存中运行，将commonjoin转化成mapjoin。一般这个值也就最多几百兆的样子。</span>
<span class="token builtin class-name">set</span> hive.mapjoin.smalltable.filesize <span class="token operator">=</span> <span class="token number">25000000</span><span class="token punctuation">;</span> 
</code></pre> 
<h5><a id="5131_125"></a>5.1.3.1、原理</h5> 
<p><strong><code>Map Join</code></strong> <strong>优化就是在</strong> <strong><code>Map</code></strong> <strong>阶段完成</strong> <strong><code>Join</code></strong> <strong>工作</strong>，而不是像通常的<code>common join</code>在<code>Reduce</code>阶段按照<code>Join</code>的列值进行分发数据到每个<code>Reduce</code>上进行<code>Join</code>工作。这样避免了 <strong><code>Shuffle</code></strong> 阶段，从而避免了数据倾斜。</p> 
<h5><a id="5132_129"></a>5.1.3.2、注意事项</h5> 
<p>这个操作会将所有的小表全量复制到每个<code>Map</code>任务节点，然后再将小表缓存在每个<code>Map</code>节点的内存里与大表进行<code>Join</code>工作。小表的大小的不能太大，一般也就几百兆，否则会出现<code>OOM</code>报错。</p> 
<h4><a id="514_Skewed_Join_133"></a>5.1.4、<strong>开启</strong> <strong><code>Skewed Join</code></strong></h4> 
<p><code>Hadoop</code> 中默认是使用<code>hive.exec.reducers.bytes.per.reducer = 1000000000</code>。也就是每个节点的<code>Reduce</code>默认是处理1G大小的数据，如果你的<code>Join</code>操作也产生了数据倾斜，那么你可以在<code>Hive</code> 中设定。</p> 
<pre><code class="prism language-bash"><span class="token builtin class-name">set</span> hive.optimize.skewjoin <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>
<span class="token builtin class-name">set</span> hive.skewjoin.key <span class="token operator">=</span> skew_key_threshold <span class="token punctuation">(</span>default <span class="token operator">=</span> <span class="token number">100000</span><span class="token punctuation">)</span>
</code></pre> 
<p>建议每次运行比较复杂的<code>SQL</code>之前都可以设一下这个参数. 如果你不知道设置多少，可以就按官方默认的1个<code>Reduce</code>只处理1G 的算法，那么 <code>skew_key_threshold = 1G/平均行长</code>。或者默认直接设成250000000 (差不多算平均行长4个字节)</p> 
<p>当我们开启<code>Skew Join</code>之后，在运行时，会对数据进行扫描并检测哪个<code>key</code>会出现倾斜，对于会倾斜的<code>key</code>，用<code>Map Join</code>做处理，不倾斜的<code>key</code>正常处理。</p> 
<h3><a id="52SQL_146"></a>5.2、<code>SQL</code>优化</h3> 
<h4><a id="521countdistinct_148"></a>5.2.1、<code>count（distinct）</code>优化</h4> 
<p>先用<code>group</code>去重，再<code>count</code>子查询。</p> 
<pre><code class="prism language-sql"><span class="token comment">--优化前</span>
<span class="token keyword">select</span> <span class="token function">count</span><span class="token punctuation">(</span><span class="token keyword">distinct</span> a<span class="token punctuation">)</span> <span class="token keyword">from</span> test <span class="token punctuation">;</span>

<span class="token comment">--优化后</span>
<span class="token keyword">select</span> count x<span class="token punctuation">.</span>a <span class="token keyword">from</span> <span class="token punctuation">(</span><span class="token keyword">select</span> a <span class="token keyword">from</span> test <span class="token keyword">group</span> <span class="token keyword">by</span> a <span class="token punctuation">)</span> x
</code></pre> 
<h4><a id="522_160"></a>5.2.2、聚合类操作，发生数据倾斜</h4> 
<h5><a id="5221_162"></a>5.2.2.1、解决方法</h5> 
<p><strong>阶段拆分-两阶段聚合：</strong> 在需要聚合的<code>key</code>前加一个随机数的前后缀，这样就能得到非常均匀的<code>key</code>，然后按这个加工之后的<code>key</code>进行第一次聚合之后，再对聚合的结果，按照原始<code>key</code>进行二次聚合，这样基本就不可能出现数据倾斜了。</p> 
<h5><a id="5222_166"></a>5.2.2.2、原理</h5> 
<p><img src="https://images2.imgbox.com/d0/14/A6SWak4n_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="5223SQL_171"></a>5.2.2.3、<code>SQL</code>示例</h5> 
<pre><code class="prism language-sql"><span class="token comment">--水果字段名为category</span>
<span class="token keyword">select</span> <span class="token function">count</span> <span class="token punctuation">(</span>substr<span class="token punctuation">(</span>x<span class="token punctuation">.</span>category<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span> 
<span class="token keyword">from</span>
<span class="token punctuation">(</span><span class="token keyword">select</span> concat<span class="token punctuation">(</span>category<span class="token punctuation">,</span><span class="token string">'_'</span><span class="token punctuation">,</span>cast<span class="token punctuation">(</span><span class="token function">round</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token operator">*</span>rand<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token number">1</span> <span class="token keyword">as</span> string<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">from</span> table1
<span class="token keyword">group</span> <span class="token keyword">by</span> concat<span class="token punctuation">(</span>category<span class="token punctuation">,</span><span class="token string">'_'</span><span class="token punctuation">,</span>cast<span class="token punctuation">(</span><span class="token function">round</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token operator">*</span>rand<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token number">1</span> <span class="token keyword">as</span> string<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span> x <span class="token comment">--1阶段聚合</span>
<span class="token keyword">group</span> <span class="token keyword">by</span> substr<span class="token punctuation">(</span>x<span class="token punctuation">.</span>category<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span>   <span class="token comment">--2阶段聚合</span>
</code></pre> 
<h4><a id="523Join_184"></a>5.2.3、大表<code>Join</code>大表发生数据倾斜</h4> 
<ul><li>大表拆分，倾斜部分单独处理；</li><li>中间表分桶排序后<code>Join</code>。</li></ul> 
<h5><a id="5231_189"></a>5.2.3.1、例子</h5> 
<p><code>table_a</code>表是一张近3个月买家交易明细表，字段如下，数据量较大：</p> 
<table><thead><tr><th></th><th></th><th></th></tr></thead><tbody><tr><td><code>buyer_id</code>（卖家<code>ID</code>）</td><td><code>seller_id</code>（卖家<code>ID</code>）</td><td><code>order_num</code>（订单数）</td></tr><tr><td>1113839839</td><td>1001</td><td>5</td></tr></tbody></table> 
<p><code>table_b</code>表是一张所有卖家信息表，数据量也很大，不满足<code>Map Join</code>的条件：</p> 
<table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td><code>seller_id</code>（卖家<code>ID</code>）</td><td><code>seller_level</code>（卖家评级）</td></tr><tr><td>1001</td><td>A</td></tr></tbody></table> 
<p>想要获取买家所有订单中，来源于不同等级卖家的数量。</p> 
<pre><code class="prism language-sql"><span class="token keyword">SELECT</span> 
   t1<span class="token punctuation">.</span>buyer_id 
  <span class="token punctuation">,</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token keyword">case</span> <span class="token keyword">when</span> t2<span class="token punctuation">.</span>seller_level <span class="token operator">=</span> <span class="token string">'A'</span> <span class="token keyword">then</span> order_num <span class="token keyword">end</span><span class="token punctuation">)</span> <span class="token keyword">as</span> a_num
  <span class="token punctuation">,</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token keyword">case</span> <span class="token keyword">when</span> t2<span class="token punctuation">.</span>seller_level <span class="token operator">=</span> <span class="token string">'B'</span> <span class="token keyword">then</span> order_num <span class="token keyword">end</span><span class="token punctuation">)</span> <span class="token keyword">as</span> b_num
  <span class="token punctuation">,</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token keyword">case</span> <span class="token keyword">when</span> t2<span class="token punctuation">.</span>seller_level <span class="token operator">=</span> <span class="token string">'C'</span> <span class="token keyword">then</span> order_num <span class="token keyword">end</span><span class="token punctuation">)</span> <span class="token keyword">as</span> c_num
<span class="token keyword">FROM</span> table_a  t1  <span class="token comment">--买家交易明细表</span>
<span class="token keyword">INNER</span> <span class="token keyword">JOIN</span> table_b t2 <span class="token comment">--卖家信息表</span>
<span class="token keyword">ON</span> t1<span class="token punctuation">.</span>seller_id <span class="token operator">=</span> t2<span class="token punctuation">.</span>seller_id
<span class="token keyword">GROUP</span> <span class="token keyword">BY</span> t1<span class="token punctuation">.</span>buyer_id<span class="token punctuation">;</span>
</code></pre> 
<h5><a id="5232_Map_Join__shuffle_221"></a>5.2.3.2、<strong>转为</strong> <code>Map Join</code> <strong>避免</strong> <strong><code>shuffle</code></strong></h5> 
<p><code>table_b</code>由于数据量较大，无法直接<code>Map Join</code> ，所以考虑通过过滤3个月内没有发生交易的卖家，来减少<code>table_b</code>的数据量，使其达到满足<code>Map Join</code> 的情况。</p> 
<pre><code class="prism language-sql"><span class="token keyword">SELECT</span> 
   t1<span class="token punctuation">.</span>buyer_id 
  <span class="token punctuation">,</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token keyword">case</span> <span class="token keyword">when</span> t4<span class="token punctuation">.</span>seller_level <span class="token operator">=</span> <span class="token string">'A'</span> <span class="token keyword">then</span> order_num <span class="token keyword">end</span><span class="token punctuation">)</span> <span class="token keyword">as</span> a_num
  <span class="token punctuation">,</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token keyword">case</span> <span class="token keyword">when</span> t4<span class="token punctuation">.</span>seller_level <span class="token operator">=</span> <span class="token string">'B'</span> <span class="token keyword">then</span> order_num <span class="token keyword">end</span><span class="token punctuation">)</span> <span class="token keyword">as</span> b_num
  <span class="token punctuation">,</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token keyword">case</span> <span class="token keyword">when</span> t4<span class="token punctuation">.</span>seller_level <span class="token operator">=</span> <span class="token string">'C'</span> <span class="token keyword">then</span> order_num <span class="token keyword">end</span><span class="token punctuation">)</span> <span class="token keyword">as</span> c_num
<span class="token keyword">FROM</span> table_a  t1
<span class="token keyword">INNER</span> <span class="token keyword">JOIN</span> 
  <span class="token punctuation">(</span>
  <span class="token keyword">SELECT</span>
     t2<span class="token punctuation">.</span>seller_id
    <span class="token punctuation">,</span>t2<span class="token punctuation">.</span>seller_level
  <span class="token keyword">FROM</span>
    table_b t2
  <span class="token keyword">INNER</span> <span class="token keyword">JOIN</span> 
    <span class="token punctuation">(</span>
    <span class="token keyword">SELECT</span>
      seller_id
    <span class="token keyword">FROM</span> table_a
    <span class="token keyword">GROUP</span> <span class="token keyword">BY</span> seller_id  
    <span class="token punctuation">)</span> t3
  <span class="token keyword">ON</span> t2<span class="token punctuation">.</span>seller_id <span class="token operator">=</span> t3<span class="token punctuation">.</span>seller_id
  <span class="token punctuation">)</span> t4  <span class="token comment">--过滤掉table_b中没有出现在table_a中的seller_id</span>
<span class="token keyword">ON</span> t1<span class="token punctuation">.</span>seller_id <span class="token operator">=</span> t4<span class="token punctuation">.</span>seller_id
<span class="token keyword">GROUP</span> <span class="token keyword">BY</span> t1<span class="token punctuation">.</span>buyer_id<span class="token punctuation">;</span>

</code></pre> 
<p>此方案在有些时候能够起作用，但大部分情况并不能解决问题，比如<code>table_b</code>经过过滤后，数量依然很大，还是不满足<code>Map Join</code>的条件。</p> 
<h5><a id="5233_255"></a>5.2.3.3、拆表一分为二，倾斜部分单独处理</h5> 
<p>首先创建一个临时表<code>temp_b</code>，存放大卖家（买家超过1万个）的名单，然后<code>table_a</code>分别<code>join temp_b</code>和<code>table_b</code>，结果<code>union all</code> 起来即可。此方案的适用情况最多，且最有效。</p> 
<pre><code class="prism language-sql"><span class="token comment">--临时表存放90天内买家超过10000的大卖家</span>
<span class="token keyword">INSERT</span> OVERWRITE <span class="token keyword">TABLE</span> temp_b
<span class="token keyword">SELECT</span>
   t1<span class="token punctuation">.</span>seller_id
  <span class="token punctuation">,</span>t2<span class="token punctuation">.</span>seller_level
<span class="token keyword">FROM</span>
<span class="token punctuation">(</span>
<span class="token keyword">SELECT</span>
   seller_id
  <span class="token punctuation">,</span><span class="token function">count</span><span class="token punctuation">(</span>buyer_id<span class="token punctuation">)</span> <span class="token keyword">as</span> buy_num
<span class="token keyword">FROM</span> table_a
<span class="token keyword">GROUP</span> <span class="token keyword">BY</span> seller_id
<span class="token punctuation">)</span> t1
<span class="token keyword">LEFT</span> <span class="token keyword">JOIN</span> 
<span class="token punctuation">(</span>
<span class="token keyword">SELECT</span>
   seller_id
  <span class="token punctuation">,</span>seller_level
<span class="token keyword">FROM</span> table_b
<span class="token punctuation">)</span> t2
<span class="token keyword">ON</span> t1<span class="token punctuation">.</span>seller_id <span class="token operator">=</span> t2<span class="token punctuation">.</span>seller_id
<span class="token operator">AND</span> t1<span class="token punctuation">.</span>buy_num <span class="token operator">&gt;</span> <span class="token number">10000</span><span class="token punctuation">;</span>


<span class="token comment">--获取最终结果</span>
<span class="token keyword">SELECT</span> 
   t7<span class="token punctuation">.</span>buyer_id 
  <span class="token punctuation">,</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token keyword">case</span> <span class="token keyword">when</span> t7<span class="token punctuation">.</span>seller_level <span class="token operator">=</span> <span class="token string">'A'</span> <span class="token keyword">then</span> t7<span class="token punctuation">.</span>order_num <span class="token keyword">end</span><span class="token punctuation">)</span> <span class="token keyword">as</span> a_num
  <span class="token punctuation">,</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token keyword">case</span> <span class="token keyword">when</span> t7<span class="token punctuation">.</span>seller_level <span class="token operator">=</span> <span class="token string">'B'</span> <span class="token keyword">then</span> t7<span class="token punctuation">.</span>order_num <span class="token keyword">end</span><span class="token punctuation">)</span> <span class="token keyword">as</span> b_num
  <span class="token punctuation">,</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token keyword">case</span> <span class="token keyword">when</span> t7<span class="token punctuation">.</span>seller_level <span class="token operator">=</span> <span class="token string">'C'</span> <span class="token keyword">then</span> t7<span class="token punctuation">.</span>order_num <span class="token keyword">end</span><span class="token punctuation">)</span> <span class="token keyword">as</span> c_num
<span class="token keyword">FROM</span>
<span class="token punctuation">(</span>
<span class="token keyword">SELECT</span>
    <span class="token comment">/*+mapjoin(t2)*/</span>
   t1<span class="token punctuation">.</span>buyer_id
  <span class="token punctuation">,</span>t1<span class="token punctuation">.</span>seller_id
  <span class="token punctuation">,</span>t1<span class="token punctuation">.</span>order_num
  <span class="token punctuation">,</span>t2<span class="token punctuation">.</span>seller_level
<span class="token keyword">FROM</span> table_a t1
<span class="token keyword">LEFT</span> <span class="token keyword">JOIN</span> temp_b t2
<span class="token keyword">ON</span> t1<span class="token punctuation">.</span>seller_id <span class="token operator">=</span> t2<span class="token punctuation">.</span>seller_id
<span class="token keyword">UNION</span> <span class="token keyword">ALL</span>  <span class="token comment">--针对大卖家map join 其他卖家正常join</span>
<span class="token keyword">SELECT</span>
   t3<span class="token punctuation">.</span>buyer_id
  <span class="token punctuation">,</span>t3<span class="token punctuation">.</span>seller_id
  <span class="token punctuation">,</span>t3<span class="token punctuation">.</span>order_num
  <span class="token punctuation">,</span>t6<span class="token punctuation">.</span>seller_level
<span class="token keyword">FROM</span> 
  table_a t3
<span class="token keyword">LEFT</span> <span class="token keyword">JOIN</span> 
  <span class="token punctuation">(</span>
  <span class="token keyword">SELECT</span>
     seller_id
    <span class="token punctuation">,</span>seller_level
  <span class="token keyword">FROM</span> table_b t4
  <span class="token keyword">LEFT</span> <span class="token keyword">JOIN</span> temp_b t5
  <span class="token keyword">ON</span> t4<span class="token punctuation">.</span>seller_id <span class="token operator">=</span> t5<span class="token punctuation">.</span>seller_id
  <span class="token keyword">WHERE</span> t5<span class="token punctuation">.</span>seller_id <span class="token operator">is</span> <span class="token boolean">null</span>
  <span class="token punctuation">)</span> t6
<span class="token keyword">ON</span> t3<span class="token punctuation">.</span>seller_id <span class="token operator">=</span> t6<span class="token punctuation">.</span>seller_id
<span class="token punctuation">)</span> t7
<span class="token keyword">GROUP</span> <span class="token keyword">BY</span> t7<span class="token punctuation">.</span>buyer_id<span class="token punctuation">;</span>
</code></pre> 
<h4><a id="524Join_324"></a>5.2.4、<code>Join</code>发生数据倾斜通用方法</h4> 
<p>解决方法：<strong>随机前缀和</strong> <strong><code>RDD</code></strong> <strong>扩容</strong>。<code>SQL</code>实现方法：</p> 
<ul><li>将大表的倾斜<code>key</code>筛选出来，随机打上前后缀，假如为1-10的数字；</li><li>将较小表<code>cross join</code>(笛卡尔积) 1-10数字共10行，再通过拼接，形成与大表对应的前后缀。（假如较小表数据量为10万，此时扩容至100万）；</li><li>此时将筛选过的大表与扩容的较小表关联，关联成功后，通过字段加工复原；</li><li>将大表其他无倾斜数据与较小表关联，<code>union all</code> 前3步处理后得到的数据。</li></ul> 
<p><img src="https://images2.imgbox.com/a1/05/Dj4S29eN_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="525_336"></a>5.2.5、空值产生的数据倾斜</h4> 
<p>解决方法：<strong>给空值进行随机赋值</strong>。</p> 
<h5><a id="_340"></a>场景</h5> 
<p>如日志中，常会有信息丢失的问题，比如日志中的 user_id，如果取其中的 user_id 和 用户表中的user_id 关联，会碰到数据倾斜的问题。</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> <span class="token operator">*</span>
<span class="token keyword">from</span>
log a
<span class="token keyword">left</span> <span class="token keyword">join</span>
users b
<span class="token keyword">on</span>  <span class="token keyword">coalesce</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>user_id<span class="token punctuation">,</span>concat<span class="token punctuation">(</span><span class="token string">'rand'</span><span class="token punctuation">,</span> rand<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">=</span> b<span class="token punctuation">.</span>user_id<span class="token punctuation">;</span>
</code></pre> 
<h3><a id="53_353"></a>5.3、其他方法</h3> 
<h4><a id="531Reduce_JVM_355"></a>5.3.1、增加<code>Reduce</code> 的<code>JVM</code>内存</h4> 
<h4><a id="532Reduce_357"></a>5.3.2、增加<code>Reduce</code>个数</h4> 
<pre><code class="prism language-bash"><span class="token builtin class-name">set</span> mapred.reduce.tasks <span class="token operator">=</span> <span class="token punctuation">[</span>num<span class="token punctuation">]</span>
</code></pre> 
<h4><a id="533partitioner_363"></a>5.3.3、自定义<code>partitioner</code></h4> 
<p>根据现在处理的这份数据，单独写一个适合的<code>partitioner</code>。比如现在是按省份进行汇总数据，如果只是简单的按省份去分（这并没有错），那么数据肯定会倾斜，因为各省的数据天然不一样。我们可以通过历史数据、抽样数据或者一些常识，对数据进行人工分区，让数据按照我们自定义的分区规则比较均匀的分配到不同的<code>task</code>中。</p> 
<h5><a id="_367"></a>常见的分区方式：</h5> 
<ul><li><strong>随机分区：</strong> 每个区域的数据基本均衡，简单易用，偶尔出现倾斜，但是特征同样也会随机打散；</li><li><strong>轮询分区：</strong> 绝对不会倾斜，但是需要提前预知分成若干份，进行轮询；</li><li><strong><code>hash</code></strong> <strong>散列：</strong> 可以针对某个特征进行<code>hash</code>散列，保证相同特征的数据在一个区，但是极容易出现数据倾斜；</li><li><strong>范围分区：</strong> 需要排序，临近的数据会被分在同一个区，可以控制分区数据均匀。</li></ul>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/89a54a73215e9342f0e2e003ecf4ace5/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">数学建模| 非线性规划（Matlab）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/1c55bbb456b19257280e5a21b53d299b/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">在PyTorch里面利用transformers的Trainer微调预训练大模型</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程爱好者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151260"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>