<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Keras基本用法 - 编程爱好者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Keras基本用法" />
<meta property="og:description" content="参考 Keras基本用法 - 云&#43;社区 - 腾讯云
Keras是目前使用最为广泛的深度学习工具之一，它的底层可以支持TensorFlow、MXNet、CNTK和Theano。如今，Keras更是被直接引入了TensorFlow的核心代码库，成为TensorFlow官网提供的高层封装之一。下面首先介绍最基本的Keras API，下面给出一个简单的样例，然后介绍如何使用Keras定义更加复杂的模型以及如何将Keras和原生态TensorFlow结合起来。
1、Keras基本用法 和TFLearn API类似，Keras API也对模型定义、损失函数、训练过程等进行了封装，而且封装之后的整个训练过程和TFLearn是基本一致的，可以分为数据处理、模型定义和模型训练三个部分。使用原生态的Keras API需要先安装Keras包，安装的方法如下：
pip install keras 以下代码展示了如何使用原生态Keras在MNIST数据集上实现LeNet-5模型。
# -*- coding: utf-8 -*- import keras from keras.datasets import mnist from keras.models import Sequential from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D from keras import backend as K num_classes = 10 img_rows, img_cols = 28, 28 (trainX, trainY), (testX, testY) = mnist.load_data() if K.image_data_format() == &#39;channels_first&#39;: trainX = trainX.reshape(trainX.shape[0], 1, img_rows, img_cols) testX = testX." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bchobby.github.io/posts/158baad7db91eff15fd069ee91d307f9/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-06-01T12:36:56+08:00" />
<meta property="article:modified_time" content="2022-06-01T12:36:56+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程爱好者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程爱好者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Keras基本用法</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p style="margin-left:.0001pt;text-align:justify;"><strong>参考 </strong><strong><a href="https://cloud.tencent.com/developer/article/1557055" rel="nofollow" title="Keras基本用法 - 云+社区 - 腾讯云">Keras基本用法 - 云+社区 - 腾讯云</a></strong></p> 
<p></p> 
<p>Keras是目前使用最为广泛的深度学习工具之一，它的底层可以支持TensorFlow、MXNet、CNTK和Theano。如今，Keras更是被直接引入了TensorFlow的核心代码库，成为TensorFlow官网提供的高层封装之一。下面首先介绍最基本的Keras API，下面给出一个简单的样例，然后介绍如何使用Keras定义更加复杂的模型以及如何将Keras和原生态TensorFlow结合起来。</p> 
<h4>1、Keras基本用法</h4> 
<p>和TFLearn API类似，Keras API也对模型定义、损失函数、训练过程等进行了封装，而且封装之后的整个训练过程和TFLearn是基本一致的，可以分为数据处理、模型定义和模型训练三个部分。使用原生态的Keras API需要先安装Keras包，安装的方法如下：</p> 
<pre class="has"><code class="language-python">pip install keras</code></pre> 
<p>以下代码展示了如何使用原生态Keras在MNIST数据集上实现LeNet-5模型。</p> 
<pre class="has"><code class="language-ruby"># -*- coding: utf-8 -*-

import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D
from keras import backend as K

num_classes = 10
img_rows, img_cols = 28, 28


(trainX, trainY), (testX, testY) = mnist.load_data()


if K.image_data_format() == 'channels_first':
   trainX = trainX.reshape(trainX.shape[0], 1, img_rows, img_cols)
   testX = testX.reshape(testX.shape[0], 1, img_rows, img_cols)
   input_shape = (1, img_rows, img_cols)
else:
   trainX = trainX.reshape(trainX.shape[0], img_rows, img_cols, 1)
   testX = testX.reshape(testX.shape[0], img_rows, img_cols, 1)
   input_shapes = (img_rows, img_cols, 1)

trainX = trainX.astype('float32')
testX = testX.astype('float32')
trainX /= 255.0
testX  /= 255.0


trainY = keras.utils.to_categorical(trainY, num_classes)
testY = keras.utils.to_categorical(testY, num_classes)


model = Sequential()


model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Conv2D(64, (5,5), activation='relu'))

model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Flatten())

model.add(Dense(500, activation='relu'))

model.add(Dense(num_classes, activation='softmax'))


model.compile(loss=keras.losses.categorical_crossentropy,
              optimizer = keras.optimizers.SGD(),
              metrics = ['accuracy'])

model.fit(trainX, trainY, batch_size=128, epochs=20, validation_data=(testX, testY))

score = model.evaluate(testX, testY)
print('Test loss:',score[0])
print('Test accuracy', score[1])






-------------------------------------------------------------
Output:

   32/10000 [..............................] - ETA: 0s
  608/10000 [&gt;.............................] - ETA: 0s
 1152/10000 [==&gt;...........................] - ETA: 0s
 1664/10000 [===&gt;..........................] - ETA: 0s
 2112/10000 [=====&gt;........................] - ETA: 0s
 2560/10000 [======&gt;.......................] - ETA: 0s
 3008/10000 [========&gt;.....................] - ETA: 0s
 3424/10000 [=========&gt;....................] - ETA: 0s
 3840/10000 [==========&gt;...................] - ETA: 0s
 4256/10000 [===========&gt;..................] - ETA: 0s
 4704/10000 [=============&gt;................] - ETA: 0s
 5152/10000 [==============&gt;...............] - ETA: 0s
 5600/10000 [===============&gt;..............] - ETA: 0s
 6112/10000 [=================&gt;............] - ETA: 0s
 6624/10000 [==================&gt;...........] - ETA: 0s
 6944/10000 [===================&gt;..........] - ETA: 0s
 7104/10000 [====================&gt;.........] - ETA: 0s
 7232/10000 [====================&gt;.........] - ETA: 0s
 7360/10000 [=====================&gt;........] - ETA: 0s
 7488/10000 [=====================&gt;........] - ETA: 0s
 7648/10000 [=====================&gt;........] - ETA: 0s
 7840/10000 [======================&gt;.......] - ETA: 0s
 8096/10000 [=======================&gt;......] - ETA: 0s
 8256/10000 [=======================&gt;......] - ETA: 0s
 8480/10000 [========================&gt;.....] - ETA: 0s
 8640/10000 [========================&gt;.....] - ETA: 0s
 8864/10000 [=========================&gt;....] - ETA: 0s
 9120/10000 [==========================&gt;...] - ETA: 0s
 9280/10000 [==========================&gt;...] - ETA: 0s
 9408/10000 [===========================&gt;..] - ETA: 0s
 9664/10000 [===========================&gt;..] - ETA: 0s
 9824/10000 [============================&gt;.] - ETA: 0s
 9984/10000 [============================&gt;.] - ETA: 0s
10000/10000 [==============================] - 2s 178us/step
Test loss: 0.09795796233266592
Test accuracy 0.970300018787384
-------------------------------------------------------------------</code></pre> 
<p>从以上代码中可以看出使用Keras API训练模型可以先定义一个Sequential类，然后在Sequential实例中通过add函数添加网络层。Keras把卷积层、池化层、RNN结构(LSTM、GRU)，全连接层等常用的神经网络结构都做了封装，可以很方便地实现深层神经网络。在神经网络结构定义好之后，Sequential实例可以通过compile函数，指定优化函数、损失函数以及训练过程中需要监控等指标。Keras对优化函数、损失函数以及监控指标都有封装，同时也支持使用自定义的方式，在Keras的API文档中有详细的介绍，这里不再赘述。最后在网络结构、损失函数和优化函数都定义好之后，Sequential实例可以通过fit函数来训练模型。类似TFLearn中的fit函数，Keras的fit函数只需给出训练数据，batch大小和训练轮数，Keras就可以自动完成模型训练的整个过程。</p> 
<p>除了能够很方便地处理图像问题，Keras对训练神经网络的支持也是非常出色的。有了Keras APA，循环神经网络的训练体系也可以通过简单的一句命令完成。以下代码给出了如何通过Keras实现自然语言感情分类问题。使用循环网络判断语言的感情(比如在以下例子中需要判断一个评价是好评还是差评)和自然语言建模问题类似，唯一的区别在于除了最后一个时间点的输出是有意义的，其他时间点的输出都可以忽略，下图展示了使用循环网络处理感情分析问题的模型结构。</p> 
<p>                            <img alt="" class="has" height="421" src="https://images2.imgbox.com/fc/da/IyL0BIba_o.png" width="463"></p> 
<pre class="has"><code class="language-python"># -*- coding: utf-8 -*-

from keras.preprocessing import sequence
from keras.models import Sequential
from keras.layers import Dense, Embedding
from keras.layers import LSTM
from keras.datasets import imdb

# 最多使用的单词数。
max_features = 20000
# 循环神经网络的截断长度。
maxlen = 80
batch_size = 32
# 加载数据并将单词转化为ID， max_features给出了最多使用的单词数。和自然语言模型类似，会将出现频率 # 较低的单词替换为统一的ID，通过Keras封装的API生成25000条训练数据和25000条测试数据，每一条数据可以
# 摆看成一段话，并且每段话都有一个好评或者差评的标签。
(trainX, trainY), (testX, testY) = imdb.load_data(num_words=max_features)
print(len(trainX), 'train sequences')
print(len(trainY), 'test_sequences')

# 在自然语言处理中，每一段话的长度都是不一样的，但循环神经网络的循环长度是固定的，所以这里需要首先
# 将所有段落统一成固定长度。对于长度不够的段落，要使用默认值0来填充，对于超过长度
# 的段落则直接忽略掉超过的部分。
trainX = sequence.pad_sequences(trainX, maxlen = maxlen)
testX  = sequence.pad_sequences(testX, maxlen=mexlen)

# 输出统一长度之后的数据维度：
# ('x_train shape:', (25000, 80))
# ('x_test shape:', (25000, 80))
print('trainX shape:', trainX.shape)
print('testX shape:', trainX.shape)

# 再完成数据预处理之后的模型结构
model = Sequential()
# 构建embedding层。128代表了embedding层的向量维度。
model.add(Embedding(max_features, 128))
# 构建LSTM层。
model.add(LSTM(128,dropout=0.2))
# 构建最后的全连接层。注意在上面构建LSTM层时只会得到最后一个节点输出，
# 如果需要输出每个时间点的结果，那么可以将return_sequence参数设置为true。
model.add(Dense(1, activation='sigmoid'))

# 与MNIST样例类似地指定损失函数，优化函数和评测指标。
model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])
# 与MNIST样例类似地指定训练数据，训练轮数，batch大小以及验证数据。
model.fitt(trainX, trainY, batch_size=batch_size, epochs=15, validation_data=(testX, testY))

# 在测试数据上评测模型
score = model.evaluate(testX, testY, batch_size=batch_size)
print('Test loss:', score[0])
print('Test accuracy:',score[1])</code></pre> 
<p>以上两个样例针对Keras的基本用法做了详细的介绍。虽然Keras的封装，很多经典的神经网络结构能很快地被实现，不过要实现一些更加灵活的网络结构、损失函数或者数据输入方法，就需要对Keras的高级用法有更多的了解。</p> 
<h4>2、Keras高级用法</h4> 
<p>上面样例中最重要的封装就是Sequential类，所有的神经网络定义和训练都是通过Sequential实例来实现的。然而从这个类的名称可以看出，它只支持顺序模型的定义。类似Inception这样的模型结构，通过Sequential类就不容易直接实现了。为了支持更加灵活的模型定义方法，Keras支持以返回值的形式定义网络层结构。以下代码展示了如何使用这种方式定义模型。</p> 
<pre class="has"><code class="language-python"># -*- coding:utf-8 -*-

import keras
from keras.datasets import mnist
from keras.layers import Input, Dense
from keras.models import Model

# 使用1中介绍的类似方法生成trainingX、trainingY、testX、testY，唯一的
# 不同是这里只使用了全连接层，所以不需要将输入整理成三维矩阵。

...

# 定义输入，这里指定的维度不用考虑batch大小。
inputs = Input(shape=(784,))
# 定义一层全连接，该层有500隐藏节点，使用ReLU激活函数，这一层的输入为inputs。
x = Dense(500, activate='relu')(inputs)
# 定义输出层。注意因为keras封装需要指定softmax作为激活函数。
predictions = Dense(10, activate='softmax')(x)

# 通过Model类创建模型，和Sequential类不同的是Model类在初始化的时候需要指定模型的输入和输出。
model = Model(inputs=inputs, outputs=predictions)

# 与1中类似的方法定义损失函数、优化函数和评测方法。
model.complie(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.SGD(),metrics=['accuracy'])

# 与1中类似的方法训练模型。
model.fit(trainX, trainY, batch_size=128, epoches=20, validation_data=(testX, testY))</code></pre> 
<p>通过这样的方式，Keras就可以实现类似Inception这样大的模型结构。以下代码展示了如何通过Keras实现Inception结构。</p> 
<pre class="has"><code class="language-python">from keras.layers import Conv2D, MaxPooling2D, Input

# 定义输入图像尺寸
input_img = Input(shape=(256,256,3))

# 定义第一个分支。
tower_1 = Conv2D(64,(1,1),padding='same',activation='relu')(input_img)
tower_1 = COnv2D(64,(3,3),padding='same',activation='relu')(tower_1)

# 定义第二个分支。与顺序模型不同，第二个分支的输入使用的是input_img，而不是第一个分支的输出。
tower_2 = Conv2D(64,(1,1),padding='same',activation='relu')(input_img)
tower_2 = Conv2D(65,(5,5),padding='same',activation='relu')(tower_2)

# 定义第三个分支。类似地，第三个分支的输入也是input_img,
tower_3 = MaxPooling2D((3,3),strides=(1,1),padding='same')(input_img)
tower_3 = Conv2D(64, (1,1), padding='same', activation='relu')(tower_3)

# 将第三个分支通过concatenate的方式拼接在一起
output = keras.layers.concatenate([tower_1, tower_2, tower_3], axis = 1)
</code></pre> 
<p>除了可以支持顺序模型，Keras也可以支持有多个输入或者输出的模型。以下代码实现了下图所示的网络结构。</p> 
<p>                               <img alt="" class="has" height="339" src="https://images2.imgbox.com/74/50/Fcz9u2c9_o.png" width="526"></p> 
<pre class="has"><code class="language-python"># -*- coding: utf-8 -*-

import keras
from tflearn,layers.core import fully_connected
from keras.datasets import mnist
from keras.layers import Input, Dense
from keras.models import Model

# 类似1的方式生成trainX, trainY, testX, testY
# 定义两个输入，一个输入为原始的图片信息，另一个输入为正确答案。
input1 = Input(shape=(784,), name="input1")
input2 = Input(shape=(10,), name="input2")

# 定义一个只有一个隐藏节点的全连接网络。
x = Dense(1, activation='relu')(input1)
# 定义只使用了一个隐藏节点的网络结构的输出层。
output1 = Desnse(10, activation='softmax',name="output1")(x)

# 将一个隐藏节点的输出和正确答案拼接在一起，这个将作为第二个输出层的输入。
y = keras.layers.concatenate([x, input2])
# 定义第二个输出层。
input3 = Dense(10, activation='softmax', name = "output2")(y)

# 定义一个有多个输入和多个输出的模型。这里只需要将所有的输入和输出给出即可。
model = Model(inputs=[inputs1, inputs2], outputs = [output1, output2])

# 定义损失函数、优化函数和测评方法。若多个输出的损失函数相同，可以只指定一个损失函数。
# 如果多个输出的损失函数不同，则可以通过一个列表或一个字典来指定每一个输出的损失函数。
# 比如可以使用：
# loss = {'output1':binary_crossentropy,'output2':binary_crossentropy}
# 求为不同的输出指定不同的损失函数。类似地，Keras也支持为不同输出产生的损失指定权重，
# 这可以通过loss_weights参数来完成。在下面的定义中，输出output1的权重为1，output2的
# 权重为0.1，所以这个模型会更加偏向于优化的第一个输出。

model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.SGD(), loss_weights = [1,0.1], metrics = ['accuracy'])

# 模型训练过程。因为有两个输入和输出，所以这里提供的数据也需要有两个输入和两个期待的正确答案输出。
# 通过列表的方式提供数据时，Keras会假设数据给出的顺序和定义Model类时输入会给出的顺序是对应的。为 # 了避免顺序不一致导致的问题，推荐使用字典的形式给出：
#  model.fit( 
#          {'input1':trainX, 'input2':trainY}
#          {'output1':trainX, 'output2':trainY}
#          ...)

model.fit([trainX, trainY], [trainY, trainY], batch_size=128, epochs=20, validation_data=([testX, testY], [testX, testY]))</code></pre> 
<p>从以上输出可以看出Keras在训练过程中会展示每个输出层的loss和accuracy。因为输出层output1只使用了一个维度为1的隐藏点，所以正确率只有29.85%。虽然输出层output2使用了正确答案作为输入，但是因为在损失函数中权重较低(只有0.1)，所以它的收敛速度较慢，在20个epoch时准确率也只有92.1%。如果将两个输出层的损失权重设为一样，那么输出层output1在20个epoch时的准确率将只有27%，而输出层output2的准确率可以达到99.9%。虽然通过返回值的方式已经可以实现大部分的神经网络模型，然而Keras API还存在两大问题。第一，原生态Keras API对训练数据的处理流程支持得不太好，基本上需要一次性将数据全部全部加载到内存。第二，原生态Keras API无法支持分布式训练。为了解决这两个问题，Keras提供了一种与原生态TensorFlow结合地更加紧密的方式。以下代码显示了如何将Keras和原生态TensorFlow API联合起来解决MNIST问题。</p> 
<pre class="has"><code class="language-python"># -*- coding: utf-8 -*-

import tensorflow as tf
from tensorflow.example.tutorials.mnist import input_data

mnist_data=input_data.read_data_sets('/path/to/MNIST_data', one_hot=True)

# 通过TensorFlow中的placeholder定义输入。类似的，Keras封装数据的网络层结构也可以支持队列输入。
# 这样可以有效避免一次性加载所有数据的问题。

x = tf.placeholder(tf.float32, shape=(None, 764))
y_ = tf.placeholder(tf.float32, shape=(None, 10))


# 直接使用TensorFlow中提供的Keras API定义网络层结构。
net = tf.keras.layers.Dense(500, activate='relu')(x)
y = tf.keras.layers.Dense(10, activation='softmax')(net)

# 定义损失函数和优化方法。注意这里可以混用Keras的API和原生态TensorFlow的API。
loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_, y))
train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)

# 定义正确的预测率作为指标。
acc_value = tf.reduce_mean(tf.keras.metric.categorical_accuracy(y_, y))

# 使用原生态TensorFlow的方式训练模型。这样就可以有效的实现分布式。
with tf.Session() as sess:
   tf.global_variables_initializer().run()
   for i in range(10000):
       xs, ys = mnist_data.train.next_batch(100)
       _, loss_value = sess.run([train_step, loss], feed_dict={x:xs, y_:ys})
       
       if i % 1000 == 0:
          print("After %d training step(s), loss on training batch is " "%g." % (i,  loss_value))
   print acc_value.eval(feed_dict={x:mnist_data.test.images, y_: mnist_data.test.labels})</code></pre> 
<h4>3、Keras的主要模块、类和函数</h4> 
<p id="modules"><strong>Modules</strong></p> 
<ul><li><a href="https://tensorflow.google.cn/api_docs/python/tf/keras/activations" rel="nofollow" title="activations">activations</a> module: Built-in activation functions.</li><li><a href="https://tensorflow.google.cn/api_docs/python/tf/keras/applications" rel="nofollow" title="applications">applications</a> module: Keras Applications are canned architectures with pre-trained weights.</li><li><a href="https://tensorflow.google.cn/api_docs/python/tf/keras/backend" rel="nofollow" title="backend">backend</a> module: Keras backend API.</li><li><a href="https://tensorflow.google.cn/api_docs/python/tf/keras/callbacks" rel="nofollow" title="callbacks">callbacks</a> module: Callbacks: utilities called at certain points during model training.</li><li><a href="https://tensorflow.google.cn/api_docs/python/tf/keras/constraints" rel="nofollow" title="constraints">constraints</a> module: Constraints: functions that impose constraints on weight values.</li><li><a href="https://tensorflow.google.cn/api_docs/python/tf/keras/datasets" rel="nofollow" title="datasets">datasets</a> module: Keras built-in datasets.</li><li><a href="https://tensorflow.google.cn/api_docs/python/tf/keras/estimator" rel="nofollow" title="estimator">estimator</a> module: Keras estimator API.</li><li><a href="https://tensorflow.google.cn/api_docs/python/tf/keras/experimental" rel="nofollow" title="experimental">experimental</a> module: Public API for tf.keras.experimental namespace.</li><li><a href="https://tensorflow.google.cn/api_docs/python/tf/keras/initializers" rel="nofollow" title="initializers">initializers</a> module: Keras initializer serialization / deserialization.</li><li><a href="https://tensorflow.google.cn/api_docs/python/tf/keras/layers" rel="nofollow" title="layers">layers</a> module: Keras layers API.</li><li><a href="https://tensorflow.google.cn/api_docs/python/tf/keras/losses" rel="nofollow" title="losses">losses</a> module: Built-in loss functions.</li><li><a href="https://tensorflow.google.cn/api_docs/python/tf/keras/metrics" rel="nofollow" title="metrics">metrics</a> module: Built-in metrics.</li><li><a href="https://tensorflow.google.cn/api_docs/python/tf/keras/mixed_precision" rel="nofollow" title="mixed_precision">mixed_precision</a> module: Public API for tf.keras.mixed_precision namespace.</li><li><a href="https://tensorflow.google.cn/api_docs/python/tf/keras/models" rel="nofollow" title="models">models</a> module: Code for model cloning, plus model-related API entries.</li><li><a href="https://tensorflow.google.cn/api_docs/python/tf/keras/optimizers" rel="nofollow" title="optimizers">optimizers</a> module: Built-in optimizer classes.</li><li><a href="https://tensorflow.google.cn/api_docs/python/tf/keras/preprocessing" rel="nofollow" title="preprocessing">preprocessing</a> module: Keras data preprocessing utils.</li><li><a href="https://tensorflow.google.cn/api_docs/python/tf/keras/regularizers" rel="nofollow" title="regularizers">regularizers</a> module: Built-in regularizers.</li><li><a href="https://tensorflow.google.cn/api_docs/python/tf/keras/utils" rel="nofollow" title="utils">utils</a> module: Keras utilities.</li><li><a href="https://tensorflow.google.cn/api_docs/python/tf/keras/wrappers" rel="nofollow" title="wrappers">wrappers</a> module: Wrappers for Keras models, providing compatibility with other frameworks.</li></ul> 
<p id="classes"><strong>Classes</strong></p> 
<ul><li><a href="https://tensorflow.google.cn/api_docs/python/tf/keras/Model" rel="nofollow" title="class Model">class Model</a>: <code>Model</code> groups layers into an object with training and inference features.</li><li><a href="https://tensorflow.google.cn/api_docs/python/tf/keras/Sequential" rel="nofollow" title="class Sequential">class Sequential</a>: Linear stack of layers.</li></ul> 
<p id="functions"><strong>Functions</strong></p> 
<ul><li><a href="https://tensorflow.google.cn/api_docs/python/tf/keras/Input" rel="nofollow" title="Input(...)">Input(...)</a>: <code>Input()</code> is used to instantiate a Keras tensor.</li></ul>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/c218cdfb1d959c40222c850c3b9b5565/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">python 合并列表中有相同元素的列表</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/1fcc1a6d4ef4922bb75841da42533ff9/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">服务器频繁重启怎么解决</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程爱好者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151260"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>