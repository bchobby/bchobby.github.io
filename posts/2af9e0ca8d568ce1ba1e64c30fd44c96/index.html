<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Spark Streaming保存数据到HBase - 编程爱好者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Spark Streaming保存数据到HBase" />
<meta property="og:description" content="本文主要讨论Spark Streaming保存计算结果数据到HBase的实现方案，包括Kerberos认证。
Spark版本：2.11-2.4.0-cdh6.3.2。
HBase版本：2.1.0-cdh6.3.2。
Spark保存数据到HBase，有两种方案：
方案一：使用HBase Client。方案二：使用Spark API。 每个方案有两种写法，一共四种写法，下面以一个示例进行说明，然后对主要部分进行拆解说明。
完整示例 示例场景：Spark Streaming消费Kafka，计算wordcount，将计算结果保存到HBase。计算结果的key作为rowkey的值，value作为cf:col的值。
示例完整代码：
package com.example.spark; import org.apache.hadoop.hbase.client.*; import org.apache.hadoop.hbase.io.ImmutableBytesWritable; import org.apache.hadoop.hbase.mapred.TableOutputFormat; import org.apache.hadoop.hbase.util.Bytes; import org.apache.hadoop.mapred.JobConf; import org.apache.hadoop.security.UserGroupInformation; import org.apache.kafka.clients.consumer.ConsumerConfig; import org.apache.kafka.clients.consumer.ConsumerRecord; import org.apache.kafka.common.serialization.StringDeserializer; import org.apache.spark.SparkConf; import org.apache.spark.SparkFiles; import org.apache.spark.api.java.JavaPairRDD; import org.apache.spark.streaming.Durations; import org.apache.spark.streaming.api.java.JavaDStream; import org.apache.spark.streaming.api.java.JavaInputDStream; import org.apache.spark.streaming.api.java.JavaPairDStream; import org.apache.spark.streaming.api.java.JavaStreamingContext; import org.apache.spark.streaming.kafka010.*; import org.apache.hadoop.conf.Configuration; import org.apache.hadoop.fs.Path; import org.apache.hadoop.hbase.HBaseConfiguration; import org.apache.hadoop.hbase.TableName; import scala.Tuple2; import java.io.IOException; import java.util.*; import java.util.regex.Pattern; /** * Consumes messages from one or more topics in Kafka and does wordcount, then save to HBase." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bchobby.github.io/posts/2af9e0ca8d568ce1ba1e64c30fd44c96/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-09-17T18:25:28+08:00" />
<meta property="article:modified_time" content="2020-09-17T18:25:28+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程爱好者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程爱好者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Spark Streaming保存数据到HBase</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>本文主要讨论Spark Streaming保存计算结果数据到HBase的实现方案，包括Kerberos认证。</p> 
<p>Spark版本：2.11-2.4.0-cdh6.3.2。</p> 
<p>HBase版本：2.1.0-cdh6.3.2。</p> 
<p>Spark保存数据到HBase，有两种方案：</p> 
<ul><li>方案一：使用HBase Client。</li><li>方案二：使用Spark API。</li></ul> 
<p>每个方案有两种写法，一共四种写法，下面以一个示例进行说明，然后对主要部分进行拆解说明。</p> 
<h2><a id="_13"></a>完整示例</h2> 
<p>示例场景：Spark Streaming消费Kafka，计算wordcount，将计算结果保存到HBase。计算结果的key作为<code>rowkey</code>的值，value作为<code>cf:col</code>的值。</p> 
<p>示例完整代码：</p> 
<pre><code class="prism language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>example<span class="token punctuation">.</span>spark<span class="token punctuation">;</span>

<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>client<span class="token punctuation">.</span>*<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>io<span class="token punctuation">.</span>ImmutableBytesWritable<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>mapred<span class="token punctuation">.</span>TableOutputFormat<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Bytes<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapred<span class="token punctuation">.</span>JobConf<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>security<span class="token punctuation">.</span>UserGroupInformation<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span>ConsumerConfig<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span>ConsumerRecord<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span>StringDeserializer<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>SparkConf<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>SparkFiles<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span>JavaPairRDD<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>Durations<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span>JavaDStream<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span>JavaInputDStream<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span>JavaPairDStream<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span>JavaStreamingContext<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>kafka010<span class="token punctuation">.</span>*<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>HBaseConfiguration<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>TableName<span class="token punctuation">;</span>
<span class="token keyword">import</span> scala<span class="token punctuation">.</span>Tuple2<span class="token punctuation">;</span>

<span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span>
<span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>*<span class="token punctuation">;</span>
<span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>regex<span class="token punctuation">.</span>Pattern<span class="token punctuation">;</span>

<span class="token comment">/**
 * Consumes messages from one or more topics in Kafka and does wordcount, then save to HBase.
 * Usage: Kafka2Spark2HBase &lt;brokers&gt; &lt;groupId&gt; &lt;topics&gt;
 *   &lt;brokers&gt; is a list of one or more Kafka brokers
 *   &lt;groupId&gt; is a consumer group name to consume from topics
 *   &lt;topics&gt; is a list of one or more kafka topics to consume from
 *
 * Example:
 * spark-submit \
 * 	--master yarn \
 * 	--principal xingweidong \
 * 	--keytab xingweidong.keytab \
 * 	--conf "spark.security.credentials.hbase.enabled=true" \
 * 	--class com.example.spark.Kafka2Spark2HBase \
 * 	devexample-1.0-SNAPSHOT.jar \
 * 	worker01.bigdata.zxxk.com:9092,worker02.bigdata.zxxk.com:9092 \
 * 	spark-streaming-consumer-group \
 * 	spark_streaming
 */</span>

<span class="token keyword">public</span> <span class="token keyword">final</span> <span class="token keyword">class</span> <span class="token class-name">Kafka2Spark2HBase</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> Pattern SPACE <span class="token operator">=</span> Pattern<span class="token punctuation">.</span><span class="token function">compile</span><span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token comment">/**
     * Spark Streaming消费Kafka。
     * @param jssc
     * @param brokers
     * @param groupId
     * @param topics
     * @return
     */</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> JavaInputDStream<span class="token operator">&lt;</span>ConsumerRecord<span class="token generics function"><span class="token punctuation">&lt;</span>String<span class="token punctuation">,</span> String<span class="token punctuation">&gt;</span></span><span class="token operator">&gt;</span> <span class="token function">directKafka</span><span class="token punctuation">(</span>JavaStreamingContext jssc<span class="token punctuation">,</span> String brokers<span class="token punctuation">,</span> String groupId<span class="token punctuation">,</span> String topics<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
        Set<span class="token generics function"><span class="token punctuation">&lt;</span>String<span class="token punctuation">&gt;</span></span> topicsSet <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">HashSet</span><span class="token operator">&lt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span>Arrays<span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span>topics<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        Map<span class="token generics function"><span class="token punctuation">&lt;</span>String<span class="token punctuation">,</span> Object<span class="token punctuation">&gt;</span></span> kafkaParams <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">HashMap</span><span class="token operator">&lt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        kafkaParams<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>ConsumerConfig<span class="token punctuation">.</span>BOOTSTRAP_SERVERS_CONFIG<span class="token punctuation">,</span> brokers<span class="token punctuation">)</span><span class="token punctuation">;</span>
        kafkaParams<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>ConsumerConfig<span class="token punctuation">.</span>GROUP_ID_CONFIG<span class="token punctuation">,</span> groupId<span class="token punctuation">)</span><span class="token punctuation">;</span>
        kafkaParams<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>ConsumerConfig<span class="token punctuation">.</span>KEY_DESERIALIZER_CLASS_CONFIG<span class="token punctuation">,</span> StringDeserializer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        kafkaParams<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>ConsumerConfig<span class="token punctuation">.</span>VALUE_DESERIALIZER_CLASS_CONFIG<span class="token punctuation">,</span> StringDeserializer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">// Create direct kafka stream with brokers and topics</span>
        JavaInputDStream<span class="token operator">&lt;</span>ConsumerRecord<span class="token generics function"><span class="token punctuation">&lt;</span>String<span class="token punctuation">,</span> String<span class="token punctuation">&gt;</span></span><span class="token operator">&gt;</span> inputDStream <span class="token operator">=</span> KafkaUtils<span class="token punctuation">.</span><span class="token function">createDirectStream</span><span class="token punctuation">(</span>
                jssc<span class="token punctuation">,</span>
                LocationStrategies<span class="token punctuation">.</span><span class="token function">PreferConsistent</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                ConsumerStrategies<span class="token punctuation">.</span><span class="token function">Subscribe</span><span class="token punctuation">(</span>topicsSet<span class="token punctuation">,</span> kafkaParams<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token keyword">return</span> inputDStream<span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    <span class="token comment">/**
     * 创建HBase配置实例，加载core-site.xml, hbase-site.xml等配置文件资源。
     * @param resources
     * @return
     */</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> Configuration <span class="token function">configWithResource</span><span class="token punctuation">(</span>List<span class="token generics function"><span class="token punctuation">&lt;</span>String<span class="token punctuation">&gt;</span></span> resources<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
        Configuration config <span class="token operator">=</span> HBaseConfiguration<span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">// 添加必要的配置文件 (hbase-site.xml, core-site.xml)</span>
        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> resources<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
            config<span class="token punctuation">.</span><span class="token function">addResource</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>resources<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>

        <span class="token keyword">return</span> config<span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    <span class="token comment">/**
     * 获取HBase Client连接，包括Kerberos认证。
     * @param resources
     * @param krb5Conf
     * @param principal
     * @param keytabFile
     * @return
     * @throws IOException
     */</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> Connection <span class="token function">getHBaseConn</span><span class="token punctuation">(</span>List<span class="token generics function"><span class="token punctuation">&lt;</span>String<span class="token punctuation">&gt;</span></span> resources<span class="token punctuation">,</span> String krb5Conf<span class="token punctuation">,</span> String principal<span class="token punctuation">,</span> String keytabFile<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException <span class="token punctuation">{<!-- --></span>
        Configuration config <span class="token operator">=</span> Kafka2Spark2HBase<span class="token punctuation">.</span><span class="token function">configWithResource</span><span class="token punctuation">(</span>resources<span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">// 进行Kerberos认证</span>
        <span class="token comment">// 设置java安全krb5.conf</span>
        System<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"java.security.krb5.conf"</span><span class="token punctuation">,</span> krb5Conf<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 设置用户主体(Principal)</span>
        config<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span><span class="token string">"kerberos.principal"</span> <span class="token punctuation">,</span> principal<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 使用用户keytab文件认证</span>
        config<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span><span class="token string">"keytab.file"</span> <span class="token punctuation">,</span> keytabFile<span class="token punctuation">)</span><span class="token punctuation">;</span>

        UserGroupInformation<span class="token punctuation">.</span><span class="token function">setConfiguration</span><span class="token punctuation">(</span>config<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">try</span> <span class="token punctuation">{<!-- --></span>
            <span class="token comment">// 登录</span>
            UserGroupInformation<span class="token punctuation">.</span><span class="token function">loginUserFromKeytab</span><span class="token punctuation">(</span>principal<span class="token punctuation">,</span> keytabFile<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">IOException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
            e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>

        <span class="token comment">// 创建连接</span>
        <span class="token keyword">return</span> ConnectionFactory<span class="token punctuation">.</span><span class="token function">createConnection</span><span class="token punctuation">(</span>config<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    <span class="token comment">/**
     * 使用HBase Client方式，每条数据连接一次HBase，写入数据。
     * @param rdd
     * @param resources
     * @param krb5Conf
     * @param principal
     * @param keytabFile
     * @param hbaseTableName
     */</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">saveToHBase11</span><span class="token punctuation">(</span>JavaPairRDD<span class="token generics function"><span class="token punctuation">&lt;</span>String<span class="token punctuation">,</span> Integer<span class="token punctuation">&gt;</span></span> rdd<span class="token punctuation">,</span> List<span class="token generics function"><span class="token punctuation">&lt;</span>String<span class="token punctuation">&gt;</span></span> resources<span class="token punctuation">,</span> String krb5Conf<span class="token punctuation">,</span> String principal<span class="token punctuation">,</span> String keytabFile<span class="token punctuation">,</span> String hbaseTableName<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
        rdd<span class="token punctuation">.</span><span class="token function">foreach</span><span class="token punctuation">(</span>line <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token punctuation">{<!-- --></span>
            Connection connection <span class="token operator">=</span> Kafka2Spark2HBase<span class="token punctuation">.</span><span class="token function">getHBaseConn</span><span class="token punctuation">(</span>resources<span class="token punctuation">,</span> krb5Conf<span class="token punctuation">,</span> principal<span class="token punctuation">,</span> keytabFile<span class="token punctuation">)</span><span class="token punctuation">;</span>
            Table table <span class="token operator">=</span> connection<span class="token punctuation">.</span><span class="token function">getTable</span><span class="token punctuation">(</span>TableName<span class="token punctuation">.</span><span class="token function">valueOf</span><span class="token punctuation">(</span>hbaseTableName<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

            <span class="token keyword">try</span> <span class="token punctuation">{<!-- --></span>
                Put put <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Put</span><span class="token punctuation">(</span>Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span>line<span class="token punctuation">.</span>_1<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                put<span class="token punctuation">.</span><span class="token function">addColumn</span><span class="token punctuation">(</span>Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span><span class="token string">"cf"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span><span class="token string">"col"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span>line<span class="token punctuation">.</span>_2<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                table<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>put<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span> <span class="token keyword">finally</span> <span class="token punctuation">{<!-- --></span>
                table<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                connection<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    <span class="token comment">/**
     * 使用HBase Client方式，每个分区连接一次HBase，写入数据。
     * @param rdd
     * @param resources
     * @param krb5Conf
     * @param principal
     * @param keytabFile
     * @param hbaseTableName
     */</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">saveToHBase12</span><span class="token punctuation">(</span>JavaPairRDD<span class="token generics function"><span class="token punctuation">&lt;</span>String<span class="token punctuation">,</span> Integer<span class="token punctuation">&gt;</span></span> rdd<span class="token punctuation">,</span> List<span class="token generics function"><span class="token punctuation">&lt;</span>String<span class="token punctuation">&gt;</span></span> resources<span class="token punctuation">,</span> String krb5Conf<span class="token punctuation">,</span> String principal<span class="token punctuation">,</span> String keytabFile<span class="token punctuation">,</span> String hbaseTableName<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
        rdd<span class="token punctuation">.</span><span class="token function">foreachPartition</span><span class="token punctuation">(</span>partitionOfRecords <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token punctuation">{<!-- --></span>
            Connection connection <span class="token operator">=</span> Kafka2Spark2HBase<span class="token punctuation">.</span><span class="token function">getHBaseConn</span><span class="token punctuation">(</span>resources<span class="token punctuation">,</span> krb5Conf<span class="token punctuation">,</span> principal<span class="token punctuation">,</span> keytabFile<span class="token punctuation">)</span><span class="token punctuation">;</span>
            Table table <span class="token operator">=</span> connection<span class="token punctuation">.</span><span class="token function">getTable</span><span class="token punctuation">(</span>TableName<span class="token punctuation">.</span><span class="token function">valueOf</span><span class="token punctuation">(</span>hbaseTableName<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

            <span class="token keyword">try</span> <span class="token punctuation">{<!-- --></span>
                <span class="token keyword">while</span> <span class="token punctuation">(</span>partitionOfRecords<span class="token punctuation">.</span><span class="token function">hasNext</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
                    Tuple2<span class="token generics function"><span class="token punctuation">&lt;</span>String<span class="token punctuation">,</span> Integer<span class="token punctuation">&gt;</span></span> line <span class="token operator">=</span> partitionOfRecords<span class="token punctuation">.</span><span class="token function">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    Put put <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Put</span><span class="token punctuation">(</span>Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span>line<span class="token punctuation">.</span>_1<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    put<span class="token punctuation">.</span><span class="token function">addColumn</span><span class="token punctuation">(</span>Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span><span class="token string">"cf"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span><span class="token string">"col"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span>line<span class="token punctuation">.</span>_2<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    table<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>put<span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token punctuation">}</span>
            <span class="token punctuation">}</span> <span class="token keyword">finally</span> <span class="token punctuation">{<!-- --></span>
                table<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                connection<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    <span class="token comment">/**
     * 使用Spark JavaPairRDD saveAsHadoopDataset 方法。
     * @param rdd
     * @param resources
     * @param hbaseTableName
     */</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">saveToHBase21</span><span class="token punctuation">(</span>JavaPairRDD<span class="token generics function"><span class="token punctuation">&lt;</span>String<span class="token punctuation">,</span> Integer<span class="token punctuation">&gt;</span></span> rdd<span class="token punctuation">,</span> List<span class="token generics function"><span class="token punctuation">&lt;</span>String<span class="token punctuation">&gt;</span></span> resources<span class="token punctuation">,</span> String hbaseTableName<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
        Configuration config <span class="token operator">=</span> Kafka2Spark2HBase<span class="token punctuation">.</span><span class="token function">configWithResource</span><span class="token punctuation">(</span>resources<span class="token punctuation">)</span><span class="token punctuation">;</span>

        JobConf jobConfig <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">JobConf</span><span class="token punctuation">(</span>config<span class="token punctuation">)</span><span class="token punctuation">;</span>
        jobConfig<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>TableOutputFormat<span class="token punctuation">.</span>OUTPUT_TABLE<span class="token punctuation">,</span> hbaseTableName<span class="token punctuation">)</span><span class="token punctuation">;</span>
        jobConfig<span class="token punctuation">.</span><span class="token function">setOutputFormat</span><span class="token punctuation">(</span>TableOutputFormat<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        JavaPairRDD<span class="token generics function"><span class="token punctuation">&lt;</span>ImmutableBytesWritable<span class="token punctuation">,</span> Put<span class="token punctuation">&gt;</span></span> hbasePuts <span class="token operator">=</span> rdd<span class="token punctuation">.</span><span class="token function">mapToPair</span><span class="token punctuation">(</span>line <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token punctuation">{<!-- --></span>
            Put put <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Put</span><span class="token punctuation">(</span>Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span>line<span class="token punctuation">.</span>_1<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            put<span class="token punctuation">.</span><span class="token function">addColumn</span><span class="token punctuation">(</span>Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span><span class="token string">"cf"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span><span class="token string">"col"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span>line<span class="token punctuation">.</span>_2<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">Tuple2</span><span class="token operator">&lt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">ImmutableBytesWritable</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> put<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        hbasePuts<span class="token punctuation">.</span><span class="token function">saveAsHadoopDataset</span><span class="token punctuation">(</span>jobConfig<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    <span class="token comment">/**
     * 使用Spark JavaPairRDD saveAsNewAPIHadoopDataset 方法。
     * @param rdd
     * @param resources
     * @param hbaseTableName
     */</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">saveToHBase22</span><span class="token punctuation">(</span>JavaPairRDD<span class="token generics function"><span class="token punctuation">&lt;</span>String<span class="token punctuation">,</span> Integer<span class="token punctuation">&gt;</span></span> rdd<span class="token punctuation">,</span> List<span class="token generics function"><span class="token punctuation">&lt;</span>String<span class="token punctuation">&gt;</span></span> resources<span class="token punctuation">,</span> String hbaseTableName<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
        Configuration config <span class="token operator">=</span> Kafka2Spark2HBase<span class="token punctuation">.</span><span class="token function">configWithResource</span><span class="token punctuation">(</span>resources<span class="token punctuation">)</span><span class="token punctuation">;</span>
        config<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span><span class="token string">"hbase.mapred.outputtable"</span><span class="token punctuation">,</span> hbaseTableName<span class="token punctuation">)</span><span class="token punctuation">;</span>
        config<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span><span class="token string">"mapreduce.job.outputformat.class"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.hadoop.hbase.mapreduce.TableOutputFormat"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        JavaPairRDD<span class="token generics function"><span class="token punctuation">&lt;</span>ImmutableBytesWritable<span class="token punctuation">,</span> Put<span class="token punctuation">&gt;</span></span> hbasePuts <span class="token operator">=</span> rdd<span class="token punctuation">.</span><span class="token function">mapToPair</span><span class="token punctuation">(</span>line <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token punctuation">{<!-- --></span>
            Put put <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Put</span><span class="token punctuation">(</span>Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span>line<span class="token punctuation">.</span>_1<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            put<span class="token punctuation">.</span><span class="token function">addColumn</span><span class="token punctuation">(</span>Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span><span class="token string">"cf"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span><span class="token string">"col"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span>line<span class="token punctuation">.</span>_2<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">Tuple2</span><span class="token operator">&lt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">ImmutableBytesWritable</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> put<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        hbasePuts<span class="token punctuation">.</span><span class="token function">saveAsNewAPIHadoopDataset</span><span class="token punctuation">(</span>config<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{<!-- --></span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>args<span class="token punctuation">.</span>length <span class="token operator">&lt;</span> <span class="token number">3</span><span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
            System<span class="token punctuation">.</span>err<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"Usage: Kafka2Spark2HBase &lt;brokers&gt; &lt;groupId&gt; &lt;topics&gt;\n"</span> <span class="token operator">+</span>
                    <span class="token string">"  &lt;brokers&gt; is a list of one or more Kafka brokers\n"</span> <span class="token operator">+</span>
                    <span class="token string">"  &lt;groupId&gt; is a consumer group name to consume from topics\n"</span> <span class="token operator">+</span>
                    <span class="token string">"  &lt;topics&gt; is a list of one or more kafka topics to consume from\n\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            System<span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>

        String brokers <span class="token operator">=</span> args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
        String groupId <span class="token operator">=</span> args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
        String topics <span class="token operator">=</span> args<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">;</span>

        <span class="token comment">// Create context with a 2 seconds batch interval</span>
        SparkConf sparkConf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SparkConf</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setAppName</span><span class="token punctuation">(</span><span class="token string">"Kafka2Spark2HBase"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        JavaStreamingContext jssc <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">JavaStreamingContext</span><span class="token punctuation">(</span>sparkConf<span class="token punctuation">,</span> Durations<span class="token punctuation">.</span><span class="token function">seconds</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        List<span class="token generics function"><span class="token punctuation">&lt;</span>String<span class="token punctuation">&gt;</span></span> resources <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token generics function"><span class="token punctuation">&lt;</span>String<span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
            <span class="token punctuation">{<!-- --></span>
                <span class="token function">add</span><span class="token punctuation">(</span><span class="token string">"/etc/hbase/conf/core-site.xml"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token function">add</span><span class="token punctuation">(</span><span class="token string">"/etc/hbase/conf/hbase-site.xml"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token function">add</span><span class="token punctuation">(</span><span class="token string">"/etc/hbase/conf/hdfs-site.xml"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span><span class="token punctuation">;</span>

        <span class="token comment">// Kerberos认证需要的配置</span>
        String krb5Conf <span class="token operator">=</span> <span class="token string">"/etc/krb5.conf"</span><span class="token punctuation">;</span>
        String principal <span class="token operator">=</span> <span class="token string">"xingweidong@BIGDATA.ZXXK.COM"</span><span class="token punctuation">;</span>
        String keytabFile <span class="token operator">=</span> SparkFiles<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"xingweidong.keytab"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// SparkFiles操作要放到SparkContext之后，否则会报空指针异常</span>
        <span class="token comment">// HBase表名</span>
        String hbaseTableName <span class="token operator">=</span> <span class="token string">"test:test"</span><span class="token punctuation">;</span>

        <span class="token comment">// 消费kafka</span>
        JavaInputDStream<span class="token operator">&lt;</span>ConsumerRecord<span class="token generics function"><span class="token punctuation">&lt;</span>String<span class="token punctuation">,</span> String<span class="token punctuation">&gt;</span></span><span class="token operator">&gt;</span> inputDStream <span class="token operator">=</span> Kafka2Spark2HBase<span class="token punctuation">.</span><span class="token function">directKafka</span><span class="token punctuation">(</span>jssc<span class="token punctuation">,</span> brokers<span class="token punctuation">,</span> groupId<span class="token punctuation">,</span> topics<span class="token punctuation">)</span><span class="token punctuation">;</span>
        JavaDStream<span class="token generics function"><span class="token punctuation">&lt;</span>String<span class="token punctuation">&gt;</span></span> dStream <span class="token operator">=</span> inputDStream<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>ConsumerRecord<span class="token operator">:</span><span class="token operator">:</span>value<span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">// word count</span>
        JavaDStream<span class="token generics function"><span class="token punctuation">&lt;</span>String<span class="token punctuation">&gt;</span></span> words <span class="token operator">=</span> dStream<span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span>x <span class="token operator">-</span><span class="token operator">&gt;</span> Arrays<span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span>SPACE<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">iterator</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        JavaPairDStream<span class="token generics function"><span class="token punctuation">&lt;</span>String<span class="token punctuation">,</span> Integer<span class="token punctuation">&gt;</span></span> wordCounts <span class="token operator">=</span> words<span class="token punctuation">.</span><span class="token function">mapToPair</span><span class="token punctuation">(</span>s <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token keyword">new</span> <span class="token class-name">Tuple2</span><span class="token operator">&lt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span>s<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">reduceByKey</span><span class="token punctuation">(</span><span class="token punctuation">(</span>i1<span class="token punctuation">,</span> i2<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> i1 <span class="token operator">+</span> i2<span class="token punctuation">)</span><span class="token punctuation">;</span>

        wordCounts<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">// 去除key为空字符串的数据，否则存入HBase时会报错。</span>
        JavaPairDStream<span class="token generics function"><span class="token punctuation">&lt;</span>String<span class="token punctuation">,</span> Integer<span class="token punctuation">&gt;</span></span> wordCountsWithNotNull <span class="token operator">=</span> wordCounts<span class="token punctuation">.</span><span class="token function">filter</span><span class="token punctuation">(</span>line <span class="token operator">-</span><span class="token operator">&gt;</span> line<span class="token punctuation">.</span>_1<span class="token punctuation">.</span><span class="token function">length</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">// 存入HBase</span>
        wordCountsWithNotNull<span class="token punctuation">.</span><span class="token function">foreachRDD</span><span class="token punctuation">(</span>rdd <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token punctuation">{<!-- --></span>
<span class="token comment">//            Kafka2Spark2HBase.saveToHBase11(rdd, resources, krb5Conf, principal, keytabFile, hbaseTableName);</span>
<span class="token comment">//            Kafka2Spark2HBase.saveToHBase12(rdd, resources, krb5Conf, principal, keytabFile, hbaseTableName);</span>
<span class="token comment">//            Kafka2Spark2HBase.saveToHBase21(rdd, resources, hbaseTableName);</span>
            Kafka2Spark2HBase<span class="token punctuation">.</span><span class="token function">saveToHBase22</span><span class="token punctuation">(</span>rdd<span class="token punctuation">,</span> resources<span class="token punctuation">,</span> hbaseTableName<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">// Start the computation</span>
        jssc<span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        jssc<span class="token punctuation">.</span><span class="token function">awaitTermination</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

</code></pre> 
<p>上述示例中，需要注意的地方主要包括以下几个部分：</p> 
<ul><li> <p>HBase Client连接。</p> </li><li> <p>任务提交。</p> </li><li> <p>主函数。</p> </li><li> <p>Spark保存数据到HBase方案一。包括<code>saveToHBase11</code>和<code>saveToHBase12</code>两种方式。</p> </li><li> <p>Spark保存数据到HBase方案二。包括<code>saveToHBase21</code>和<code>saveToHBase22</code>两种方式。</p> </li></ul> 
<p>接下来按照顺序对这几部分进行详细描述。</p> 
<h2><a id="HBase_Client_315"></a>HBase Client连接</h2> 
<p>示例代码中有一部分是Java通过HBase Client连接HBase的逻辑，这里不作过多介绍，详情请参考 <a href="https://blog.csdn.net/xwd127429/article/details/108225877">Java连接HBase(含Kerberos)</a>。</p> 
<h2><a id="_321"></a>任务提交方式说明</h2> 
<p>本节主要描述与本文主题相关的spark-submit提交任务的注意事项。Spark master为YARN。</p> 
<p>这里假设程序的jar包名为<code>devexample-1.0-SNAPSHOT.jar</code>，程序参数值如下：</p> 
<table><thead><tr><th>参数</th><th>值</th></tr></thead><tbody><tr><td>brokers</td><td><code>worker01.bigdata.zxxk.com:9092,worker02.bigdata.zxxk.com:9092</code></td></tr><tr><td>groupId</td><td><code>spark-streaming-consumer-group</code></td></tr><tr><td>topics</td><td>spark_streaming</td></tr></tbody></table> 
<h3><a id="SparkHBase_333"></a>Spark用户和HBase用户一致</h3> 
<p>提交命令：</p> 
<pre><code class="prism language-shell">spark-submit \
	--master yarn \
	--principal xingweidong \
	--keytab xingweidong.keytab \
	--conf <span class="token string">"spark.security.credentials.hbase.enabled=true"</span> \
	--class com.example.spark.Kafka2Spark2HBase \
	devexample-1.0-SNAPSHOT.jar \
	worker01.bigdata.zxxk.com:9092,worker02.bigdata.zxxk.com:9092 \
	spark-streaming-consumer-group \
	spark_streaming
</code></pre> 
<p>主要选项说明</p> 
<table><thead><tr><th>选项</th><th>说明</th></tr></thead><tbody><tr><td>–principal</td><td>只对YARN有用。用户主体，用于Kerberos认证。</td></tr><tr><td>–keytab</td><td>只对YARN有用。用户keytab，用于Kerberos认证。可以通过<code>SparkFiles.get(fileName)</code> 访问。</td></tr><tr><td>–conf “spark.security.credentials.hbase.enabled=true”</td><td>启用spark连接hbase的安全证书。如果设置为false，则无法连接到启用安全的hbase服务。在CDH中，这个配置默认为true，可以不在spark-submit指定配置。</td></tr></tbody></table> 
<h3><a id="SparkHBase_358"></a>Spark用户和HBase用户不一致</h3> 
<p>假设Spark任务用户主体是<code>xingweidong</code>，HBase用户主体是<code>hbase_xingweidong</code></p> 
<p>提交命令：</p> 
<pre><code class="prism language-shell">spark-submit \
	--master yarn \
	--principal xingweidong \
	--keytab xingweidong.keytab \
	--files hbase_xingweidong.keytab<span class="token comment">#hbaseuser.keytab \</span>
	--conf <span class="token string">"spark.security.credentials.hbase.enabled=true"</span> \
	--class com.example.spark.Kafka2Spark2HBase \
	devexample-1.0-SNAPSHOT.jar \
	worker01.bigdata.zxxk.com:9092,worker02.bigdata.zxxk.com:9092 \
	spark-streaming-consumer-group \
	spark_streaming \
	hbaseuser
</code></pre> 
<p>这里主要增加了<code>--files</code>选项，用于提交额外的资源文件，选项说明如下：</p> 
<blockquote> 
 <p>Comma-separated list of files to be placed in the working directory of each executor. File paths of these files in executors can be accessed via SparkFiles.get(fileName).</p> 
</blockquote> 
<p>使用<code>--files</code>选项添加的文件，可以通过<code>SparkFiles.get(fileName)</code>进行访问，另外<code>--files</code>选项支持别名，使用<code>#</code>标记别名，例如<code>hbase_xingweidong.keytab#hbaseuser.keytab</code>，<code>hbase_xingweidong.keytab</code>文件的别名是<code>hbaseuser.keytab</code>，如果使用了别名，那么<code>SparkFiles.get(fileName)</code>的<code>fileName</code>需要指定为别名。别名功能方便我们在应用中使用固定的文件名获取资源，而不需要依赖实际的文件名。</p> 
<h2><a id="Main_387"></a>Main函数主要部分说明</h2> 
<p>假设Spark用户和HBase用户一致。</p> 
<h3><a id="SparkFiles_391"></a>SparkFiles说明</h3> 
<p>代码片段：</p> 
<pre><code class="prism language-java">String keytabFile <span class="token operator">=</span> SparkFiles<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"xingweidong.keytab"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>这里使用SparkFiles获取keytab文件，用于HBase客户端认证。SparkFiles操作要放到SparkContext之后，否则会报空指针异常。</p> 
<h3><a id="_401"></a>结果数据处理</h3> 
<p>代码片段：</p> 
<pre><code class="prism language-java"><span class="token comment">// 去除key为空字符串的数据，否则存入HBase时会报错。</span>
JavaPairDStream<span class="token generics function"><span class="token punctuation">&lt;</span>String<span class="token punctuation">,</span> Integer<span class="token punctuation">&gt;</span></span> wordCountsWithNotNull <span class="token operator">=</span> wordCounts<span class="token punctuation">.</span><span class="token function">filter</span><span class="token punctuation">(</span>line <span class="token operator">-</span><span class="token operator">&gt;</span> line<span class="token punctuation">.</span>_1<span class="token punctuation">.</span><span class="token function">length</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>这里针对HBase的数据要求做了一些处理，在本文的示例，结果数据是(word, count)的&lt;k, v&gt;结构，其中word作为HBase的rowkey存储，因为HBase的rowkey要求是非空字符串，所以需要对结果数据集进行过滤。</p> 
<p>在实际的应用中，可能需要更多的处理。</p> 
<h3><a id="HBase_414"></a>保存到HBase</h3> 
<p>代码片段：</p> 
<pre><code class="prism language-java"><span class="token comment">// 存入HBase</span>
wordCountsWithNotNull<span class="token punctuation">.</span><span class="token function">foreachRDD</span><span class="token punctuation">(</span>rdd <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token punctuation">{<!-- --></span>
    <span class="token comment">// Kafka2Spark2HBase.saveToHBase11(rdd, resources, krb5Conf, principal, keytabFile, hbaseTableName);</span>
    <span class="token comment">// Kafka2Spark2HBase.saveToHBase12(rdd, resources, krb5Conf, principal, keytabFile, hbaseTableName);</span>
    <span class="token comment">// Kafka2Spark2HBase.saveToHBase21(rdd, resources, hbaseTableName);</span>
    Kafka2Spark2HBase<span class="token punctuation">.</span><span class="token function">saveToHBase22</span><span class="token punctuation">(</span>rdd<span class="token punctuation">,</span> resources<span class="token punctuation">,</span> hbaseTableName<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>这里有两个重点，一个是<code>foreachRDD</code>，另一个是将rdd保存到HBase的方法。</p> 
<p><code>foreachRDD</code>是Spark Streaming通用的输出算子，用于将数据保存到文件、数据库等外部系统，Spark官方介绍如下：</p> 
<pre><code>The most generic output operator that applies a function, func, to each RDD generated from the stream. This function should push the data in each RDD to an external system, such as saving the RDD to files, or writing it over the network to a database. Note that the function func is executed in the driver process running the streaming application, and will usually have RDD actions in it that will force the computation of the streaming RDDs.
</code></pre> 
<p>将rdd保存到HBase的两种方案都是借助<code>foreachRDD</code>完成，接下来的内容就对这两种方案进行重点描述和分析。</p> 
<h2><a id="SparkHBase_440"></a>Spark保存数据到HBase方案一</h2> 
<p>该方案是参考自Spark官方文档 <a href="http://spark.apache.org/docs/2.4.0/streaming-programming-guide.html#design-patterns-for-using-foreachrdd" rel="nofollow">Design Patterns for using foreachRDD</a>。这个文档描述了如何使用<code>foreachRDD</code>将数据保存到外部系统的通用方式。</p> 
<p>我在此基础上结合了HBase Client连接，将数据保存到HBase。</p> 
<p>该方案有两种方法，在示例中分别是：</p> 
<ul><li>saveToHBase11</li><li>saveToHBase12 (推荐)</li></ul> 
<p>这两种方法都是参考自上面提到的Spark官方文档。性能上，saveToHBase12这种方法会好一些，具体可以分析代码和参考上面提到的Spark官方文档。</p> 
<h3><a id="saveToHBase11_453"></a>saveToHBase11</h3> 
<p>代码：</p> 
<pre><code class="prism language-java"><span class="token comment">/**
 * 使用HBase Client方式，每条数据连接一次HBase，写入数据。
 * @param rdd
 * @param resources
 * @param krb5Conf
 * @param principal
 * @param keytabFile
 * @param hbaseTableName
 */</span>
<span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">saveToHBase11</span><span class="token punctuation">(</span>JavaPairRDD<span class="token generics function"><span class="token punctuation">&lt;</span>String<span class="token punctuation">,</span> Integer<span class="token punctuation">&gt;</span></span> rdd<span class="token punctuation">,</span> List<span class="token generics function"><span class="token punctuation">&lt;</span>String<span class="token punctuation">&gt;</span></span> resources<span class="token punctuation">,</span> String krb5Conf<span class="token punctuation">,</span> String principal<span class="token punctuation">,</span> String keytabFile<span class="token punctuation">,</span> String hbaseTableName<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
    rdd<span class="token punctuation">.</span><span class="token function">foreach</span><span class="token punctuation">(</span>line <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token punctuation">{<!-- --></span>
        Connection connection <span class="token operator">=</span> Kafka2Spark2HBase<span class="token punctuation">.</span><span class="token function">getHBaseConn</span><span class="token punctuation">(</span>resources<span class="token punctuation">,</span> krb5Conf<span class="token punctuation">,</span> principal<span class="token punctuation">,</span> keytabFile<span class="token punctuation">)</span><span class="token punctuation">;</span>
        Table table <span class="token operator">=</span> connection<span class="token punctuation">.</span><span class="token function">getTable</span><span class="token punctuation">(</span>TableName<span class="token punctuation">.</span><span class="token function">valueOf</span><span class="token punctuation">(</span>hbaseTableName<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token keyword">try</span> <span class="token punctuation">{<!-- --></span>
            Put put <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Put</span><span class="token punctuation">(</span>Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span>line<span class="token punctuation">.</span>_1<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            put<span class="token punctuation">.</span><span class="token function">addColumn</span><span class="token punctuation">(</span>Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span><span class="token string">"cf"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span><span class="token string">"col"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span>line<span class="token punctuation">.</span>_2<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            table<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>put<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span> <span class="token keyword">finally</span> <span class="token punctuation">{<!-- --></span>
            table<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            connection<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>这个方法是通过rdd的<code>foreach</code>方法，每一行数据都需要单独创建HBase连接，将数据保存进HBase，然后关闭连接，需要频繁进行HBase连接的创建关闭。</p> 
<h3><a id="saveToHBase12_486"></a>saveToHBase12</h3> 
<p>代码：</p> 
<pre><code class="prism language-java"><span class="token comment">/**
 * 使用HBase Client方式，每个分区连接一次HBase，写入数据。
 * @param rdd
 * @param resources
 * @param krb5Conf
 * @param principal
 * @param keytabFile
 * @param hbaseTableName
 */</span>
<span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">saveToHBase12</span><span class="token punctuation">(</span>JavaPairRDD<span class="token generics function"><span class="token punctuation">&lt;</span>String<span class="token punctuation">,</span> Integer<span class="token punctuation">&gt;</span></span> rdd<span class="token punctuation">,</span> List<span class="token generics function"><span class="token punctuation">&lt;</span>String<span class="token punctuation">&gt;</span></span> resources<span class="token punctuation">,</span> String krb5Conf<span class="token punctuation">,</span> String principal<span class="token punctuation">,</span> String keytabFile<span class="token punctuation">,</span> String hbaseTableName<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
    rdd<span class="token punctuation">.</span><span class="token function">foreachPartition</span><span class="token punctuation">(</span>partitionOfRecords <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token punctuation">{<!-- --></span>
        Connection connection <span class="token operator">=</span> Kafka2Spark2HBase<span class="token punctuation">.</span><span class="token function">getHBaseConn</span><span class="token punctuation">(</span>resources<span class="token punctuation">,</span> krb5Conf<span class="token punctuation">,</span> principal<span class="token punctuation">,</span> keytabFile<span class="token punctuation">)</span><span class="token punctuation">;</span>
        Table table <span class="token operator">=</span> connection<span class="token punctuation">.</span><span class="token function">getTable</span><span class="token punctuation">(</span>TableName<span class="token punctuation">.</span><span class="token function">valueOf</span><span class="token punctuation">(</span>hbaseTableName<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token keyword">try</span> <span class="token punctuation">{<!-- --></span>
            <span class="token keyword">while</span> <span class="token punctuation">(</span>partitionOfRecords<span class="token punctuation">.</span><span class="token function">hasNext</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
                Tuple2<span class="token generics function"><span class="token punctuation">&lt;</span>String<span class="token punctuation">,</span> Integer<span class="token punctuation">&gt;</span></span> line <span class="token operator">=</span> partitionOfRecords<span class="token punctuation">.</span><span class="token function">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                Put put <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Put</span><span class="token punctuation">(</span>Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span>line<span class="token punctuation">.</span>_1<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                put<span class="token punctuation">.</span><span class="token function">addColumn</span><span class="token punctuation">(</span>Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span><span class="token string">"cf"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span><span class="token string">"col"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span>line<span class="token punctuation">.</span>_2<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                table<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>put<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span> <span class="token keyword">finally</span> <span class="token punctuation">{<!-- --></span>
            table<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            connection<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>这个方法是通过rdd的<code>foreachPartition</code>方法，每一个分区都需要单独创建HBase连接，将数据保存进HBase，然后关闭连接。</p> 
<p>相比于saveToHBase11的方法，理论上，saveToHBase12创建HBase连接的次数会更少。</p> 
<h2><a id="SparkHBase_526"></a>Spark保存数据到HBase方案二</h2> 
<p>该方案同样是参考自Spark官方文档 <a href="http://spark.apache.org/docs/2.4.0/streaming-programming-guide.html#design-patterns-for-using-foreachrdd" rel="nofollow">Design Patterns for using foreachRDD</a>。</p> 
<p>我在此基础上使用了Spark提供的算子，将数据保存到HBase。</p> 
<p>该方案有两种方法，在示例中分别是：</p> 
<ul><li>saveToHBase21</li><li>saveToHBase22 (推荐)</li></ul> 
<p><strong>该方案使用Spark任务的提交用户访问HBase，所以需要确保提交用户拥有必要的HBase相关表的操作权限。</strong></p> 
<h3><a id="_541"></a>前置知识</h3> 
<p>在介绍这两种方法之前，需要先补充一下Hadoop MapReduce的一些知识。</p> 
<p>Hadoop MapReduce分为两套API，分别是：</p> 
<ul><li>mapred</li><li>mapreduce</li></ul> 
<p>其中mapreduce相对于mapred较新，一般称为新API。</p> 
<p>在Hadoop生态中，大部分服务都对接了这两套API，比如本文涉及到的HBase和Spark。</p> 
<p>在HBase中，对应关系如下：</p> 
<table><thead><tr><th>MapReduce API</th><th>HBase API</th></tr></thead><tbody><tr><td>mapred</td><td>org.apache.hadoop.hbase.mapred.*</td></tr><tr><td>mapreduce</td><td>org.apache.hadoop.hbase.mapreduce.*</td></tr></tbody></table> 
<p>在Spark中，本文用到的两个算子的对应关系：</p> 
<table><thead><tr><th>MapReduce API</th><th>Spark API</th></tr></thead><tbody><tr><td>mapred</td><td>saveAsHadoopDataset</td></tr><tr><td>mapreduce</td><td>saveAsNewAPIHadoopDataset</td></tr></tbody></table> 
<p>其中saveToHBase21方式使用Spark的<code>saveAsHadoopDataset</code>算子，saveToHBase22方式使用Spark的<code>saveAsNewAPIHadoopDataset</code>算子。</p> 
<p>在服务的衔接上，需要使用配套的API。</p> 
<h3><a id="saveToHBase21_574"></a>saveToHBase21</h3> 
<p>代码：</p> 
<pre><code class="prism language-java"><span class="token comment">/**
 * 使用Spark JavaPairRDD saveAsHadoopDataset 方法。
 * @param rdd
 * @param resources
 * @param hbaseTableName
 */</span>
<span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">saveToHBase21</span><span class="token punctuation">(</span>JavaPairRDD<span class="token generics function"><span class="token punctuation">&lt;</span>String<span class="token punctuation">,</span> Integer<span class="token punctuation">&gt;</span></span> rdd<span class="token punctuation">,</span> List<span class="token generics function"><span class="token punctuation">&lt;</span>String<span class="token punctuation">&gt;</span></span> resources<span class="token punctuation">,</span> String hbaseTableName<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
    Configuration config <span class="token operator">=</span> Kafka2Spark2HBase<span class="token punctuation">.</span><span class="token function">configWithResource</span><span class="token punctuation">(</span>resources<span class="token punctuation">)</span><span class="token punctuation">;</span>

    JobConf jobConfig <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">JobConf</span><span class="token punctuation">(</span>config<span class="token punctuation">)</span><span class="token punctuation">;</span>
    jobConfig<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>TableOutputFormat<span class="token punctuation">.</span>OUTPUT_TABLE<span class="token punctuation">,</span> hbaseTableName<span class="token punctuation">)</span><span class="token punctuation">;</span>
    jobConfig<span class="token punctuation">.</span><span class="token function">setOutputFormat</span><span class="token punctuation">(</span>TableOutputFormat<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    JavaPairRDD<span class="token generics function"><span class="token punctuation">&lt;</span>ImmutableBytesWritable<span class="token punctuation">,</span> Put<span class="token punctuation">&gt;</span></span> hbasePuts <span class="token operator">=</span> rdd<span class="token punctuation">.</span><span class="token function">mapToPair</span><span class="token punctuation">(</span>line <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token punctuation">{<!-- --></span>
        Put put <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Put</span><span class="token punctuation">(</span>Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span>line<span class="token punctuation">.</span>_1<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        put<span class="token punctuation">.</span><span class="token function">addColumn</span><span class="token punctuation">(</span>Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span><span class="token string">"cf"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span><span class="token string">"col"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span>line<span class="token punctuation">.</span>_2<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">Tuple2</span><span class="token operator">&lt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">ImmutableBytesWritable</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> put<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    hbasePuts<span class="token punctuation">.</span><span class="token function">saveAsHadoopDataset</span><span class="token punctuation">(</span>jobConfig<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>该方法使用Spark的<code>saveAsHadoopDataset</code>算子，这个算子可以将RDD输出到任何Hadoop支持的系统。</p> 
<p>应用注意事项：</p> 
<ol><li>saveAsHadoopDataset参数类型是JobConf，所以需要将配置转换成JobConf。</li><li>JobConf需要设置OutputFormat，包括输出表名和输出格式。</li></ol> 
<p>其中<strong>TableOutputFormat</strong>的包路径是<strong>org.apache.hadoop.hbase.mapred.TableOutputFormat</strong>。</p> 
<h3><a id="saveToHBase22_612"></a>saveToHBase22</h3> 
<p>代码：</p> 
<pre><code class="prism language-java"><span class="token comment">/**
 * 使用Spark JavaPairRDD saveAsNewAPIHadoopDataset 方法。
 * @param rdd
 * @param resources
 * @param hbaseTableName
 */</span>
<span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">saveToHBase22</span><span class="token punctuation">(</span>JavaPairRDD<span class="token generics function"><span class="token punctuation">&lt;</span>String<span class="token punctuation">,</span> Integer<span class="token punctuation">&gt;</span></span> rdd<span class="token punctuation">,</span> List<span class="token generics function"><span class="token punctuation">&lt;</span>String<span class="token punctuation">&gt;</span></span> resources<span class="token punctuation">,</span> String hbaseTableName<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
    Configuration config <span class="token operator">=</span> Kafka2Spark2HBase<span class="token punctuation">.</span><span class="token function">configWithResource</span><span class="token punctuation">(</span>resources<span class="token punctuation">)</span><span class="token punctuation">;</span>
    config<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span><span class="token string">"hbase.mapred.outputtable"</span><span class="token punctuation">,</span> hbaseTableName<span class="token punctuation">)</span><span class="token punctuation">;</span>
    config<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span><span class="token string">"mapreduce.job.outputformat.class"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.hadoop.hbase.mapreduce.TableOutputFormat"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    JavaPairRDD<span class="token generics function"><span class="token punctuation">&lt;</span>ImmutableBytesWritable<span class="token punctuation">,</span> Put<span class="token punctuation">&gt;</span></span> hbasePuts <span class="token operator">=</span> rdd<span class="token punctuation">.</span><span class="token function">mapToPair</span><span class="token punctuation">(</span>line <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token punctuation">{<!-- --></span>
        Put put <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Put</span><span class="token punctuation">(</span>Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span>line<span class="token punctuation">.</span>_1<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        put<span class="token punctuation">.</span><span class="token function">addColumn</span><span class="token punctuation">(</span>Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span><span class="token string">"cf"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span><span class="token string">"col"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span>line<span class="token punctuation">.</span>_2<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">Tuple2</span><span class="token operator">&lt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">ImmutableBytesWritable</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> put<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    hbasePuts<span class="token punctuation">.</span><span class="token function">saveAsNewAPIHadoopDataset</span><span class="token punctuation">(</span>config<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>该方法使用Spark的<code>saveAsNewAPIHadoopDataset</code>算子，这个算子可以将RDD输出到任何Hadoop支持的系统。</p> 
<p>应用注意事项：</p> 
<ol><li>saveAsNewAPIHadoopDataset参数类型是Configuration，可以直接使用目标系统的配置。</li><li>Configuration需要设置OutputFormat，包括输出表名和输出格式。</li></ol> 
<p>这里的OutputFormat使用的是<strong>org.apache.hadoop.hbase.mapred.TableOutputFormat</strong>。</p> 
<h3><a id="_648"></a>拓展</h3> 
<p>关于saveAsNewAPIHadoopDataset和saveAsHadoopDataset的更多内容可以参考：</p> 
<p><a href="https://blog.csdn.net/xwd127429/article/details/108649941">saveAsHadoopDataset和saveAsNewAPIHadoopDataset源码分析及用法说明</a></p> 
<h2><a id="_658"></a>结束语</h2> 
<p>在本文描述的两个方案中，其中方案一比较通用，可以应多大部分情况，在处理连接池可以重用的外部系统时，可以进一步提高性能；方案二只适用于Hadoop支持的系统，使用比较方便。</p> 
<p>每个方案都有一个推荐的方法，在使用时可以优先选择。</p> 
<p>这里没有做具体的性能对比，不过针对于本文的示例场景，我觉得使用<code>saveAsNewAPIHadoopDataset</code>算子可能是更好的选择。</p> 
<p>在实际使用中，需要分析具体情况，来选择较合适的方法。</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/693bbf9d8c1b993c90c418cc50e3e5e2/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">stm移植W5500官方库遇到spi读取IP地址等信息错误</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/27a1241260f185dc157a775c9ad0dde7/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">allegro .brd文件转成AD .pcbdoc文件</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程爱好者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151260"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>