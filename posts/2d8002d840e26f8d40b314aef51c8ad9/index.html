<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>图神经网络 - 编程爱好者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="图神经网络" />
<meta property="og:description" content="目前，大多数图神经网络模型都有一个通用的架构。我将它们称为图卷积神经网络（GCNs），这些模型是可卷积的，因为滤波器参数在图中所有位置或者一个局部位置上（ Duvenaud et al., NIPS 2015）都可以共享。
对于这些模型，它们的目标是要学习图G=（V，E）上的信号或特征的一个映射。它们的输入包括：
每一个节点i的特征描述xi，可以写成一个N*D的特征矩阵（N表示节点数，D表示输入的特征数）矩阵形式的图结构的特征描述，通常是以邻接矩阵的形式（或者其他的形式） 模型会产生一个节点级别的输出Z（一个N*F的特征矩阵，其中F表示每一个节点的输出特征数）。图级别的输出可以通过引入一些池化操作来建模（Duvenaud等, NIPS 2015）。
每一个神经网络层可以写成这样一个非线性函数：
这里 ， （Z也可以作为图级别的输出），L是层数，这个模型主要在于f（）怎样选择以及参数化。
GCN第二部分：简单例子
作为示例，考虑下边这样一个简单的单层前向传播的形式：
这里，W是l层神经网络的参数矩阵，( ) 是非线性激活函数比如ReLU。这个模型尽管简单但是却非常有效（我们马上就会介绍）。
但是首先，让我们来看一下这个简单模型的两个限制：首先，和A相乘意味着对于每个节点，我们都整合了它的邻居节点的特征向量，但是却不包括这个节点本身（万一图中有自环存在）。我们可以通过在图中强行加入自环来解决这个问题，也就是给矩阵A加上一个单位阵。
第二个限制是A通常是非归一化的，因此和A相乘会完全改变特征向量的尺度（可以通过看A的特征值来理解）。归一化使A的各行和为1，比如，这里D是节点度的对角矩阵，这样就解决了这个问题。那么与相乘也就是对邻居节点的特征取平均。实际上，当我们使用对称归一化时，比如（这将不再仅仅是相邻节点的平均值），动力学会更加的有趣。
结合这两种技巧，我们基本上得到了[Kipf &amp; Welling (ICLR 2017)]文章中的传播规则：
这里，是单位阵，是矩阵的节点度对角矩阵。
GCN第三部分：空手道俱乐部网络的嵌入
空手道俱乐部图，颜色表示通过基于模块化的聚类获得的社团
现在让我们来看一下，上边简单的GCN模型是怎样在一些知名的数据集上表现得如何，比如Zachary的空手道俱乐部网络数据（见上图）。
我们使用一个三层GCN，随机初始化权重。在训练权重之前，我们将图的邻接矩阵和X=I（即单位阵，因为我们没有任何的节点特征）输入模型。这个3层的GCN在前向过程中做了三次传播并且有效的对每个节点的3阶邻居进行了卷积（所有的节点可达3阶）。值得注意的是，这个模型生成的这些节点的嵌入和图的社区结构非常类似（见下图）。还记得我们完全随机初始化的权重并且现在还没有进行任何的训练更新。
使用GCN（随机初始化权重）做空手道俱乐部网络中的节点嵌入
这似乎有点令人惊讶，最近一篇论文提出的DeepWalk模型 (Perozzi et al., KDD 2014)通过复杂的非监督的训练过程也可以学习到一个相似的嵌入。使用这个简单的未经训练的GCN模型几乎“免费”的获得了这样的嵌入，这怎么可能呢？
我们可以通过将GCN模型解释为网络图上的著名的Weisfeiler-Lehman（WL）算法的广义可微分版本来理解。1维的WL算法是这样的：
对图上的所有节点：得到邻居节点的特征根据更新节点特征，这里hush（）是一个一个单射散列函数迭代k次直到收敛 实际上，WL算法为大多数图分配一个独特的特征。也就是说每一个节点都被分配到一个可以唯一描述它在图中的角色的特征。例外是像网格（grid）、链（chain）等高度规则的图。对于大多数不规则的图，这个特征分配可以用来检验图同构（比如两个图是否相同，取决于节点的排列）。
回到我们图卷积层传播规则上（现在从向量角度来看）：这里j是邻居节点的索引，是边的正则化常量，来源于GCN模型中用到的对称正则化邻接矩阵。我们现在看到，这种传播规则可以解释为原始WL算法中使用的哈希函数的可微分和参数化（即）变体。如果我们现在选择一个合适的正交的非线性并且初始化随机的权重矩阵（比如，使用（Glorot &amp; Bengio, AISTATS 2010）的初始化方式），在实践中这个更新规则最后会稳定下来（归功于的正则化）。
经过观察，我们得到了非常有意义的平滑的嵌入，然后我们可以将嵌入后的距离解释为局部图结构的（不）相似性！
GCN第四部分：非监督学习
由于我们模型中所有的内容都是可微分的和参数化的，所以我们可以添加标签，训练模型并观察嵌入效果。我们可以使用Kipf &amp; Welling (ICLR 2017)文章中介绍的GCN的半监督学习算法。我们只需为每个节点标注类别或者社团（下面视频中突出显示的节点），然后开始进行多次迭代的训练。
用GCN进行半监督分类：300次训练迭代中隐空间的动态变化，每个类别有一个标签，带标签标的节点突出显示。
我们注意到，这个模型直接产生了一个二维的可以直接可视化的隐空间。我们观察到这个3层的的GCN模型尝试线性区分社团，每类社团给出一个标签。考虑到该模型并没有输入节点的特征描述，所以这个结果可以说是非常卓越的。同样的，初始化的节点特征是可以提供的，在(Kipf &amp; Welling, ICLR 2017)这篇文章的实验中我们确实是提供了的，因此在图数据的分类上达到了最好的效果。
结论
对这个问题的研究才刚刚开始，过去几个月已经看到了令人兴奋的发展，但是目前为止我们可能只是抓住了这个模型的表面。图神经网络如何进一步解决一些特定类型的问题仍然有待观察，比如有向和关系图的学习，如何利用学到的网络嵌入等等。这里的论文清单绝对不是最全面的，我预计在不久的将来会有更多有趣的应用和扩展。如果你有一些令人兴奋的想法或问题需要分享，请在下面的评论中告诉我们！
补充说明
这篇博客文章并不是对图神经网络领域的详尽回顾，因为为了使这篇文章更具可读性并且具有一个连贯的故事线，我忽略了一些近期和较早的论文。 但是如果你想深入研究这个主题，并且全面了解目前为止已经研究过的内容和正在研究的内容，那么我在这里提到的论文是一个很好的开端。
参考文献
Bruna et al., ICLR 2014, http://arxiv." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bchobby.github.io/posts/2d8002d840e26f8d40b314aef51c8ad9/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-03-28T16:19:42+08:00" />
<meta property="article:modified_time" content="2019-03-28T16:19:42+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程爱好者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程爱好者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">图神经网络</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>目前，大多数图神经网络模型都有一个通用的架构。<strong>我将它们称为图卷积神经网络（GCNs），这些模型是可卷积的，因为滤波器参数在图中所有位置或者一个局部位置上（ Duvenaud et al., NIPS 2015）都可以共享。</strong></p> 
<p>对于这些模型，它们的<strong>目标是要学习图G=（V，E）上的信号或特征的一个映射。</strong>它们的输入包括：</p> 
<ul><li>每一个节点i的特征描述xi，可以写成一个N*D的特征矩阵（N表示节点数，D表示输入的特征数）</li><li>矩阵形式的图结构的特征描述，通常是以邻接矩阵的形式（或者其他的形式）</li></ul> 
<p>模型会产生一个节点级别的输出Z（一个N*F的特征矩阵，其中F表示每一个节点的输出特征数）。图级别的输出可以通过引入一些池化操作来建模（Duvenaud等, NIPS 2015）。</p> 
<p>每一个神经网络层可以写成这样一个非线性函数：</p> 
<p>这里 ， （Z也可以作为图级别的输出），L是层数，这个模型主要在于f（）怎样选择以及参数化。</p> 
<p><strong>GCN第二部分：简单例子</strong></p> 
<p>作为示例，考虑下边这样一个简单的单层前向传播的形式：</p> 
<p>这里，W是l层神经网络的参数矩阵，( ) 是非线性激活函数比如ReLU。这个模型尽管简单但是却非常有效（我们马上就会介绍）。</p> 
<p>但是首先，让我们来看一下这个简单模型的两个限制：<strong>首先，和A相乘意味着对于每个节点，我们都整合了它的邻居节点的特征向量，但是却不包括这个节点本身（万一图中有自环存在）。</strong>我们可以通过在图中强行加入自环来解决这个问题，也就是给矩阵A加上一个单位阵。</p> 
<p><strong>第二个限制是A通常是非归一化的，因此和A相乘会完全改变特征向量的尺度（可以通过看A的特征值来理解）。</strong>归一化使A的各行和为1，比如，这里D是节点度的对角矩阵，这样就解决了这个问题。那么与相乘也就是对邻居节点的特征取平均。实际上，当我们使用对称归一化时，比如（这将不再仅仅是相邻节点的平均值），动力学会更加的有趣。</p> 
<p>结合这两种技巧，我们基本上得到了[Kipf &amp; Welling (ICLR 2017)]文章中的传播规则：</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/8a/19/GwdUVp0k_o.png"></p> 
<p>这里，是单位阵，是矩阵的节点度对角矩阵。</p> 
<p><strong>GCN第三部分：空手道俱乐部网络的嵌入</strong></p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/3e/3b/BrW617dq_o.jpg"></p> 
<p><strong>空手道俱乐部图，颜色表示通过基于模块化的聚类获得的社团</strong></p> 
<p>现在让我们来看一下，上边简单的GCN模型是怎样在一些知名的数据集上表现得如何，比如Zachary的空手道俱乐部网络数据（见上图）。</p> 
<p>我们使用一个三层GCN，随机初始化权重。在训练权重之前，我们将图的邻接矩阵和X=I（即单位阵，因为我们没有任何的节点特征）输入模型。这个3层的GCN在前向过程中做了三次传播并且有效的对每个节点的3阶邻居进行了卷积（所有的节点可达3阶）。值得注意的是，这个模型生成的这些节点的嵌入和图的社区结构非常类似（见下图）。还记得我们完全随机初始化的权重并且现在还没有进行任何的训练更新。</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/d6/0d/LUpZSI5S_o.png"></p> 
<p><strong>使用GCN（随机初始化权重）做空手道俱乐部网络中的节点嵌入</strong></p> 
<p>这似乎有点令人惊讶，最近一篇论文提出的DeepWalk模型 (Perozzi et al., KDD 2014)通过复杂的非监督的训练过程也可以学习到一个相似的嵌入。使用这个简单的未经训练的GCN模型几乎“免费”的获得了这样的嵌入，这怎么可能呢？</p> 
<p><strong>我们可以通过将GCN模型解释为网络图上的著名的Weisfeiler-Lehman（WL）算法的广义可微分版本来理解。</strong>1维的WL算法是这样的：</p> 
<ul><li>对图上的所有节点：</li><li>得到邻居节点的特征</li><li>根据更新节点特征，这里hush（）是一个一个单射散列函数</li><li>迭代k次直到收敛</li></ul> 
<p><strong>实际上，WL算法为大多数图分配一个独特的特征。</strong>也就是说每一个节点都被分配到一个可以唯一描述它在图中的角色的特征。例外是像网格（grid）、链（chain）等高度规则的图。对于大多数不规则的图，这个特征分配可以用来检验图同构（比如两个图是否相同，取决于节点的排列）。</p> 
<p>回到我们图卷积层传播规则上（现在从向量角度来看）：这里j是邻居节点的索引，是边的正则化常量，来源于GCN模型中用到的对称正则化邻接矩阵。我们现在看到，这种传播规则可以解释为原始WL算法中使用的哈希函数的可微分和参数化（即）变体。如果我们现在选择一个合适的正交的非线性并且初始化随机的权重矩阵（比如，使用（Glorot &amp; Bengio, AISTATS 2010）的初始化方式），在实践中这个更新规则最后会稳定下来（归功于的正则化）。</p> 
<p>经过观察，我们得到了非常有意义的平滑的嵌入，然后我们可以将嵌入后的距离解释为局部图结构的（不）相似性！</p> 
<p><strong>GCN第四部分：非监督学习</strong></p> 
<p>由于我们模型中所有的内容都是可微分的和参数化的，所以我们可以添加标签，训练模型并观察嵌入效果。我们可以使用Kipf &amp; Welling (ICLR 2017)文章中介绍的GCN的半监督学习算法。我们只需为每个节点标注类别或者社团（下面视频中突出显示的节点），然后开始进行多次迭代的训练。</p> 
<p> </p> 
<p><strong>用GCN进行半监督分类：300次训练迭代中隐空间的动态变化，每个类别有一个标签，带标签标的节点突出显示。</strong></p> 
<p>我们注意到，这个模型直接产生了一个二维的可以直接可视化的隐空间。我们观察到这个3层的的GCN模型尝试线性区分社团，每类社团给出一个标签。考虑到该模型并没有输入节点的特征描述，所以这个结果可以说是非常卓越的。同样的，初始化的节点特征是可以提供的，在(Kipf &amp; Welling, ICLR 2017)这篇文章的实验中我们确实是提供了的，<strong>因此在图数据的分类上达到了最好的效果。</strong></p> 
<p>结论</p> 
<p>对这个问题的研究才刚刚开始，过去几个月已经看到了令人兴奋的发展，但是目前为止我们可能只是抓住了这个模型的表面。<strong>图神经网络如何进一步解决一些特定类型的问题仍然有待观察，比如有向和关系图的学习，如何利用学到的网络嵌入等等。</strong>这里的论文清单绝对不是最全面的，我预计在不久的将来会有更多有趣的应用和扩展。如果你有一些令人兴奋的想法或问题需要分享，请在下面的评论中告诉我们！</p> 
<p><strong>补充说明</strong></p> 
<p>这篇博客文章并不是对图神经网络领域的详尽回顾，因为为了使这篇文章更具可读性并且具有一个连贯的故事线，我忽略了一些近期和较早的论文。 但是如果你想深入研究这个主题，并且全面了解目前为止已经研究过的内容和正在研究的内容，那么我在这里提到的论文是一个很好的开端。</p> 
<p><strong>参考文献</strong></p> 
<ol><li>Bruna et al., ICLR 2014, http://arxiv.org/abs/1312.6203</li><li>Henaff et al., 2015, http://arxiv.org/abs/1506.05163</li><li>Duvenaud et al., NIPS 2015, http://papers.nips.cc/paper/5954-convolutional-networks-on-graphs-for-learning-molecular-fingerprints</li><li>Li et al., ICLR 2016, https://arxiv.org/abs/1511.05493</li><li>Defferrard et al., NIPS 2016, https://arxiv.org/abs/1606.09375</li><li>Kipf &amp; Welling, ICLR 2017, http://arxiv.org/abs/1609.02907</li><li>How powerful are Graph Convolutions?http://www.inference.vc/how-powerful-are-graph-convolutions-review-of-kipf-welling-2016-2/</li><li>Jain et al., CVPR 2016, https://arxiv.org/abs/1511.05298</li><li>Brandes et al., 2008, http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.68.6623</li><li>Perozzi et al., KDD 2014, https://arxiv.org/abs/1403.6652</li><li>Glorot &amp; Bengio, AISTATS 2010, http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf</li><li>本文 GCN 项目仓库：https://github.com/tkipf/gcn</li></ol> 
<blockquote> 
 <p>原文地址：</p> 
 <p>https://tkipf.github.io/graph-convolutional-networks/</p> 
</blockquote> 
<p> </p> 
<p> </p> 
<p> </p> 
<p> </p> 
<p> </p> 
<p> </p> 
<p> </p> 
<p> </p> 
<p> </p> 
<p> </p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b340c387f8dac02a54397cd4db25c141/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">flutter 项目实战五  item 点击跳转，webview加载</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/2e51a97cd8df3a2aa4421ad84910d316/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">在CSDN复制代码的技巧</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程爱好者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151260"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>