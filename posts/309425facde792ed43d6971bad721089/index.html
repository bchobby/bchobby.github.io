<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>优化改进YOLOv5算法之Wise-IOU损失函数 - 编程爱好者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="优化改进YOLOv5算法之Wise-IOU损失函数" />
<meta property="og:description" content="1 Wise-IOU损失函数 边界框回归（BBR）的损失函数对于目标检测至关重要。它的良好定义将为模型带来显著的性能改进。大多数现有的工作假设训练数据中的样本是高质量的，并侧重于增强BBR损失的拟合能力。如果盲目地加强低质量样本的BBR，这将危及本地化性能。Focal EIoU v1被提出来解决这个问题，但由于其静态聚焦机制（FM），非单调FM的潜力没有被充分利用。基于这一思想，作者提出了一种基于IoU的损失，该损失具有动态非单调FM，名为Wise IoU（WIoU）。当WIoU应用于最先进的实时检测器YOLOv7时，MS-COCO数据集上的AP75从53.03%提高到54.50%。
现有工作记锚框为 ，目标框为 IoU 用于度量目标检测任务中预测框与真实框的重叠程度，定义为：
同时，IoU 有一个致命的缺陷，可以在下面公式中观察到。当边界框之间没有重叠时 ， 反向传播的梯度消失。这导致重叠区域的宽度 在训练时无法更新
现有的工作考虑了许多与包围盒相关的几何因素并构造了惩罚项 来解决这个问题，现有的边界框损失都是基于加法的损失，并遵循以下范式：
Distance-IoU
DIoU 将惩罚项定义为中心点连接的归一化长度：
同时为最小包围框的尺寸 提供了负梯度，这将使得 增大而阻碍预测框与目标框重叠： 但不可否认的是，距离度量的确是一个极其有效的解决方案，成为高效边界框损失的必要因子。EIoU 在此基础上加大了对距离度量的惩罚力度，其惩罚项定义为：
Complete-IoU
在的基础上，CIoU 增加了对纵横比一致性的考虑：
其中的描述了纵横比一致性：
其中反向传播的梯度满足 ，也就是不可能为预测框的宽高提供同号的梯度。在前文对 DIoU 的分析中可知 DIoU 会产生负梯度，当这个负梯度与正好抵消时，会导致预测框无法优化。而 CIoU 对纵横比一致性的考虑将打破这种僵局。
Scylla-IoU
Zhora Gevorgyan 证明了中心对齐的边界框会具有更快的收敛速度，以 angle cost、distance cost、shape cost 构造了 SIoU。其中 angle cost 描述了边界框中心连线与 x-y 轴的最小夹角：
distance cost 描述了两边界框的中心点在x轴和y轴上的归一化距离，其惩罚力度与 angle cost 正相关。distance cost 被定义为：
shape cost 描述了两边界框的形状差异，当两边界框的尺寸不一致时不为 0。shape cost 被定义为：
与类似，它们都由 distance cost 和 shape cost 组成： Wise IoU" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bchobby.github.io/posts/309425facde792ed43d6971bad721089/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-02-21T23:43:57+08:00" />
<meta property="article:modified_time" content="2023-02-21T23:43:57+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程爱好者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程爱好者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">优化改进YOLOv5算法之Wise-IOU损失函数</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2>1 Wise-IOU损失函数</h2> 
<p>边界框回归（BBR）的损失函数对于目标检测至关重要。它的良好定义将为模型带来显著的性能改进。大多数现有的工作假设训练数据中的样本是高质量的，并侧重于增强BBR损失的拟合能力。如果盲目地加强低质量样本的BBR，这将危及本地化性能。Focal EIoU v1被提出来解决这个问题，但由于其静态聚焦机制（FM），非单调FM的潜力没有被充分利用。基于这一思想，作者提出了一种基于IoU的损失，该损失具有动态非单调FM，名为Wise IoU（WIoU）。当WIoU应用于最先进的实时检测器YOLOv7时，MS-COCO数据集上的AP75从53.03%提高到54.50%。</p> 
<p>现有工作<img alt="" src="https://images2.imgbox.com/16/2f/XqIfe1pE_o.png">记锚框为 ，目标框为 <img alt="" src="https://images2.imgbox.com/ac/44/4eEpgyGD_o.png"></p> 
<p class="img-center"><img alt="" height="302" src="https://images2.imgbox.com/ad/83/rzTglzm3_o.png" width="387"></p> 
<p> </p> 
<p> IoU 用于度量目标检测任务中预测框与真实框的重叠程度，定义为：</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/96/f2/sEs47ODY_o.png"></p> 
<p>同时，IoU 有一个致命的缺陷，可以在下面公式中观察到。当边界框之间没有重叠时 ， 反向传播的梯度消失。这导致重叠区域的宽度  在训练时无法更新</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/de/c5/G8CUN65p_o.png"></p> 
<p>现有的工作考虑了许多与包围盒相关的几何因素并构造了惩罚项  来解决这个问题，现有的边界框损失都是基于加法的损失，并遵循以下范式：</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/75/5d/x6WCCwkY_o.png"></p> 
<p><strong>Distance-IoU</strong><br> DIoU 将惩罚项定义为中心点连接的归一化长度：</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/a8/48/Z4dowd8T_o.png"></p> 
<p>同时为最小包围框的尺寸 <img alt="" src="https://images2.imgbox.com/07/73/EWMUaoB0_o.png">提供了负梯度，这将使得 <img alt="" src="https://images2.imgbox.com/e6/e8/404jmQc9_o.png">增大而阻碍预测框与目标框重叠：  </p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/c8/cd/gMn8n0SJ_o.png"></p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/b4/8f/SH6ei0ne_o.png"></p> 
<p>但不可否认的是，距离度量的确是一个极其有效的解决方案，成为高效边界框损失的必要因子。EIoU 在此基础上加大了对距离度量的惩罚力度，其惩罚项定义为：</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/08/c1/088cLpdX_o.png"></p> 
<p><strong>Complete-IoU</strong><br> 在<img alt="" src="https://images2.imgbox.com/02/f3/JFFSpODb_o.png">的基础上，CIoU 增加了对纵横比一致性的考虑：</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/e8/36/QdgKXASU_o.png"></p> 
<p>其中的<img alt="" src="https://images2.imgbox.com/cf/bd/qc3InlVL_o.png">描述了纵横比一致性：</p> 
<p class="img-center"><img alt="" height="199" src="https://images2.imgbox.com/83/c8/3UuexWNT_o.png" width="377"></p> 
<p>其中<img alt="" src="https://images2.imgbox.com/18/3d/73uKJ5pP_o.png">反向传播的梯度满足 ，也就是<img alt="" src="https://images2.imgbox.com/40/66/2rD0Bjkh_o.png">不可能为预测框的宽高提供同号的梯度。在前文对 DIoU 的分析中可知 DIoU 会产生负梯度<img alt="" src="https://images2.imgbox.com/95/ec/LaSRLlta_o.png">，当这个负梯度与<img alt="" src="https://images2.imgbox.com/b3/bb/lhoQnixy_o.png">正好抵消时，会导致预测框无法优化。而 CIoU 对纵横比一致性的考虑将打破这种僵局。</p> 
<p class="img-center"><img alt="" height="359" src="https://images2.imgbox.com/65/e8/u9cWBdye_o.png" width="667"></p> 
<p><strong> Scylla-IoU</strong><br> Zhora Gevorgyan 证明了中心对齐的边界框会具有更快的收敛速度，以 angle cost、distance cost、shape cost 构造了 SIoU。其中 angle cost 描述了边界框中心连线与 x-y 轴的最小夹角：</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/8f/f1/cX1LaTcg_o.png"></p> 
<p>distance cost 描述了两边界框的中心点在x轴和y轴上的归一化距离，其惩罚力度与 angle cost 正相关。distance cost 被定义为：</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/dc/55/Vf28n54L_o.png"></p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/73/e7/SuAuGFtJ_o.png"></p> 
<p>shape cost 描述了两边界框的形状差异，当两边界框的尺寸不一致时不为 0。shape cost 被定义为：</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/52/1c/9gizj6AX_o.png"></p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/35/f6/OAwBh6ml_o.png"></p> 
<p><img alt="" src="https://images2.imgbox.com/65/d2/aWlGDmWz_o.png">与<img alt="" src="https://images2.imgbox.com/5d/d7/XnbPdRCV_o.png">类似，它们都由 distance cost 和 shape cost 组成：  </p> 
<p><strong>Wise IoU</strong></p> 
<p><strong>Wise-IoU v1</strong><br> 因为训练数据中难以避免地包含低质量示例，所以如距离、纵横比之类的几何度量都会加剧对低质量示例的惩罚从而使模型的泛化性能下降。好的损失函数应该在锚框与目标框较好地重合时削弱几何度量的惩罚，不过多地干预训练将使模型有更好的泛化能力。在此基础上，我们根据距离度量构建了距离注意力，得到了具有两层注意力机制的 WIoU v1：</p> 
<ul><li><img alt="" src="https://images2.imgbox.com/47/87/l9YlxXf8_o.png">，这将显著放大普通质量锚框的 <img alt="" src="https://images2.imgbox.com/d7/91/xMVpFYfs_o.png"></li></ul> 
<p><img alt="" src="https://images2.imgbox.com/3a/27/SrR2CfdH_o.png">，这将显著降低高质量锚框的<img alt="" src="https://images2.imgbox.com/95/5d/CYkZZHNJ_o.png">，并在锚框与目标框重合较好的情况下显著降低其对中心点距离的关注</p> 
<p class="img-center"><img alt="" height="130" src="https://images2.imgbox.com/90/d5/YHPYVGf8_o.png" width="514"></p> 
<p>为了防止<img alt="" src="https://images2.imgbox.com/b1/dd/L8Vcm7Hi_o.png">产生阻碍收敛的梯度，将<img alt="" src="https://images2.imgbox.com/25/70/eshS6Jto_o.png">从计算图 (上标 * 表示此操作) 中分离。因为它有效地消除了阻碍收敛的因素，所以我们没有引入新的度量指标，如纵横比。 </p> 
<p><strong>Wise-IoU v2</strong><br> Focal Loss 设计了一种针对交叉熵的单调聚焦机制，有效降低了简单示例对损失值的贡献。这使得模型能够聚焦于困难示例，获得分类性能的提升。类似地，我们构造了<img alt="" src="https://images2.imgbox.com/12/4d/0DsEEdjy_o.png">的单调聚焦系数<img alt="" src="https://images2.imgbox.com/f6/93/BAQfRuMA_o.png">:</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/5b/50/z4WV32zc_o.png"></p> 
<p> 在模型训练过程中，梯度增益<img alt="" src="https://images2.imgbox.com/2d/3d/767oP4bq_o.png">随着<img alt="" src="https://images2.imgbox.com/9d/f4/u1h17TzA_o.png">的减小而减小，导致训练后期收敛速度较慢。因此，引入<img alt="" src="https://images2.imgbox.com/a7/1b/vqQbLFg4_o.png">的均值作为归一化因子：</p> 
<p> </p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/f5/32/BZvwsqzD_o.png"></p> 
<p>其中的<img alt="" src="https://images2.imgbox.com/70/0e/sU3wsjw7_o.png">为动量为<em>m</em>的滑动平均值，动态更新归一化因子使梯度增益<img alt="" src="https://images2.imgbox.com/28/7f/ujuMseUz_o.png">整体保持在较高水平，解决了训练后期收敛速度慢的问题  </p> 
<p><strong>Wise-IoU v3</strong><br> 定义离群度以描述锚框的质量，其定义为：</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/b7/62/KXXzpwgi_o.png"></p> 
<p>离群度小意味着锚框质量高，我们为其分配一个小的梯度增益，以便使边界框回归聚焦到普通质量的锚框上。对离群度较大的锚框分配较小的梯度增益，将有效防止低质量示例产生较大的有害梯度。我们利用  构造了一个非单调聚焦系数并将其应用于 WIoU v1:</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/97/a5/5BUIJwoa_o.png"></p> 
<p class="img-center"><img alt="" height="249" src="https://images2.imgbox.com/e7/fe/mRYYQ2U2_o.png" width="419"></p> 
<p>其中，当<img alt="" src="https://images2.imgbox.com/b8/96/q3OF0mKy_o.png">时, <img alt="" src="https://images2.imgbox.com/52/19/RsSYJStr_o.png">使得<img alt="" src="https://images2.imgbox.com/88/46/tFxXjj5B_o.png">。当锚框的离群程度满足<img alt="" src="https://images2.imgbox.com/68/fd/TcRaCfMM_o.png">(<img alt="" src="https://images2.imgbox.com/56/f2/b11s4PPm_o.png">为定值)时，锚框将获得最高的梯度增益。由于<img alt="" src="https://images2.imgbox.com/e3/dc/FaLh1jNz_o.png">是动态的，锚框的质量划分标准也是动态的，这使得 WIoU v3 在每一时刻都能做出最符合当前情况的梯度增益分配策略      </p> 
<p>为了防止低质量锚框在训练初期落后，我们初始化<img alt="" src="https://images2.imgbox.com/96/0c/uldzK7J1_o.png">使得<img alt="" src="https://images2.imgbox.com/42/70/rFXQ486L_o.png">的锚框具有最高的梯度增益。为了在训练的早期阶段保持这样的策略，需要设置一个小的动量<img alt="" src="https://images2.imgbox.com/79/81/OGJzxrXz_o.png">来延迟<img alt="" src="https://images2.imgbox.com/44/0b/NXJsGvso_o.png">接近真实值  <img alt="" src="https://images2.imgbox.com/61/c5/ZahsNGkz_o.png">的时间。对于 batch size 为<img alt="" src="https://images2.imgbox.com/b6/fa/0tIwf3CV_o.png">的训练，我们建议将动量设置为：</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/58/a2/OJRZYg5C_o.png"></p> 
<p> 这种设置使得经过t轮训练后有<img alt="" src="https://images2.imgbox.com/91/05/twTieADr_o.png">。在训练的中后期，WIoU v3 将小梯度增益分配给低质量的锚框以减少有害梯度。同时 WIoU v3 会聚焦于普通质量的锚框，提高模型的定位性能 </p> 
<h2>2 YOLOv5中添加Wise-IOU损失函数</h2> 
<p>yolov5-6.1版本中的iou损失函数是在utils/metrics.py文件定义的，在该文件添加以下关于Wise-IOU函数的代码，如下所示</p> 
<pre><code class="language-python">import numpy as np
import torch, math

class WIoU_Scale:
    ''' monotonous: {
            None: origin v1
            True: monotonic FM v2
            False: non-monotonic FM v3
        }
        momentum: The momentum of running mean'''
    
    iou_mean = 1.
    monotonous = False
    _momentum = 1 - 0.5 ** (1 / 7000)
    _is_train = True

    def __init__(self, iou):
        self.iou = iou
        self._update(self)
    
    @classmethod
    def _update(cls, self):
        if cls._is_train: cls.iou_mean = (1 - cls._momentum) * cls.iou_mean + \
                                         cls._momentum * self.iou.detach().mean().item()
    
    @classmethod
    def _scaled_loss(cls, self, gamma=1.9, delta=3):
        if isinstance(self.monotonous, bool):
            if self.monotonous:
                return (self.iou.detach() / self.iou_mean).sqrt()
            else:
                beta = self.iou.detach() / self.iou_mean
                alpha = delta * torch.pow(gamma, beta - delta)
                return beta / alpha
        return 1
    

def bbox_iou(box1, box2, xywh=True, GIoU=False, DIoU=False, CIoU=False, SIoU=False, EIoU=False, WIoU=False, Focal=False, alpha=1, gamma=0.5, scale=False, eps=1e-7):
    # Returns Intersection over Union (IoU) of box1(1,4) to box2(n,4)

    # Get the coordinates of bounding boxes
    if xywh:  # transform from xywh to xyxy
        (x1, y1, w1, h1), (x2, y2, w2, h2) = box1.chunk(4, -1), box2.chunk(4, -1)
        w1_, h1_, w2_, h2_ = w1 / 2, h1 / 2, w2 / 2, h2 / 2
        b1_x1, b1_x2, b1_y1, b1_y2 = x1 - w1_, x1 + w1_, y1 - h1_, y1 + h1_
        b2_x1, b2_x2, b2_y1, b2_y2 = x2 - w2_, x2 + w2_, y2 - h2_, y2 + h2_
    else:  # x1, y1, x2, y2 = box1
        b1_x1, b1_y1, b1_x2, b1_y2 = box1.chunk(4, -1)
        b2_x1, b2_y1, b2_x2, b2_y2 = box2.chunk(4, -1)
        w1, h1 = b1_x2 - b1_x1, (b1_y2 - b1_y1).clamp(eps)
        w2, h2 = b2_x2 - b2_x1, (b2_y2 - b2_y1).clamp(eps)

    # Intersection area
    inter = (b1_x2.minimum(b2_x2) - b1_x1.maximum(b2_x1)).clamp(0) * \
            (b1_y2.minimum(b2_y2) - b1_y1.maximum(b2_y1)).clamp(0)

    # Union Area
    union = w1 * h1 + w2 * h2 - inter + eps
    if scale:
        self = WIoU_Scale(1 - (inter / union))

    # IoU
    # iou = inter / union # ori iou
    iou = torch.pow(inter/(union + eps), alpha) # alpha iou
    if CIoU or DIoU or GIoU or EIoU or SIoU or WIoU:
        cw = b1_x2.maximum(b2_x2) - b1_x1.minimum(b2_x1)  # convex (smallest enclosing box) width
        ch = b1_y2.maximum(b2_y2) - b1_y1.minimum(b2_y1)  # convex height
        if CIoU or DIoU or EIoU or SIoU or WIoU:  # Distance or Complete IoU https://arxiv.org/abs/1911.08287v1
            c2 = (cw ** 2 + ch ** 2) ** alpha + eps  # convex diagonal squared
            rho2 = (((b2_x1 + b2_x2 - b1_x1 - b1_x2) ** 2 + (b2_y1 + b2_y2 - b1_y1 - b1_y2) ** 2) / 4) ** alpha  # center dist ** 2
            if CIoU:  # https://github.com/Zzh-tju/DIoU-SSD-pytorch/blob/master/utils/box/box_utils.py#L47
                v = (4 / math.pi ** 2) * (torch.atan(w2 / h2) - torch.atan(w1 / h1)).pow(2)
                with torch.no_grad():
                    alpha_ciou = v / (v - iou + (1 + eps))
                if Focal:
                    return iou - (rho2 / c2 + torch.pow(v * alpha_ciou + eps, alpha)), torch.pow(inter/(union + eps), gamma)  # Focal_CIoU
                else:
                    return iou - (rho2 / c2 + torch.pow(v * alpha_ciou + eps, alpha))  # CIoU
            elif EIoU:
                rho_w2 = ((b2_x2 - b2_x1) - (b1_x2 - b1_x1)) ** 2
                rho_h2 = ((b2_y2 - b2_y1) - (b1_y2 - b1_y1)) ** 2
                cw2 = torch.pow(cw ** 2 + eps, alpha)
                ch2 = torch.pow(ch ** 2 + eps, alpha)
                if Focal:
                    return iou - (rho2 / c2 + rho_w2 / cw2 + rho_h2 / ch2), torch.pow(inter/(union + eps), gamma) # Focal_EIou
                else:
                    return iou - (rho2 / c2 + rho_w2 / cw2 + rho_h2 / ch2) # EIou
            elif SIoU:
                # SIoU Loss https://arxiv.org/pdf/2205.12740.pdf
                s_cw = (b2_x1 + b2_x2 - b1_x1 - b1_x2) * 0.5 + eps
                s_ch = (b2_y1 + b2_y2 - b1_y1 - b1_y2) * 0.5 + eps
                sigma = torch.pow(s_cw ** 2 + s_ch ** 2, 0.5)
                sin_alpha_1 = torch.abs(s_cw) / sigma
                sin_alpha_2 = torch.abs(s_ch) / sigma
                threshold = pow(2, 0.5) / 2
                sin_alpha = torch.where(sin_alpha_1 &gt; threshold, sin_alpha_2, sin_alpha_1)
                angle_cost = torch.cos(torch.arcsin(sin_alpha) * 2 - math.pi / 2)
                rho_x = (s_cw / cw) ** 2
                rho_y = (s_ch / ch) ** 2
                gamma = angle_cost - 2
                distance_cost = 2 - torch.exp(gamma * rho_x) - torch.exp(gamma * rho_y)
                omiga_w = torch.abs(w1 - w2) / torch.max(w1, w2)
                omiga_h = torch.abs(h1 - h2) / torch.max(h1, h2)
                shape_cost = torch.pow(1 - torch.exp(-1 * omiga_w), 4) + torch.pow(1 - torch.exp(-1 * omiga_h), 4)
                if Focal:
                    return iou - torch.pow(0.5 * (distance_cost + shape_cost) + eps, alpha), torch.pow(inter/(union + eps), gamma) # Focal_SIou
                else:
                    return iou - torch.pow(0.5 * (distance_cost + shape_cost) + eps, alpha) # SIou
            elif WIoU:
                if Focal:
                    raise RuntimeError("WIoU do not support Focal.")
                elif scale:
                    return getattr(WIoU_Scale, '_scaled_loss')(self), (1 - iou) * torch.exp((rho2 / c2)), iou # WIoU https://arxiv.org/abs/2301.10051
                else:
                    return iou, torch.exp((rho2 / c2)) # WIoU v1
            if Focal:
                return iou - rho2 / c2, torch.pow(inter/(union + eps), gamma)  # Focal_DIoU
            else:
                return iou - rho2 / c2  # DIoU
        c_area = cw * ch + eps  # convex area
        if Focal:
            return iou - torch.pow((c_area - union) / c_area + eps, alpha), torch.pow(inter/(union + eps), gamma)  # Focal_GIoU https://arxiv.org/pdf/1902.09630.pdf
        else:
            return iou - torch.pow((c_area - union) / c_area + eps, alpha)  # GIoU https://arxiv.org/pdf/1902.09630.pdf
    if Focal:
        return iou, torch.pow(inter/(union + eps), gamma)  # Focal_IoU
    else:
        return iou  # IoU
</code></pre> 
<p>然后在utils/loss.py文件中调用bbox_iou损失函数时，将WIoU设置为True即可。</p> 
<p class="img-center"><img alt="" height="335" src="https://images2.imgbox.com/fd/0c/03HxvIxe_o.png" width="800"></p> 
<p> </p> 
<p> </p> 
<p></p> 
<p></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/6c5a0a4214187f60f08b0f1d395fb8e9/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">SAP SD模块 信用额度不正确怎么办</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/00e67b703faef994de595e1d5ce96b59/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">flink流式分析</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程爱好者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151260"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>