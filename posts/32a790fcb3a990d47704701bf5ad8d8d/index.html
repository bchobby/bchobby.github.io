<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>使用HybridSN进行高光谱图像分类 - 编程爱好者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="使用HybridSN进行高光谱图像分类" />
<meta property="og:description" content="文章目录 一、前言二、高光谱图像三、HybridSN模型四、注意力机制五、开始实验5.1 下载数据集5.2 PCA降维5.3 训练模型5.4 可视化结果5.5 分析结论 六、思考七、结语 一、前言 高光谱图像（Hyperspectral image，以下简称HSI）分类广泛应用于遥感图像的分析，随着深度学习和神经网络的兴起，越来越多的人使用二维CNN对HSI进行分类，而HSI分类性能却高度依赖于空间和光谱信息，由于计算复杂度增加，很少有人将三维CNN应用于HSI分类中。这篇 Exploring 3-D–2-D CNN Feature Hierarchy for Hyperspectral Image Classification构建一种混合网络(HybridSN)解决了HSI分类所遇到的问题，它首先用三维CNN提取空间-光谱的特征，然后在三维CNN基础上进一步使用二维CNN学习更多抽象层次的空间特征，这与单独使用三维CNN相比，混合的CNN模型既降低了复杂性，也提升了性能。经实验证明，使用HybridSN进行HSI分类，能够获得非常不错的效果。
二、高光谱图像 在进行高光谱图像分类之前，我认为有必要了解什么是高光谱图像。从计算机的角度来说，高光谱图像（Hyperspectral image）就是由多通道（几十甚至几百个）的数组构成的图像，每个像素点都有很多的数来描述，单个通道上的“灰度值”反映了被拍摄对象对于某一波段的光的反射情况。
我们知道，常见的RGB彩色图像只有三个通道，而高光谱图像有几十甚至几百个通道，所以高光谱图像包含包含更多的目标信息，利用高光谱图像进行目标的分类识别也必然比采用RGB图像具有更高的准确度。如下图所示，利用高光谱相机可以拍摄出由不同波长组成的空间立方体图像（即高光谱图像），用一个光谱曲线将其显示出来，横轴表示波长，纵轴表示反射系数，由于同一物体对不同波长的光反射因子不一样，因此利用高光谱图像更能反映出不同物体的差异性。
其实高光谱成像技术在很早以前就已经被广泛应用了，天上的卫星拍摄到的就是高光谱图像，通过分析每个像素点的光谱曲线，可以把不同地面目标对应的像素点分类，从而在高光谱图像中把地面、建筑物、草坪、江河等等区分开。
三、HybridSN模型 对于HSI分类问题，我们在提取空间信息的同时，也希望能获取到不同波长的光谱信息，而二维CNN是无法处理光谱信息的，也就无法提取到更具有判别性的特征图。幸运的是，三维CNN能够同时提取光谱和空间的特征，但代价是增加计算复杂度。为了充分发挥二维和三维CNN的优势，Swalpa Kumar Roy等人提出了HSI分类模型HybridSN，其模型图如下图所示，它由三个三维卷积、一个二维卷积和三个全连接层组成。
在HybridSN模型中，三维卷积核的尺寸分别为8×3×3×7×1(即图中 K 1 1 K_1^1 K11​=3 ， K 2 1 K_2^1 K21​=3 ， K 3 1 K_3^1 K31​=7)、16×3×3×5×8(即图中 K 1 2 K_1^2 K12​=3 ， K 2 2 K_2^2 K22​=3 ， K 3 2 K_3^2 K32​=5)和32×3×3×3×16(即图中 K 1 3 K_1^3 K13​=3 ， K 2 3 K_2^3 K23​=3 ， K 3 3 K_3^3 K33​=3），分别位于第一、第二和第三卷积层中。其中，16×3×3×5×8表示输入特征图的个数为8，输出特征图个数为16，三维卷积核大小为3x3x5，可理解为有两个空间维度和一个光谱维度。二维卷积在flatten之前被应用一次，它能有效的判别空间信息，也不会大量损失光谱信息，这是对HSI数据非常重要。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bchobby.github.io/posts/32a790fcb3a990d47704701bf5ad8d8d/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-01-05T17:16:57+08:00" />
<meta property="article:modified_time" content="2021-01-05T17:16:57+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程爱好者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程爱好者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">使用HybridSN进行高光谱图像分类</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-dracula">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><ul><li><a href="#_2" rel="nofollow">一、前言</a></li><li><a href="#_6" rel="nofollow">二、高光谱图像</a></li><li><a href="#HybridSN_18" rel="nofollow">三、HybridSN模型</a></li><li><a href="#_117" rel="nofollow">四、注意力机制</a></li><li><a href="#_286" rel="nofollow">五、开始实验</a></li><li><ul><li><a href="#51__299" rel="nofollow">5.1 下载数据集</a></li><li><a href="#52_PCA_309" rel="nofollow">5.2 PCA降维</a></li><li><a href="#53__391" rel="nofollow">5.3 训练模型</a></li><li><a href="#54__468" rel="nofollow">5.4 可视化结果</a></li><li><a href="#55__491" rel="nofollow">5.5 分析结论</a></li></ul> 
   </li><li><a href="#_501" rel="nofollow">六、思考</a></li><li><a href="#_540" rel="nofollow">七、结语</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h3><a id="_2"></a>一、前言</h3> 
<p>高光谱图像（Hyperspectral image，以下简称HSI）分类广泛应用于遥感图像的分析，随着深度学习和神经网络的兴起，越来越多的人使用二维CNN对HSI进行分类，而HSI分类性能却高度依赖于空间和光谱信息，由于计算复杂度增加，很少有人将三维CNN应用于HSI分类中。这篇 <a href="https://ieeexplore.ieee.org/document/8736016" rel="nofollow">Exploring 3-D–2-D CNN Feature Hierarchy for Hyperspectral Image Classification</a>构建一种混合网络(HybridSN)解决了HSI分类所遇到的问题，它首先用三维CNN提取空间-光谱的特征，然后在三维CNN基础上进一步使用二维CNN学习更多抽象层次的空间特征，这与单独使用三维CNN相比，混合的CNN模型既降低了复杂性，也提升了性能。经实验证明，使用HybridSN进行HSI分类，能够获得非常不错的效果。</p> 
<h3><a id="_6"></a>二、高光谱图像</h3> 
<p>在进行高光谱图像分类之前，我认为有必要了解什么是高光谱图像。从计算机的角度来说，高光谱图像（Hyperspectral image）就是由多通道（几十甚至几百个）的数组构成的图像，每个像素点都有很多的数来描述，<strong>单个通道上的“灰度值”反映了被拍摄对象对于某一波段的光的反射情况。</strong></p> 
<p>我们知道，常见的RGB彩色图像只有三个通道，而高光谱图像有几十甚至几百个通道，所以高光谱图像包含包含更多的目标信息，利用高光谱图像进行目标的分类识别也必然比采用RGB图像具有更高的准确度。如下图所示，利用高光谱相机可以拍摄出由不同波长组成的空间立方体图像（即高光谱图像），用一个光谱曲线将其显示出来，横轴表示波长，纵轴表示反射系数，由于同一物体对不同波长的光反射因子不一样，因此利用高光谱图像更能反映出不同物体的差异性。</p> 
<p><img src="https://images2.imgbox.com/d8/51/B0XPlG5W_o.png" alt=""></p> 
<p>其实高光谱成像技术在很早以前就已经被广泛应用了，天上的卫星拍摄到的就是高光谱图像，通过分析每个像素点的光谱曲线，可以把不同地面目标对应的像素点分类，从而在高光谱图像中把地面、建筑物、草坪、江河等等区分开。</p> 
<h3><a id="HybridSN_18"></a>三、HybridSN模型</h3> 
<p>对于HSI分类问题，我们在提取空间信息的同时，也希望能获取到不同波长的光谱信息，而二维CNN是无法处理光谱信息的，也就无法提取到更具有判别性的特征图。幸运的是，三维CNN能够同时提取光谱和空间的特征，但代价是增加计算复杂度。为了充分发挥二维和三维CNN的优势，Swalpa Kumar Roy等人提出了HSI分类模型HybridSN，其模型图如下图所示，它由三个三维卷积、一个二维卷积和三个全连接层组成。</p> 
<p><img src="https://images2.imgbox.com/18/ab/lPoF6m3s_o.png" alt=""></p> 
<p>在HybridSN模型中，三维卷积核的尺寸分别为<code>8×3×3×7×1</code>(即图中<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          K 
         
        
          1 
         
        
          1 
         
        
       
      
        K_1^1 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.06222em; vertical-align: -0.248108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.07153em;">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.814108em;"><span class="" style="top: -2.45189em; margin-left: -0.07153em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.248108em;"><span class=""></span></span></span></span></span></span></span></span></span></span>=3 ，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          K 
         
        
          2 
         
        
          1 
         
        
       
      
        K_2^1 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.06222em; vertical-align: -0.248108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.07153em;">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.814108em;"><span class="" style="top: -2.45189em; margin-left: -0.07153em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.248108em;"><span class=""></span></span></span></span></span></span></span></span></span></span>=3 ，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          K 
         
        
          3 
         
        
          1 
         
        
       
      
        K_3^1 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.06222em; vertical-align: -0.248108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.07153em;">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.814108em;"><span class="" style="top: -2.45189em; margin-left: -0.07153em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.248108em;"><span class=""></span></span></span></span></span></span></span></span></span></span>=7)、<code>16×3×3×5×8</code>(即图中<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          K 
         
        
          1 
         
        
          2 
         
        
       
      
        K_1^2 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.06222em; vertical-align: -0.248108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.07153em;">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.814108em;"><span class="" style="top: -2.45189em; margin-left: -0.07153em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.248108em;"><span class=""></span></span></span></span></span></span></span></span></span></span>=3 ，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          K 
         
        
          2 
         
        
          2 
         
        
       
      
        K_2^2 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.06222em; vertical-align: -0.248108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.07153em;">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.814108em;"><span class="" style="top: -2.45189em; margin-left: -0.07153em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.248108em;"><span class=""></span></span></span></span></span></span></span></span></span></span>=3 ，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          K 
         
        
          3 
         
        
          2 
         
        
       
      
        K_3^2 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.06222em; vertical-align: -0.248108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.07153em;">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.814108em;"><span class="" style="top: -2.45189em; margin-left: -0.07153em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.248108em;"><span class=""></span></span></span></span></span></span></span></span></span></span>=5)和<code>32×3×3×3×16</code>(即图中<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          K 
         
        
          1 
         
        
          3 
         
        
       
      
        K_1^3 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.06222em; vertical-align: -0.248108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.07153em;">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.814108em;"><span class="" style="top: -2.45189em; margin-left: -0.07153em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.248108em;"><span class=""></span></span></span></span></span></span></span></span></span></span>=3 ，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          K 
         
        
          2 
         
        
          3 
         
        
       
      
        K_2^3 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.06222em; vertical-align: -0.248108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.07153em;">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.814108em;"><span class="" style="top: -2.45189em; margin-left: -0.07153em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.248108em;"><span class=""></span></span></span></span></span></span></span></span></span></span>=3 ，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          K 
         
        
          3 
         
        
          3 
         
        
       
      
        K_3^3 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.06222em; vertical-align: -0.248108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.07153em;">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.814108em;"><span class="" style="top: -2.45189em; margin-left: -0.07153em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.248108em;"><span class=""></span></span></span></span></span></span></span></span></span></span>=3），分别位于第一、第二和第三卷积层中。其中，<code>16×3×3×5×8</code>表示输入特征图的个数为8，输出特征图个数为16，三维卷积核大小为<code>3x3x5</code>，可理解为有两个空间维度和一个光谱维度。<strong>二维卷积在flatten之前被应用一次，它能有效的判别空间信息，也不会大量损失光谱信息，这是对HSI数据非常重要</strong>。</p> 
<p>模型的详细参数配置如下表所示，可以看出，第一个FC层（即dense1)参数量最多，最后一个全连接层（dense3）的输出为16，这是因为Indian Pines (IP)数据集的类别数为16。HybridSN中可训练的权重参数总数为5122176，所有参数都是随机初始化的，使用Adam优化器，交叉熵损失函数，学习率为0.001，batch大小为128，训练100个epoch。</p> 
<p><img src="https://images2.imgbox.com/b3/4e/uulrIHWK_o.gif" alt=""></p> 
<p>下面是我实现的HybridSN模型：</p> 
<pre><code class="prism language-python">class_num <span class="token operator">=</span> <span class="token number">16</span>
<span class="token keyword">class</span> <span class="token class-name">HybridSN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>  
  <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span>class_num<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token builtin">super</span><span class="token punctuation">(</span>HybridSN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>conv3d_features <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
        nn<span class="token punctuation">.</span>Conv3d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Conv3d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Conv3d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>

    self<span class="token punctuation">.</span>conv2d_features <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
        nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span> <span class="token operator">*</span> <span class="token number">18</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>

    self<span class="token punctuation">.</span>classifier <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
        nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span> <span class="token operator">*</span> <span class="token number">17</span> <span class="token operator">*</span> <span class="token number">17</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>
 
  <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv3d_features<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">*</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2d_features<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
    x <span class="token operator">=</span> self<span class="token punctuation">.</span>classifier<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token keyword">return</span> x
</code></pre> 
<p>带有Batch Normalization的HybridSN模型：</p> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">HybridSN_BN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>  
  <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span>class_num<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token builtin">super</span><span class="token punctuation">(</span>HybridSN_BN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>conv3d_features <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
        nn<span class="token punctuation">.</span>Conv3d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>BatchNorm3d<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Conv3d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>BatchNorm3d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Conv3d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>BatchNorm3d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>

    self<span class="token punctuation">.</span>conv2d_features <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
        nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span> <span class="token operator">*</span> <span class="token number">18</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>

    self<span class="token punctuation">.</span>classifier <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
        nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span> <span class="token operator">*</span> <span class="token number">17</span> <span class="token operator">*</span> <span class="token number">17</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>
 
  <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv3d_features<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">*</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2d_features<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
    x <span class="token operator">=</span> self<span class="token punctuation">.</span>classifier<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token keyword">return</span> x
</code></pre> 
<p>上面我实现了两种模型，一种是原始的HybridSN模型，另一种是带有Batch Normalization的HybridSN模型，下面还会再实现另外两种模型。</p> 
<h3><a id="_117"></a>四、注意力机制</h3> 
<p>为了提升HSI分类模型的性能，我也实现了带有注意力机制的HybridSN模型进行训练，这里我采用<a href="https://arxiv.org/pdf/1807.06521.pdf" rel="nofollow">CBAM: Convolutional Block Attention Module</a>的空间注意力和通道注意力机制。</p> 
<p>（1）Channnel attetion module(通道注意力模块)</p> 
<p>通道注意力模是解决<strong>look what</strong>的问题，主要是探索不同通道之间特征图的关系，通过分配各个卷积通道上的资源，使模型更应该注意哪一部分特征。通道注意力的过程如下：</p> 
<p><img src="https://images2.imgbox.com/8d/fd/50GFB9G3_o.png" alt=""></p> 
<ol><li>首先使用MaxPool和AvgPool聚合两个空间维度上的特征，实现时可以用<code>AdaptiveAvgPool2d</code>和<code>AdaptiveMaxPool2d</code>保证尺寸不变</li><li>然后通过共享的MLP层，即FC+Relu+FC层，学习每个通道的权重，再将两个特征图相加，后接一个sigmoid函数。</li><li>最后将结果与未经channel attention的原始输入相乘，从而得到的新的特征图。</li></ol> 
<p>Channnel attetion module实现如下：</p> 
<pre><code class="prism language-python"><span class="token comment"># 参考 https://github.com/luuuyi/CBAM.PyTorch</span>
<span class="token keyword">class</span> <span class="token class-name">ChannelAttention</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_planes<span class="token punctuation">,</span> ratio<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>ChannelAttention<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>avg_pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>AdaptiveAvgPool2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>max_pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>fc1   <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_planes<span class="token punctuation">,</span> in_planes <span class="token operator">//</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>relu1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc2   <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_planes <span class="token operator">//</span> <span class="token number">16</span><span class="token punctuation">,</span> in_planes<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>sigmoid <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        avg_out <span class="token operator">=</span> self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>self<span class="token punctuation">.</span>relu1<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>self<span class="token punctuation">.</span>avg_pool<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        max_out <span class="token operator">=</span> self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>self<span class="token punctuation">.</span>relu1<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>self<span class="token punctuation">.</span>max_pool<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        out <span class="token operator">=</span> avg_out <span class="token operator">+</span> max_out
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
</code></pre> 
<p>（2）Spatial attention module(空间注意力模块)</p> 
<p>空间注意力模块解决的是<strong>look where</strong>的问题，通过对特征图每个位置进行二维调整（即attention调整），使模型关注到值得更多关注的区域上。空间注意力的过程如下：</p> 
<p><img src="https://images2.imgbox.com/1b/b2/Bke9Hdl6_o.png" alt=""></p> 
<ol><li>首先对不同特征图上相同位置的像素值进行全局的MaxPooling和AvgPooling操作，分别得到两个spatial attention map。</li><li>将这两个特征图concatenate，通过7*7的卷积核对这个feature map进行卷积操作，后接一个sigmoid函数。</li><li>最后把得到的空间注意力特征图与未经Spatial attention的原始输入相乘，得到的新的特征图。</li></ol> 
<p>Spatial attention module实现如下：</p> 
<pre><code class="prism language-python"><span class="token comment"># 参考 https://github.com/luuuyi/CBAM.PyTorch</span>
<span class="token keyword">class</span> <span class="token class-name">SpatialAttention</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>SpatialAttention<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">assert</span> kernel_size <span class="token keyword">in</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'kernel size must be 3 or 7'</span>
        padding <span class="token operator">=</span> <span class="token number">3</span> <span class="token keyword">if</span> kernel_size <span class="token operator">==</span> <span class="token number">7</span> <span class="token keyword">else</span> <span class="token number">1</span>

        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> kernel_size<span class="token punctuation">,</span> padding<span class="token operator">=</span>padding<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>sigmoid <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        avg_out <span class="token operator">=</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>x<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        max_out<span class="token punctuation">,</span> _ <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>avg_out<span class="token punctuation">,</span> max_out<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
</code></pre> 
<p><strong>加上注意力机制的HybridSN模型如下：</strong></p> 
<pre><code class="prism language-python">class_num <span class="token operator">=</span> <span class="token number">16</span>
<span class="token keyword">class</span> <span class="token class-name">HybridSN_Attention</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>  
  <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span>class_num<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token builtin">super</span><span class="token punctuation">(</span>HybridSN_Attention<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>conv3d_features <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
        nn<span class="token punctuation">.</span>Conv3d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Conv3d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Conv3d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>
	<span class="token comment"># 通道和空间注意力</span>
    self<span class="token punctuation">.</span>ca <span class="token operator">=</span> ChannelAttention<span class="token punctuation">(</span><span class="token number">32</span> <span class="token operator">*</span> <span class="token number">18</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>sa <span class="token operator">=</span> SpatialAttention<span class="token punctuation">(</span><span class="token punctuation">)</span>

    self<span class="token punctuation">.</span>conv2d_features <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
        nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span> <span class="token operator">*</span> <span class="token number">18</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>

    self<span class="token punctuation">.</span>classifier <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
        nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span> <span class="token operator">*</span> <span class="token number">17</span> <span class="token operator">*</span> <span class="token number">17</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>
 
  <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv3d_features<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">*</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    x <span class="token operator">=</span> self<span class="token punctuation">.</span>ca<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">*</span> x
    x <span class="token operator">=</span> self<span class="token punctuation">.</span>sa<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">*</span> x

    x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2d_features<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
    x <span class="token operator">=</span> self<span class="token punctuation">.</span>classifier<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token keyword">return</span> x
</code></pre> 
<p><strong>加上Batch Normalization、注意力机制的HybridSN模型如下：</strong></p> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">HybridSN_BN_Attention</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>  
  <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span>class_num<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token builtin">super</span><span class="token punctuation">(</span>HybridSN_BN_Attention<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>conv3d_features <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
        nn<span class="token punctuation">.</span>Conv3d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>BatchNorm3d<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Conv3d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>BatchNorm3d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Conv3d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>BatchNorm3d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>

    self<span class="token punctuation">.</span>ca <span class="token operator">=</span> ChannelAttention<span class="token punctuation">(</span><span class="token number">32</span> <span class="token operator">*</span> <span class="token number">18</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>sa <span class="token operator">=</span> SpatialAttention<span class="token punctuation">(</span><span class="token punctuation">)</span>

    self<span class="token punctuation">.</span>conv2d_features <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
        nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span> <span class="token operator">*</span> <span class="token number">18</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>


    self<span class="token punctuation">.</span>classifier <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
        nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span> <span class="token operator">*</span> <span class="token number">17</span> <span class="token operator">*</span> <span class="token number">17</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>
 
  <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv3d_features<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">*</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    x <span class="token operator">=</span> self<span class="token punctuation">.</span>ca<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">*</span> x
    x <span class="token operator">=</span> self<span class="token punctuation">.</span>sa<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">*</span> x

    x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2d_features<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
    x <span class="token operator">=</span> self<span class="token punctuation">.</span>classifier<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token keyword">return</span> x
</code></pre> 
<h3><a id="_286"></a>五、开始实验</h3> 
<p>上面，我共实现了四种HybridSN模型，分别是：</p> 
<ul><li>原始的HybridSN模型</li><li>加上Batch Normalization的HybridSN模型：HybridSN_BN</li><li>加上通道和空间注意力机制的HybridSN模型：HybridSN_Attention</li><li>加上Batch Normalization、通道和空间注意力机制的HybridSN模型：HybridSN_BN_Attention</li></ul> 
<p>下面我将分别用这四种模型测试Indian Pines数据集，并分析结果。(考虑到篇幅，下面我只写出了主要的方法，全部实现过程请看我的colab)</p> 
<h4><a id="51__299"></a>5.1 下载数据集</h4> 
<p>Indian Pines 是最早的用于HSI分类的数据集，该数据集有尺寸为145×145 的空间图像和224个波长范围为400～2500nm的光谱反射谱带，由于第 104~108、150-163 和第 220 个波段不能被水反射，因此一般使用的是剔除了这 20 个波段后剩下的 200 个波段作为测试的对象。该数据集共有16类庄稼，用不同的颜色标出。可通过如下方式下载数据集：</p> 
<pre><code class="prism language-python">! wget http<span class="token punctuation">:</span><span class="token operator">//</span>www<span class="token punctuation">.</span>ehu<span class="token punctuation">.</span>eus<span class="token operator">/</span>ccwintco<span class="token operator">/</span>uploads<span class="token operator">/</span><span class="token number">6</span><span class="token operator">/</span><span class="token number">67</span><span class="token operator">/</span>Indian_pines_corrected<span class="token punctuation">.</span>mat
! wget http<span class="token punctuation">:</span><span class="token operator">//</span>www<span class="token punctuation">.</span>ehu<span class="token punctuation">.</span>eus<span class="token operator">/</span>ccwintco<span class="token operator">/</span>uploads<span class="token operator">/</span>c<span class="token operator">/</span>c4<span class="token operator">/</span>Indian_pines_gt<span class="token punctuation">.</span>mat
! pip install spectral
</code></pre> 
<h4><a id="52_PCA_309"></a>5.2 PCA降维</h4> 
<p>可以把HSI数据立方体表示为<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         I 
        
       
           
        
       
         ∈ 
        
        
        
          R 
         
         
         
           M 
          
         
           × 
          
         
           N 
          
         
           × 
          
         
           D 
          
         
        
       
      
        I\ \in R^{M \times N \times D} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.72243em; vertical-align: -0.0391em;"></span><span class="mord mathdefault" style="margin-right: 0.07847em;">I</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mspace"> </span><span class="mrel">∈</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.841331em; vertical-align: 0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.841331em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.10903em;">M</span><span class="mbin mtight">×</span><span class="mord mathdefault mtight" style="margin-right: 0.10903em;">N</span><span class="mbin mtight">×</span><span class="mord mathdefault mtight" style="margin-right: 0.02778em;">D</span></span></span></span></span></span></span></span></span></span></span></span></span> ，其中<em>I</em>为原始输入，<em>M</em>为宽度，<em>N</em>为高度，<em>D</em>为光谱带数（即深度）。<strong>I</strong>中的每一个HSI像素都包含<em>D个</em>光谱量，并形成一个one-hot 标签向量，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         Y 
        
       
         = 
        
       
         ( 
        
        
        
          y 
         
        
          1 
         
        
       
         , 
        
        
        
          y 
         
        
          2 
         
        
       
         , 
        
       
         ⋯ 
         
       
         , 
        
        
        
          y 
         
        
          C 
         
        
       
         ) 
        
       
         ∈ 
        
        
        
          R 
         
         
         
           1 
          
         
           × 
          
         
           1 
          
         
           × 
          
         
           C 
          
         
        
       
      
        Y = ({<!-- -->{\rm{y}}_1},{<!-- -->{\rm{y}}_2}, \cdots ,{<!-- -->{\rm{y}}_C}) \in {R^{1 \times 1 \times C}} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.22222em;">Y</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord"><span class="mord"><span class="mord"><span class="mord mathrm" style="margin-right: 0.01389em;">y</span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord"><span class="mord"><span class="mord mathrm" style="margin-right: 0.01389em;">y</span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="minner">⋯</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord"><span class="mord"><span class="mord mathrm" style="margin-right: 0.01389em;">y</span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.328331em;"><span class="" style="top: -2.55em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.07153em;">C</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.841331em; vertical-align: 0em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right: 0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.841331em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">×</span><span class="mord mtight">1</span><span class="mbin mtight">×</span><span class="mord mathdefault mtight" style="margin-right: 0.07153em;">C</span></span></span></span></span></span></span></span></span></span></span></span></span></span>，其中，C表示谱带覆盖类别（land-cover categories）。然而，高光谱像素谱带覆盖类别的混合特性，使得类内差异性和类间相似性较高，这对任何模型来说都具有很大的挑战，为了消除光谱冗余，我们采用主成分分析(PCA)的方法将谱带的数量从<em>D</em>减少到<em>B</em>，同时保持相同的空间尺寸（即宽度<em>M</em>和高度<em>N</em>）。因为只减少了光谱带的数量，从而保留了空间信息，这对识别任何物体都是非常重要的。这里将PCA降维后的数据表示为<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         X 
        
       
         ∈ 
        
        
        
          R 
         
         
         
           M 
          
         
           × 
          
         
           N 
          
         
           × 
          
         
           B 
          
         
        
       
      
        X \in {R^{M \times N \times B}} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.72243em; vertical-align: -0.0391em;"></span><span class="mord mathdefault" style="margin-right: 0.07847em;">X</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.841331em; vertical-align: 0em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right: 0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.841331em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.10903em;">M</span><span class="mbin mtight">×</span><span class="mord mathdefault mtight" style="margin-right: 0.10903em;">N</span><span class="mbin mtight">×</span><span class="mord mathdefault mtight" style="margin-right: 0.05017em;">B</span></span></span></span></span></span></span></span></span></span></span></span></span></span>， 其中X为PCA后的修正输入，<em>M</em>为宽度，<em>N</em>为高度，<em>B</em>为PCA后的谱带数。</p> 
<p>为了更好的进行HSI分类，下面将HSI数据立方体划分为一个个小的有重叠的3D-patch，其真值由中心像素的标签决定。对于上面<strong>X</strong>中的3D neighboring patches <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         P 
        
       
         ∈ 
        
        
        
          R 
         
         
         
           S 
          
         
           × 
          
         
           S 
          
         
           × 
          
         
           B 
          
         
        
       
      
        P \in {R^{S \times S \times B}} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.72243em; vertical-align: -0.0391em;"></span><span class="mord mathdefault" style="margin-right: 0.13889em;">P</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.841331em; vertical-align: 0em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right: 0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.841331em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.05764em;">S</span><span class="mbin mtight">×</span><span class="mord mathdefault mtight" style="margin-right: 0.05764em;">S</span><span class="mbin mtight">×</span><span class="mord mathdefault mtight" style="margin-right: 0.05017em;">B</span></span></span></span></span></span></span></span></span></span></span></span></span></span> ，其空间位置的中心为<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         ( 
        
       
         α 
        
       
         , 
        
       
         β 
        
       
         ) 
        
       
      
        (\alpha ,\beta ) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right: 0.0037em;">α</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord mathdefault" style="margin-right: 0.05278em;">β</span><span class="mclose">)</span></span></span></span></span>，覆盖S×S窗口或空间范围和所有<em>B</em>谱段。因此，在位置<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         ( 
        
       
         α 
        
       
         , 
        
       
         β 
        
       
         ) 
        
       
      
        (\alpha ,\beta ) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right: 0.0037em;">α</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord mathdefault" style="margin-right: 0.05278em;">β</span><span class="mclose">)</span></span></span></span></span>处的3D-patch，用<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          P 
         
         
         
           α 
          
         
           , 
          
         
           β 
          
         
        
       
      
        {P_{\alpha ,\beta }} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.969438em; vertical-align: -0.286108em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.336108em;"><span class="" style="top: -2.55em; margin-left: -0.13889em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.0037em;">α</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right: 0.05278em;">β</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span></span></span></span></span></span>表示，涵盖了宽度从<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         α 
        
       
         − 
        
       
         ( 
        
       
         S 
        
       
         − 
        
       
         1 
        
       
         ) 
        
       
         / 
        
       
         2 
        
       
      
        \alpha - (S - 1)/2 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.66666em; vertical-align: -0.08333em;"></span><span class="mord mathdefault" style="margin-right: 0.0037em;">α</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right: 0.05764em;">S</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">1</span><span class="mclose">)</span><span class="mord">/</span><span class="mord">2</span></span></span></span></span> 到 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         α 
        
       
         + 
        
       
         ( 
        
       
         S 
        
       
         − 
        
       
         1 
        
       
         ) 
        
       
         / 
        
       
         2 
        
       
      
        \alpha + (S - 1)/2 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.66666em; vertical-align: -0.08333em;"></span><span class="mord mathdefault" style="margin-right: 0.0037em;">α</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right: 0.05764em;">S</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">1</span><span class="mclose">)</span><span class="mord">/</span><span class="mord">2</span></span></span></span></span> ，高度从<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         β 
        
       
         − 
        
       
         ( 
        
       
         S 
        
       
         − 
        
       
         1 
        
       
         ) 
        
       
         / 
        
       
         2 
        
       
      
        \beta - (S - 1)/2 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.88888em; vertical-align: -0.19444em;"></span><span class="mord mathdefault" style="margin-right: 0.05278em;">β</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right: 0.05764em;">S</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">1</span><span class="mclose">)</span><span class="mord">/</span><span class="mord">2</span></span></span></span></span> 到 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         β 
        
       
         + 
        
       
         ( 
        
       
         S 
        
       
         − 
        
       
         1 
        
       
         ) 
        
       
         / 
        
       
         2 
        
       
      
        \beta + (S - 1)/2 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.88888em; vertical-align: -0.19444em;"></span><span class="mord mathdefault" style="margin-right: 0.05278em;">β</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right: 0.05764em;">S</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">1</span><span class="mclose">)</span><span class="mord">/</span><span class="mord">2</span></span></span></span></span>，以及PCA降维后的数据立方体<em>X</em>的所有<em>B</em>谱段。</p> 
<p>下面是PCA降维及3D-patch的实现过程：</p> 
<pre><code class="prism language-python"><span class="token comment"># 对高光谱数据 X 应用 PCA 变换</span>
<span class="token keyword">def</span> <span class="token function">applyPCA</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> numComponents<span class="token punctuation">)</span><span class="token punctuation">:</span>
    newX <span class="token operator">=</span> np<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>X<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    pca <span class="token operator">=</span> PCA<span class="token punctuation">(</span>n_components<span class="token operator">=</span>numComponents<span class="token punctuation">,</span> whiten<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    newX <span class="token operator">=</span> pca<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>newX<span class="token punctuation">)</span>
    newX <span class="token operator">=</span> np<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>newX<span class="token punctuation">,</span> <span class="token punctuation">(</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> numComponents<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> newX

<span class="token comment"># 对单个像素周围提取 patch 时，边缘像素就无法取了，因此，给这部分像素进行 padding 操作</span>
<span class="token keyword">def</span> <span class="token function">padWithZeros</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> margin<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    newX <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">2</span> <span class="token operator">*</span> margin<span class="token punctuation">,</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">2</span><span class="token operator">*</span> margin<span class="token punctuation">,</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    x_offset <span class="token operator">=</span> margin
    y_offset <span class="token operator">=</span> margin
    newX<span class="token punctuation">[</span>x_offset<span class="token punctuation">:</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> x_offset<span class="token punctuation">,</span> y_offset<span class="token punctuation">:</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> y_offset<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> X
    <span class="token keyword">return</span> newX

<span class="token comment"># 在每个像素周围提取 patch ，然后创建成符合 keras 处理的格式</span>
<span class="token keyword">def</span> <span class="token function">createImageCubes</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> windowSize<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> removeZeroLabels <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 给 X 做 padding</span>
    margin <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token punctuation">(</span>windowSize <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">)</span>
    zeroPaddedX <span class="token operator">=</span> padWithZeros<span class="token punctuation">(</span>X<span class="token punctuation">,</span> margin<span class="token operator">=</span>margin<span class="token punctuation">)</span>
    <span class="token comment"># split patches</span>
    patchesData <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> windowSize<span class="token punctuation">,</span> windowSize<span class="token punctuation">,</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    patchesLabels <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    patchIndex <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> r <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>margin<span class="token punctuation">,</span> zeroPaddedX<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">-</span> margin<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> c <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>margin<span class="token punctuation">,</span> zeroPaddedX<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> margin<span class="token punctuation">)</span><span class="token punctuation">:</span>
            patch <span class="token operator">=</span> zeroPaddedX<span class="token punctuation">[</span>r <span class="token operator">-</span> margin<span class="token punctuation">:</span>r <span class="token operator">+</span> margin <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> c <span class="token operator">-</span> margin<span class="token punctuation">:</span>c <span class="token operator">+</span> margin <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span>   
            patchesData<span class="token punctuation">[</span>patchIndex<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> patch
            patchesLabels<span class="token punctuation">[</span>patchIndex<span class="token punctuation">]</span> <span class="token operator">=</span> y<span class="token punctuation">[</span>r<span class="token operator">-</span>margin<span class="token punctuation">,</span> c<span class="token operator">-</span>margin<span class="token punctuation">]</span>
            patchIndex <span class="token operator">=</span> patchIndex <span class="token operator">+</span> <span class="token number">1</span>
    <span class="token keyword">if</span> removeZeroLabels<span class="token punctuation">:</span>
        patchesData <span class="token operator">=</span> patchesData<span class="token punctuation">[</span>patchesLabels<span class="token operator">&gt;</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
        patchesLabels <span class="token operator">=</span> patchesLabels<span class="token punctuation">[</span>patchesLabels<span class="token operator">&gt;</span><span class="token number">0</span><span class="token punctuation">]</span>
        patchesLabels <span class="token operator">-=</span> <span class="token number">1</span>
    <span class="token keyword">return</span> patchesData<span class="token punctuation">,</span> patchesLabels
<span class="token keyword">def</span> <span class="token function">splitTrainTestSet</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> testRatio<span class="token punctuation">,</span> randomState<span class="token operator">=</span><span class="token number">345</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> test_size<span class="token operator">=</span>testRatio<span class="token punctuation">,</span> random_state<span class="token operator">=</span>randomState<span class="token punctuation">,</span> stratify<span class="token operator">=</span>y<span class="token punctuation">)</span>
    <span class="token keyword">return</span> X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test
</code></pre> 
<p>然后，创建数据集加载类：</p> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">""" Training dataset"""</span>
<span class="token keyword">class</span> <span class="token class-name">TrainDS</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span> 
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span><span class="token builtin">len</span> <span class="token operator">=</span> Xtrain<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>x_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span>Xtrain<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>y_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span>ytrain<span class="token punctuation">)</span>        
    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 根据索引返回数据和对应的标签</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>x_data<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>y_data<span class="token punctuation">[</span>index<span class="token punctuation">]</span>
    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span> 
        <span class="token comment"># 返回文件数据的数目</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span><span class="token builtin">len</span>

<span class="token triple-quoted-string string">""" Testing dataset"""</span>
<span class="token keyword">class</span> <span class="token class-name">TestDS</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span> 
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span><span class="token builtin">len</span> <span class="token operator">=</span> Xtest<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>x_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span>Xtest<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>y_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span>ytest<span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 根据索引返回数据和对应的标签</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>x_data<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>y_data<span class="token punctuation">[</span>index<span class="token punctuation">]</span>
    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span> 
        <span class="token comment"># 返回文件数据的数目</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span><span class="token builtin">len</span>
</code></pre> 
<h4><a id="53__391"></a>5.3 训练模型</h4> 
<p>为了更高效的分析训练结果，我创建了一个训练和测试的方法，然后将上面提到的四种模型作为参数进行训练。</p> 
<p>（1）训练方法</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span><span class="token punctuation">:</span>
  current_loss_his <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
  current_Acc_his <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

  best_net_wts <span class="token operator">=</span> copy<span class="token punctuation">.</span>deepcopy<span class="token punctuation">(</span>net<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
  best_acc <span class="token operator">=</span> <span class="token number">0.0</span>

  criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
  optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span>

  <span class="token comment"># 开始训练</span>
  total_loss <span class="token operator">=</span> <span class="token number">0</span>
  <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
      net<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 将模型设置为训练模式</span>
      <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
          inputs <span class="token operator">=</span> inputs<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
          labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
          <span class="token comment"># 优化器梯度归零</span>
          optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
          <span class="token comment"># 正向传播 +　反向传播 + 优化 </span>
          outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
          loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>
          loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
          optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
          total_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

      net<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>   <span class="token comment"># 将模型设置为验证模式</span>
      current_acc <span class="token operator">=</span> test_acc<span class="token punctuation">(</span>net<span class="token punctuation">)</span>
      current_Acc_his<span class="token punctuation">.</span>append<span class="token punctuation">(</span>current_acc<span class="token punctuation">)</span>

      <span class="token keyword">if</span> current_acc <span class="token operator">&gt;</span> best_acc<span class="token punctuation">:</span>
        best_acc <span class="token operator">=</span> current_acc
        best_net_wts <span class="token operator">=</span> copy<span class="token punctuation">.</span>deepcopy<span class="token punctuation">(</span>net<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

      <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'[Epoch: %d]   [loss avg: %.4f]   [current loss: %.4f]  [current acc: %.4f]'</span> <span class="token operator">%</span><span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> total_loss<span class="token operator">/</span><span class="token punctuation">(</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> current_acc<span class="token punctuation">)</span><span class="token punctuation">)</span>
      current_loss_his<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

  <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Finished Training'</span><span class="token punctuation">)</span>
  <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Best Acc:%.4f"</span> <span class="token operator">%</span><span class="token punctuation">(</span>best_acc<span class="token punctuation">)</span><span class="token punctuation">)</span>

  <span class="token comment"># load best model weights</span>
  net<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>best_net_wts<span class="token punctuation">)</span>

  <span class="token keyword">return</span> net<span class="token punctuation">,</span>current_loss_his<span class="token punctuation">,</span>current_Acc_his

</code></pre> 
<p>（2）测试方法</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">test_acc</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span><span class="token punctuation">:</span>
  count <span class="token operator">=</span> <span class="token number">0</span>
  <span class="token comment"># 模型测试</span>
  <span class="token keyword">for</span> inputs<span class="token punctuation">,</span> _ <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span>
      inputs <span class="token operator">=</span> inputs<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
      outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
      outputs <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
      <span class="token keyword">if</span> count <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
          y_pred_test <span class="token operator">=</span>  outputs
          count <span class="token operator">=</span> <span class="token number">1</span>
      <span class="token keyword">else</span><span class="token punctuation">:</span>
          y_pred_test <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span> <span class="token punctuation">(</span>y_pred_test<span class="token punctuation">,</span> outputs<span class="token punctuation">)</span> <span class="token punctuation">)</span>

  <span class="token comment"># 生成分类报告</span>
  classification <span class="token operator">=</span> classification_report<span class="token punctuation">(</span>ytest<span class="token punctuation">,</span> y_pred_test<span class="token punctuation">,</span> digits<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>
  index_acc <span class="token operator">=</span> classification<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'weighted avg'</span><span class="token punctuation">)</span>
  accuracy <span class="token operator">=</span> classification<span class="token punctuation">[</span>index_acc<span class="token operator">+</span><span class="token number">17</span><span class="token punctuation">:</span>index_acc<span class="token operator">+</span><span class="token number">23</span><span class="token punctuation">]</span>
  <span class="token keyword">return</span> <span class="token builtin">float</span><span class="token punctuation">(</span>accuracy<span class="token punctuation">)</span>
</code></pre> 
<h4><a id="54__468"></a>5.4 可视化结果</h4> 
<p>HybridSN、HybridSN_BN、HybridSN_Attention、HybridSN_BN_Attention的训练结果如下：</p> 
<p>（1）四种模型的Loss下降曲线</p> 
<p><img src="https://images2.imgbox.com/26/c0/JvoSKtpD_o.png" alt="https://gitee.com/wxler/blogimg/raw/master/imgs/20210104232504.png"></p> 
<p>（2）四种模型的Accuracy变化曲线</p> 
<p><img src="https://images2.imgbox.com/e9/d7/WF6JWseV_o.png" alt=""></p> 
<p>（3）四种模型最佳Precision、Recall、F1-Score</p> 
<table><thead><tr><th align="center">模型</th><th align="center">Accuracy</th><th align="center">Recall</th><th align="center">F1-Score</th></tr></thead><tbody><tr><td align="center">HybridSN</td><td align="center">0.9790</td><td align="center">0.9788</td><td align="center">0.9786</td></tr><tr><td align="center">HybridSN_BN</td><td align="center">0.9897</td><td align="center">0.9888</td><td align="center">0.9888</td></tr><tr><td align="center">HybridSN_Attention</td><td align="center">0.9807</td><td align="center">0.9806</td><td align="center">0.9805</td></tr><tr><td align="center">HybridSN_BN_Attention</td><td align="center">0.9885</td><td align="center">0.9884</td><td align="center">0.9884</td></tr></tbody></table> 
<h4><a id="55__491"></a>5.5 分析结论</h4> 
<p>从收敛速度上看，HybridSN_BN和HybridSN_BN_Attention远快于另外两种模型，说明加上Batch Normalization之后，模型的收敛速度大大提升，而HybridSN_BN和HybridSN_BN_Attention的收敛速度几乎一致，说明Attention并没有提升收敛速度的作用。四种模型大约在25个epoch以后就不怎么收敛了，说明HybridSN本身的收敛速度还是很快的，只不过加了BN以后这种效果更明显了。</p> 
<p>从准确度上看，HybridSN_BN、HybridSN_Attention、HybridSN_BN_Attention均高于HybridSN，说明Attention和Batch Normalization都有提升模型分类准确度的作用，相比HybridSN_Attention而言，HybridSN_BN提升的效果更明显，这就说明了BN不仅提升收敛速度方面效果显著，在提升准确度方面也是很不错的。但是，HybridSN_BN_Attention相比HybridSN_BN，无论是Precision、Recall还是F1-Score，都下降了，说明了BN和Attention这两种机制并不搭配，在下面的思考中，我也给出了为什么会出现这种情况个人理解。</p> 
<p>可以看到，HybridSN模型的收敛速度很快，能在25个epoch内实现，准确度也很高，四种模型的准确度都达到了97%以上，说明采用三维和二维卷积的混合网络，是非常有助于解决高光谱图像分类问题的。</p> 
<h3><a id="_501"></a>六、思考</h3> 
<p>（1）二维卷积和三维卷积的区别</p> 
<p>二维卷积是最常见、用途最广泛的卷积，主要用于提取空间特征，对于一张图片来说，可以根据设定的卷积核的不同，提取不同的特征，如数字图像处理中模糊、锐化、去噪操作都是用特定卷积核实现的。在CNN中，二维卷积的卷积核权重是可学习的，再加上激活函数的非线性变换，几乎可以拟合出任何想要的模型。三维卷积的卷积核可以看作一个数据立方体，因此三维卷积处理的对象是一个立方体图像（或其它相似的数据），三维卷积的思想与二维卷积相同，只不过多了一个维度，所以三维卷积不仅提取处理空间特征，也可以提取除了空间特征以外的另一维度的特征。由于高光谱图像不仅有空间信息，还有不同波长的光谱信息，因此使用三维卷积来提取高光谱图像的特征就再好不过了，但是三维卷积有一个致命的缺点，就是计算复杂度太高，参数量也比二维卷积多出了一维维度的倍数，所以采用三维和二维卷积的混合网络即降低了模型的复杂性，也提升了模型的性能。</p> 
<p>（2）为什么Batch Normalization能够加快收敛速度</p> 
<p>Batch Normalization，顾名思义，以进行学习时的batch为单位，按batch进行规范化。具体而言，把每层神经网络任意神经元输入值的分布强行拉回到均值为0方差为1的标准正态分布，用数学式表示的话，如下所示：</p> 
<p><img src="https://images2.imgbox.com/70/23/pebEttxX_o.png" alt="img"></p> 
<p><em>m代表batch的大小，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           μ 
          
         
           B 
          
         
        
       
         μ_B 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.19444em;"></span><span class="mord"><span class="mord mathdefault">μ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.328331em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.05017em;">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>为批处理数据的均值，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           σ 
          
         
           B 
          
         
           2 
          
         
        
       
         σ^2_B 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.08944em; vertical-align: -0.275331em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.814108em;"><span class="" style="top: -2.42467em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.05017em;">B</span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.275331em;"><span class=""></span></span></span></span></span></span></span></span></span></span>为批处理数据的方差。</em></p> 
<p>BN层可以让激活函数(非线性变化函数)的输入数据落入比较敏感的区域，缓解了梯度消失问题，加速了网络收敛速度。同时，BN层将每一个batch的均值与方差引入到网络中，由于每个batch的这两个值都不相同，可看做为训练过程增加了随机噪音，可以起到一定的正则效果，防止过拟合。</p> 
<p>（3）为什么多测试几次网络会发现每次分类的结果都不一样？</p> 
<p>我认为导致网络每次测试的结果都不一样原因是：没有使用net.eval()将模型切换至测试模式。我们知道，dropout的本质通过在学习过程中随机删除神经元，从而每一次都让不同的模型进行学习。比如，以概率 p=0.6 随机将神经元置0，就相当于在10个神经元选4个神经元输出(4个神经元在工作，另外6神经元置0)，这时我们就相当于训练了 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          C 
         
        
          10 
         
        
          4 
         
        
       
      
        C_{10}^4 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.06222em; vertical-align: -0.248108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.814108em;"><span class="" style="top: -2.45189em; margin-left: -0.07153em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">0</span></span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.248108em;"><span class=""></span></span></span></span></span></span></span></span></span></span> 个模型，只是每个模型的参数量更少了。如果测试时仍处理训练模式，那么也会随机将神经元置为0，这就带来了不确定的结果，而在测试模式下，<strong>dropout层会让所有的激活单元都通过</strong>，最后的输出再乘以 (1-p) 作为模型的测试结果，这样得到的数据就是确定的了。同样的，是否处于测试模式也会影响BN层的工作机制，从而影响测试的结果。因此，合理的运用model.train()和model.eval()对测试的结果是至关重要的。</p> 
<p>（4）如果想要进一步提升高光谱图像的分类性能，可以如何使用注意力机制？</p> 
<p>在上述实验中，给HybridSN加上注意力机制后模型的性能有了提升，我也尝试了把注意力机制加在HybridSN模型不同位置上作比较（结果没有在上面呈现），发现把Attention加在第三个三维卷积后，二维卷积之前比加在二维卷积后效果更好。我认为这是因为高光谱图像经过二维卷积之后会损失一部分光谱信息，如果将注意力机制加在二维卷积之后，那么Attention抽取关键信息的效果就不明显了（会忽略少部分光谱信息的关键区域），所以应该把Attention加在第三个三维卷积后，这样会保留更多的光谱信息，从而进一步提升高光谱图像的分类性能。从上面的结果中也看到了，加上Attention之后，模型的Precision、Recall、F1-Score都提升了。</p> 
<p>（5）为什么HybridSN_BN_Attention的性能不如HybridSN_BN？</p> 
<p>我刚开始也很疑惑，为什么两个被公认性能优越的模块加在一起后性能反而下降了呢？我想了很久，得出了自己的一点理解：因为BN是固定每一次输入Batch的分布，把每层神经网络任意神经元输入值的分布强行拉回到均值为0方差为1的标准正态分布，而Attention是为了获取更加显著的区域，经过Attention后显著的区域会变得更为突出，这在一定程度上打乱了原来输入的分布，从这方面来讲，这两个模块似乎是一种相互互斥的存在，效果自然就下降了。这相当于一个精通python的人认为python是世界上最好的语言，而另一个精通java的人认为java是最好世界上的语言，当一个人即会java也会python时，它可能任何一个都不精通。当然，得到这样的结果也可能是如下原因造成：</p> 
<ul><li>由于Indian Pines数据集自身特点，模型对其分类性能的评估并没有广义性，可能在另外一个数据集上BN+Attenion的性能又比只有BN的模型好了</li><li>模型本身的结果可能就存在问题，如果调整一下各个模块的顺序，改变各个模块内卷积核的参数，结果会不会更好呢？</li></ul> 
<p>由于时间原因及个人知识水平的限制，并没有做更多的探索，还望见谅。</p> 
<h3><a id="_540"></a>七、结语</h3> 
<p>HybridSN是一种用于HSI分类的混合网络模型，以三维和二维卷积结合的方式既提升了模型的性能，也降低了复杂度。另外，分别加上BN、Attention之后，模型的性能都有了提升，BN提升更加明显，但是把BN和Attention一起加在HybridSN中，会发现HybridSN_BN_Attention的性能虽然比原始的HybridSN有所提升，但不如HybridSN_BN，我认为这是因为两个模块是一种互斥的存在，从而导致HybridSN_BN的性能降低，上面也给出了自己的解释。这次实验让我学到了很多，不仅熟练掌握了HSI分类，也对BN和Attention的印象更加深刻，更明白了不是所有优秀的模块组合起来就能取得好的结果，只有不断的分析、实践、思考，才能更好的理解其本质。</p> 
<p>最后，附上本文在colab的实现过程：<a href="https://colab.research.google.com/drive/12QbZqcxfplFEm7yp3X9wgi7jYXmqRjz9?usp=sharing" rel="nofollow">https://colab.research.google.com/drive/12QbZqcxfplFEm7yp3X9wgi7jYXmqRjz9?usp=sharing</a></p> 
<p>【参考文档】</p> 
<p><a href="https://ieeexplore.ieee.org/document/8736016" rel="nofollow">HybridSN: Exploring 3-D–2-D CNN Feature Hierarchy for Hyperspectral Image Classification</a></p> 
<p><a href="https://github.com/luuuyi/CBAM.PyTorch">CBAM: Convolutional Block Attention Module</a></p> 
<p><a href="https://blog.csdn.net/qq_38290648/article/details/80596543">高光谱数据集</a></p> 
<p><a href="https://www.sohu.com/a/308158769_394987" rel="nofollow">高光谱图像</a></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/ce92ca48c133b23b48ec64fdf0fe2078/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">差分阻抗为多少_谈谈差分信号</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/4d0ef1cf3e028735b75b8054ce0d9006/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">word页眉前后不一致怎么设置_Word排版到天亮？我有特别的使用技巧！</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程爱好者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151260"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>