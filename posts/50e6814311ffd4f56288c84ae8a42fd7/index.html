<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>大数据培训如何优化HiveSQL - 编程爱好者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="大数据培训如何优化HiveSQL" />
<meta property="og:description" content="Hive作为大数据平台举足轻重的框架，以其稳定性和简单易用性也成为当前构建企业级数据仓库时使用最多的框架之一。
但是如果我们只局限于会使用Hive，而不考虑性能问题，就难搭建出一个完美的数仓，所以Hive性能调优是我们大数据从业者必须掌握的技能。本文将给大家讲解Hive性能调优的一些方法及技巧。
Hive性能调优的方式
为什么都说性能优化这项工作是比较难的，因为一项技术的优化，必然是一项综合性的工作，它是多门技术的结合。我们如果只局限于一种技术，那么肯定做不好优化的。
下面将从多个完全不同的角度来介绍Hive优化的多样性，我们先来一起感受下。
1. SQL语句优化
SQL语句优化涉及到的内容太多，因篇幅有限，不能一一介绍到，所以就拿几个典型举例，让大家学到这种思想，以后遇到类似调优问题可以往这几个方面多思考下。
1. union all
insert into table stu partition(tp)
select s_age,max(s_birth) stat,&#39;max&#39; tp
from stu_ori
group by s_age
union all
insert into table stu partition(tp)
select s_age,min(s_birth) stat,&#39;min&#39; tp
from stu_ori
group by s_age;
我们简单分析上面的SQl语句，就是将每个年龄的最大和最小的生日获取出来放到同一张表中，union all 前后的两个语句都是对同一张表按照s_age进行分组，然后分别取最大值和最小值。对同一张表相同的字段进行两次分组，这造成了极大浪费，我们能不能改造下呢，当然是可以的，为大家介绍一个语法：from ... insert into ... ，这个语法将from前置，作用就是使用一张表，可以进行多次插入操作：
--开启动态分区
set hive.exec.dynamic.partition=true;
set hive.exec.dynamic.partition.mode=nonstrict;
from stu_ori
insert into table stu partition(tp)
select s_age,max(s_birth) stat,&#39;max&#39; tp
group by s_age
insert into table stu partition(tp)" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bchobby.github.io/posts/50e6814311ffd4f56288c84ae8a42fd7/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-07-14T14:02:15+08:00" />
<meta property="article:modified_time" content="2022-07-14T14:02:15+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程爱好者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程爱好者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">大数据培训如何优化HiveSQL</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>Hive作为大数据平台举足轻重的框架，以其稳定性和简单易用性也成为当前构建企业级数据仓库时使用最多的框架之一。</p> 
<p>但是如果我们只局限于会使用Hive，而不考虑性能问题，就难搭建出一个完美的数仓，所以Hive性能调优是我们大数据从业者必须掌握的技能。本文将给大家讲解Hive性能调优的一些方法及技巧。</p> 
<p><strong>Hive性能调优的方式</strong></p> 
<p>为什么都说性能优化这项工作是比较难的，因为一项技术的优化，必然是一项综合性的工作，它是多门技术的结合。我们如果只局限于一种技术，那么肯定做不好优化的。</p> 
<p>下面将从多个完全不同的角度来介绍Hive优化的多样性，我们先来一起感受下。</p> 
<p><strong>1. SQL语句优化</strong></p> 
<p>SQL语句优化涉及到的内容太多，因篇幅有限，不能一一介绍到，所以就拿几个典型举例，让大家学到这种思想，以后遇到类似调优问题可以往这几个方面多思考下。</p> 
<p></p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/5c/f4/pbWDluo0_o.png"></p> 
<p> </p> 
<p><strong>1. union all</strong></p> 
<p>insert into table stu partition(tp)</p> 
<p>select s_age,max(s_birth) stat,'max' tp</p> 
<p>from stu_ori</p> 
<p>group by s_age</p> 
<p>union all</p> 
<p>insert into table stu partition(tp)</p> 
<p>select s_age,min(s_birth) stat,'min' tp</p> 
<p>from stu_ori</p> 
<p>group by s_age;</p> 
<p>我们简单分析上面的SQl语句，就是将每个年龄的最大和最小的生日获取出来放到同一张表中，union all 前后的两个语句都是对同一张表按照s_age进行分组，然后分别取最大值和最小值。对同一张表相同的字段进行两次分组，这造成了极大浪费，我们能不能改造下呢，当然是可以的，为大家介绍一个语法：from ... insert into ... ，这个语法将from前置，作用就是使用一张表，可以进行多次插入操作：</p> 
<p>--开启动态分区</p> 
<p>set hive.exec.dynamic.partition=true;</p> 
<p>set hive.exec.dynamic.partition.mode=nonstrict;</p> 
<p>from stu_ori</p> 
<p>insert into table stu partition(tp)</p> 
<p>select s_age,max(s_birth) stat,'max' tp</p> 
<p>group by s_age</p> 
<p>insert into table stu partition(tp)</p> 
<p>select s_age,min(s_birth) stat,'min' tp</p> 
<p>group by s_age;</p> 
<p>上面的SQL就可以对stu_ori表的s_age字段分组一次而进行两次不同的插入操作。</p> 
<p><strong>这个例子告诉我们一定要多了解SQL语句，如果我们不知道这种语法，一定不会想到这种方式的</strong>。</p> 
<p><strong>2. distinct</strong></p> 
<p>先看一个SQL，去重计数：</p> 
<p>select count(1)</p> 
<p>from(</p> 
<p>select s_age</p> 
<p>from stu</p> 
<p>group by s_age</p> 
<p>) b;</p> 
<p>这是简单统计年龄的枚举值个数，为什么不用distinct？</p> 
<p>select count(distinct s_age)</p> 
<p>from stu;</p> 
<p>有人说因为在数据量特别大的情况下使用第一种方式能够有效避免Reduce端的数据倾斜，但是事实如此吗？</p> 
<p>我们先不管数据量特别大这个问题，<strong>就当前的业务和环境下使用distinct一定会比上面那种子查询的方式效率高</strong>。原因有以下几点：</p> 
<ol><li>上面进行去重的字段是年龄字段，要知道年龄的枚举值是非常有限的，就算计算1岁到100岁之间的年龄，s_age的最大枚举值才是100，如果转化成MapReduce来解释的话，在Map阶段，每个Map会对s_age去重。由于s_age枚举值有限，因而每个Map得到的s_age也有限，最终得到reduce的数据量也就是map数量*s_age枚举值的个数。</li><li>distinct的命令会在内存中构建一个hashtable，查找去重的时间复杂度是O(1)；group by在不同版本间变动比较大，有的版本会用构建hashtable的形式去重，有的版本会通过排序的方式， 排序最优时间复杂度无法到O(1)。另外，第一种方式(group by)去重会转化为两个任务，会消耗更多的磁盘网络I/O资源。</li><li>最新的Hive 3.0中新增了 count(distinct ) 优化，通过配置 hive.optimize.countdistinct，即使真的出现数据倾斜也可以自动优化，自动改变SQL执行的逻辑。</li><li>第二种方式(distinct)比第一种方式(group by)代码简洁，表达的意思简单明了，如果没有特殊的问题，代码简洁就是优！</li></ol> 
<p><strong>这个例子告诉我们，有时候我们不要过度优化，调优讲究适时调优，过早进行调优有可能做的是无用功甚至产生负效应，在调优上投入的工作成本和回报不成正比。调优需要遵循一定的原则</strong>。</p> 
<p><strong>2. 数据格式优化</strong></p> 
<p>Hive提供了多种数据存储组织格式，不同格式对程序的运行效率也会有极大的影响。</p> 
<p>Hive提供的格式有TEXT、SequenceFile、RCFile、ORC和Parquet等。</p> 
<p>SequenceFile是一个二进制key/value对结构的平面文件，在早期的Hadoop平台上被广泛用于MapReduce输出/输出格式，以及作为数据存储格式。</p> 
<p>Parquet是一种列式数据存储格式，可以兼容多种计算引擎，如MapRedcue和Spark等，对多层嵌套的数据结构提供了良好的性能支持，是目前Hive生产环境中数据存储的主流选择之一_<a class="link-info" href="http://www.atguigu.com" rel="nofollow" title="大数据培训">大数据培训</a>。</p> 
<p>ORC优化是对RCFile的一种优化，它提供了一种高效的方式来存储Hive数据，同时也能够提高Hive的读取、写入和处理数据的性能，能够兼容多种计算引擎。事实上，在实际的生产环境中，ORC已经成为了Hive在数据存储上的主流选择之一。</p> 
<p>我们使用同样数据及SQL语句，只是数据存储格式不同，得到如下执行时长：</p> 
<p></p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/0f/4f/YTII6RDm_o.png"></p> 
<p> </p> 
<p>注：CPU时间：表示运行程序所占用服务器CPU资源的时间。<br> 用户等待耗时：记录的是用户从提交作业到返回结果期间用户等待的所有时间。</p> 
<p><strong>查询TextFile类型的数据表CPU耗时33分钟， 查询ORC类型的表耗时1分52秒，时间得以极大缩短，可见不同的数据存储格式也能给HiveSQL性能带来极大的影响。</strong></p> 
<p><strong>3. 小文件过多优化</strong></p> 
<p>小文件如果过多，对 hive 来说，在进行查询时，每个小文件都会当成一个块，启动一个Map任务来完成，而一个Map任务启动和初始化的时间远远大于逻辑处理的时间，就会造成很大的资源浪费。而且，同时可执行的Map数量是受限的。</p> 
<p><strong>4. 并行执行优化</strong></p> 
<p>Hive会将一个查询转化成一个或者多个阶段。这样的阶段可以是MapReduce阶段、抽样阶段、合并阶段、limit阶段。或者Hive执行过程中可能需要的其他阶段。默认情况下，Hive一次只会执行一个阶段。不过，某个特定的job可能包含众多的阶段，而这些阶段可能并非完全互相依赖的，也就是说有些阶段是可以并行执行的，这样可能使得整个job的执行时间缩短。如果有更多的阶段可以并行执行，那么job可能就越快完成。</p> 
<p>通过设置参数hive.exec.parallel值为true，就可以开启并发执行。在共享集群中，需要注意下，如果job中并行阶段增多，那么集群利用率就会增加。</p> 
<p>set hive.exec.parallel=true; //打开任务并行执行</p> 
<p>set hive.exec.parallel.thread.number=16; //同一个sql允许最大并行度，默认为8。</p> 
<p>当然得是在系统资源比较空闲的时候才有优势，否则没资源，并行也起不来。</p> 
<p><strong>5. 数据倾斜优化</strong></p> 
<p>数据倾斜的原理都知道，就是某一个或几个key占据了整个数据的90%，这样整个任务的效率都会被这个key的处理拖慢，同时也可能会因为相同的key会聚合到一起造成内存溢出。</p> 
<p><strong>Hive的数据倾斜一般的处理方案</strong>：</p> 
<p>常见的做法，通过参数调优：</p> 
<p>set hive.map.aggr=true;</p> 
<p>set hive.groupby.skewindata = ture;</p> 
<p>当选项设定为true时，生成的查询计划有两个MapReduce任务。</p> 
<p>在第一个MapReduce中，map的输出结果集合会随机分布到reduce中，每个reduce做部分聚合操作，并输出结果。</p> 
<p>这样处理的结果是，相同的Group By Key有可能分发到不同的reduce中，从而达到负载均衡的目的；</p> 
<p>第二个MapReduce任务再根据预处理的数据结果按照Group By Key分布到reduce中（这个过程可以保证相同的Group By Key分布到同一个reduce中），最后完成最终的聚合操作。</p> 
<p>但是这个处理方案对于我们来说是个黑盒，无法把控。</p> 
<p><strong>那么在日常需求的情况下如何处理这种数据倾斜的情况呢：</strong></p> 
<ol><li>sample采样，获取哪些集中的key；</li><li>将集中的key按照一定规则添加随机数；</li><li>进行join，由于打散了，所以数据倾斜避免了；</li><li>在处理结果中对之前的添加的随机数进行切分，变成原始的数据。</li></ol> 
<p>例：如发现有90%的key都是null，数据量一旦过大必然出现数据倾斜，可采用如下方式：</p> 
<p>SELECT *</p> 
<p>FROM a</p> 
<p>LEFT JOIN b ON CASE</p> 
<p>WHEN a.user_id IS NULL THEN concat('hive_', rand())</p> 
<p>ELSE a.user_id</p> 
<p>END = b.user_id;</p> 
<p><strong>注意</strong>：给null值随机赋的值不要与表中已有的值重复，不然会导致结果错误。</p> 
<p><strong>6. Limit 限制调整优化</strong></p> 
<p>一般情况下，Limit语句还是需要执行整个查询语句，然后再返回部分结果。</p> 
<p>有一个配置属性可以开启，避免这种情况：<strong>对数据源进行抽样</strong>。</p> 
<p><strong>hive.limit.optimize.enable=true</strong> -- 开启对数据源进行采样的功能</p> 
<p><strong>hive.limit.row.max.size</strong> -- 设置最小的采样容量</p> 
<p><strong>hive.limit.optimize.limit.file</strong> -- 设置最大的采样样本数</p> 
<p><strong>缺点</strong>：有可能部分数据永远不会被处理到</p> 
<p><strong>7. JOIN优化</strong></p> 
<p><strong>1. 使用相同的连接键</strong></p> 
<p>当对3个或者更多个表进行join连接时，如果每个on子句都使用相同的连接键的话，那么只会产生一个MapReduce job。</p> 
<p><strong>2. 尽量尽早地过滤数据</strong></p> 
<p>减少每个阶段的数据量,对于分区表要加分区，同时只选择需要使用到的字段。</p> 
<p><strong>3. 尽量原子化操作</strong></p> 
<p>尽量避免一个SQL包含复杂逻辑，可以使用中间表来完成复杂的逻辑。</p> 
<p><strong>8. 谓词下推优化</strong></p> 
<p>Hive中的 Predicate Pushdown 简称谓词下推，简而言之，<strong>就是在不影响结果的情况下，尽量将过滤条件下推到join之前进行</strong>。谓词下推后，过滤条件在map端执行，减少了map端的输出，降低了数据在集群上传输的量，节约了集群的资源，也提升了任务的性能。</p> 
<p>我们看下面这个语句：</p> 
<p>select s1.key, s2.key</p> 
<p>from s1 left join s2</p> 
<p>on s1.key &gt; '2';</p> 
<p>上面是一个Left Join语句，s1是左表，称为保留行表，s2是右表。</p> 
<p><strong>问</strong>：on条件的s1.key &gt; '2' 是在join之前执行还是之后？也就是会不会进行谓词下推?</p> 
<p><strong>答</strong>：不会进行谓词下推，因为s1是保留行表，过滤条件会在join之后执行。</p> 
<p>而下面这个语句：</p> 
<p>select s1.key, s2.key</p> 
<p>from s1 left join s2</p> 
<p>on s2.key &gt; '2';</p> 
<p>s2表不是保留行，所以s2.key&gt;2条件可以下推到s2表中，也就是join之前执行。</p> 
<p>再看下面这个语句：</p> 
<p>select s1.key, s2.key</p> 
<p>from s1 left join s2</p> 
<p>where s1.key &gt; '2';</p> 
<p>右表s2为NULL补充表。</p> 
<p>s1不是NULL补充表，所以s1.key&gt;2可以进行谓词下推。</p> 
<p>而下面语句：</p> 
<p>select s1.key, s2.key</p> 
<p>from s1 left join s2</p> 
<p>where s2.key &gt; '2';</p> 
<p>由于s2为NULL补充表，所以s2.key&gt;2过滤条件不能下推。</p> 
<p>那么谓词下推的规则是什么，到底什么时候会进行下推，什么时候不会下推，<strong>总结了下面的一张表，建议收藏保存</strong>：</p> 
<p></p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/0b/3b/GfbvehEQ_o.png"></p> 
<p> </p> 
<p><strong>案例</strong>：</p> 
<p>select a.*</p> 
<p>from a</p> 
<p>left join b on a.uid = b.uid</p> 
<p>where a.ds='2020-08-10'</p> 
<p>and b.ds='2020-08-10'</p> 
<p><strong>上面这个SQL主要犯了两个错误</strong>：</p> 
<p>1.右表(上方b表)的where条件写在join后面，会导致先全表关联在过滤分区。</p> 
<p>注：虽然a表的where条件也写在join后面，但是a表会进行谓词下推，也就是先执行where条件，再执行join，但是b表不会进行谓词下推！</p> 
<p>2.on的条件没有过滤null值的情况，如果两个数据表存在大批量null值的情况，会造成数据倾斜。</p> 
<p><strong>最后</strong></p> 
<p>代码优化原则：</p> 
<ul><li>理透需求原则，这是优化的根本；</li><li>把握数据全链路原则，这是优化的脉络；</li><li>坚持代码的简洁原则，这让优化更加简单；</li><li>没有瓶颈时谈论优化，这是自寻烦恼。</li></ul> 
<p><span style="color:#d7d8d9;">文章来源于数据管道</span></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/51fa51c23909cefa15401349f6b5eda8/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">vue 一键点击下载对应图片</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/9cd511f5aa46d563dd332267f7f91804/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">如何在PD虚拟机中开启系统的嵌套虚拟化功能？</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程爱好者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151260"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>