<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>理清GPU、CUDA、CUDA Toolkit、cuDNN关系以及下载安装 - 编程爱好者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="理清GPU、CUDA、CUDA Toolkit、cuDNN关系以及下载安装" />
<meta property="og:description" content="介于在服务器上安装Nvidia、CUDA、cuDNN等等，对各自的概念以及它们之间存在的关系一直不够清晰，借此机会，整理相关内容于此，若有错误望指正，评论多交流
目录 GPU显卡驱动DriverCUDACUDA ToolkitNVCCcuDNNCUDA Toolkit和 显卡驱动 的版本对应CUDA / CUDA Toolkit和cuDNN的版本对应显卡驱动程序的选择nvidia-smi 和 nvcc 结果的版本为何不一致使用conda命令安装pytorch时候cudatoolkit的版本是哪个？CUDA多版本切换/管理方式写在最后（一定要看嗷！） GPU 显卡是我们平时说的GPU，现在大多数的电脑使用NVIDIA公司生产的显卡；常见的型号有Tesla V100，GTX950M，GTX1050TI，GTX1080等。
显卡驱动Driver 特指NVIDIA的显卡驱动程序。
CUDA CUDA是显卡厂商NVIDIA推出的运算平台。CUDA™是一种由NVIDIA推出的通用并行计算架构，是一种并行计算平台和编程模型，该架构使GPU能够解决复杂的计算问题。CUDA英文全称是Compute Unified Device Architecture。
有人说：CUDA是一门编程语言，像C,C&#43;&#43;,python 一样，也有人说CUDA是API。
官方说：CUDA是一个并行计算平台和编程模型，能够使得使用GPU进行通用计算变得简单和优雅。
运行CUDA应用程序要求系统至少具有一个具有CUDA功能的GPU和与CUDA Toolkit兼容的驱动程序。
查看CUDA版本命令：nvcc -V 或nvcc --version或cat /usr/local/cuda/version.txt
需要知道：CUDA和CUDA Driver显卡驱动不是一一对应的，比如同一台电脑上可同时安装CUDA 9.0、CUDA 9.2、CUDA 10.0等版本。
CUDA Toolkit CUDA工具包的主要包含了CUDA-C和CUDA-C&#43;&#43;编译器、一些科学库和实用程序库、CUDA和library API的代码示例、和一些CUDA开发工具。（通常在安装CUDA Toolkit的时候会默认安装CUDA Driver；但是我们经常只安装CUDA Driver，没有安装CUDA Toolkit，因为有时不一定用到CUDA Toolkit；比如我们的笔记本电脑，安装个CUDA Driver就可正常看视频、办公和玩游戏了）
详细内容见NVIDIA官方
NVCC NVCC就是CUDA的编译器,可以从CUDA Toolkit的/bin目录中获取,类似于gcc就是c语言的编译器。由于程序是要经过编译器编程成可执行的二进制文件，而cuda程序有两种代码，一种是运行在cpu上的host代码，一种是运行在gpu上的device代码，所以nvcc编译器要保证两部分代码能够编译成二进制文件在不同的机器上执行。
cuDNN cuDNN的全称为NVIDIA CUDA® Deep Neural Network library，是NVIDIA专门针对深度神经网络中的基础操作而设计基于GPU的加速库。cuDNN为深度神经网络中的标准流程提供了高度优化的实现方式，例如convolution、pooling、normalization以及activation layers的前向以及后向过程。
CUDA这个平台一开始并没有安装cuDNN库，当开发者们需要用到深度学习GPU加速时才安装cuDNN库，工作速度相较CPU快很多。
CUDNN是基于CUDA的深度学习GPU加速库，有了它才能在GPU上完成深度学习的计算；
来自知乎的解释：CUDA看作是一个工作台，上面配有很多工具，如锤子、螺丝刀等。cuDNN是基于CUDA的深度学习GPU加速库，有了它才能在GPU上完成深度学习的计算。它就相当于工作的工具，比如它就是个扳手。但是CUDA这个工作台买来的时候，并没有送扳手。想要在CUDA上运行深度神经网络，就要安装cuDNN，就像你想要拧个螺帽就要把扳手买回来。这样才能使GPU进行深度神经网络的工作，工作速度相较CPU快很多。
基本上所有的深度学习框架都支持cuDNN这一加速工具，例如：Caffe、Caffe2、TensorFlow、Torch、Pytorch、Theano等。
Caffe可以通过修改Makefile.config中的相应选项来修改是否在编译Caffe的过程中编译cuDNN，如果没有编译cuDNN的话，执行一些基于Caffe这一深度学习框架的程序速度上要慢3-5倍（Caffe官网上说不差多少，明明差很多嘛）。Caffe对cuDNN的版本不是很严格，只要大于cuDNN 4就可以。
查看cuDNN版本：cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bchobby.github.io/posts/52cb2c897af06e1237695be5b28bcb2c/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-05-09T20:15:41+08:00" />
<meta property="article:modified_time" content="2023-05-09T20:15:41+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程爱好者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程爱好者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">理清GPU、CUDA、CUDA Toolkit、cuDNN关系以及下载安装</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>介于在服务器上安装Nvidia、CUDA、cuDNN等等，对各自的概念以及它们之间存在的关系一直不够清晰，借此机会，整理相关内容于此，若有错误望指正，评论多交流<br> </p> 
<div class="toc"> 
 <h4>目录</h4> 
 <ul><li><ul><li><a href="#GPU_2" rel="nofollow">GPU</a></li><li><a href="#Driver_5" rel="nofollow">显卡驱动Driver</a></li><li><a href="#CUDA_8" rel="nofollow">CUDA</a></li><li><a href="#CUDA_Toolkit_18" rel="nofollow">CUDA Toolkit</a></li><li><a href="#NVCC_22" rel="nofollow">NVCC</a></li><li><a href="#cuDNN_24" rel="nofollow">cuDNN</a></li><li><a href="#CUDA_Toolkit___36" rel="nofollow">CUDA Toolkit和 显卡驱动 的版本对应</a></li><li><a href="#CUDA__CUDA_ToolkitcuDNN_56" rel="nofollow">CUDA / CUDA Toolkit和cuDNN的版本对应</a></li><li><a href="#_65" rel="nofollow">显卡驱动程序的选择</a></li><li><a href="#nvidiasmi__nvcc__72" rel="nofollow">nvidia-smi 和 nvcc 结果的版本为何不一致</a></li><li><a href="#condapytorchcudatoolkit_87" rel="nofollow">使用conda命令安装pytorch时候cudatoolkit的版本是哪个？</a></li><li><a href="#CUDA_111" rel="nofollow">CUDA多版本切换/管理方式</a></li><li><a href="#_130" rel="nofollow">写在最后（一定要看嗷！）</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h3><a id="GPU_2"></a>GPU</h3> 
<p>显卡是我们平时说的GPU，现在大多数的电脑使用NVIDIA公司生产的显卡；常见的型号有Tesla V100，GTX950M，GTX1050TI，GTX1080等。</p> 
<h3><a id="Driver_5"></a>显卡驱动Driver</h3> 
<p>特指NVIDIA的显卡驱动程序。</p> 
<h3><a id="CUDA_8"></a>CUDA</h3> 
<p>CUDA是显卡厂商NVIDIA推出的运算平台。CUDA™是一种由NVIDIA推出的通用并行计算架构，是一种并行计算平台和编程模型，该架构使GPU能够解决复杂的计算问题。CUDA英文全称是Compute Unified Device Architecture。</p> 
<blockquote> 
 <p>有人说：CUDA是一门编程语言，像C,C++,python 一样，也有人说CUDA是API。<br> 官方说：CUDA是一个并行计算平台和编程模型，能够使得使用GPU进行通用计算变得简单和优雅。<br> 运行CUDA应用程序要求系统至少具有一个具有CUDA功能的GPU和与CUDA Toolkit兼容的驱动程序。<br> 查看CUDA版本命令：<code>nvcc -V</code> 或<code>nvcc --version</code>或<code>cat /usr/local/cuda/version.txt</code></p> 
</blockquote> 
<p><strong>需要知道：CUDA和CUDA Driver显卡驱动不是一一对应的，比如同一台电脑上可同时安装CUDA 9.0、CUDA 9.2、CUDA 10.0等版本。</strong></p> 
<h3><a id="CUDA_Toolkit_18"></a>CUDA Toolkit</h3> 
<p>CUDA工具包的主要包含了CUDA-C和CUDA-C++编译器、一些科学库和实用程序库、CUDA和library API的代码示例、和一些CUDA开发工具。（通常在安装CUDA Toolkit的时候会默认安装CUDA Driver；但是我们经常只安装CUDA Driver，没有安装CUDA Toolkit，因为有时不一定用到CUDA Toolkit；比如我们的笔记本电脑，安装个CUDA Driver就可正常看视频、办公和玩游戏了）<br> 详细内容见<a href="https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html#major-components" rel="nofollow">NVIDIA官方</a></p> 
<h3><a id="NVCC_22"></a>NVCC</h3> 
<p>NVCC就是CUDA的编译器,可以从CUDA Toolkit的/bin目录中获取,类似于gcc就是c语言的编译器。由于程序是要经过编译器编程成可执行的二进制文件，而cuda程序有两种代码，一种是运行在cpu上的host代码，一种是运行在gpu上的device代码，所以nvcc编译器要保证两部分代码能够编译成二进制文件在不同的机器上执行。</p> 
<h3><a id="cuDNN_24"></a>cuDNN</h3> 
<p>cuDNN的全称为NVIDIA CUDA® Deep Neural Network library，是NVIDIA专门针对深度神经网络中的基础操作而设计基于GPU的加速库。cuDNN为深度神经网络中的标准流程提供了高度优化的实现方式，例如convolution、pooling、normalization以及activation layers的前向以及后向过程。<br> CUDA这个平台一开始并没有安装cuDNN库，当开发者们需要用到深度学习GPU加速时才安装cuDNN库，工作速度相较CPU快很多。</p> 
<blockquote> 
 <p>CUDNN是基于CUDA的深度学习GPU加速库，有了它才能在GPU上完成深度学习的计算；<br> <strong>来自知乎的解释：CUDA看作是一个工作台，上面配有很多工具，如锤子、螺丝刀等。cuDNN是基于CUDA的深度学习GPU加速库，有了它才能在GPU上完成深度学习的计算。它就相当于工作的工具，比如它就是个扳手。但是CUDA这个工作台买来的时候，并没有送扳手。想要在CUDA上运行深度神经网络，就要安装cuDNN，就像你想要拧个螺帽就要把扳手买回来。这样才能使GPU进行深度神经网络的工作，工作速度相较CPU快很多。</strong><br> 基本上所有的深度学习框架都支持cuDNN这一加速工具，例如：Caffe、Caffe2、TensorFlow、Torch、Pytorch、Theano等。<br> Caffe可以通过修改Makefile.config中的相应选项来修改是否在编译Caffe的过程中编译cuDNN，如果没有编译cuDNN的话，执行一些基于Caffe这一深度学习框架的程序速度上要慢3-5倍（Caffe官网上说不差多少，明明差很多嘛）。Caffe对cuDNN的版本不是很严格，只要大于cuDNN 4就可以。<br> 查看cuDNN版本：<code>cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2</code></p> 
</blockquote> 
<hr> 
<h3><a id="CUDA_Toolkit___36"></a>CUDA Toolkit和 显卡驱动 的版本对应</h3> 
<p>每个版本的CUDA Toolkit 都对应一个最低版本的显卡驱动版本（CUDA Driver），详情见下表。<a href="https://www.nvidia.com/Download/index.aspx" rel="nofollow">显卡驱动下载</a>，<a href="https://developer.nvidia.com/CUDA-TOOLKIT-ARCHIVE" rel="nofollow">CUDA Toolkit下载</a>，<a href="https://blog.csdn.net/qq_30163461/article/details/80314630">显卡驱动安装教程</a>，<a href="https://zhuanlan.zhihu.com/p/47330858" rel="nofollow">CUDA Toolkit安装教程1</a>，<a href="https://blog.csdn.net/wf19930209/article/details/81879514">CUDA Toolkit安装教程2</a></p> 
<blockquote> 
 <p>安装CUDA Driver核心命令：<code>sudo sh ./NVIDIA-Linux-x86_64-???.??.run</code><br> 详细教程参考其他博客</p> 
</blockquote> 
<p><strong>需要知道：CUDA Toolkit和显卡驱动有版本的对应关系。<br> 但同时：在同一台机器上（即同一个CUDA Driver版本）可以安装多个版本的CUDA（如CUDA 9.0、CUDA 10.1……只需要满足当前CUDA Driver版本支持安装的CUDA版本即可，满足关系见下图。</strong></p> 
<p><strong>我的理解：安装CUDA就是安装CUDA Toolkit（CUDA是运算平台名称、CUDA Toolkit是工具包），就是从官网下载CUDA Toolkit安装.run文件（如cuda_9.0.176_384.81_linux.run）进行安装。<br> 安装成功后，在/usr/local路径下才会有cuda-9.0文件夹，且同时才可以使用<code>nvcc -V</code>可以查询到CUDA版本</strong><img src="https://images2.imgbox.com/fe/fc/hfk7q1A6_o.png" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p><a href="https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html" rel="nofollow">上图的官方文档</a></p> 
</blockquote> 
<ul><li>Anaconda在安装Pytorch时，会同时用户安装cudatoolkit，如命令<code>conda install pytorch torchvision torchaudio cudatoolkit=10.1 -c pytorch</code>，其主要包含应用程序在使用CUDA相关的功能时所依赖的动态链接库。conda安装只会安装一些计算库，不会安装编译工具。而官方的cuda包包含的东西会完整一些。</li><li>使用 Anaconda 安装的 CUDA Toolkit 不位于 lib64 路径中，也不会产生冲突</li><li>在考虑<code>pip install tensorflow-gpu</code>安装tensorflow时，如安装TensorFlow2.1，需要安装CUDA Toolkit版本为10.1，而安装Tensorflow1.14.0，则要求cuda==10.0（tensorflow与cuda也有版本兼容问题，<a href="https://tensorflow.google.cn/install/source#linux" rel="nofollow">官方文档</a>）<br> 查询上图，我们发现需要显卡驱动版本应该大于等于418.96，故系统中的显卡驱动版本应该至少为418.39。</li><li><strong>CUDA Toolkit本地安装包(local)内含特定版本Nvidia显卡驱动的，当在CUDA官网下载CUDA Toolkit后进行安装时会让用户选择安装项。</strong></li><li><strong>如果想安装其他版本的显卡驱动，则就需要在Nvidia官网自己下载并先安装好（或本机已经安装了合适版本的显卡驱动时），最后在安装CUDA Toolkit时取消安装内置版本的Nvidia显卡驱动。</strong></li></ul> 
<hr> 
<h3><a id="CUDA__CUDA_ToolkitcuDNN_56"></a>CUDA / CUDA Toolkit和cuDNN的版本对应</h3> 
<p><strong>CUDA / CUDA Toolkit和cuDNN之间有版本对应关系。<br> 但同时：同一个CUDA 版本支持安装多个版本的cuDNN（如cuDNN v7.6.4、cuDNN v7.6.3……选择其一安装即可。</strong><a href="https://developer.nvidia.com/rdp/cudnn-archive" rel="nofollow">cuDNN下载</a>，<a href="https://blog.csdn.net/kingfoulin/article/details/98872965">cuDNN下载安装教程</a></p> 
<ul><li>查阅cuDNN下载网站，可以知道，如果目前电脑中安装了CUDA Toolkit=10.1（也就是CUDA10.1），那么cuDNN的可选版本有7.6.4、7.6.3、7.6.2<br> 同上，如需要安装TensorFlow2.1，故我们需要安装CUDA Toolkit=10.1，同时cuDNN就需要从7.6.4、7.6.3、7.6.2这三个版本中选择。</li></ul> 
<hr> 
<h3><a id="_65"></a>显卡驱动程序的选择</h3> 
<p><img src="https://images2.imgbox.com/0d/f1/1bEek3gN_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/cf/5d/p7ilYX63_o.png" alt="在这里插入图片描述"><br> 可以查看所下载的驱动版本支持的GPU版本：<br> <img src="https://images2.imgbox.com/48/c1/frKIqfk1_o.png" alt="在这里插入图片描述"></p> 
<hr> 
<h3><a id="nvidiasmi__nvcc__72"></a>nvidia-smi 和 nvcc 结果的版本为何不一致</h3> 
<p>首先需要知道，两者不是必须一致<br> <img src="https://images2.imgbox.com/59/2c/PDlnSyeH_o.png" alt="在这里插入图片描述"><br> CUDA 有两种API，分别是运行时API和驱动API：Runtime API 与 Driver API。<br> <strong>nvidia-smi是 CUDA Driver API（驱动API）的版本，也是当前驱动支持的最高CUDA版本</strong>，如在这里是10.0。<br> 而<strong>nvcc的结果是对应 CUDA Runtime API（运行API）的版本</strong>：<br> <img src="https://images2.imgbox.com/8b/7d/PXUJbwIJ_o.png" alt="在这里插入图片描述"><br> <strong>每个CUDA的版本（指上文介绍安装的cudatoolkit）会要求一个最低的显卡驱动版本；而显卡驱动会提供一个最高支持的CUDA 版本。</strong></p> 
<blockquote> 
 <p>https://blog.csdn.net/ljp1919/article/details/102640512<br> https://blog.csdn.net/qxqxqzzz/article/details/103453413<br> https://forums.developer.nvidia.com/t/cuda-driver-version-9-0-cuda-runtime-version-8-0/60139<br> https://stackoverflow.com/questions/53422407/different-cuda-versions-shown-by-nvcc-and-nvidia-smi<br> https://www.cnblogs.com/yhjoker/p/10972795.html<br> https://zhuanlan.zhihu.com/p/91334380</p> 
</blockquote> 
<hr> 
<h3><a id="condapytorchcudatoolkit_87"></a>使用conda命令安装pytorch时候cudatoolkit的版本是哪个？</h3> 
<p><strong>答：</strong> 我们只需要根据项目代码要求来确定cudaoolkit包的版本，安装相应的pytorch即可，如算法需要cuda10.2，那么就可以<code>conda install pytorch torchvision cudatoolkit=10.2 -c pytorch</code>。<br> 上述命令在使conda安装torch时候，会提供一个cudatoolkit工具包，其中包含了CUDA的运行API(主要是一些动态链接库文件libXXXX.so.xxx等)，在运行基于pytorch的代码时会使用conda提供的cudatoolkit包，而忽视Nvidia官方的CUDA Toolkit。这也就是为什么有时候我们通过<code>nvcc -V</code>查看的CUDA运行API版本很低(比如7.5)，但是能成功运行cuda9.0的pytorch的原因。<br> <strong>但是需要注意：</strong> 如果项目代码需要使用<code>python setup.py develop</code>或<code>./make.sh</code>来编译依赖cuda的torch模块(如C语言脚本)时候，这个时候可能会导致错误，错误原因是编译过程使用的是系统自带的CUDA而不是conda安装的CUDA包，当系统自带CUDA版本不支持项目代码时，会引发一些奇怪的问题，所以最好的办法是保持conda安装的cudatoolkit版本与系统自带版本(<code>nvcc -V</code>查看)一致。<br> 那么可能就有人要问了，“不能编译的时候调用conda安装pytorch时附带安装的cudatoolkit吗？”答案是往往不行，因为conda只安装上了部分动态链接文件，只占Nvidia官方CUDA的一小部分，且没有安装开发工具包和驱动程序，而往往编译过程需要依赖其他头文件等，conda安装的cudatoolkit不具备这些头文件等，故不行。<br> 办法也只能是自行安装一个新版本CUDA，具体过程见上文，多版本CUDA管理见下文。</p> 
<p><strong>pytorch寻找可用CUDA的路径：</strong><br> 1、环境变量CUDA_HOME 或 CUDA_PATH<br> 2、/usr/local/cuda<br> 3、which nvcc的上级目录<br> 4、如果上述都没有结果，则torch.utils.cpp_extension.CUDA_HOME为None，会使用conda安装的cudatoolkit，其路径为cudart 库文件目录的上级目录。</p> 
<pre><code># pytorch 实际使用的运行时的 CUDA 目录
import torch.utils.cpp_extension
torch.utils.cpp_extension.CUDA_HOME  #会打印出CUDA的目录，如 /usr/local/cuda

# 编译时使用的 cuda 版本
import torch
torch.version.cuda  # 就是conda环境中安装pytorch时候安装的cuda版本
</code></pre> 
<hr> 
<h3><a id="CUDA_111"></a>CUDA多版本切换/管理方式</h3> 
<p>当本机上安装有多个版本cuda时可以通过一下步骤进行管理/版本切换，比如我们要切换使用cuda9.1：<br> sudo vim ~/.bashrc加入以下的内容：</p> 
<pre><code class="prism language-bash"><span class="token builtin class-name">export</span> <span class="token assign-left variable">LD_LIBRARY_PATH</span><span class="token operator">=</span><span class="token variable">$LD_LIBRARY_PATH</span>:/usr/local/cuda/lib64
<span class="token builtin class-name">export</span> <span class="token assign-left variable"><span class="token environment constant">PATH</span></span><span class="token operator">=</span><span class="token environment constant">$PATH</span>:/usr/local/cuda/bin
<span class="token builtin class-name">export</span> <span class="token assign-left variable">CUDA_HOME</span><span class="token operator">=</span><span class="token variable">$CUDA_HOME</span>:/usr/local/cuda
</code></pre> 
<p>修改完毕保存，<code>source ~/.bashrc</code></p> 
<pre><code class="prism language-bash"><span class="token function">sudo</span> <span class="token function">rm</span> -rf /usr/local/cuda <span class="token comment"># 删除旧版本的软连接</span>
<span class="token function">sudo</span> <span class="token function">ln</span> -s /usr/local/cuda-9.1 /usr/local/cuda <span class="token comment"># 建立新版本的软连接</span>
                                              <span class="token comment"># 前面的路径是需要的版本的cuda的安装路径。</span>
</code></pre> 
<p>之后再使用nvcc -V查看cuda版本，如<br> <img src="https://images2.imgbox.com/f2/aa/O7S4MFBs_o.png" alt=""></p> 
<hr> 
<h3><a id="_130"></a>写在最后（一定要看嗷！）</h3> 
<ul><li><code>conda search 【package_name】 --info</code> 或 <code>anaconda search -t conda 【package_name】</code>这个命令可以查看当前源可下载安装的包的版本+平台等信息。</li><li>在安装pytorch的时常用命令<code>conda install pytorch=x torvhsion=x cudatoolkit=10.1 -c pytorch</code>中的<code>-c</code>的含义是指定搜索程序包的其他通道。Navigator和conda查找包的位置，如果希望从默认通道以外的其他通道安装，则要使用-c指定具体通道，默认为http://conda.anaconda.org/.。所以上述安装pytorch的命令中<code>-c</code>的意义是指定从torch官方的渠道进行下载，而不使用默认渠道。<br> <mark>另外</mark>：博主遇到了以下情况：<br> 使用<code>conda install pytorch=1.8.0 torchvision=0.9.0 cudatoolkit=10.1 -c torch</code>会报找不到目标资源，进而无法安装；而<code>conda install pytorch=1.8.0 torchvision=0.9.0 cudatoolkit=10.1 -c pytorch</code>可以找到目标资源并成功安装。</li><li>在安装Nvidia驱动时，可能会遇到gcc版本过高或较低的问题，可以参考其他文章安装合适版本的gcc，<a href="http://ftp.gnu.org/gnu/gcc/" rel="nofollow">gcc镜像下载</a>，<a href="https://blog.csdn.net/u011622208/article/details/102542268#comments_13740667">gcc5.4安装教程</a>。</li><li>cmake下载源：<a href="https://cmake.org/files/" rel="nofollow">https://cmake.org/files/</a>。安装教程见下方：<a href="https://blog.csdn.net/zhangyuexiang123/article/details/86123526">教程</a></li></ul> 
<pre><code>tar xzvf cmake-3.11.2.tar.gz
sudo apt-get install gcc   # 确认是否安装好
sudo apt-get install g++  # 确认是否安装好
cd  cmake-3.11.2
sudo ./bootstrap
sudo make
sudo make install
</code></pre> 
<ul><li>执行<code>conda install tensorflow-gpu=xx</code>会自动安装cudatoolkit和cudnn。</li><li>以深度学习为例，当网络模型依赖CUDA时，可以直接用conda安装CUDA(这里安装的只是CUDA的部分，只有部分动态链接库)，如<code>conda install cudatoolkit==XXX</code>，无需安装从 nvidia 官网下载cuda 安装包（但这样做需要确保GPU显卡驱动是已经安装好的）。<br> <a href="https://blog.csdn.net/qq_43705697/article/details/121618276?spm=1001.2101.3001.6661.1&amp;utm_medium=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-121618276-blog-109895048.pc_relevant_default&amp;depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-121618276-blog-109895048.pc_relevant_default&amp;utm_relevant_index=1">conda虚拟环境单独安装cuda和cudnn教程</a></li><li><mark>好用的源</mark>，可以自主选择torch+cuda版本下载并本地安装<code>pip install xxx.whl</code> (并且强烈建议再加上<code>--no-deps</code>来取消依赖项检查)：<br> torch+cuda.whl：<code>https://download.pytorch.org/whl/torch_stable.html</code><br> torch_scatter、torch_spline_conv、torch_sparse、torch_cluster：<code>https://data.pyg.org/whl/</code>（需要根据环境中已安装好的torch-cuda版本进行选择）</li><li>关于安装pytorch和torchvision，安装指定版本的pytorch可以使用<code>conda install pytorch==XXXX</code>，同样经常用到的torchvision也可以用conda安装，需要注意torch、torchvision和python三者间有个版本对应关系，见下表或<a href="https://pytorch.org/get-started/previous-versions/" rel="nofollow">pytorch-previous-version安装</a>。</li><li>pytorch官方文档：<a href="https://pytorch.org/docs/1.8.0/" rel="nofollow">https://pytorch.org/docs/1.8.0/</a></li></ul> 
<table><thead><tr><th>pytorch</th><th>torchvision</th><th>python</th><th>cuda</th></tr></thead><tbody><tr><td>1.8.0</td><td>0.9.0</td><td>&gt;=3.6</td><td>10.2,11.1</td></tr><tr><td>1.7.1</td><td>0.8.2</td><td>&gt;=3.6</td><td>9.2, 10.1,10.2,11.0</td></tr><tr><td>1.7.0</td><td>0.8.0</td><td>&gt;=3.6</td><td>9.2, 10.1,10.2,11.0</td></tr><tr><td>1.6.0</td><td>0.7.0</td><td>&gt;=3.6</td><td>9.2, 10.1,10.2</td></tr><tr><td>1.5.1</td><td>0.6.1</td><td>&gt;=3.5</td><td>9.2, 10.1,10.2</td></tr><tr><td>1.5.0</td><td>0.6.0</td><td>&gt;=3.5</td><td>9.2, 10.1,10.2</td></tr><tr><td>1.4.0</td><td>0.5.0</td><td>==2.7, &gt;=3.5, &lt;=3.8</td><td>9.2, 10.0</td></tr><tr><td>1.3.1</td><td>0.4.2</td><td>==2.7, &gt;=3.5, &lt;=3.7</td><td>9.2, 10.0</td></tr><tr><td>1.3.0</td><td>0.4.1</td><td>==2.7, &gt;=3.5, &lt;=3.7</td><td>9.2, 10.0</td></tr><tr><td>1.2.0</td><td>0.4.0</td><td>==2.7, &gt;=3.5, &lt;=3.7</td><td>9.2, 10.0</td></tr><tr><td>1.1.0</td><td>0.3.0</td><td>==2.7, &gt;=3.5, &lt;=3.7</td><td>9.0, 10.0</td></tr><tr><td>&lt;=1.0.1</td><td>0.2.2</td><td>==2.7, &gt;=3.5, &lt;=3.7</td><td>9.0, 10.0</td></tr></tbody></table> 
<ul><li>显卡算力查询：<a href="https://developer.nvidia.com/cuda-gpus" rel="nofollow">https://developer.nvidia.com/cuda-gpus</a>，再根据下表选择安装哪一cuda版本的pytorch，从而尽可能的榨取GPU算力。<br> <img src="https://images2.imgbox.com/64/ac/5STRcxGu_o.png" alt="图片来自维基百科"></li></ul> 
<p>代求证：<br> <mark>conda install pytorch安装的是torch CPU版本，conda install pytorch torchvision -c pytorch安装的是GPU版本</mark><br> <mark>切换CUDA版本不用增删动态链接库，而是使用 LD_LIBRARY_PATH 来控制适用不同版本的 CUDA runtime。 anaconda 也是用 LD_LIBRARY_PATH 来控制CUDA版本的</mark><br> <mark>在使用 CMake 等编译和运行的过程中，可以根据 CUDA_PATH 这个环境变量选择CUDA 版本，而不需要删除、创建软连接</mark></p> 
<p>更多详情见：<a href="https://zhuanlan.zhihu.com/p/91334380" rel="nofollow">知乎专栏</a></p> 
<p>对网络上一些言语若有疑问，欢迎在评论区交流 [抱拳][抱拳][抱拳]</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/a86d90672e833de374afd21341ee8190/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">如何写好日常代码以及一些常见的坑</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/b660f82b244c6aa77e68e13aafa8b1eb/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">贪吃蛇的实现—C语言</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程爱好者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151260"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>