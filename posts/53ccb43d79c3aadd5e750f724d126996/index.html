<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【图神经网络】Pytorch图神经网络库——PyG异构图学习 - 编程爱好者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【图神经网络】Pytorch图神经网络库——PyG异构图学习" />
<meta property="og:description" content="PyG异构图学习 举个例子创建异构图Utility函数 异构图Transformations创建异构图神经网络自动转换GNN模型使用异构卷积包装器部署现有的异构算子 异构图采样参考资料 大量真实世界数据集存储为异构图，这促使Pytorch Geometric（PyG）中引入专门的功能。例如，推荐领域中的大多数图（如社交图）都是异构的，因为它们存储关于不同类型的实体及其不同类型的关系的信息。本文介绍如何将异构图映射到PyG，以及如何将它们用作图形神经网络模型的输入。 异构图具有不同类型的信息附加到节点和边上。因此，由于类型和维数的差异，单个节点或边特征张量不能包含整个图的所有节点或边特征。相反，需要为节点和边分别指定一组类型，每个类型都有自己的数据张量。由于数据结构的不同，消息传递公式也随之改变，允许以节点或边类型为条件计算消息和更新函数。
举个例子 作为一个示例，我们从OGB数据集看一下异构ogbn-mag网络:
给定的异构图有1,939,743个节点，节点类型分为作者、论文、机构和研究领域四种。它还有21,111,007条边，属于以下四种类型之一:
writes(写作)：作者写一篇特定的论文affiliated with(附属于)：作者附属于某一特定机构cites(引用)：一篇论文引用另一篇论文has topic(有主题)：一篇论文有一个特定研究领域的主题 这个图的任务是根据图中存储的信息推断出每一篇论文(会议或期刊)的发表地点。
创建异构图 首先，我们可以创建torch_geometric.data.HeteroData类型的数据对象，为每种类型分别定义节点特征张量、边索引张量和边特征张量：
from torch_geometric.data import HeteroData data = HeteroData() # 实例化一个空对象 # 初始化结点特征 data[&#39;paper&#39;].x = ... # [num_papers, num_features_paper] data[&#39;author&#39;].x = ... # [num_authors, num_features_author] data[&#39;institution&#39;].x = ... # [num_institutions, num_features_institution] data[&#39;field_of_study&#39;].x = ... # [num_field, num_features_field] # 初始化边索引 data[&#39;paper&#39;, &#39;cites&#39;, &#39;paper&#39;].edge_index = ... # [2, num_edges_cites] data[&#39;author&#39;, &#39;writes&#39;, &#39;paper&#39;].edge_index = ... # [2, num_edges_writes] data[&#39;author&#39;, &#39;affiliated_with&#39;, &#39;institution&#39;]." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bchobby.github.io/posts/53ccb43d79c3aadd5e750f724d126996/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-12-25T08:00:00+08:00" />
<meta property="article:modified_time" content="2022-12-25T08:00:00+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程爱好者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程爱好者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【图神经网络】Pytorch图神经网络库——PyG异构图学习</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>PyG异构图学习</h4> 
 <ul><li><a href="#_4" rel="nofollow">举个例子</a></li><li><a href="#_14" rel="nofollow">创建异构图</a></li><li><ul><li><a href="#Utility_73" rel="nofollow">Utility函数</a></li></ul> 
  </li><li><a href="#Transformations_113" rel="nofollow">异构图Transformations</a></li><li><a href="#_127" rel="nofollow">创建异构图神经网络</a></li><li><ul><li><a href="#GNN_135" rel="nofollow">自动转换GNN模型</a></li><li><a href="#_203" rel="nofollow">使用异构卷积包装器</a></li><li><a href="#_238" rel="nofollow">部署现有的异构算子</a></li></ul> 
  </li><li><a href="#_274" rel="nofollow">异构图采样</a></li><li><a href="#_352" rel="nofollow">参考资料</a></li></ul> 
</div> 
<br> 大量真实世界数据集存储为异构图，这促使Pytorch Geometric（PyG）中引入专门的功能。例如，推荐领域中的大多数图（如社交图）都是异构的，因为它们存储关于不同类型的实体及其不同类型的关系的信息。本文介绍如何将异构图映射到PyG，以及如何将它们用作图形神经网络模型的输入。 
<p></p> 
<p>异构图具有不同类型的信息附加到节点和边上。因此，由于类型和维数的差异，单个节点或边特征张量不能包含整个图的所有节点或边特征。相反，需要为节点和边分别指定一组类型，每个类型都有自己的数据张量。由于数据结构的不同，消息传递公式也随之改变，允许以节点或边类型为条件计算消息和更新函数。</p> 
<h2><a id="_4"></a>举个例子</h2> 
<p>作为一个示例，我们从OGB数据集看一下异构<code>ogbn-mag</code>网络:<br> <img src="https://images2.imgbox.com/62/ae/N18dUhSx_o.png" alt="OGBN-MAG网络"><br> 给定的异构图有1,939,743个节点，节点类型分为作者、论文、机构和研究领域四种。它还有21,111,007条边，属于以下四种类型之一:</p> 
<ul><li>writes(写作)：作者写一篇特定的论文</li><li>affiliated with(附属于)：作者附属于某一特定机构</li><li>cites(引用)：一篇论文引用另一篇论文</li><li>has topic(有主题)：一篇论文有一个特定研究领域的主题</li></ul> 
<p>这个图的任务是根据图中存储的信息推断出每一篇论文(会议或期刊)的发表地点。</p> 
<h2><a id="_14"></a>创建异构图</h2> 
<p>首先，我们可以创建<code>torch_geometric.data.HeteroData</code>类型的数据对象，为每种类型分别定义<code>节点特征张量</code>、<code>边索引张量</code>和<code>边特征张量</code>：</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>data <span class="token keyword">import</span> HeteroData

data <span class="token operator">=</span> HeteroData<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 实例化一个空对象</span>

<span class="token comment"># 初始化结点特征</span>
data<span class="token punctuation">[</span><span class="token string">'paper'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>x <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token comment"># [num_papers, num_features_paper]</span>
data<span class="token punctuation">[</span><span class="token string">'author'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>x <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token comment"># [num_authors, num_features_author]</span>
data<span class="token punctuation">[</span><span class="token string">'institution'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>x <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token comment"># [num_institutions, num_features_institution]</span>
data<span class="token punctuation">[</span><span class="token string">'field_of_study'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>x <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token comment"># [num_field, num_features_field]</span>
<span class="token comment"># 初始化边索引</span>
data<span class="token punctuation">[</span><span class="token string">'paper'</span><span class="token punctuation">,</span> <span class="token string">'cites'</span><span class="token punctuation">,</span> <span class="token string">'paper'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>edge_index <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token comment"># [2, num_edges_cites]</span>
data<span class="token punctuation">[</span><span class="token string">'author'</span><span class="token punctuation">,</span> <span class="token string">'writes'</span><span class="token punctuation">,</span> <span class="token string">'paper'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>edge_index <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token comment"># [2, num_edges_writes]</span>
data<span class="token punctuation">[</span><span class="token string">'author'</span><span class="token punctuation">,</span> <span class="token string">'affiliated_with'</span><span class="token punctuation">,</span> <span class="token string">'institution'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>edge_index <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token comment"># [2, num_edges_affiliated]</span>
data<span class="token punctuation">[</span><span class="token string">'author'</span><span class="token punctuation">,</span> <span class="token string">'has_topic'</span><span class="token punctuation">,</span> <span class="token string">'institution'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>edge_index <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token comment"># [2, num_edges_topic]</span>
<span class="token comment"># 初始化边特征</span>
data<span class="token punctuation">[</span><span class="token string">'paper'</span><span class="token punctuation">,</span> <span class="token string">'cites'</span><span class="token punctuation">,</span> <span class="token string">'paper'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>edge_attr <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token comment"># [num_edges_cites, num_features_cites]</span>
data<span class="token punctuation">[</span><span class="token string">'author'</span><span class="token punctuation">,</span> <span class="token string">'writes'</span><span class="token punctuation">,</span> <span class="token string">'paper'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>edge_attr <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token comment"># [num_edges_writes, num_features_writes]</span>
data<span class="token punctuation">[</span><span class="token string">'author'</span><span class="token punctuation">,</span> <span class="token string">'affiliated_with'</span><span class="token punctuation">,</span> <span class="token string">'institution'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>edge_attr <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token comment"># [num_edges_affiliated, num_features_affiliated]</span>
data<span class="token punctuation">[</span><span class="token string">'paper'</span><span class="token punctuation">,</span> <span class="token string">'has_topic'</span><span class="token punctuation">,</span> <span class="token string">'field_of_study'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>edge_attr <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token comment"># [num_edges_topic, num_features_topic]</span>
</code></pre> 
<p><strong>节点或边张量将在第一次访问时自动创建</strong>，并由字符串类型的键索引。节点类型由单个字符串标识，而边类型由字符串的三元组 <code>(source_node_type, edge_type, destination_node_type)</code>标识：边类型标识符和边类型可以存在的两个节点类型。并且，数据对象允许每种类型有不同的特征维度。</p> 
<p>包含按属性名而不是按节点或边类型分组的异构信息的字典可以通过<code>data.{attribute_name}_dict</code>直接访问，并作为输入到GNN模型中:</p> 
<pre><code class="prism language-python">model <span class="token operator">=</span> HeteroGNN<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
<span class="token comment"># 下面是数据对象调用方式</span>
output <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">.</span>x_dict<span class="token punctuation">,</span> data<span class="token punctuation">.</span>edge_index_dict<span class="token punctuation">,</span> data<span class="token punctuation">.</span>edge_attr_dict<span class="token punctuation">)</span>
</code></pre> 
<p><strong>如果该数据集存在于PyG数据集列表中，则可以直接导入和使用。并且它将被下载到根目录并自动处理</strong>。</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> OGB_MAG

dataset <span class="token operator">=</span> OGB_MAG<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'./data'</span><span class="token punctuation">,</span> preprocess<span class="token operator">=</span><span class="token string">'metapath2vec'</span><span class="token punctuation">)</span>
data <span class="token operator">=</span> dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
</code></pre> 
<p>数据对象可以打印出来进行验证:</p> 
<pre><code class="prism language-python">HeteroData<span class="token punctuation">(</span>
  paper<span class="token operator">=</span><span class="token punctuation">{<!-- --></span>
    x<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">736389</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    y<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">736389</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    train_mask<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">736389</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    val_mask<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">736389</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    test_mask<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">736389</span><span class="token punctuation">]</span>
  <span class="token punctuation">}</span><span class="token punctuation">,</span>
  author<span class="token operator">=</span><span class="token punctuation">{<!-- --></span> x<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1134649</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">]</span> <span class="token punctuation">}</span><span class="token punctuation">,</span>
  institution<span class="token operator">=</span><span class="token punctuation">{<!-- --></span> x<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">8740</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">]</span> <span class="token punctuation">}</span><span class="token punctuation">,</span>
  field_of_study<span class="token operator">=</span><span class="token punctuation">{<!-- --></span> x<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">59965</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">]</span> <span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">(</span>author<span class="token punctuation">,</span> affiliated_with<span class="token punctuation">,</span> institution<span class="token punctuation">)</span><span class="token operator">=</span><span class="token punctuation">{<!-- --></span> edge_index<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1043998</span><span class="token punctuation">]</span> <span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">(</span>author<span class="token punctuation">,</span> writes<span class="token punctuation">,</span> paper<span class="token punctuation">)</span><span class="token operator">=</span><span class="token punctuation">{<!-- --></span> edge_index<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">7145660</span><span class="token punctuation">]</span> <span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">(</span>paper<span class="token punctuation">,</span> cites<span class="token punctuation">,</span> paper<span class="token punctuation">)</span><span class="token operator">=</span><span class="token punctuation">{<!-- --></span> edge_index<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">5416271</span><span class="token punctuation">]</span> <span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">(</span>paper<span class="token punctuation">,</span> has_topic<span class="token punctuation">,</span> field_of_study<span class="token punctuation">)</span><span class="token operator">=</span><span class="token punctuation">{<!-- --></span> edge_index<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">7505078</span><span class="token punctuation">]</span> <span class="token punctuation">}</span>
<span class="token punctuation">)</span>

</code></pre> 
<p>注意：最初的ogbn mag网络只为“paper”节点提供特征。在OGB_MAG中，我们提供了下载其处理版本的选项，其中结构特征（从“metapath2vec”或“TransE”获得）被添加到无特征节点，这通常在向OGB排行榜提交的排名靠前的文件中进行。</p> 
<h3><a id="Utility_73"></a>Utility函数</h3> 
<p><code>torch_geometric.data.HeteroData</code>类提供了许多有用的实用函数来修改和分析给定的图。例如，单个节点或边存储可以被单独索引:</p> 
<pre><code class="prism language-python">paper_node_data <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token string">'paper'</span><span class="token punctuation">]</span>
cites_edge_data <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token string">'paper'</span><span class="token punctuation">,</span> <span class="token string">'cites'</span><span class="token punctuation">,</span> <span class="token string">'paper'</span><span class="token punctuation">]</span>
</code></pre> 
<p>可以添加新的节点类型或张量，并删除它们:</p> 
<pre><code class="prism language-python">data<span class="token punctuation">[</span><span class="token string">'paper'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>year <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    <span class="token comment"># Setting a new paper attribute</span>
<span class="token keyword">del</span> data<span class="token punctuation">[</span><span class="token string">'field_of_study'</span><span class="token punctuation">]</span>  <span class="token comment"># Deleting 'field_of_study' node type</span>
<span class="token keyword">del</span> data<span class="token punctuation">[</span><span class="token string">'has_topic'</span><span class="token punctuation">]</span>       <span class="token comment"># Deleting 'has_topic' edge type</span>
</code></pre> 
<p>可以访问数据对象的元数据，包含所有当前节点和边类型的信息:</p> 
<pre><code class="prism language-python">node_types<span class="token punctuation">,</span> edge_types <span class="token operator">=</span> data<span class="token punctuation">.</span>metadata<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>node_types<span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token string">'paper'</span><span class="token punctuation">,</span> <span class="token string">'author'</span><span class="token punctuation">,</span> <span class="token string">'institution'</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>edge_types<span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'paper'</span><span class="token punctuation">,</span> <span class="token string">'cites'</span><span class="token punctuation">,</span> <span class="token string">'paper'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">(</span><span class="token string">'author'</span><span class="token punctuation">,</span> <span class="token string">'writes'</span><span class="token punctuation">,</span> <span class="token string">'paper'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">(</span><span class="token string">'author'</span><span class="token punctuation">,</span> <span class="token string">'affiliated_with'</span><span class="token punctuation">,</span> <span class="token string">'institution'</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre> 
<p>数据对象可以像往常一样在设备之间传输:</p> 
<pre><code class="prism language-python">data <span class="token operator">=</span> data<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda:0'</span><span class="token punctuation">)</span>
data <span class="token operator">=</span> data<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>还可以使用其他辅助函数来分析给定的图</p> 
<pre><code class="prism language-python">data<span class="token punctuation">.</span>has_isolated_nodes<span class="token punctuation">(</span><span class="token punctuation">)</span>
data<span class="token punctuation">.</span>has_self_loops<span class="token punctuation">(</span><span class="token punctuation">)</span>
data<span class="token punctuation">.</span>is_undirected<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>并且可以通过<code>to_homogeneous()</code>将其转换为同构的“类型化”图，该图能够在不同类型之间保持特征的维数匹配:</p> 
<pre><code class="prism language-python">homogeneous_data <span class="token operator">=</span> data<span class="token punctuation">.</span>to_homogeneous<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>homogeneous_data<span class="token punctuation">)</span>
Data<span class="token punctuation">(</span>x<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1879778</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">]</span><span class="token punctuation">,</span> edge_index<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">13605929</span><span class="token punctuation">]</span><span class="token punctuation">,</span> edge_type<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">13605929</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<p>在这里，<code>homogeneous_data.Edge_type</code>表示一个边级向量，以整数形式保存每条边的边类型。</p> 
<h2><a id="Transformations_113"></a>异构图Transformations</h2> 
<p>大多数用于预处理规则图的<code>transformations</code>也适用于异构图数据对象。</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch_geometric<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> T

data <span class="token operator">=</span> T<span class="token punctuation">.</span>ToUndirected<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>
data <span class="token operator">=</span> T<span class="token punctuation">.</span>AddSelfLoops<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>
data <span class="token operator">=</span> T<span class="token punctuation">.</span>NormalizeFeatures<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>
</code></pre> 
<p>这里，<code>ToUndirected()</code>通过为图中的所有边添加反向边，将有向图转换为无向图。消息传递将在所有边的两个方向上执行。</p> 
<p>对于所有类型为<code>node_type</code>的节点和所有现有形式的边类型<code>('node_type'， 'edge_type'， 'node_type')</code>，函数<code>AddSelfLoops()</code>将添加自循环边。因此，<strong>在消息传递期间，每个节点可能从自身接收一个或多个消息(每个适当的边类型接收一个消息)</strong>。</p> 
<p><code>NormalizeFeatures()</code>的工作方式与同质情况类似，并将所有指定的特征归并为1。</p> 
<h2><a id="_127"></a>创建异构图神经网络</h2> 
<p>标准消息传递GNN (<code>MP-GNN</code>)不能简单地应用于异构图数据，因为不同类型的节点特征和边特征由于特征类型的差异不能由相同的函数处理。避免这种情况的一种自然方法是为每种边类型分别实现消息和更新函数。<strong>在运行时，MP-GNN 算法需要在消息计算期间迭代边类型字典，在节点更新期间迭代节点类型字典</strong>。<br> 为了避免不必要的运行时开销，并尽可能简单地创建异构MP-GNN，Pytorch Geometric为用户提供了三种方法来创建异构图数据模型:</p> 
<ol><li>通过使用 <code>torch_geometrici .nn.to_hetero()</code>或 <code>torch_geometrici .nn.to_hetero_with_bases()</code>自动将一个同质GNN模型转换为一个异构的GNN模型;</li><li>使用PyGs包装器<code>torch_geometric..nn.conv.HeteroCov</code>为异构卷积定义不同类型的独立函数</li><li>部署现有的(或编写您自己的)异构 GNN 算子</li></ol> 
<p>下面将详细介绍每个方法：</p> 
<h3><a id="GNN_135"></a>自动转换GNN模型</h3> 
<p>Pytorch geometry允许使用内置函数 <code>torch_geometrical .nn.to_hetero()</code>或 <code>torch_geometrical .nn.to_hetero_with_bases()</code>自动将任何PyG GNN模型转换为异构输入图形的模型。</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch_geometric<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> T
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> OGB_MAG
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>nn <span class="token keyword">import</span> SAGEConv<span class="token punctuation">,</span> to_hetero

<span class="token comment"># 读取数据集 并自动预处理为无向图</span>
dataset <span class="token operator">=</span> OGB_MAG<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'./data'</span><span class="token punctuation">,</span> preprocess<span class="token operator">=</span><span class="token string">'metapath2vec'</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>T<span class="token punctuation">.</span>ToUndirected<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
data <span class="token operator">=</span> dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

<span class="token keyword">class</span> <span class="token class-name">GNN</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> hidden_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> SAGEConv<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> hidden_channels<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> SAGEConv<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> edge_index<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">,</span> edge_index<span class="token punctuation">)</span><span class="token punctuation">.</span>relu<span class="token punctuation">(</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">,</span> edge_index<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x


model <span class="token operator">=</span> GNN<span class="token punctuation">(</span>hidden_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span>dataset<span class="token punctuation">.</span>num_classes<span class="token punctuation">)</span>
model <span class="token operator">=</span> to_hetero<span class="token punctuation">(</span>model<span class="token punctuation">,</span> data<span class="token punctuation">.</span>metadata<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> aggr<span class="token operator">=</span><span class="token string">'sum'</span><span class="token punctuation">)</span>
</code></pre> 
<p>该过程采用一个现有的GNN模型，并复制消息函数以分别处理每个边类型，如下图所示。<br> <img src="https://images2.imgbox.com/d8/1c/Qg3Uyvnp_o.png" alt="同质图与异质图"><br> 因此，<strong>该模型现在期望将节点和边类型作为键作为输入参数的字典，而不是在同构图中使用的单张量</strong>。注意，我们将<code>in_channels</code>的元组传递给SAGEConv，以便允许在二分图中传递消息。</p> 
<p>由于输入特性的数量和张量的大小因不同类型而异，<strong>PyG可以利用延迟初始化来初始化异构GNN中的参数(用-1表示in_channels参数)</strong>。这允许我们避免计算和跟踪计算图的所有张量大小。<strong>所有现有的PyG操作符都支持延迟初始化</strong>。我们可以通过调用一次来初始化模型的参数:</p> 
<pre><code class="prism language-python"><span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># Initialize lazy modules.</span>
    out <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">.</span>x_dict<span class="token punctuation">,</span> data<span class="token punctuation">.</span>edge_index_dict<span class="token punctuation">)</span>
</code></pre> 
<p><code>to_hetero()</code>和 <code>to_hetero_with_bases()</code>对于可以自动转换为异构体系结构的同构体系结构来说都非常灵活。举个例子：</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>nn <span class="token keyword">import</span> GATConv<span class="token punctuation">,</span> Linear<span class="token punctuation">,</span> to_hetero
<span class="token comment"># 定义模型 全部延迟初始化</span>
<span class="token keyword">class</span> <span class="token class-name">GAT</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> hidden_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> GATConv<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> hidden_channels<span class="token punctuation">,</span> add_self_loops<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>lin1 <span class="token operator">=</span> Linear<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> hidden_channels<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> GATConv<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> add_self_loops<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>lin2 <span class="token operator">=</span> Linear<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> edge_index<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">,</span> edge_index<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>lin1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>relu<span class="token punctuation">(</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">,</span> edge_index<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>lin2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x
<span class="token comment"># 转换</span>
model <span class="token operator">=</span> GAT<span class="token punctuation">(</span>hidden_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span>dataset<span class="token punctuation">.</span>num_classes<span class="token punctuation">)</span>
model <span class="token operator">=</span> to_hetero<span class="token punctuation">(</span>model<span class="token punctuation">,</span> data<span class="token punctuation">.</span>metadata<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> aggr<span class="token operator">=</span><span class="token string">'sum'</span><span class="token punctuation">)</span>
</code></pre> 
<p>通常，可以使用如下方法训练(其实和torch中一样，需要注意的就是传入数据的字典表示)：</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    out <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">.</span>x_dict<span class="token punctuation">,</span> data<span class="token punctuation">.</span>edge_index_dict<span class="token punctuation">)</span>
    mask <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token string">'paper'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>train_mask
    loss <span class="token operator">=</span> F<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span>out<span class="token punctuation">[</span><span class="token string">'paper'</span><span class="token punctuation">]</span><span class="token punctuation">[</span>mask<span class="token punctuation">]</span><span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token string">'paper'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>y<span class="token punctuation">[</span>mask<span class="token punctuation">]</span><span class="token punctuation">)</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token builtin">float</span><span class="token punctuation">(</span>loss<span class="token punctuation">)</span>
</code></pre> 
<h3><a id="_203"></a>使用异构卷积包装器</h3> 
<p>异构卷积卷积包装器 <code>torch_geometric.nn.conv.HeteroConv</code>允许定义自定义异构消息和更新函数，以从头开始为异构图构建任意MP-GNNs。虽然 <code>to_hetero()</code>自动转换器对所有边类型使用相同的操作，但<strong>包装器允许为不同的边类型定义不同的操作</strong>。<code>HeteroConv</code><strong>接受一个子模块字典作为输入，图数据中的每一种边类型都有一个</strong>。下面的示例演示如何应用它。</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>nn <span class="token keyword">import</span> HeteroConv<span class="token punctuation">,</span> GCNConv<span class="token punctuation">,</span> SAGEConv<span class="token punctuation">,</span> GATConv<span class="token punctuation">,</span> Linear

<span class="token keyword">class</span> <span class="token class-name">HeteroGNN</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> hidden_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> num_layers<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>convs <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_layers<span class="token punctuation">)</span><span class="token punctuation">:</span>
            conv <span class="token operator">=</span> HeteroConv<span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span>
                <span class="token punctuation">(</span><span class="token string">'paper'</span><span class="token punctuation">,</span> <span class="token string">'cites'</span><span class="token punctuation">,</span> <span class="token string">'paper'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> GCNConv<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> hidden_channels<span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token punctuation">(</span><span class="token string">'author'</span><span class="token punctuation">,</span> <span class="token string">'writes'</span><span class="token punctuation">,</span> <span class="token string">'paper'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> SAGEConv<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> hidden_channels<span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token punctuation">(</span><span class="token string">'paper'</span><span class="token punctuation">,</span> <span class="token string">'rev_writes'</span><span class="token punctuation">,</span> <span class="token string">'author'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> GATConv<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> hidden_channels<span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">}</span><span class="token punctuation">,</span> aggr<span class="token operator">=</span><span class="token string">'sum'</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>convs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>conv<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>lin <span class="token operator">=</span> Linear<span class="token punctuation">(</span>hidden_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x_dict<span class="token punctuation">,</span> edge_index_dict<span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token comment"># 需要注意的就是这里需要传入字典</span>
        <span class="token keyword">for</span> conv <span class="token keyword">in</span> self<span class="token punctuation">.</span>convs<span class="token punctuation">:</span>
            x_dict <span class="token operator">=</span> conv<span class="token punctuation">(</span>x_dict<span class="token punctuation">,</span> edge_index_dict<span class="token punctuation">)</span>
            x_dict <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>key<span class="token punctuation">:</span> x<span class="token punctuation">.</span>relu<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> key<span class="token punctuation">,</span> x <span class="token keyword">in</span> x_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>lin<span class="token punctuation">(</span>x_dict<span class="token punctuation">[</span><span class="token string">'author'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

model <span class="token operator">=</span> HeteroGNN<span class="token punctuation">(</span>hidden_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span>dataset<span class="token punctuation">.</span>num_classes<span class="token punctuation">,</span>
                  num_layers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
</code></pre> 
<p>我们可以通过调用一次来初始化模型(更多关于惰性初始模式的细节请参阅<a href="https://pytorch-geometric.readthedocs.io/en/latest/notes/heterogeneous.html#lazyinit" rel="nofollow">这里</a>)</p> 
<pre><code class="prism language-python"><span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># Initialize lazy modules.</span>
     out <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">.</span>x_dict<span class="token punctuation">,</span> data<span class="token punctuation">.</span>edge_index_dict<span class="token punctuation">)</span>
</code></pre> 
<h3><a id="_238"></a>部署现有的异构算子</h3> 
<p>PyG提供了操作符(例如，<code>torch_geometrical.nn.convt.hgtconv</code>)，这是专门为异构图设计的。这些操作符可以直接用于构建异构的GNN模型，如下例所示:</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>nn <span class="token keyword">import</span> HGTConv<span class="token punctuation">,</span> Linear

<span class="token keyword">class</span> <span class="token class-name">HGT</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> hidden_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> num_layers<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
	<span class="token comment"># 将各种类型的边使用线性层转换为同一个维度</span>
        self<span class="token punctuation">.</span>lin_dict <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>ModuleDict<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> node_type <span class="token keyword">in</span> data<span class="token punctuation">.</span>node_types<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>lin_dict<span class="token punctuation">[</span>node_type<span class="token punctuation">]</span> <span class="token operator">=</span> Linear<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> hidden_channels<span class="token punctuation">)</span>

	<span class="token comment"># 堆叠多层异构卷积层 num_heads是使用了多头注意力机制 </span>
        self<span class="token punctuation">.</span>convs <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_layers<span class="token punctuation">)</span><span class="token punctuation">:</span>
            conv <span class="token operator">=</span> HGTConv<span class="token punctuation">(</span>hidden_channels<span class="token punctuation">,</span> hidden_channels<span class="token punctuation">,</span> data<span class="token punctuation">.</span>metadata<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>num_heads<span class="token punctuation">,</span> group<span class="token operator">=</span><span class="token string">'sum'</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>convs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>conv<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>lin <span class="token operator">=</span> Linear<span class="token punctuation">(</span>hidden_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x_dict<span class="token punctuation">,</span> edge_index_dict<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> node_type<span class="token punctuation">,</span> x <span class="token keyword">in</span> x_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            x_dict<span class="token punctuation">[</span>node_type<span class="token punctuation">]</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>lin_dict<span class="token punctuation">[</span>node_type<span class="token punctuation">]</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>relu_<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">for</span> conv <span class="token keyword">in</span> self<span class="token punctuation">.</span>convs<span class="token punctuation">:</span>
            x_dict <span class="token operator">=</span> conv<span class="token punctuation">(</span>x_dict<span class="token punctuation">,</span> edge_index_dict<span class="token punctuation">)</span>

        <span class="token keyword">return</span> self<span class="token punctuation">.</span>lin<span class="token punctuation">(</span>x_dict<span class="token punctuation">[</span><span class="token string">'author'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

model <span class="token operator">=</span> HGT<span class="token punctuation">(</span>hidden_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span>dataset<span class="token punctuation">.</span>num_classes<span class="token punctuation">,</span>
            num_heads<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> num_layers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>

<span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># Initialize lazy modules.</span>
     out <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">.</span>x_dict<span class="token punctuation">,</span> data<span class="token punctuation">.</span>edge_index_dict<span class="token punctuation">)</span>
</code></pre> 
<h2><a id="_274"></a>异构图采样</h2> 
<p>PyG为异构图形的采样提供了各种功能，例如在标准的<code>torch_geometric.loader.NeighborLoader</code>类或专用的异构图形采样器，如 <code>torch_geometric.loader.HGTLoader</code>。这对于大型异构图的高效表示学习特别有用，因为在这种情况下，处理完整数量的邻居的计算开销太大。对其他采样器(如 <code>torch_geometrical.loader.ClusterLoader</code>,<code>torch_geometric.loader.GraphSAINTLoader</code>)的异构图形支持很快就会加入。</p> 
<p>总的来说，所有异构图形加载器都将生成一个 <code>HeteroData</code>对象作为输出，其中包含原始数据的一个子集，其主要不同之处是其采样过程的工作方式。因此，将训练过程从全批处理转换为小批处理只需要很小的代码更改。</p> 
<p>使用 <code>NeighborLoader</code>进行邻居采样的工作原理如下:</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch_geometric<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> T
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> OGB_MAG
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>loader <span class="token keyword">import</span> NeighborLoader

transform <span class="token operator">=</span> T<span class="token punctuation">.</span>ToUndirected<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># Add reverse edge types.</span>
data <span class="token operator">=</span> OGB_MAG<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'./data'</span><span class="token punctuation">,</span> preprocess<span class="token operator">=</span><span class="token string">'metapath2vec'</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transform<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

train_loader <span class="token operator">=</span> NeighborLoader<span class="token punctuation">(</span>
    data<span class="token punctuation">,</span>
    <span class="token comment"># Sample 15 neighbors for each node and each edge type for 2 iterations:</span>
    num_neighbors<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">15</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span>
    <span class="token comment"># Use a batch size of 128 for sampling training nodes of type "paper":</span>
    batch_size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span>
    input_nodes<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">'paper'</span><span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token string">'paper'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>train_mask<span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

batch <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p><code>NeighborLoader</code>既适用于同构图，也适用于异构图。当在异构图中操作时，可以对单个边类型的采样邻居数量进行更细粒度的控制，但不是必需的，例如:</p> 
<pre><code class="prism language-python">num_neighbors <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>key<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">15</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token number">2</span> <span class="token keyword">for</span> key <span class="token keyword">in</span> data<span class="token punctuation">.</span>edge_types<span class="token punctuation">}</span>
</code></pre> 
<p>使用<code>input _ node</code> 参数，我们进一步指定节点的类型和索引，我们希望从这些节点中抽样本地邻域，例如根据<code>data['paper'].train_mask</code>标记为训练节点的所有“paper”节点。</p> 
<p>打印<code>Batch</code>，然后产生以下输出:</p> 
<pre><code class="prism language-python">HeteroData<span class="token punctuation">(</span>
  paper<span class="token operator">=</span><span class="token punctuation">{<!-- --></span>
    x<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">20799</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    y<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">20799</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    train_mask<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">20799</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    val_mask<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">20799</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    test_mask<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">20799</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    batch_size<span class="token operator">=</span><span class="token number">128</span>
  <span class="token punctuation">}</span><span class="token punctuation">,</span>
  author<span class="token operator">=</span><span class="token punctuation">{<!-- --></span> x<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">4419</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">]</span> <span class="token punctuation">}</span><span class="token punctuation">,</span>
  institution<span class="token operator">=</span><span class="token punctuation">{<!-- --></span> x<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">302</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">]</span> <span class="token punctuation">}</span><span class="token punctuation">,</span>
  field_of_study<span class="token operator">=</span><span class="token punctuation">{<!-- --></span> x<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2605</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">]</span> <span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">(</span>author<span class="token punctuation">,</span> affiliated_with<span class="token punctuation">,</span> institution<span class="token punctuation">)</span><span class="token operator">=</span><span class="token punctuation">{<!-- --></span> edge_index<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">(</span>author<span class="token punctuation">,</span> writes<span class="token punctuation">,</span> paper<span class="token punctuation">)</span><span class="token operator">=</span><span class="token punctuation">{<!-- --></span> edge_index<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">5927</span><span class="token punctuation">]</span> <span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">(</span>paper<span class="token punctuation">,</span> cites<span class="token punctuation">,</span> paper<span class="token punctuation">)</span><span class="token operator">=</span><span class="token punctuation">{<!-- --></span> edge_index<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">11829</span><span class="token punctuation">]</span> <span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">(</span>paper<span class="token punctuation">,</span> has_topic<span class="token punctuation">,</span> field_of_study<span class="token punctuation">)</span><span class="token operator">=</span><span class="token punctuation">{<!-- --></span> edge_index<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">10573</span><span class="token punctuation">]</span> <span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">(</span>institution<span class="token punctuation">,</span> rev_affiliated_with<span class="token punctuation">,</span> author<span class="token punctuation">)</span><span class="token operator">=</span><span class="token punctuation">{<!-- --></span> edge_index<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">829</span><span class="token punctuation">]</span> <span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">(</span>paper<span class="token punctuation">,</span> rev_writes<span class="token punctuation">,</span> author<span class="token punctuation">)</span><span class="token operator">=</span><span class="token punctuation">{<!-- --></span> edge_index<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">5512</span><span class="token punctuation">]</span> <span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">(</span>field_of_study<span class="token punctuation">,</span> rev_has_topic<span class="token punctuation">,</span> paper<span class="token punctuation">)</span><span class="token operator">=</span><span class="token punctuation">{<!-- --></span> edge_index<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">10499</span><span class="token punctuation">]</span> <span class="token punctuation">}</span>
<span class="token punctuation">)</span>
</code></pre> 
<p>batch共有28187个节点，用于计算128个“paper”节点的嵌入。被采样的节点总是根据它们被采样的顺序进行排序。因此，<code>batch['paper'].batch_size</code>节点表示原始的<code>mini-batch</code>节点集合，便于通过切片获得最终的输出嵌入。</p> 
<p>在小批处理模式下训练我们的异构GNN模型与在全批处理模式下训练类似，只是我们通过 <code>train_loader</code>迭代生成的<code>mini-batch</code>，并基于单个mini-batch小批处优化模型参数:</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>

    total_examples <span class="token operator">=</span> total_loss <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> batch <span class="token keyword">in</span> train_loader<span class="token punctuation">:</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        batch <span class="token operator">=</span> batch<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda:0'</span><span class="token punctuation">)</span>
        batch_size <span class="token operator">=</span> batch<span class="token punctuation">[</span><span class="token string">'paper'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>batch_size
        out <span class="token operator">=</span> model<span class="token punctuation">(</span>batch<span class="token punctuation">.</span>x_dict<span class="token punctuation">,</span> batch<span class="token punctuation">.</span>edge_index_dict<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> F<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span>out<span class="token punctuation">[</span><span class="token string">'paper'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span>batch_size<span class="token punctuation">]</span><span class="token punctuation">,</span>
                               batch<span class="token punctuation">[</span><span class="token string">'paper'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>y<span class="token punctuation">[</span><span class="token punctuation">:</span>batch_size<span class="token punctuation">]</span><span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

        total_examples <span class="token operator">+=</span> batch_size
        total_loss <span class="token operator">+=</span> <span class="token builtin">float</span><span class="token punctuation">(</span>loss<span class="token punctuation">)</span> <span class="token operator">*</span> batch_size

    <span class="token keyword">return</span> total_loss <span class="token operator">/</span> total_examples
</code></pre> 
<p>重要的是，在损失计算过程中，我们只使用了前128个“paper”节点。我们基于<code>batch['paper'].batch_size</code>,对<code>labels batch['paper'.y</code>和输出 <code>out['paper']</code>来表示原始mini-batch的标签和输出。</p> 
<h2><a id="_352"></a>参考资料</h2> 
<p>[1] <a href="https://pytorch-geometric.readthedocs.io/en/latest/notes/heterogeneous.html" rel="nofollow">HETEROGENEOUS GRAPH LEARNING</a></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/7f8fa490ff5e06a69de42ef0f9daf8ba/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Java实现文件上传和下载</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/12cba96dd804863e786d8270c6089739/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Speedify使用步骤</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程爱好者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151260"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>