<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>第五节Hadoop学习案例——MapReduce案例（WordCount） - 编程爱好者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="第五节Hadoop学习案例——MapReduce案例（WordCount）" />
<meta property="og:description" content="提示：本文章内容主要围绕案例展开
目录
1 需求分析
1.1 需求
1.2 数据准备
1.3 原理
2 编码操作
2.1 创建项目
2.2 创建包和类
2.2.1 创建包
2.2.2 创建类
2.2 引入jar包
2.2.1 引入MR相关jar
2.2.2 引入打包插件
2.3 拷贝官方样例
2.4 修改样例代码
2.4.1 main方法程序阅读
2.4.2 WordCountMapper
2.4.3 WordCountReduce
2.4.4 替换实现类
2.5 程序打包
2.5.1 父项目pom修改
2.5.2 打包
2.6 程序测试
2.6.1 创建目录
2.6.2 上传程序
2.6.3 分布式文件系统上传测试数据
2.6.4 执行程序
2.6.5 查看结果
提示：以下是本篇文章正文内容，下面案例可供参考
1 需求分析 1.1 需求 统计文件中各个单词出现的个数 1.2 数据准备 数据准备：hello.txt Once when l was six years old l saw a magnificent picture in a book called True Stories from Nature, about the primeval forest." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bchobby.github.io/posts/5692ab482b025f6e400921fac9350a32/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-10-10T09:27:40+08:00" />
<meta property="article:modified_time" content="2022-10-10T09:27:40+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程爱好者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程爱好者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">第五节Hadoop学习案例——MapReduce案例（WordCount）</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <blockquote> 
 <p>提示：本文章内容主要围绕案例展开</p> 
</blockquote> 
<p id="main-toc"><strong>目录</strong></p> 
<p id="1%20%E9%9C%80%E6%B1%82%E5%88%86%E6%9E%90-toc" style="margin-left:0px;"><a href="#1%20%E9%9C%80%E6%B1%82%E5%88%86%E6%9E%90" rel="nofollow">1 需求分析</a></p> 
<p id="1.1%20%E9%9C%80%E6%B1%82-toc" style="margin-left:40px;"><a href="#1.1%20%E9%9C%80%E6%B1%82" rel="nofollow">1.1 需求</a></p> 
<p id="1.2%20%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87-toc" style="margin-left:40px;"><a href="#1.2%20%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87" rel="nofollow">1.2 数据准备</a></p> 
<p id="1.3%20%E5%8E%9F%E7%90%86-toc" style="margin-left:40px;"><a href="#1.3%20%E5%8E%9F%E7%90%86" rel="nofollow">1.3 原理</a></p> 
<p id="-toc" style="margin-left:0px;"><a href="#2%20%E7%BC%96%E7%A0%81%E6%93%8D%E4%BD%9C" rel="nofollow">2 编码操作</a></p> 
<p id="2.1%20%E5%88%9B%E5%BB%BA%E9%A1%B9%E7%9B%AE-toc" style="margin-left:40px;"><a href="#2.1%20%E5%88%9B%E5%BB%BA%E9%A1%B9%E7%9B%AE" rel="nofollow">2.1 创建项目</a></p> 
<p id="2.2%20%E5%88%9B%E5%BB%BA%E5%8C%85%E5%92%8C%E7%B1%BB-toc" style="margin-left:40px;"><a href="#2.2%20%E5%88%9B%E5%BB%BA%E5%8C%85%E5%92%8C%E7%B1%BB" rel="nofollow">2.2 创建包和类</a></p> 
<p id="2.2.1%20%E5%88%9B%E5%BB%BA%E5%8C%85-toc" style="margin-left:80px;"><a href="#2.2.1%20%E5%88%9B%E5%BB%BA%E5%8C%85" rel="nofollow">2.2.1 创建包</a></p> 
<p id="2.2.2%20%E5%88%9B%E5%BB%BA%E7%B1%BB-toc" style="margin-left:80px;"><a href="#2.2.2%20%E5%88%9B%E5%BB%BA%E7%B1%BB" rel="nofollow">2.2.2 创建类</a></p> 
<p id="2.2%20%E5%BC%95%E5%85%A5jar%E5%8C%85-toc" style="margin-left:40px;"><a href="#2.2%20%E5%BC%95%E5%85%A5jar%E5%8C%85" rel="nofollow">2.2 引入jar包</a></p> 
<p id="2.2.1%20%E5%BC%95%E5%85%A5MR%E7%9B%B8%E5%85%B3jar-toc" style="margin-left:80px;"><a href="#2.2.1%20%E5%BC%95%E5%85%A5MR%E7%9B%B8%E5%85%B3jar" rel="nofollow">2.2.1 引入MR相关jar</a></p> 
<p id="2.2.2%20%E5%BC%95%E5%85%A5%E6%89%93%E5%8C%85%E6%8F%92%E4%BB%B6-toc" style="margin-left:80px;"><a href="#2.2.2%20%E5%BC%95%E5%85%A5%E6%89%93%E5%8C%85%E6%8F%92%E4%BB%B6" rel="nofollow">2.2.2 引入打包插件</a></p> 
<p id="2.3%20%E6%8B%B7%E8%B4%9D%E5%AE%98%E6%96%B9%E6%A0%B7%E4%BE%8B-toc" style="margin-left:40px;"><a href="#2.3%20%E6%8B%B7%E8%B4%9D%E5%AE%98%E6%96%B9%E6%A0%B7%E4%BE%8B" rel="nofollow">2.3 拷贝官方样例</a></p> 
<p id="2.4%20%E4%BF%AE%E6%94%B9%E6%A0%B7%E4%BE%8B%E4%BB%A3%E7%A0%81-toc" style="margin-left:40px;"><a href="#2.4%20%E4%BF%AE%E6%94%B9%E6%A0%B7%E4%BE%8B%E4%BB%A3%E7%A0%81" rel="nofollow">2.4 修改样例代码</a></p> 
<p id="2.4.1%20main%E6%96%B9%E6%B3%95%E7%A8%8B%E5%BA%8F%E9%98%85%E8%AF%BB-toc" style="margin-left:80px;"><a href="#2.4.1%20main%E6%96%B9%E6%B3%95%E7%A8%8B%E5%BA%8F%E9%98%85%E8%AF%BB" rel="nofollow">2.4.1 main方法程序阅读</a></p> 
<p id="2.4.2%20WordCountMapper-toc" style="margin-left:80px;"><a href="#2.4.2%20WordCountMapper" rel="nofollow">2.4.2 WordCountMapper</a></p> 
<p id="2.4.3%20WordCountReduce-toc" style="margin-left:80px;"><a href="#2.4.3%20WordCountReduce" rel="nofollow">2.4.3 WordCountReduce</a></p> 
<p id="2.4.4%20%E6%9B%BF%E6%8D%A2%E5%AE%9E%E7%8E%B0%E7%B1%BB-toc" style="margin-left:80px;"><a href="#2.4.4%20%E6%9B%BF%E6%8D%A2%E5%AE%9E%E7%8E%B0%E7%B1%BB" rel="nofollow">2.4.4 替换实现类</a></p> 
<p id="2.5%20%E7%A8%8B%E5%BA%8F%E6%89%93%E5%8C%85-toc" style="margin-left:40px;"><a href="#2.5%20%E7%A8%8B%E5%BA%8F%E6%89%93%E5%8C%85" rel="nofollow">2.5 程序打包</a></p> 
<p id="2.5.1%20%E7%88%B6%E9%A1%B9%E7%9B%AEpom%E4%BF%AE%E6%94%B9-toc" style="margin-left:80px;"><a href="#2.5.1%20%E7%88%B6%E9%A1%B9%E7%9B%AEpom%E4%BF%AE%E6%94%B9" rel="nofollow">2.5.1 父项目pom修改</a></p> 
<p id="2.5.2%20%E6%89%93%E5%8C%85-toc" style="margin-left:80px;"><a href="#2.5.2%20%E6%89%93%E5%8C%85" rel="nofollow">2.5.2 打包</a></p> 
<p id="2.6%20%E7%A8%8B%E5%BA%8F%E6%B5%8B%E8%AF%95-toc" style="margin-left:40px;"><a href="#2.6%20%E7%A8%8B%E5%BA%8F%E6%B5%8B%E8%AF%95" rel="nofollow">2.6 程序测试</a></p> 
<p id="2.6.1%20%E5%88%9B%E5%BB%BA%E7%9B%AE%E5%BD%95-toc" style="margin-left:80px;"><a href="#2.6.1%20%E5%88%9B%E5%BB%BA%E7%9B%AE%E5%BD%95" rel="nofollow">2.6.1 创建目录</a></p> 
<p id="2.6.2%20%E4%B8%8A%E4%BC%A0%E7%A8%8B%E5%BA%8F-toc" style="margin-left:80px;"><a href="#2.6.2%20%E4%B8%8A%E4%BC%A0%E7%A8%8B%E5%BA%8F" rel="nofollow">2.6.2 上传程序</a></p> 
<p id="2.6.3%20%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%B8%8A%E4%BC%A0%E6%B5%8B%E8%AF%95%E6%95%B0%E6%8D%AE-toc" style="margin-left:80px;"><a href="#2.6.3%20%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%B8%8A%E4%BC%A0%E6%B5%8B%E8%AF%95%E6%95%B0%E6%8D%AE" rel="nofollow">2.6.3 分布式文件系统上传测试数据</a></p> 
<p id="2.6.4%20%E6%89%A7%E8%A1%8C%E7%A8%8B%E5%BA%8F-toc" style="margin-left:80px;"><a href="#2.6.4%20%E6%89%A7%E8%A1%8C%E7%A8%8B%E5%BA%8F" rel="nofollow">2.6.4 执行程序</a></p> 
<p id="-toc" style="margin-left:0px;">                  <a href="#2.6.5%20%E6%9F%A5%E7%9C%8B%E7%BB%93%E6%9E%9C" rel="nofollow">2.6.5 查看结果</a></p> 
<hr id="hr-toc"> 
<p></p> 
<p><code>提示：以下是本篇文章正文内容，下面案例可供参考</code></p> 
<h2 id="1%20%E9%9C%80%E6%B1%82%E5%88%86%E6%9E%90"><span style="color:#335b8a;"><strong><strong><span style="color:#335b8a;"><strong>1 需求分析</strong></span></strong></strong></span></h2> 
<p></p> 
<h3 id="1.1%20%E9%9C%80%E6%B1%82"><span style="color:#4f81bd;"><strong><strong><span style="color:#4f81bd;"><strong>1.1 需求</strong></span></strong></strong></span></h3> 
<ul><li>统计文件中各个单词出现的个数</li></ul> 
<h3 id="1.2%20%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87"><span style="color:#4f81bd;"><strong><strong><span style="color:#4f81bd;"><strong>1.2 数据准备</strong></span></strong></strong></span></h3> 
<ul><li>数据准备：hello.txt</li></ul> 
<p>Once when l was six years old l saw a magnificent picture in a book called True Stories from Nature, about the primeval forest.<br> lt was a picture of a boa constrictor in the act of swallowing an animal.<br> Here is a copy of the drawing: In the book it said:"Boa constrictors swallow their prey whole, without chewing it.<br> After that they are not able to move, and they sleep through the six months that they need for digestion."<br> And after some work with a coloured pencil l succeeded in making my first drawing.<br> My Drawing Number One.<br> lt iooked like this: I showed my masterpiece to the grown-ups, and asked them whether the drawing frightened them.<br> But they answered:"Frighten?<br> why should anyone be frightened by a hat?<br> My drawing was not a picture of a hat.<br> lt was a picture of a boa constrictor digesting an elephant.<br> But since the grown-ups were not able to understand it, I made another drawing.<br> l drew the inside of the boa constrictor, so that the grown-ups could see it clearly.<br> They always need to have things explained.</p> 
<p><img alt="" height="251" src="https://images2.imgbox.com/a9/82/Pzh0UD4h_o.png" width="700"></p> 
<h3 id="1.3%20%E5%8E%9F%E7%90%86"><span style="color:#4f81bd;"><strong><strong><span style="color:#4f81bd;"><strong>1.3 原理</strong></span></strong></strong></span></h3> 
<p><img alt="" height="278" src="https://images2.imgbox.com/b7/dd/iToJxOSt_o.png" width="700"></p> 
<h2><a id="pandas_16"></a></h2> 
<p></p> 
<ul><li>数据切分：把文本中的每一行进行切分。hadoop提供类实现。</li><li>每一行切分出来形成一个split，交给map进行处理，map会把一行数据中的单词以key-value的形式进行输出，发现一个单词就设置一个key。key是单词名称，value是1。</li><li>map把最终的到数据经过整理以后交给不同的reduce进行处理，不同的reduce会收到不同的key-value数据。图中有些reduce收到以B开头的数据，有些reduce收到以C开头的数据。</li><li>reduce会把收到的数据进行合并计算，输出最终的一个结果。</li></ul> 
<h2 id="2%20%E7%BC%96%E7%A0%81%E6%93%8D%E4%BD%9C"><span style="color:#335b8a;"><strong><strong><span style="color:#335b8a;"><strong>2 编码操作</strong></span></strong></strong></span></h2> 
<h3 id="2.1%20%E5%88%9B%E5%BB%BA%E9%A1%B9%E7%9B%AE"><span style="color:#4f81bd;"><strong><strong><span style="color:#4f81bd;"><strong>2.1 创建项目</strong></span></strong></strong></span></h3> 
<ul><li>创建一个mr-demo的子模块</li></ul> 
<p><img alt="" height="450" src="https://images2.imgbox.com/2e/53/mhqhlVJn_o.png" width="700"></p> 
<p></p> 
<p><img alt="" height="652" src="https://images2.imgbox.com/4e/2e/bBt5cPwY_o.png" width="700"></p> 
<p><img alt="" height="652" src="https://images2.imgbox.com/0a/ef/O9KSzQmd_o.png" width="700"></p> 
<p><img alt="" height="507" src="https://images2.imgbox.com/a7/f5/zhEjGNSI_o.png" width="700"></p> 
<h3 id="2.2%20%E5%88%9B%E5%BB%BA%E5%8C%85%E5%92%8C%E7%B1%BB"><span style="color:#4f81bd;"><strong><strong><span style="color:#4f81bd;"><strong>2.2 创建包和类</strong></span></strong></strong></span></h3> 
<h4 id="2.2.1%20%E5%88%9B%E5%BB%BA%E5%8C%85"><span style="color:#4f81bd;"><strong><strong><span style="color:#4f81bd;"><strong>2.2.1 创建包</strong></span></strong></strong></span></h4> 
<ul><li>创建org.hadoop.mr包</li></ul> 
<p><img alt="" height="411" src="https://images2.imgbox.com/41/24/kPmwUgKj_o.png" width="700"></p> 
<p></p> 
<p><img alt="" height="224" src="https://images2.imgbox.com/6d/2b/vmdR4Jj1_o.png" width="700"></p> 
<p><img alt="" height="492" src="https://images2.imgbox.com/9f/82/DH7H36gy_o.png" width="700"></p> 
<h4 id="2.2.2%20%E5%88%9B%E5%BB%BA%E7%B1%BB"><span style="color:#4f81bd;"><strong><strong><span style="color:#4f81bd;"><strong>2.2.2 创建类</strong></span></strong></strong></span></h4> 
<ul><li>创建WordCount类</li></ul> 
<p><img alt="" height="374" src="https://images2.imgbox.com/0c/79/mNBD8Fh5_o.png" width="700"></p> 
<p> <img alt="" height="462" src="https://images2.imgbox.com/e9/c3/B7yD37kQ_o.png" width="700"></p> 
<p> <img alt="" height="400" src="https://images2.imgbox.com/01/f2/xakwmbjV_o.png" width="700"></p> 
<p> </p> 
<h3 id="2.2%20%E5%BC%95%E5%85%A5jar%E5%8C%85"><span style="color:#4f81bd;"><strong><strong><span style="color:#4f81bd;"><strong>2.2 引入jar包</strong></span></strong></strong></span></h3> 
<h4 id="2.2.1%20%E5%BC%95%E5%85%A5MR%E7%9B%B8%E5%85%B3jar"><span style="color:#4f81bd;"><strong><strong><span style="color:#4f81bd;"><strong>2.2.1 引入MR相关jar</strong></span></strong></strong></span></h4> 
<ul><li>切记一定要联网，联网，联网</li><li>检查IDEA里面pom.xml文件是否引入正常</li><li>在pom.xml里面加入以下代码</li></ul> 
<pre><code class="language-XML">  &lt;dependencies&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;
      &lt;artifactId&gt;hadoop-common&lt;/artifactId&gt;
      &lt;version&gt;2.9.2&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;
      &lt;artifactId&gt;hadoop-mapreduce-client-jobclient&lt;/artifactId&gt;
      &lt;version&gt;2.9.2&lt;/version&gt;
      &lt;scope&gt;provided&lt;/scope&gt;
    &lt;/dependency&gt;
  &lt;/dependencies&gt;</code></pre> 
<p><img alt="" height="412" src="https://images2.imgbox.com/f5/4d/hVkIovwh_o.png" width="700"></p> 
<ul><li>点击Reload一般情况下能看到正常引入相关JAR</li></ul> 
<p><img alt="" height="287" src="https://images2.imgbox.com/8c/4d/4yqyX1Zy_o.png" width="700"></p> 
<ul><li>如果Reload不能正常引入可以尝试package 
  <ul><li>一定要联网下载JAR包</li><li>有时候能正常打包，但是代码仍然报错，重启IDEA再Reload就可以解决</li><li>如果报错则检查Maven的settings配置是否正确</li><li>如果告知具体的JAR下载不了，可以换一个网络再次尝试，也可以到仓库里面删除具体的jar包重新下载</li><li>可以换Maven仓库再尝试下载</li></ul></li></ul> 
<p><img alt="" height="304" src="https://images2.imgbox.com/58/43/pkgcIWp6_o.png" width="700"></p> 
<p>新手在使用maven引入JAR包的时候非常容易出错，多尝试即可</p> 
<h4 id="2.2.2%20%E5%BC%95%E5%85%A5%E6%89%93%E5%8C%85%E6%8F%92%E4%BB%B6"><span style="color:#4f81bd;"><strong><strong><span style="color:#4f81bd;"><strong>2.2.2 引入打包插件</strong></span></strong></strong></span></h4> 
<ul><li>需要打包运行在集群环境</li><li>在pom.xml文件里面引入以下配置</li></ul> 
<p style="margin-left:24pt;"><strong><strong>build配置需放置在dependencies标签后面，但是要在project标签里面</strong></strong></p> 
<p> </p> 
<pre><code class="language-XML">  &lt;build&gt;
  	&lt;plugins&gt;
	    &lt;plugin&gt;
	    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
	     &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;
	      &lt;configuration&gt;
	       &lt;archive&gt;
	         &lt;manifest&gt;
	           &lt;mainClass&gt;org.hadoop.mr.demo.WordCount&lt;/mainClass&gt;
	         &lt;/manifest&gt;
	       &lt;/archive&gt;
	     &lt;/configuration&gt;
	    &lt;/plugin&gt;
  	&lt;/plugins&gt;
  &lt;/build&gt;



  &lt;build&gt;
  	&lt;plugins&gt;
	    &lt;plugin&gt;
	    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
	     &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;
	      &lt;configuration&gt;
	       &lt;archive&gt;
	         &lt;manifest&gt;
	           &lt;mainClass&gt;org.hadoop.mr.FriendRecommend&lt;/mainClass&gt;
	         &lt;/manifest&gt;
	       &lt;/archive&gt;
	     &lt;/configuration&gt;
	    &lt;/plugin&gt;
  	&lt;/plugins&gt;
  &lt;/build&gt;</code></pre> 
<p><img alt="" height="342" src="https://images2.imgbox.com/ca/4d/GmbhwdQY_o.png" width="700"></p> 
<ul><li>mainClass配置需修改，并且鼠标放置在上面且按住ctrl键能连接到对应的类文件</li></ul> 
<p><img alt="" height="354" src="https://images2.imgbox.com/a1/72/ZhYXmyyT_o.png" width="700"> </p> 
<h3 id="2.3%20%E6%8B%B7%E8%B4%9D%E5%AE%98%E6%96%B9%E6%A0%B7%E4%BE%8B"><span style="color:#4f81bd;"><strong><strong><span style="color:#4f81bd;"><strong>2.3 拷贝官方样例</strong></span></strong></strong></span></h3> 
<ul><li>官方提供了WordCount的样例，我们需要拷贝过来</li><li>把官方样例类里面的代码拷贝到我们创建的WordCount类中</li><li>import代码中使用的jar包，import过程需要注意import的报名对应</li></ul> 
<p> </p> 
<pre><code class="language-java">import java.io.IOException; 
import java.util.StringTokenizer; 
 
import org.apache.hadoop.conf.Configuration; 
import org.apache.hadoop.fs.Path; 
import org.apache.hadoop.io.IntWritable; 
import org.apache.hadoop.io.Text; 
import org.apache.hadoop.mapreduce.Job; 
import org.apache.hadoop.mapreduce.Mapper; 
import org.apache.hadoop.mapreduce.Reducer; 
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat; 
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat; 
import org.apache.hadoop.util.GenericOptionsParser; 
 
 
public class WordCount { 
 
    public static class TokenizerMapper 
            extends Mapper&lt;Object, Text, Text, IntWritable&gt;{ 
 
        private final static IntWritable one = new IntWritable(1); 
        private Text word = new Text(); 
 
        public void map(Object key, Text value, Context context 
        ) throws IOException, InterruptedException { 
            StringTokenizer itr = new StringTokenizer(value.toString()); 
            while (itr.hasMoreTokens()) { 
                word.set(itr.nextToken()); 
                context.write(word, one); 
            } 
        } 
    } 
 
    public static class IntSumReducer 
            extends Reducer&lt;Text,IntWritable,Text,IntWritable&gt; { 
        private IntWritable result = new IntWritable(); 
 
        public void reduce(Text key, Iterable&lt;IntWritable&gt; values, 
                           Context context 
        ) throws IOException, InterruptedException { 
            int sum = 0; 
            for (IntWritable val : values) { 
                sum += val.get(); 
            } 
            result.set(sum); 
            context.write(key, result); 
        } 
    } 
 
    public static void main(String[] args) throws Exception { 
        Configuration conf = new Configuration(); 
        String[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs(); 
        if (otherArgs.length &lt; 2) { 
            System.err.println("Usage: wordcount &lt;in&gt; [&lt;in&gt;...] &lt;out&gt;"); 
            System.exit(2); 
        } 
        Job job = Job.getInstance(conf, "word count"); 
        job.setJarByClass(WordCount.class); 
        job.setMapperClass(TokenizerMapper.class); 
        job.setCombinerClass(IntSumReducer.class); 
        job.setReducerClass(IntSumReducer.class); 
        job.setOutputKeyClass(Text.class); 
        job.setOutputValueClass(IntWritable.class); 
        for (int i = 0; i &lt; otherArgs.length - 1; ++i) { 
            FileInputFormat.addInputPath(job, new Path(otherArgs[i])); 
        } 
        FileOutputFormat.setOutputPath(job, 
                new Path(otherArgs[otherArgs.length - 1])); 
        System.exit(job.waitForCompletion(true) ? 0 : 1); 
    } 
 
}</code></pre> 
<h3 id="2.4%20%E4%BF%AE%E6%94%B9%E6%A0%B7%E4%BE%8B%E4%BB%A3%E7%A0%81"><span style="color:#4f81bd;"><strong><strong><span style="color:#4f81bd;"><strong>2.4 修改样例代码</strong></span></strong></strong></span></h3> 
<h4 id="2.4.1%20main%E6%96%B9%E6%B3%95%E7%A8%8B%E5%BA%8F%E9%98%85%E8%AF%BB"><span style="color:#4f81bd;"><strong><strong><span style="color:#4f81bd;"><strong>2.4.1 main方法程序阅读</strong></span></strong></strong></span></h4> 
<ul><li>map的实现逻辑通过TokenizerMapper来实现</li><li>reduce逻辑通过IntSumReducer来实现</li><li>当前TokenizerMapper和IntSumReducer是WordCount的内部类，我们为了方便理解，需要把这两个类移到外部</li><li>TokenizerMapper和IntSumReducer类需要注释掉</li></ul> 
<pre><code class="language-java">	public static void main(String[] args) throws Exception {
		//通过Configuration加装配置信息，配置信息在真正运行的虚拟机上
		Configuration conf = new Configuration();
		//解析main方法的入参，入参包含：计算时数据放在哪个目录；计算完成后结果写入哪个目录
		//参数不能小于2
		String[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs();
		if (otherArgs.length &lt; 2) {
			System.err.println("Usage: wordcount &lt;in&gt; [&lt;in&gt;...] &lt;out&gt;");
			System.exit(2);
		}
		//创建Job类型对象，通过Job来运行计算任务
		Job job = Job.getInstance(conf, "word count");
		
		//Job运行的执行类是WordCount
		job.setJarByClass(WordCount.class);
		//计算任务的map逻辑由TokenizerMapper来完成
		job.setMapperClass(TokenizerMapper.class);
		//合并优化方法，暂时不用
		//job.setCombinerClass(IntSumReducer.class);
		//执行reduce逻辑方法是IntSumReducer
		job.setReducerClass(IntSumReducer.class);
		
		//执行完成结果输出key和value分别对应的类型
		job.setOutputKeyClass(Text.class);
		job.setOutputValueClass(IntWritable.class);
		
		//处理输入数据，输入数据可以是多个目录，通过循环把输入路径添加到处理路径下
		for (int i = 0; i &lt; otherArgs.length - 1; ++i) {
			FileInputFormat.addInputPath(job, new Path(otherArgs[i]));
		}
		
		//输出路径只有一个
		FileOutputFormat.setOutputPath(job, new Path(otherArgs[otherArgs.length - 1]));
		
		//运行Job等待完成，0成功
		System.exit(job.waitForCompletion(true) ? 0 : 1);
	}</code></pre> 
<h4 id="2.4.2%20WordCountMapper"><span style="color:#4f81bd;"><strong><strong><span style="color:#4f81bd;"><strong>2.4.2 WordCountMapper</strong></span></strong></strong></span></h4> 
<ul><li>创建一个WordCountMapper类</li></ul> 
<p>/**<br>  *  <br>  * WordCountMapper需要继承Hadoop提供的Mapper<br>  * 1、Mapper&lt;KEYIN, VALUEIN, KEYOUT, VALUEOUT&gt;<br>  * Mapper参数：<br>  * KEYIN、VALUEIN-代表输入数据，KEYIN代表输入数据key类型，VALUEIN代表输入数据value类型<br>  * KEYIN-切分的类由hadoop提供的类提供的，切分出来这个key是一个偏移量（long类型，字符位置），这个偏移量本程序用不到，使用Object类型替代<br>  * VALUEIN-数据切分按照行切分，每行数据是一个字符串<br>  * KEYOUT、VALUEOUT-代表输出数据，KEYOUT代表输出数据key类型，VALUEIN代表输出数据value类型<br>  * KEYOUT-数据处理完成后，key是一个单词名称，使用Text类型<br>  * VALUEOUT-数量<br>  * 2、map(Object key, Text value, Context context)<br>  * Context 上下文，代表hadoop中MapReduce中的计算环境<br>  *  <br>  *  <br>  * 3、重写map方法<br>  *  <br>  *<br>  */</p> 
<pre><code class="language-java">public class WordCountMapper extends Mapper&lt;Object, Text, Text, IntWritable&gt; { 
	 
    public void map(Object key, Text value, Context context) throws IOException, InterruptedException{ 
    	//将获得的value进行切分（每行字符串），单词之间空格切分，获得一个数组 
        String[] words = value.toString().split(" "); 
        //遍历数组，获得每个单词，每个单词标记为1进行输出 
        for (int i = 0; i &lt; words.length; i++) { 
        	String word = words[i]; 
        	 
        	Text text = new Text(); 
        	text.set(word); 
        	context.write(text,new IntWritable(1)); 
		} 
    } 
}</code></pre> 
<h4 id="2.4.3%20WordCountReduce"><span style="color:#4f81bd;"><strong><strong><span style="color:#4f81bd;"><strong>2.4.3 WordCountReduce</strong></span></strong></strong></span></h4> 
<ul><li>创建一个WordCountReduce类</li><li>WordCountReduce 一个单词调用一次</li></ul> 
<p><em><span style="color:#60a0b0;">/**</span></em><br>  <em><span style="color:#60a0b0;">*</span></em> <br>  <em><span style="color:#60a0b0;">*</span></em> WordCountReduce需要继承Hadoop提供的Reducer<br>  <em><span style="color:#60a0b0;">*</span></em> <em><span style="color:#60a0b0;">1、</span></em>Reducer<strong><span style="color:#007020;">&lt;KEYIN</span></strong><strong><span style="color:#ff0000;">,</span></strong><span style="color:#007020;"> VALUEIN</span><strong><span style="color:#ff0000;">,</span></strong><span style="color:#007020;"> KEYOUT</span><strong><span style="color:#ff0000;">,</span></strong><span style="color:#007020;"> VALUEOUT</span><strong><span style="color:#007020;">&gt;</span></strong><br>  <em><span style="color:#60a0b0;">*</span></em>    Reducer参数：<br>  <em><span style="color:#60a0b0;">*</span></em>  KEYIN、VALUEIN<em><span style="color:#60a0b0;">-</span></em>代表输入数据，KEYIN代表输入数据key类型，VALUEIN代表输入数据value类型。此处reduce的输入是map的输出<br>  <em><span style="color:#60a0b0;">*</span></em>  KEYIN<em><span style="color:#60a0b0;">-</span></em> Text<br>  <em><span style="color:#60a0b0;">*</span></em>  VALUEIN<em><span style="color:#60a0b0;">-</span></em>IntWritable<br>  <em><span style="color:#60a0b0;">*</span></em>  KEYOUT、VALUEOUT<em><span style="color:#60a0b0;">-</span></em>代表输出数据，KEYOUT代表输出数据key类型，VALUEIN代表输出数据value类型<br>  <em><span style="color:#60a0b0;">*</span></em>  KEYOUT<em><span style="color:#60a0b0;">-</span></em>Reducer做合并，最终输出也是单词和数量，key是Text<br>  <em><span style="color:#60a0b0;">*</span></em>  VALUEOUT<em><span style="color:#60a0b0;">-</span></em>数量<br>  <em><span style="color:#60a0b0;">*</span></em> <em><span style="color:#60a0b0;">2、</span></em>reduce<em><span style="color:#60a0b0;">(</span></em>Object key<em><span style="color:#60a0b0;">,</span></em> Iterable values<em><span style="color:#60a0b0;">,</span></em> Context context<em><span style="color:#60a0b0;">)</span></em><br>  <em><span style="color:#60a0b0;">*</span></em>  Iterable 输入的value类型IntWritable<em><span style="color:#60a0b0;">,</span></em>并且是迭代泛型参数，表示值是一个列表。收集到的数据是合并的数据。<br>  <em><span style="color:#60a0b0;">*</span></em>  Context 上下文，代表hadoop中MapReduce中的计算环境<br>  <em><span style="color:#60a0b0;">*</span></em><br>  <em><span style="color:#60a0b0;">*/</span></em></p> 
<pre><code class="language-java">public class WordCountReduce extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; {

	protected void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException {
		//设置计数
		int sum = 0;
		//遍历values列表进行加总
		for (IntWritable intWritable : values) {
			sum = sum + intWritable.get();
		}

		//获得每个单词最终次数，进行输出
		context.write(key, new IntWritable(sum));
	}
}</code></pre> 
<h4 id="2.4.4%20%E6%9B%BF%E6%8D%A2%E5%AE%9E%E7%8E%B0%E7%B1%BB"><span style="color:#4f81bd;"><strong><strong><span style="color:#4f81bd;"><strong>2.4.4 替换实现类</strong></span></strong></strong></span></h4> 
<ul><li>WordCount类中TokenizerMapper和IntSumReducer确认注释掉</li></ul> 
<p><img alt="" height="399" src="https://images2.imgbox.com/78/04/VIOlMnuV_o.png" width="700"></p> 
<ul><li>WordCount类中main方法map和reduce实现类替换成自定义实现类</li></ul> 
<p> </p> 
<pre><code class="language-java">	public static void main(String[] args) throws Exception {
		//通过Configuration加装配置信息，配置信息在真正运行的虚拟机上
		Configuration conf = new Configuration();
		//解析main方法的入参，入参包含：计算时数据放在哪个目录；计算完成后结果写入哪个目录
		//参数不能小于2
		String[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs();
		if (otherArgs.length &lt; 2) {
			System.err.println("Usage: wordcount &lt;in&gt; [&lt;in&gt;...] &lt;out&gt;");
			System.exit(2);
		}
		//创建Job类型对象，通过Job来运行计算任务
		Job job = Job.getInstance(conf, "word count");
		
		//Job运行的执行类是WordCount
		job.setJarByClass(WordCount.class);
		//计算任务的map逻辑由WordCountMapper来完成
		job.setMapperClass(WordCountMapper.class);
		//合并优化方法，暂时不用
		//job.setCombinerClass(IntSumReducer.class);
		//执行reduce逻辑方法是WordCountReduce
		job.setReducerClass(WordCountReduce.class);
		
		//执行完成结果输出key和value分别对应的类型
		job.setOutputKeyClass(Text.class);
		job.setOutputValueClass(IntWritable.class);
		
		//处理输入数据，输入数据可以是多个目录，通过循环把输入路径添加到处理路径下
		for (int i = 0; i &lt; otherArgs.length - 1; ++i) {
			FileInputFormat.addInputPath(job, new Path(otherArgs[i]));
		}
		
		//输出路径只有一个
		FileOutputFormat.setOutputPath(job, new Path(otherArgs[otherArgs.length - 1]));
		
		//运行Job等待完成，0成功
		System.exit(job.waitForCompletion(true) ? 0 : 1);
	}</code></pre> 
<p></p> 
<h3 id="2.5%20%E7%A8%8B%E5%BA%8F%E6%89%93%E5%8C%85"><span style="color:#4f81bd;"><strong><strong><span style="color:#4f81bd;"><strong>2.5 程序打包</strong></span></strong></strong></span></h3> 
<h4 id="2.5.1%20%E7%88%B6%E9%A1%B9%E7%9B%AEpom%E4%BF%AE%E6%94%B9"><span style="color:#4f81bd;"><strong><strong><span style="color:#4f81bd;"><strong>2.5.1 父项目pom修改</strong></span></strong></strong></span></h4> 
<ul><li>注释掉无关项目</li></ul> 
<p><img alt="" height="710" src="https://images2.imgbox.com/00/a5/IxrS7EhB_o.png" width="1200"></p> 
<p> </p> 
<h4 id="2.5.2%20%E6%89%93%E5%8C%85"><span style="color:#4f81bd;"><strong><strong><span style="color:#4f81bd;"><strong>2.5.2 打包</strong></span></strong></strong></span></h4> 
<ul><li>在父项目的maven视图下点击package进行打包</li></ul> 
<p><img alt="" height="262" src="https://images2.imgbox.com/9a/f8/Xi7dsZF1_o.png" width="700"></p> 
<p> </p> 
<ul><li>如果打包成功可以获得jar包</li></ul> 
<p><img alt="" height="323" src="https://images2.imgbox.com/fe/25/v9O1EWaM_o.png" width="700"></p> 
<p> <img alt="" height="322" src="https://images2.imgbox.com/0d/89/WEOIBI9k_o.png" width="700"></p> 
<p> </p> 
<p></p> 
<h3 id="2.6%20%E7%A8%8B%E5%BA%8F%E6%B5%8B%E8%AF%95"><span style="color:#4f81bd;"><strong><strong><span style="color:#4f81bd;"><strong>2.6 程序测试</strong></span></strong></strong></span></h3> 
<h4 id="2.6.1%20%E5%88%9B%E5%BB%BA%E7%9B%AE%E5%BD%95"><span style="color:#4f81bd;"><strong><strong><span style="color:#4f81bd;"><strong>2.6.1 创建目录</strong></span></strong></strong></span></h4> 
<ul><li>创建程序以及数据存放目录</li></ul> 
<p>cd /opt/<br> ls # 如果目录下没有testData目录的话自己手动创建一下即可<br> cd testData/<br> mkdir mapreduce<br> cd mapreduce/</p> 
<p><img alt="" height="385" src="https://images2.imgbox.com/79/9c/B2cuMmTX_o.png" width="700"></p> 
<h4 id="2.6.2%20%E4%B8%8A%E4%BC%A0%E7%A8%8B%E5%BA%8F"><span style="color:#4f81bd;"><strong><strong><span style="color:#4f81bd;"><strong>2.6.2 上传程序</strong></span></strong></strong></span></h4> 
<ul><li>把程序先上传到虚拟机node01里面</li></ul> 
<p>cd /opt/testData/mapreduce/</p> 
<p>rz</p> 
<p> <img alt="" height="185" src="https://images2.imgbox.com/d6/68/0aUWFm6o_o.png" width="700"></p> 
<p> </p> 
<p></p> 
<h4 id="2.6.3%20%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%B8%8A%E4%BC%A0%E6%B5%8B%E8%AF%95%E6%95%B0%E6%8D%AE"><span style="color:#4f81bd;"><strong><strong><span style="color:#4f81bd;"><strong>2.6.3 分布式文件系统上传测试数据</strong></span></strong></strong></span></h4> 
<ul><li>首先上传本地测试文件hello.txt到虚拟机</li></ul> 
<p>cd /opt/testData/mapreduce/<br> rz</p> 
<p><img alt="" height="49" src="https://images2.imgbox.com/34/bb/3KK3edZ1_o.png" width="700"></p> 
<p> </p> 
<ul><li>确认Hadoop集群已经开启 
  <ul><li>此处必须开启yarn集群</li></ul></li></ul> 
<p>start-dfs.sh<br> start-yarn.sh</p> 
<p><img alt="" height="149" src="https://images2.imgbox.com/62/4d/Oq9g7UOF_o.png" width="700"></p> 
<ul><li>分布式文件系统创建input目录并且input目录上传测试文件hello.txt</li></ul> 
<p>hdfs dfs -mkdir /input<br> hdfs dfs -put hello.txt  /input</p> 
<p>hdfs dfs -ls /input</p> 
<p><img alt="" height="282" src="https://images2.imgbox.com/96/9b/LTu9MdCu_o.png" width="700"></p> 
<h4 id="2.6.4%20%E6%89%A7%E8%A1%8C%E7%A8%8B%E5%BA%8F"><span style="color:#4f81bd;"><strong><strong><span style="color:#4f81bd;"><strong>2.6.4 执行程序</strong></span></strong></strong></span></h4> 
<p>hadoop jar mr-demo-0.0.1-SNAPSHOT.jar  /input /output</p> 
<p></p> 
<p><img alt="" height="230" src="https://images2.imgbox.com/07/f7/jAjTWdHs_o.png" width="700"></p> 
<hr> 
<h2><a id="_45"></a></h2> 
<h4 id="2.6.5%20%E6%9F%A5%E7%9C%8B%E7%BB%93%E6%9E%9C"><span style="color:#4f81bd;"><strong><strong><span style="color:#4f81bd;"><strong>2.6.5 查看结果</strong></span></strong></strong></span></h4> 
<p>hdfs dfs -cat /output/part-r-00000</p> 
<p><img alt="" height="222" src="https://images2.imgbox.com/06/40/bLD6LoFH_o.png" width="700"></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/434ad245f9cb0e0e565c57751a7972b5/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">CorelDRAW2022中文正式版特色功能介绍</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/bd479399b7025a8cf8a8a37a00c44d81/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">吸顶效果：1.css属性sticky优缺点 2.简单js实现吸顶效果</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程爱好者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151260"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>