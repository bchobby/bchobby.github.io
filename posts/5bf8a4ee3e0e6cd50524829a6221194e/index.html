<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>sqoop的基本语法详解及可能遇到的错误 - 编程爱好者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="sqoop的基本语法详解及可能遇到的错误" />
<meta property="og:description" content="0 sqoop介绍 Apache Sqoop是专为Apache Hadoop和结构化数据存储如关系数据库之间的数据转换工具的有效工具。你可以使用Sqoop从外部结构化数据存储的数据导入到Hadoop分布式文件系统或相关系统如Hive和HBase。相反，Sqoop可以用来从Hadoop的数据提取和导出到外部结构化数据存储如关系数据库和企业数据仓库。
Sqoop专为大数据批量传输设计，能够分割数据集并创建Hadoop任务来处理每个区块。
sqoop的安装和下载可参考该地址
1 使用场景 Sqoop底层其实就是MapReduce，那使用Sqoop必然会存在数据延迟的问题，我个人建议哈，在数据量不是很大或者实时性要求不高的情况下，使用Sqoop还是很方便的哈，直接通过配置就可以各种数据的导入导出。如果大家学习过Spark应该知道其实Spark SQL用起来也是很方便的，给我们提供了外部数据源，方便我们对各种数据类型的读写哈。 所以怎么用看大家的自己选择，没有最好的，只有最适合自己的~。
官网
使用手册
2 查看帮助命令 查看命令帮助（sqoop help
）
[hadoop@zhangyu lib]$ sqoop help usage: sqoop COMMAND [ARGS] Available commands: codegen Generate code to interact with database records create-hive-table Import a table definition into Hive eval Evaluate a SQL statement and display the results export Export an HDFS directory to a database table help List available commands import Import a table from a database to HDFS import-all-tables Import tables from a database to HDFS import-mainframe Import datasets from a mainframe server to HDFS job Work with saved jobs list-databases List available databases on a server list-tables List available tables in a database merge Merge results of incremental imports metastore Run a standalone Sqoop metastore version Display version information See &#39;sqoop help COMMAND&#39; for information on a specific command." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bchobby.github.io/posts/5bf8a4ee3e0e6cd50524829a6221194e/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2018-01-15T21:53:54+08:00" />
<meta property="article:modified_time" content="2018-01-15T21:53:54+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程爱好者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程爱好者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">sqoop的基本语法详解及可能遇到的错误</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h4><a id="0_sqoop_0"></a>0 sqoop介绍</h4> 
<p>Apache Sqoop是专为Apache Hadoop和结构化数据存储如关系数据库之间的数据转换工具的有效工具。你可以使用Sqoop从外部结构化数据存储的数据导入到Hadoop分布式文件系统或相关系统如Hive和HBase。相反，Sqoop可以用来从Hadoop的数据提取和导出到外部结构化数据存储如关系数据库和企业数据仓库。<br> Sqoop专为大数据批量传输设计，能够分割数据集并创建Hadoop任务来处理每个区块。<br> sqoop的安装和下载可参考<a href="http://blog.csdn.net/yu0_zhang0/article/details/79067383">该地址</a></p> 
<h4><a id="1__4"></a>1 使用场景</h4> 
<p>Sqoop底层其实就是MapReduce，那使用Sqoop必然会存在数据延迟的问题，我个人建议哈，在数据量不是很大或者实时性要求不高的情况下，使用Sqoop还是很方便的哈，直接通过配置就可以各种数据的导入导出。如果大家学习过Spark应该知道其实Spark SQL用起来也是很方便的，给我们提供了外部数据源，方便我们对各种数据类型的读写哈。 所以怎么用看大家的自己选择，<strong>没有最好的，只有最适合自己的~。</strong></p> 
<p><a href="http://sqoop.apache.org/" rel="nofollow">官网</a><br> <a href="http://sqoop.apache.org/docs/1.4.7/SqoopUserGuide.html" rel="nofollow">使用手册</a></p> 
<h4><a id="2__9"></a>2 查看帮助命令</h4> 
<p>查看命令帮助（sqoop help<br> ）</p> 
<pre><code class="prism language-shell"><span class="token punctuation">[</span>hadoop@zhangyu lib<span class="token punctuation">]</span>$ sqoop <span class="token function">help</span>
usage: sqoop COMMAND <span class="token punctuation">[</span>ARGS<span class="token punctuation">]</span>

Available commands:
  codegen            Generate code to interact with database records
  create-hive-table  Import a table definition into Hive
  <span class="token function">eval</span>               Evaluate a SQL statement and display the results
  <span class="token function">export</span>             Export an HDFS directory to a database table
  <span class="token function">help</span>               List available commands
  <span class="token function">import</span>             Import a table from a database to HDFS
  import-all-tables  Import tables from a database to HDFS
  import-mainframe   Import datasets from a mainframe server to HDFS
  job                Work with saved <span class="token function">jobs</span>
  list-databases     List available databases on a server
  list-tables        List available tables <span class="token keyword">in</span> a database
  merge              Merge results of incremental imports
  metastore          Run a standalone Sqoop metastore
  version            Display version information

See <span class="token string">'sqoop help COMMAND'</span> <span class="token keyword">for</span> information on a specific command.

这里提示我们使用sqoop <span class="token function">help</span> command（要查询的命令）进行该命令的详细查询
</code></pre> 
<h4><a id="3_listdatabases_37"></a>3 list-databases</h4> 
<pre><code class="prism language-shell"><span class="token punctuation">[</span>hadoop@zhangyu lib<span class="token punctuation">]</span>$ sqoop <span class="token function">help</span> list-databases
</code></pre> 
<ol><li>–connect jdbc:mysql://hostname:port/database指定mysql数据库主机名和端口号和数据库名(默认端口号为3306)；</li><li>–username : root 指定数据库用户名</li><li>–password :123456 指定数据库密码</li></ol> 
<pre><code class="prism language-shell"><span class="token punctuation">[</span>hadoop@zhangyu lib<span class="token punctuation">]</span>$ sqoop list-databases \
<span class="token operator">&gt;</span> --connect jdbc:mysql://localhost:3306 \
<span class="token operator">&gt;</span> --username root \
<span class="token operator">&gt;</span> --password 123456

结果：
information_schema
basic01
mysql
performance_schema
sqoop
<span class="token function">test</span>
</code></pre> 
<h4><a id="4_listtables_60"></a>4 list-tables</h4> 
<pre><code class="prism language-shell"><span class="token punctuation">[</span>hadoop@zhangyu lib<span class="token punctuation">]</span>$ sqoop list-tables \
<span class="token operator">&gt;</span> --connect jdbc:mysql://localhost:3306/sqoop \
<span class="token operator">&gt;</span> --username root \
<span class="token operator">&gt;</span> --password 123456
结果：
stu
</code></pre> 
<h4><a id="5_mysqlHDFSimport_70"></a>5 将mysql导入HDFS中(import)：</h4> 
<p>(默认导入当前用户目录下/user/用户名/表名)<br> 说到这里扩展一个小知识点：<code>hdfs dfs -ls</code>和<code>hdfs dfs -ls \</code>的区别。（自己动手去测试下~~~）</p> 
<pre><code class="prism language-shell">sqoop <span class="token function">import</span> --connect jdbc:mysql://localhost/database --username root --password 123456 --table example –m 1
</code></pre> 
<ol><li>–table : example mysql中即将导出的表</li><li>-m 1 指定启动一个map进程，如果表很大，可以启动多个map进程，默认是4个</li></ol> 
<p><strong>这里可能会出现两个错误，如下：</strong></p> 
<ul><li>第一个错误</li></ul> 
<pre><code class="prism language-java"><span class="token number">18</span><span class="token operator">/</span><span class="token number">01</span><span class="token operator">/</span><span class="token number">14</span> <span class="token number">16</span><span class="token operator">:</span><span class="token number">01</span><span class="token operator">:</span><span class="token number">19</span> ERROR tool<span class="token punctuation">.</span>ImportTool<span class="token operator">:</span> Error during <span class="token keyword">import</span><span class="token operator">:</span> No primary key could be found <span class="token keyword">for</span> table stu<span class="token punctuation">.</span> Please specify one with <span class="token operator">--</span>split<span class="token operator">-</span>by or perform a sequential <span class="token keyword">import</span> with <span class="token string">'-m 1'</span><span class="token punctuation">.</span>
</code></pre> 
<ul><li>提示可以看出，在我们从mysql中导出的表没有设定主键，提示我们使用把<code>--split-by</code>或者把参数-m设置为1，这里大家会不会问到，这倒是是为什么呢？</li></ul> 
<ol><li>Sqoop通可以过–split-by指定切分的字段，–m设置mapper的数量。通过这两个参数分解生成m个where子句，进行分段查询。</li><li>split-by 根据不同的参数类型有不同的切分方法，如表共有100条数据其中id为int类型，并且我们指定–split-by id，我们不设置map数量使用默认的为四个，首先Sqoop会取获取切分字段的MIN()和MAX()即（–split -by），再根据map数量进行划分，这是字段值就会分为四个map：（1-25）（26-50）（51-75）（75-100）。</li><li>根据MIN和MAX不同的类型采用不同的切分方式支持有Date,Text,Float,Integer， Boolean,NText,BigDecimal等等。</li><li>所以，若导入的表中没有主键，将-m 设置称1或者设置split-by，即只有一个map运行，缺点是不能并行map录入数据。（注意，当-m 设置的值大于1时，split-by必须设置字段） 。</li><li>split-by即便是int型，若不是连续有规律递增的话，各个map分配的数据是不均衡的，可能会有些map很忙，有些map几乎没有数据处理的情况。</li></ol> 
<ul><li>第二个错误</li></ul> 
<pre><code class="prism language-java">Exception in thread <span class="token string">"main"</span> java<span class="token punctuation">.</span>lang<span class="token punctuation">.</span>NoClassDefFoundError<span class="token operator">:</span> org<span class="token operator">/</span>json<span class="token operator">/</span>JSONObject
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>sqoop<span class="token punctuation">.</span>util<span class="token punctuation">.</span>SqoopJsonUtil<span class="token punctuation">.</span><span class="token function">getJsonStringforMap</span><span class="token punctuation">(</span>SqoopJsonUtil<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">42</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>sqoop<span class="token punctuation">.</span>SqoopOptions<span class="token punctuation">.</span><span class="token function">writeProperties</span><span class="token punctuation">(</span>SqoopOptions<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">742</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>sqoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>JobBase<span class="token punctuation">.</span><span class="token function">putSqoopOptionsToConfiguration</span><span class="token punctuation">(</span>JobBase<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">369</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>sqoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>JobBase<span class="token punctuation">.</span><span class="token function">createJob</span><span class="token punctuation">(</span>JobBase<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">355</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>sqoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>ImportJobBase<span class="token punctuation">.</span><span class="token function">runImport</span><span class="token punctuation">(</span>ImportJobBase<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">249</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>sqoop<span class="token punctuation">.</span>manager<span class="token punctuation">.</span>SqlManager<span class="token punctuation">.</span><span class="token function">importTable</span><span class="token punctuation">(</span>SqlManager<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">692</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>sqoop<span class="token punctuation">.</span>manager<span class="token punctuation">.</span>MySQLManager<span class="token punctuation">.</span><span class="token function">importTable</span><span class="token punctuation">(</span>MySQLManager<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">118</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>sqoop<span class="token punctuation">.</span>tool<span class="token punctuation">.</span>ImportTool<span class="token punctuation">.</span><span class="token function">importTable</span><span class="token punctuation">(</span>ImportTool<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">497</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>sqoop<span class="token punctuation">.</span>tool<span class="token punctuation">.</span>ImportTool<span class="token punctuation">.</span><span class="token function">run</span><span class="token punctuation">(</span>ImportTool<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">605</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>sqoop<span class="token punctuation">.</span>Sqoop<span class="token punctuation">.</span><span class="token function">run</span><span class="token punctuation">(</span>Sqoop<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">143</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>util<span class="token punctuation">.</span>ToolRunner<span class="token punctuation">.</span><span class="token function">run</span><span class="token punctuation">(</span>ToolRunner<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">70</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>sqoop<span class="token punctuation">.</span>Sqoop<span class="token punctuation">.</span><span class="token function">runSqoop</span><span class="token punctuation">(</span>Sqoop<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">179</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>sqoop<span class="token punctuation">.</span>Sqoop<span class="token punctuation">.</span><span class="token function">runTool</span><span class="token punctuation">(</span>Sqoop<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">218</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>sqoop<span class="token punctuation">.</span>Sqoop<span class="token punctuation">.</span><span class="token function">runTool</span><span class="token punctuation">(</span>Sqoop<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">227</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>sqoop<span class="token punctuation">.</span>Sqoop<span class="token punctuation">.</span><span class="token function">main</span><span class="token punctuation">(</span>Sqoop<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">236</span><span class="token punctuation">)</span>
Caused by<span class="token operator">:</span> java<span class="token punctuation">.</span>lang<span class="token punctuation">.</span>ClassNotFoundException<span class="token operator">:</span> org<span class="token punctuation">.</span>json<span class="token punctuation">.</span>JSONObject
        at java<span class="token punctuation">.</span>net<span class="token punctuation">.</span>URLClassLoader<span class="token punctuation">.</span><span class="token function">findClass</span><span class="token punctuation">(</span>URLClassLoader<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">381</span><span class="token punctuation">)</span>
        at java<span class="token punctuation">.</span>lang<span class="token punctuation">.</span>ClassLoader<span class="token punctuation">.</span><span class="token function">loadClass</span><span class="token punctuation">(</span>ClassLoader<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">424</span><span class="token punctuation">)</span>
        at sun<span class="token punctuation">.</span>misc<span class="token punctuation">.</span>Launcher$AppClassLoader<span class="token punctuation">.</span><span class="token function">loadClass</span><span class="token punctuation">(</span>Launcher<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">331</span><span class="token punctuation">)</span>
        at java<span class="token punctuation">.</span>lang<span class="token punctuation">.</span>ClassLoader<span class="token punctuation">.</span><span class="token function">loadClass</span><span class="token punctuation">(</span>ClassLoader<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">357</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token number">15</span> more
</code></pre> 
<p><strong>这里我们需要导入java-json.jar包，</strong><a href="http://www.java2s.com/Code/Jar/j/Downloadjavajsonjar.htm" rel="nofollow">下载地址</a>，把java-json.jar添加到…/sqoop/lib目录</p> 
<ul><li>说了那么多来看我们的第一个导入语句：</li></ul> 
<pre><code class="prism language-shell"><span class="token punctuation">[</span>hadoop@zhangyu lib<span class="token punctuation">]</span>$ sqoop <span class="token function">import</span> --connect jdbc:mysql://localhost:3306/sqoop --username root --password 123456 --table stu

</code></pre> 
<p><strong>生成的日志信息大家一定要好好理解</strong></p> 
<p><strong>我们查看HDFS上的文件</strong></p> 
<pre><code>[hadoop@zhangyu lib]$ hdfs dfs -ls /user/hadoop/stu
Found 4 items
-rw-r--r--   1 hadoop supergroup          0 2018-01-14 17:07 /user/hadoop/stu/_SUCCESS
-rw-r--r--   1 hadoop supergroup         11 2018-01-14 17:07 /user/hadoop/stu/part-m-00000
-rw-r--r--   1 hadoop supergroup          7 2018-01-14 17:07 /user/hadoop/stu/part-m-00001
-rw-r--r--   1 hadoop supergroup          9 2018-01-14 17:07 /user/hadoop/stu/part-m-00002
[hadoop@zhangyu lib]$ hdfs dfs -cat /user/hadoop/stu/"part*"
1,zhangsan
2,lisi
3,wangwu

</code></pre> 
<ul><li>加上参数m</li></ul> 
<pre><code class="prism language-shell"><span class="token punctuation">[</span>hadoop@zhangyu lib<span class="token punctuation">]</span>$ sqoop <span class="token function">import</span> --connect jdbc:mysql://localhost:3306/sqoop --username root --password 123456 --table stu
 -m 1

</code></pre> 
<ul><li>第三个错误<br> 这里第三个错误，是我在把Postgres中的数据导入到HDFS中出现的错误：</li></ul> 
<pre><code class="prism language-shell"><span class="token punctuation">[</span>hdfs@hik003 /apps/sqoop<span class="token punctuation">]</span>$ sqoop <span class="token function">import</span> \
<span class="token operator">&gt;</span> --connect jdbc:postgresql://localhost:5432/test \
<span class="token operator">&gt;</span> --username root \
<span class="token operator">&gt;</span> --password 123456 \
<span class="token operator">&gt;</span> --table test_info \
<span class="token operator">&gt;</span> --target-dir /test/ \
<span class="token operator">&gt;</span> --mapreduce-job-name FromPgSQL2HDFS \
<span class="token operator">&gt;</span> -m 1
</code></pre> 
<pre><code class="prism language-java">Warning<span class="token operator">:</span> <span class="token operator">/</span>opt<span class="token operator">/</span>cloudera<span class="token operator">/</span>parcels<span class="token operator">/</span>CDH<span class="token operator">-</span><span class="token number">5.16</span><span class="token number">.1</span><span class="token operator">-</span><span class="token number">1.</span>cdh5<span class="token punctuation">.</span><span class="token number">16.1</span><span class="token punctuation">.</span>p0<span class="token punctuation">.</span><span class="token number">3</span><span class="token operator">/</span>bin<span class="token operator">/</span><span class="token punctuation">.</span><span class="token punctuation">.</span>/lib<span class="token operator">/</span>sqoop<span class="token operator">/</span><span class="token punctuation">.</span><span class="token punctuation">.</span>/accumulo does not exist<span class="token operator">!</span> Accumulo imports will fail<span class="token punctuation">.</span>
Please set $ACCUMULO_HOME to the root of your Accumulo installation<span class="token punctuation">.</span>
<span class="token number">19</span><span class="token operator">/</span><span class="token number">05</span><span class="token operator">/</span><span class="token number">17</span> <span class="token number">20</span><span class="token operator">:</span><span class="token number">38</span><span class="token operator">:</span><span class="token number">15</span> INFO sqoop<span class="token punctuation">.</span>Sqoop<span class="token operator">:</span> Running Sqoop version<span class="token operator">:</span> <span class="token number">1.4</span><span class="token number">.6</span><span class="token operator">-</span>cdh5<span class="token punctuation">.</span><span class="token number">16.1</span>
<span class="token number">19</span><span class="token operator">/</span><span class="token number">05</span><span class="token operator">/</span><span class="token number">17</span> <span class="token number">20</span><span class="token operator">:</span><span class="token number">38</span><span class="token operator">:</span><span class="token number">15</span> WARN tool<span class="token punctuation">.</span>BaseSqoopTool<span class="token operator">:</span> Setting your password on the command<span class="token operator">-</span>line is insecure<span class="token punctuation">.</span> Consider using <span class="token operator">-</span>P instead<span class="token punctuation">.</span>
<span class="token number">19</span><span class="token operator">/</span><span class="token number">05</span><span class="token operator">/</span><span class="token number">17</span> <span class="token number">20</span><span class="token operator">:</span><span class="token number">38</span><span class="token operator">:</span><span class="token number">15</span> INFO manager<span class="token punctuation">.</span>SqlManager<span class="token operator">:</span> Using <span class="token keyword">default</span> fetchSize of <span class="token number">1000</span>
<span class="token number">19</span><span class="token operator">/</span><span class="token number">05</span><span class="token operator">/</span><span class="token number">17</span> <span class="token number">20</span><span class="token operator">:</span><span class="token number">38</span><span class="token operator">:</span><span class="token number">15</span> INFO tool<span class="token punctuation">.</span>CodeGenTool<span class="token operator">:</span> Beginning code generation
<span class="token number">19</span><span class="token operator">/</span><span class="token number">05</span><span class="token operator">/</span><span class="token number">17</span> <span class="token number">20</span><span class="token operator">:</span><span class="token number">38</span><span class="token operator">:</span><span class="token number">15</span> INFO manager<span class="token punctuation">.</span>SqlManager<span class="token operator">:</span> Executing SQL statement<span class="token operator">:</span> SELECT t<span class="token punctuation">.</span>* FROM <span class="token string">"camera_govern_info"</span> AS t LIMIT <span class="token number">1</span>
<span class="token number">19</span><span class="token operator">/</span><span class="token number">05</span><span class="token operator">/</span><span class="token number">17</span> <span class="token number">20</span><span class="token operator">:</span><span class="token number">38</span><span class="token operator">:</span><span class="token number">15</span> ERROR orm<span class="token punctuation">.</span>ClassWriter<span class="token operator">:</span> Cannot resolve SQL type <span class="token number">1111</span>
<span class="token number">19</span><span class="token operator">/</span><span class="token number">05</span><span class="token operator">/</span><span class="token number">17</span> <span class="token number">20</span><span class="token operator">:</span><span class="token number">38</span><span class="token operator">:</span><span class="token number">15</span> ERROR orm<span class="token punctuation">.</span>ClassWriter<span class="token operator">:</span> Cannot resolve SQL type <span class="token number">1111</span>
<span class="token number">19</span><span class="token operator">/</span><span class="token number">05</span><span class="token operator">/</span><span class="token number">17</span> <span class="token number">20</span><span class="token operator">:</span><span class="token number">38</span><span class="token operator">:</span><span class="token number">15</span> ERROR orm<span class="token punctuation">.</span>ClassWriter<span class="token operator">:</span> Cannot resolve SQL type <span class="token number">1111</span>
<span class="token number">19</span><span class="token operator">/</span><span class="token number">05</span><span class="token operator">/</span><span class="token number">17</span> <span class="token number">20</span><span class="token operator">:</span><span class="token number">38</span><span class="token operator">:</span><span class="token number">15</span> ERROR orm<span class="token punctuation">.</span>ClassWriter<span class="token operator">:</span> Cannot resolve SQL type <span class="token number">1111</span>
<span class="token number">19</span><span class="token operator">/</span><span class="token number">05</span><span class="token operator">/</span><span class="token number">17</span> <span class="token number">20</span><span class="token operator">:</span><span class="token number">38</span><span class="token operator">:</span><span class="token number">15</span> ERROR orm<span class="token punctuation">.</span>ClassWriter<span class="token operator">:</span> No Java type <span class="token keyword">for</span> SQL type <span class="token number">1111</span> <span class="token keyword">for</span> column geom
<span class="token number">19</span><span class="token operator">/</span><span class="token number">05</span><span class="token operator">/</span><span class="token number">17</span> <span class="token number">20</span><span class="token operator">:</span><span class="token number">38</span><span class="token operator">:</span><span class="token number">15</span> ERROR orm<span class="token punctuation">.</span>ClassWriter<span class="token operator">:</span> No Java type <span class="token keyword">for</span> SQL type <span class="token number">1111</span> <span class="token keyword">for</span> column geom
<span class="token number">19</span><span class="token operator">/</span><span class="token number">05</span><span class="token operator">/</span><span class="token number">17</span> <span class="token number">20</span><span class="token operator">:</span><span class="token number">38</span><span class="token operator">:</span><span class="token number">15</span> ERROR orm<span class="token punctuation">.</span>ClassWriter<span class="token operator">:</span> No Java type <span class="token keyword">for</span> SQL type <span class="token number">1111</span> <span class="token keyword">for</span> column geom
<span class="token number">19</span><span class="token operator">/</span><span class="token number">05</span><span class="token operator">/</span><span class="token number">17</span> <span class="token number">20</span><span class="token operator">:</span><span class="token number">38</span><span class="token operator">:</span><span class="token number">15</span> ERROR orm<span class="token punctuation">.</span>ClassWriter<span class="token operator">:</span> No Java type <span class="token keyword">for</span> SQL type <span class="token number">1111</span> <span class="token keyword">for</span> column geom
<span class="token number">19</span><span class="token operator">/</span><span class="token number">05</span><span class="token operator">/</span><span class="token number">17</span> <span class="token number">20</span><span class="token operator">:</span><span class="token number">38</span><span class="token operator">:</span><span class="token number">15</span> ERROR orm<span class="token punctuation">.</span>ClassWriter<span class="token operator">:</span> No Java type <span class="token keyword">for</span> SQL type <span class="token number">1111</span> <span class="token keyword">for</span> column geom
<span class="token number">19</span><span class="token operator">/</span><span class="token number">05</span><span class="token operator">/</span><span class="token number">17</span> <span class="token number">20</span><span class="token operator">:</span><span class="token number">38</span><span class="token operator">:</span><span class="token number">15</span> ERROR orm<span class="token punctuation">.</span>ClassWriter<span class="token operator">:</span> No Java type <span class="token keyword">for</span> SQL type <span class="token number">1111</span> <span class="token keyword">for</span> column geom
<span class="token number">19</span><span class="token operator">/</span><span class="token number">05</span><span class="token operator">/</span><span class="token number">17</span> <span class="token number">20</span><span class="token operator">:</span><span class="token number">38</span><span class="token operator">:</span><span class="token number">15</span> ERROR orm<span class="token punctuation">.</span>ClassWriter<span class="token operator">:</span> No Java type <span class="token keyword">for</span> SQL type <span class="token number">1111</span> <span class="token keyword">for</span> column geom
<span class="token number">19</span><span class="token operator">/</span><span class="token number">05</span><span class="token operator">/</span><span class="token number">17</span> <span class="token number">20</span><span class="token operator">:</span><span class="token number">38</span><span class="token operator">:</span><span class="token number">15</span> ERROR orm<span class="token punctuation">.</span>ClassWriter<span class="token operator">:</span> No Java type <span class="token keyword">for</span> SQL type <span class="token number">1111</span> <span class="token keyword">for</span> column geom
<span class="token number">19</span><span class="token operator">/</span><span class="token number">05</span><span class="token operator">/</span><span class="token number">17</span> <span class="token number">20</span><span class="token operator">:</span><span class="token number">38</span><span class="token operator">:</span><span class="token number">15</span> ERROR orm<span class="token punctuation">.</span>ClassWriter<span class="token operator">:</span> No Java type <span class="token keyword">for</span> SQL type <span class="token number">1111</span> <span class="token keyword">for</span> column geom
<span class="token number">19</span><span class="token operator">/</span><span class="token number">05</span><span class="token operator">/</span><span class="token number">17</span> <span class="token number">20</span><span class="token operator">:</span><span class="token number">38</span><span class="token operator">:</span><span class="token number">15</span> ERROR orm<span class="token punctuation">.</span>ClassWriter<span class="token operator">:</span> No Java type <span class="token keyword">for</span> SQL type <span class="token number">1111</span> <span class="token keyword">for</span> column geom
<span class="token number">19</span><span class="token operator">/</span><span class="token number">05</span><span class="token operator">/</span><span class="token number">17</span> <span class="token number">20</span><span class="token operator">:</span><span class="token number">38</span><span class="token operator">:</span><span class="token number">15</span> ERROR orm<span class="token punctuation">.</span>ClassWriter<span class="token operator">:</span> No Java type <span class="token keyword">for</span> SQL type <span class="token number">1111</span> <span class="token keyword">for</span> column geom
<span class="token number">19</span><span class="token operator">/</span><span class="token number">05</span><span class="token operator">/</span><span class="token number">17</span> <span class="token number">20</span><span class="token operator">:</span><span class="token number">38</span><span class="token operator">:</span><span class="token number">15</span> ERROR sqoop<span class="token punctuation">.</span>Sqoop<span class="token operator">:</span> Got exception running Sqoop<span class="token operator">:</span> java<span class="token punctuation">.</span>lang<span class="token punctuation">.</span>NullPointerException
java<span class="token punctuation">.</span>lang<span class="token punctuation">.</span>NullPointerException
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>sqoop<span class="token punctuation">.</span>orm<span class="token punctuation">.</span>ClassWriter<span class="token punctuation">.</span><span class="token function">parseNullVal</span><span class="token punctuation">(</span>ClassWriter<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">1389</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>sqoop<span class="token punctuation">.</span>orm<span class="token punctuation">.</span>ClassWriter<span class="token punctuation">.</span><span class="token function">parseColumn</span><span class="token punctuation">(</span>ClassWriter<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">1414</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>sqoop<span class="token punctuation">.</span>orm<span class="token punctuation">.</span>ClassWriter<span class="token punctuation">.</span><span class="token function">myGenerateParser</span><span class="token punctuation">(</span>ClassWriter<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">1540</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>sqoop<span class="token punctuation">.</span>orm<span class="token punctuation">.</span>ClassWriter<span class="token punctuation">.</span><span class="token function">generateParser</span><span class="token punctuation">(</span>ClassWriter<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">1503</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>sqoop<span class="token punctuation">.</span>orm<span class="token punctuation">.</span>ClassWriter<span class="token punctuation">.</span><span class="token function">generateClassForColumns</span><span class="token punctuation">(</span>ClassWriter<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">1958</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>sqoop<span class="token punctuation">.</span>orm<span class="token punctuation">.</span>ClassWriter<span class="token punctuation">.</span><span class="token function">generate</span><span class="token punctuation">(</span>ClassWriter<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">1749</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>sqoop<span class="token punctuation">.</span>tool<span class="token punctuation">.</span>CodeGenTool<span class="token punctuation">.</span><span class="token function">generateORM</span><span class="token punctuation">(</span>CodeGenTool<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">106</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>sqoop<span class="token punctuation">.</span>tool<span class="token punctuation">.</span>ImportTool<span class="token punctuation">.</span><span class="token function">importTable</span><span class="token punctuation">(</span>ImportTool<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">494</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>sqoop<span class="token punctuation">.</span>tool<span class="token punctuation">.</span>ImportTool<span class="token punctuation">.</span><span class="token function">run</span><span class="token punctuation">(</span>ImportTool<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">621</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>sqoop<span class="token punctuation">.</span>Sqoop<span class="token punctuation">.</span><span class="token function">run</span><span class="token punctuation">(</span>Sqoop<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">147</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>util<span class="token punctuation">.</span>ToolRunner<span class="token punctuation">.</span><span class="token function">run</span><span class="token punctuation">(</span>ToolRunner<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">70</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>sqoop<span class="token punctuation">.</span>Sqoop<span class="token punctuation">.</span><span class="token function">runSqoop</span><span class="token punctuation">(</span>Sqoop<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">183</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>sqoop<span class="token punctuation">.</span>Sqoop<span class="token punctuation">.</span><span class="token function">runTool</span><span class="token punctuation">(</span>Sqoop<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">234</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>sqoop<span class="token punctuation">.</span>Sqoop<span class="token punctuation">.</span><span class="token function">runTool</span><span class="token punctuation">(</span>Sqoop<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">243</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>sqoop<span class="token punctuation">.</span>Sqoop<span class="token punctuation">.</span><span class="token function">main</span><span class="token punctuation">(</span>Sqoop<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">252</span><span class="token punctuation">)</span>
		
		
		https<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span>yq<span class="token punctuation">.</span>aliyun<span class="token punctuation">.</span>com<span class="token operator">/</span>articles<span class="token operator">/</span><span class="token number">578819</span>
</code></pre> 
<p>这里就是字段类型的问题了,postgresql数据库中geometry类型的字段，是用于存放经纬度的字段类型,在转化时出现了错误。改变数据库中的字段类型。</p> 
<p><strong>这里大家可能也会出现一个错误，在hdfs上已经存，错误如下：</strong></p> 
<pre><code class="prism language-java"><span class="token number">18</span><span class="token operator">/</span><span class="token number">01</span><span class="token operator">/</span><span class="token number">14</span> <span class="token number">17</span><span class="token operator">:</span><span class="token number">52</span><span class="token operator">:</span><span class="token number">47</span> ERROR tool<span class="token punctuation">.</span>ImportTool<span class="token operator">:</span> Encountered IOException running <span class="token keyword">import</span> job<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapred<span class="token punctuation">.</span>FileAlreadyExistsException<span class="token operator">:</span> Output directory hdfs<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span><span class="token number">192.168</span><span class="token number">.137</span><span class="token number">.200</span><span class="token operator">:</span><span class="token number">9000</span><span class="token operator">/</span>user<span class="token operator">/</span>hadoop<span class="token operator">/</span>stu already exists
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>FileOutputFormat<span class="token punctuation">.</span><span class="token function">checkOutputSpecs</span><span class="token punctuation">(</span>FileOutputFormat<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">146</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>JobSubmitter<span class="token punctuation">.</span><span class="token function">checkSpecs</span><span class="token punctuation">(</span>JobSubmitter<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">270</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>JobSubmitter<span class="token punctuation">.</span><span class="token function">submitJobInternal</span><span class="token punctuation">(</span>JobSubmitter<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">143</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Job$<span class="token number">10.</span><span class="token function">run</span><span class="token punctuation">(</span>Job<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">1307</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Job$<span class="token number">10.</span><span class="token function">run</span><span class="token punctuation">(</span>Job<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">1304</span><span class="token punctuation">)</span>
        at java<span class="token punctuation">.</span>security<span class="token punctuation">.</span>AccessController<span class="token punctuation">.</span><span class="token function">doPrivileged</span><span class="token punctuation">(</span>Native Method<span class="token punctuation">)</span>
        at javax<span class="token punctuation">.</span>security<span class="token punctuation">.</span>auth<span class="token punctuation">.</span>Subject<span class="token punctuation">.</span><span class="token function">doAs</span><span class="token punctuation">(</span>Subject<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">422</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>security<span class="token punctuation">.</span>UserGroupInformation<span class="token punctuation">.</span><span class="token function">doAs</span><span class="token punctuation">(</span>UserGroupInformation<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">1693</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Job<span class="token punctuation">.</span><span class="token function">submit</span><span class="token punctuation">(</span>Job<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">1304</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span>Job<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">1325</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>sqoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>ImportJobBase<span class="token punctuation">.</span><span class="token function">doSubmitJob</span><span class="token punctuation">(</span>ImportJobBase<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">196</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>sqoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>ImportJobBase<span class="token punctuation">.</span><span class="token function">runJob</span><span class="token punctuation">(</span>ImportJobBase<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">169</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>sqoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>ImportJobBase<span class="token punctuation">.</span><span class="token function">runImport</span><span class="token punctuation">(</span>ImportJobBase<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">266</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>sqoop<span class="token punctuation">.</span>manager<span class="token punctuation">.</span>SqlManager<span class="token punctuation">.</span><span class="token function">importTable</span><span class="token punctuation">(</span>SqlManager<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">692</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>sqoop<span class="token punctuation">.</span>manager<span class="token punctuation">.</span>MySQLManager<span class="token punctuation">.</span><span class="token function">importTable</span><span class="token punctuation">(</span>MySQLManager<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">118</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>sqoop<span class="token punctuation">.</span>tool<span class="token punctuation">.</span>ImportTool<span class="token punctuation">.</span><span class="token function">importTable</span><span class="token punctuation">(</span>ImportTool<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">497</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>sqoop<span class="token punctuation">.</span>tool<span class="token punctuation">.</span>ImportTool<span class="token punctuation">.</span><span class="token function">run</span><span class="token punctuation">(</span>ImportTool<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">605</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>sqoop<span class="token punctuation">.</span>Sqoop<span class="token punctuation">.</span><span class="token function">run</span><span class="token punctuation">(</span>Sqoop<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">143</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>util<span class="token punctuation">.</span>ToolRunner<span class="token punctuation">.</span><span class="token function">run</span><span class="token punctuation">(</span>ToolRunner<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">70</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>sqoop<span class="token punctuation">.</span>Sqoop<span class="token punctuation">.</span><span class="token function">runSqoop</span><span class="token punctuation">(</span>Sqoop<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">179</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>sqoop<span class="token punctuation">.</span>Sqoop<span class="token punctuation">.</span><span class="token function">runTool</span><span class="token punctuation">(</span>Sqoop<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">218</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>sqoop<span class="token punctuation">.</span>Sqoop<span class="token punctuation">.</span><span class="token function">runTool</span><span class="token punctuation">(</span>Sqoop<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">227</span><span class="token punctuation">)</span>
        at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>sqoop<span class="token punctuation">.</span>Sqoop<span class="token punctuation">.</span><span class="token function">main</span><span class="token punctuation">(</span>Sqoop<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">236</span><span class="token punctuation">)</span>
</code></pre> 
<ul><li>删除目标目录后在导入,并且指定mapreduce的job的名字<br> 参数：<code>--delete-target-dir</code> <code>--mapreduce-job-name</code></li></ul> 
<pre><code class="prism language-shell"><span class="token punctuation">[</span>hadoop@zhangyu lib<span class="token punctuation">]</span>$ sqoop <span class="token function">import</span> \
<span class="token operator">&gt;</span> --connect jdbc:mysql://localhost:3306/sqoop \
<span class="token operator">&gt;</span> --username root --password 123456 \
<span class="token operator">&gt;</span> --mapreduce-job-name FromMySQL2HDFS \
<span class="token operator">&gt;</span> --delete-target-dir \
<span class="token operator">&gt;</span> --table stu \
<span class="token operator">&gt;</span> -m 1
</code></pre> 
<ul><li>导入到指定目录</li></ul> 
<p>参数：<code>--target-dir /directory</code></p> 
<pre><code class="prism language-shell"><span class="token punctuation">[</span>hadoop@zhangyu lib<span class="token punctuation">]</span>$ sqoop <span class="token function">import</span> --connect jdbc:mysql://localhost:3306/sqoop --username root -password 123456 --table stu -m 1 --target-dir /sqoop/
</code></pre> 
<p><strong>查看HDFS上的文件</strong></p> 
<pre><code class="prism language-shell"><span class="token punctuation">[</span>hadoop@zhangyu lib<span class="token punctuation">]</span>$ hdfs dfs -ls /sqoop
Found 2 items
-rw-r--r--   1 hadoop supergroup          0 2018-01-14 18:07 /sqoop/_SUCCESS
-rw-r--r--   1 hadoop supergroup         27 2018-01-14 18:07 /sqoop/part-m-00000
<span class="token punctuation">[</span>hadoop@zhangyu lib<span class="token punctuation">]</span>$ hdfs dfs -cat /sqoop/part-m-00000
1,zhangsan
2,lisi
3,wangwu
</code></pre> 
<ul><li>指定字段之间的分隔符<br> 参数<code>--fields-terminated-by</code></li></ul> 
<pre><code class="prism language-shell"><span class="token punctuation">[</span>hadoop@zhangyu lib<span class="token punctuation">]</span>$ sqoop <span class="token function">import</span> \
<span class="token operator">&gt;</span> --connect jdbc:mysql://localhost:3306/sqoop \
<span class="token operator">&gt;</span> --username root --password 123456 \
<span class="token operator">&gt;</span> --table stu \
<span class="token operator">&gt;</span> --mapreduce-job-name FromMySQL2HDFS \
<span class="token operator">&gt;</span> --delete-target-dir \
<span class="token operator">&gt;</span> --fields-terminated-by <span class="token string">'\t'</span> \
<span class="token operator">&gt;</span> -m 1 

HDFS上查询结果：
<span class="token punctuation">[</span>hadoop@zhangyu lib<span class="token punctuation">]</span>$ hdfs dfs -ls /user/hadoop/stu/ 
Found 2 items
-rw-r--r--   1 hadoop supergroup          0 2018-01-14 19:47 /user/hadoop/stu/_SUCCESS
-rw-r--r--   1 hadoop supergroup         27 2018-01-14 19:47 /user/hadoop/stu/part-m-0000 

<span class="token punctuation">[</span>hadoop@zhangyu lib<span class="token punctuation">]</span>$ hdfs dfs -cat /user/hadoop/stu/part-m-00000   
1       zhangsan
2       lisi
3       wangwu
（字段之间变为空格）
</code></pre> 
<ul><li>如果表中的字段为null转化为0</li></ul> 
<p>参数<code>--null-non-string</code></p> 
<ol><li>–null-string含义是 string类型的字段，当Value是NULL，替换成指定的字符</li><li>–null-non-string 含义是非string类型的字段，当Value是NULL，替换成指定字符先</li></ol> 
<pre><code class="prism language-shell">导入薪资表
<span class="token punctuation">[</span>hadoop@zhangyu lib<span class="token punctuation">]</span>$ sqoop <span class="token function">import</span> \
<span class="token operator">&gt;</span> --connect jdbc:mysql://localhost:3306/sqoop \
<span class="token operator">&gt;</span> --username root --password 123456 \
<span class="token operator">&gt;</span> --table sal \
<span class="token operator">&gt;</span> --mapreduce-job-name FromMySQL2HDFS \
<span class="token operator">&gt;</span> --delete-target-dir \
<span class="token operator">&gt;</span> --fields-terminated-by <span class="token string">'\t'</span> \
<span class="token operator">&gt;</span> -m 1

查询结果：
<span class="token punctuation">[</span>hadoop@zhangyu lib<span class="token punctuation">]</span>$  hdfs dfs -cat /user/hadoop/sal/part-m-00000
zhangsan        1000
lisi    2000
wangwu  null

加上参数`--null-string
<span class="token punctuation">[</span>hadoop@zhangyu lib<span class="token punctuation">]</span>$ sqoop <span class="token function">import</span> \
<span class="token operator">&gt;</span> --connect jdbc:mysql://localhost:3306/sqoop \
<span class="token operator">&gt;</span> --username root --password 123456 \
<span class="token operator">&gt;</span> --table sal \
<span class="token operator">&gt;</span> --mapreduce-job-name FromMySQL2HDFS \
<span class="token operator">&gt;</span> --delete-target-dir \
<span class="token operator">&gt;</span> --fields-terminated-by <span class="token string">'\t'</span> \
<span class="token operator">&gt;</span> -m 1 \
<span class="token operator">&gt;</span> --null-string 0

查看结果
<span class="token punctuation">[</span>hadoop@zhangyu lib<span class="token punctuation">]</span>$  hdfs dfs -cat /user/hadoop/sal/part-m-00000
zhangsan        1000
lisi    2000
wangwu  0
</code></pre> 
<ul><li>导入表中的部分字段<br> 参数<code>--columns</code></li></ul> 
<pre><code class="prism language-shell"><span class="token punctuation">[</span>hadoop@zhangyu ~<span class="token punctuation">]</span>$ sqoop <span class="token function">import</span> \
<span class="token operator">&gt;</span> --connect jdbc:mysql://localhost:3306/sqoop \
<span class="token operator">&gt;</span> --username root --password 123456 \
<span class="token operator">&gt;</span> --table stu \
<span class="token operator">&gt;</span> --mapreduce-job-name FromMySQL2HDFS \
<span class="token operator">&gt;</span> --delete-target-dir \
<span class="token operator">&gt;</span> --fields-terminated-by <span class="token string">'\t'</span> \
<span class="token operator">&gt;</span> -m 1 \
<span class="token operator">&gt;</span> --null-string 0 \
<span class="token operator">&gt;</span> --columns <span class="token string">"name"</span> 

查询结果：
<span class="token punctuation">[</span>hadoop@zhangyu ~<span class="token punctuation">]</span>$ hdfs dfs -cat /user/hadoop/stu/part-m-00000
zhangsan
lisi
wangwu
</code></pre> 
<ul><li>按条件导入数据<br> 参数<code>--where</code></li></ul> 
<pre><code class="prism language-shell"><span class="token punctuation">[</span>hadoop@zhangyu ~<span class="token punctuation">]</span>$ sqoop <span class="token function">import</span> \
<span class="token operator">&gt;</span> --connect jdbc:mysql://localhost:3306/sqoop \
<span class="token operator">&gt;</span> --username root --password 123456 \
<span class="token operator">&gt;</span> --table stu \
<span class="token operator">&gt;</span> --mapreduce-job-name FromMySQL2HDFS \
<span class="token operator">&gt;</span> --delete-target-dir \
<span class="token operator">&gt;</span> --fields-terminated-by <span class="token string">'\t'</span> \
<span class="token operator">&gt;</span> -m 1 \
<span class="token operator">&gt;</span> --null-string 0 \
<span class="token operator">&gt;</span> --columns <span class="token string">"name"</span> \
<span class="token operator">&gt;</span> --target-dir STU_COLUMN_WHERE \
<span class="token operator">&gt;</span> --where <span class="token string">'id&lt;3'</span>

查询结果：
                                                                                   
zhangsan
lisi
</code></pre> 
<ul><li>按照sql语句进行导入<br> 参数<code>--query</code><br> <strong>使用<code>--query</code>关键字，就不能使用<code>--table</code>和<code>--columns</code></strong><br> <strong>自定义sql语句的where条件中必须包含字符串 <code>$CONDITIONS</code>，<code>$CONDITIONS</code>是一个变量，用于给多个map任务划分任务范 围；</strong></li></ul> 
<pre><code class="prism language-shell">sqoop <span class="token function">import</span> \
--connect jdbc:mysql://localhost:3306/sqoop \
--username root --password 123456 \
--mapreduce-job-name FromMySQL2HDFS \
--delete-target-dir \
--fields-terminated-by <span class="token string">'\t'</span> \
-m 1 \
--null-string 0 \
--target-dir STU_COLUMN_QUERY \
--query <span class="token string">"select * from stu where id&gt;1 and \<span class="token variable">$CONDITIONS</span>"</span>
                                                                              （或者quer使用这种格式：--query <span class="token string">'select * from emp where id&gt;1 and <span class="token variable">$CONDITIONS</span>'</span>）                                           
</code></pre> 
<p>结果：</p> 
<pre><code>2       lisi
3       wangwu
</code></pre> 
<h4><a id="6__396"></a>6 在文件中执行</h4> 
<ul><li>创建文件sqoop-import-hdfs.txt</li></ul> 
<pre><code class="prism language-shell"><span class="token punctuation">[</span>hadoop@zhangyu data<span class="token punctuation">]</span>$ <span class="token function">vi</span> sqoop-import-hdfs.txt                                   
<span class="token function">import</span>
--connect
jdbc:mysql://localhost:3306/sqoop
--username
root
--password
123456
--table
stu
--target-dir 
STU_option_file
</code></pre> 
<ul><li>执行</li></ul> 
<pre><code class="prism language-shell"><span class="token punctuation">[</span>hadoop@zhangyu data<span class="token punctuation">]</span>$ sqoop --option-file /home/hadoop/data/sqoop-import-hdfs.txt

查询结果：
<span class="token punctuation">[</span>hadoop@zhangyu data<span class="token punctuation">]</span>$ hdfs dfs -cat STU_option_file/<span class="token string">"part*"</span>
1,zhangsan
2,lisi
3,wangwu
</code></pre> 
<h4><a id="7_eval_423"></a>7 eval</h4> 
<p>查看帮助命令对与该命令的解释为： Evaluate a SQL statement and display the results，也就是说执行一个SQL语句并查询出结果。</p> 
<pre><code class="prism language-shell"><span class="token punctuation">[</span>hadoop@zhangyu data<span class="token punctuation">]</span>$ sqoop <span class="token function">eval</span> \
<span class="token operator">&gt;</span> --connect jdbc:mysql://localhost:3306/sqoop \
<span class="token operator">&gt;</span> --username root --password 123456 \
<span class="token operator">&gt;</span> --query <span class="token string">"select * from stu"</span> 
Warning: /opt/software/sqoop/<span class="token punctuation">..</span>/hbase does not exist<span class="token operator">!</span> HBase imports will fail.
Please <span class="token keyword">set</span> <span class="token variable">$HBASE_HOME</span> to the root of your HBase installation.
Warning: /opt/software/sqoop/<span class="token punctuation">..</span>/hcatalog does not exist<span class="token operator">!</span> HCatalog <span class="token function">jobs</span> will fail.
Please <span class="token keyword">set</span> <span class="token variable">$HCAT_HOME</span> to the root of your HCatalog installation.
Warning: /opt/software/sqoop/<span class="token punctuation">..</span>/accumulo does not exist<span class="token operator">!</span> Accumulo imports will fail.
Please <span class="token keyword">set</span> <span class="token variable">$ACCUMULO_HOME</span> to the root of your Accumulo installation.
Warning: /opt/software/sqoop/<span class="token punctuation">..</span>/zookeeper does not exist<span class="token operator">!</span> Accumulo imports will fail.
Please <span class="token keyword">set</span> <span class="token variable">$ZOOKEEPER_HOME</span> to the root of your Zookeeper installation.
18/01/14 21:35:25 INFO sqoop.Sqoop: Running Sqoop version: 1.4.6-cdh5.7.0
18/01/14 21:35:25 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
18/01/14 21:35:26 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
--------------------------------------
<span class="token operator">|</span> <span class="token function">id</span>          <span class="token operator">|</span> name                 <span class="token operator">|</span> 
--------------------------------------
<span class="token operator">|</span> 1           <span class="token operator">|</span> zhangsan             <span class="token operator">|</span> 
<span class="token operator">|</span> 2           <span class="token operator">|</span> lisi                 <span class="token operator">|</span> 
<span class="token operator">|</span> 3           <span class="token operator">|</span> wangwu               <span class="token operator">|</span> 
--------------------------------------
</code></pre> 
<h4><a id="8_HDFSMySQLHiveMySQL_450"></a>8 HDFS数据导出到MySQL（Hive中的数据导入到MySQL）</h4> 
<p>导出HDFS上的sal数据，查询数据：</p> 
<pre><code class="prism language-shell"><span class="token punctuation">[</span>hadoop@zhangyu data<span class="token punctuation">]</span>$ hdfs dfs -cat sal/part-m-00000
zhangsan        1000
lisi    2000
wangwu  0
</code></pre> 
<ul><li>在执行导出语句前先创建sal_demo表（不创建表会报错）：</li></ul> 
<pre><code class="prism language-shell">mysql<span class="token operator">&gt;</span> create table sal_demo like sal<span class="token punctuation">;</span>
</code></pre> 
<ul><li>导出语句：</li></ul> 
<pre><code class="prism language-shell"><span class="token punctuation">[</span>hadoop@zhangyu data<span class="token punctuation">]</span>$ sqoop <span class="token function">export</span> \
<span class="token operator">&gt;</span> --connect jdbc:mysql://localhost:3306/sqoop \
<span class="token operator">&gt;</span> --username root \
<span class="token operator">&gt;</span> --password 123456 \
<span class="token operator">&gt;</span> --table sal_demo \
<span class="token operator">&gt;</span> --input-fields-terminated-by <span class="token string">'\t'</span>\
<span class="token operator">&gt;</span> --export-dir /user/hadoop/sal/
</code></pre> 
<ol><li>–table sal_demo ：指定导出表的名称；</li><li>–input-fields-terminated-by：可以用来指定hdfs上文件的分隔符，默认是逗号（查询数据室可以看出我是用的是\t，所以这里指定为\t ，<strong>这里大家小心可能因为分隔符的原因报错</strong>）</li><li>–export-dir ：导出数据的目录。</li></ol> 
<pre><code class="prism language-shell">结果：
mysql<span class="token operator">&gt;</span> <span class="token keyword">select</span> * from sal_demo<span class="token punctuation">;</span>
+----------+--------+
<span class="token operator">|</span> name     <span class="token operator">|</span> salary <span class="token operator">|</span>
+----------+--------+
<span class="token operator">|</span> zhangsan <span class="token operator">|</span> 1000   <span class="token operator">|</span>
<span class="token operator">|</span> lisi     <span class="token operator">|</span> 2000   <span class="token operator">|</span>
<span class="token operator">|</span> wangwu   <span class="token operator">|</span> 0      <span class="token operator">|</span>
+----------+--------+
3 rows <span class="token keyword">in</span> <span class="token keyword">set</span> <span class="token punctuation">(</span>0.00 sec<span class="token punctuation">)</span>
</code></pre> 
<p>(如果在导入一次会追加在表中)</p> 
<ul><li>插入中文乱码问题</li></ul> 
<pre><code class="prism language-shell">sqoop <span class="token function">export</span> --connect <span class="token string">"jdbc:mysql://localhost:3306/test?useUnicode=true&amp;characterEncoding=utf-8"</span> --username root --password 123456 --table sal -m 1 --export-dir /user/hadoop/sal/

</code></pre> 
<ul><li>指定导出的字段<br> <code>--columns &lt;col,col,col...&gt;</code></li></ul> 
<pre><code class="prism language-shell"><span class="token punctuation">[</span>hadoop@zhangyu data<span class="token punctuation">]</span>$ sqoop <span class="token function">export</span> \
<span class="token operator">&gt;</span> --connect jdbc:mysql://localhost:3306/sqoop \
<span class="token operator">&gt;</span> --username root \
<span class="token operator">&gt;</span> --password 123456 \
<span class="token operator">&gt;</span> --table sal_demo3 \
<span class="token operator">&gt;</span> --input-fields-terminated-by <span class="token string">'\t'</span> \
<span class="token operator">&gt;</span> --export-dir /user/hadoop/sal/ \
<span class="token operator">&gt;</span> --columns name
</code></pre> 
<p>查询结果：</p> 
<pre><code class="prism language-shell">mysql<span class="token operator">&gt;</span> <span class="token keyword">select</span> * from sal_demo3  
    -<span class="token operator">&gt;</span> <span class="token punctuation">;</span>
+----------+--------+
<span class="token operator">|</span> name     <span class="token operator">|</span> salary <span class="token operator">|</span>
+----------+--------+
<span class="token operator">|</span> zhangsan <span class="token operator">|</span> NULL   <span class="token operator">|</span>
<span class="token operator">|</span> lisi     <span class="token operator">|</span> NULL   <span class="token operator">|</span>
<span class="token operator">|</span> wangwu   <span class="token operator">|</span> NULL   <span class="token operator">|</span>
+----------+--------+
3 rows <span class="token keyword">in</span> <span class="token keyword">set</span> <span class="token punctuation">(</span>0.00 sec<span class="token punctuation">)</span>
</code></pre> 
<h4><a id="9_MySQLHive_525"></a>9 MySQL的中的数据导入到Hive中</h4> 
<ul><li>执行导入语句</li></ul> 
<pre><code>[hadoop@zhangyu ~]$ sqoop import \
&gt; --connect jdbc:mysql://localhost:3306/sqoop \
&gt; --username root --password 123456 \
&gt; --table stu \
&gt; --create-hive-table \
&gt; --hive-database hive \
&gt; --hive-import \
&gt; --hive-overwrite \
&gt; --hive-table stu_import \
&gt; --mapreduce-job-name FromMySQL2HDFS \
&gt; --delete-target-dir \
&gt; --fields-terminated-by '\t' \
&gt; -m 1 \
&gt; --null-non-string 0
</code></pre> 
<p>–create-hive-table ：创建目标表，如果有会报错；<br> –hive-database：指定hive数据库；<br> –hive-import ：指定导入hive（没有这个条件导入到hdfs中）；<br> –hive-overwrite ：覆盖；<br> –hive-table stu_import :指定hive中表的名字，如果不指定使用导入的表的表名。</p> 
<p><strong>这里可能会报错，错误如下：</strong></p> 
<pre><code class="prism language-shell">18/01/15 01:29:28 ERROR hive.HiveConfig: Could not load org.apache.hadoop.hive.conf.HiveConf. Make sure HIVE_CONF_DIR is <span class="token keyword">set</span> correctly.
18/01/15 01:29:28 ERROR tool.ImportTool: Encountered IOException running <span class="token function">import</span> job: java.io.IOException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.conf.HiveConf
        at org.apache.sqoop.hive.HiveConfig.getHiveConf<span class="token punctuation">(</span>HiveConfig.java:50<span class="token punctuation">)</span>
        at org.apache.sqoop.hive.HiveImport.getHiveArgs<span class="token punctuation">(</span>HiveImport.java:392<span class="token punctuation">)</span>
        at org.apache.sqoop.hive.HiveImport.executeExternalHiveScript<span class="token punctuation">(</span>HiveImport.java:379<span class="token punctuation">)</span>
        at org.apache.sqoop.hive.HiveImport.executeScript<span class="token punctuation">(</span>HiveImport.java:337<span class="token punctuation">)</span>
        at org.apache.sqoop.hive.HiveImport.importTable<span class="token punctuation">(</span>HiveImport.java:241<span class="token punctuation">)</span>
        at org.apache.sqoop.tool.ImportTool.importTable<span class="token punctuation">(</span>ImportTool.java:514<span class="token punctuation">)</span>
        at org.apache.sqoop.tool.ImportTool.run<span class="token punctuation">(</span>ImportTool.java:605<span class="token punctuation">)</span>
        at org.apache.sqoop.Sqoop.run<span class="token punctuation">(</span>Sqoop.java:143<span class="token punctuation">)</span>
        at org.apache.hadoop.util.ToolRunner.run<span class="token punctuation">(</span>ToolRunner.java:70<span class="token punctuation">)</span>
        at org.apache.sqoop.Sqoop.runSqoop<span class="token punctuation">(</span>Sqoop.java:179<span class="token punctuation">)</span>
        at org.apache.sqoop.Sqoop.runTool<span class="token punctuation">(</span>Sqoop.java:218<span class="token punctuation">)</span>
        at org.apache.sqoop.Sqoop.runTool<span class="token punctuation">(</span>Sqoop.java:227<span class="token punctuation">)</span>
        at org.apache.sqoop.Sqoop.main<span class="token punctuation">(</span>Sqoop.java:236<span class="token punctuation">)</span>
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hive.conf.HiveConf
        at java.net.URLClassLoader.findClass<span class="token punctuation">(</span>URLClassLoader.java:381<span class="token punctuation">)</span>
        at java.lang.ClassLoader.loadClass<span class="token punctuation">(</span>ClassLoader.java:424<span class="token punctuation">)</span>
        at sun.misc.Launcher<span class="token variable">$AppClassLoader</span>.loadClass<span class="token punctuation">(</span>Launcher.java:331<span class="token punctuation">)</span>
        at java.lang.ClassLoader.loadClass<span class="token punctuation">(</span>ClassLoader.java:357<span class="token punctuation">)</span>
        at java.lang.Class.forName0<span class="token punctuation">(</span>Native Method<span class="token punctuation">)</span>
        at java.lang.Class.forName<span class="token punctuation">(</span>Class.java:264<span class="token punctuation">)</span>
        at org.apache.sqoop.hive.HiveConfig.getHiveConf<span class="token punctuation">(</span>HiveConfig.java:44<span class="token punctuation">)</span>
        <span class="token punctuation">..</span>. 12 <span class="token function">more</span>
</code></pre> 
<p><strong>网上找的资料基本都在说配置个人环境变量，并没有卵用，到hive目录的lib下拷贝几个jar包，问题就解决了！</strong></p> 
<pre><code class="prism language-shell"><span class="token punctuation">[</span>hadoop@zhangyu lib<span class="token punctuation">]</span>$ <span class="token function">cp</span> hive-common-1.1.0-cdh5.7.0.jar /opt/software/sqoop/lib/
<span class="token punctuation">[</span>hadoop@zhangyu lib<span class="token punctuation">]</span>$ <span class="token function">cd</span> hive-shims* /opt/software/sqoop/lib/
</code></pre> 
<ul><li>查看hive中导入的数据</li></ul> 
<pre><code class="prism language-shell">hive<span class="token operator">&gt;</span> show tables<span class="token punctuation">;</span>
OK
stu_import
Time taken: 0.067 seconds, Fetched: 1 row<span class="token punctuation">(</span>s<span class="token punctuation">)</span>
hive<span class="token operator">&gt;</span> <span class="token keyword">select</span> * from emp_import
    <span class="token operator">&gt;</span> <span class="token punctuation">;</span>
OK
1       zhangsan
2       lisiw 
3       wangwu
</code></pre> 
<p><strong>导入Hive不建议大家使用–create-hive-table,建议事先创建好hive表</strong><br> 使用create创建表后，我们可以查看字段对应的类型，发现有些并不是我们想要的类型，所以我们要事先创建好表的结构再导入数据。</p> 
<ul><li>导入到hive指定分区</li></ul> 
<pre><code class="prism language-shell">--hive-partition-key <span class="token operator">&lt;</span>partition-key<span class="token operator">&gt;</span>             Sets the partition key
                                                    to use when importing
                                                    to hive
 --hive-partition-value <span class="token operator">&lt;</span>partition-value<span class="token operator">&gt;</span>         Sets the partition
                                                    value to use when
                                                    importing to hive
</code></pre> 
<ul><li>示例：</li></ul> 
<pre><code class="prism language-shell"><span class="token punctuation">[</span>hadoop@zhangyu lib<span class="token punctuation">]</span>$ sqoop <span class="token function">import</span> \
<span class="token operator">&gt;</span> --connect jdbc:mysql://localhost:3306/sqoop \
<span class="token operator">&gt;</span> --username root --password 123456 \
<span class="token operator">&gt;</span> --table stu \
<span class="token operator">&gt;</span> --create-hive-table \
<span class="token operator">&gt;</span> --hive-database hive \
<span class="token operator">&gt;</span> --hive-import \
<span class="token operator">&gt;</span> --hive-overwrite \
<span class="token operator">&gt;</span> --hive-table stu_import1 \
<span class="token operator">&gt;</span> --mapreduce-job-name FromMySQL2HDFS \
<span class="token operator">&gt;</span> --delete-target-dir \
<span class="token operator">&gt;</span> --fields-terminated-by <span class="token string">'\t'</span> \
<span class="token operator">&gt;</span> -m 1 \
<span class="token operator">&gt;</span> --null-non-string 0 \
<span class="token operator">&gt;</span> --hive-partition-key dt \
<span class="token operator">&gt;</span> --hive-partition-value <span class="token string">"2018-08-08"</span>

</code></pre> 
<ul><li>hive上进行查询</li></ul> 
<pre><code>hive&gt; select * from stu_import1;
OK
1       zhangsan        2018-08-08
2       lisi    2018-08-08
3       wangwu  2018-08-08
Time taken: 0.121 seconds, Fetched: 3 row(s)
</code></pre> 
<h4><a id="10_sqoop_job_643"></a>10 sqoop job的使用</h4> 
<p><strong>就是把sqoop执行的语句变成一个job，并不是在创建语句的时候执行，你可以查看该job，可以任何时候执行该job，也可以删除job，这样就方便我们进行任务的调度</strong></p> 
<pre><code>--create &lt;job-id&gt;  创建一个新的job.
--delete &lt;job-id&gt;  删除job
--exec &lt;job-id&gt;     执行job
--show &lt;job-id&gt;    显示job的参数
--list                     列出所有的job
</code></pre> 
<ul><li>创建一个job</li></ul> 
<pre><code class="prism language-shell">sqoop job --create person_job1 -- <span class="token function">import</span> --connect jdbc:mysql://localhost:3306/sqoop \
--username root \
--password 123456 \
--table sal_demo3 \
-m 1 \
--delete-target-dir 
</code></pre> 
<ul><li>查看可用的job</li></ul> 
<pre><code class="prism language-shell"><span class="token punctuation">[</span>hadoop@zhangyu lib<span class="token punctuation">]</span>$ sqoop job --list
Available jobs:
  person_job1
</code></pre> 
<ul><li>执行person_job完成导入</li></ul> 
<pre><code class="prism language-shell"><span class="token punctuation">[</span>hadoop@zhangyu lib<span class="token punctuation">]</span>$ sqoop job --exec person_job1

<span class="token punctuation">[</span>hadoop@zhangyu lib<span class="token punctuation">]</span>$ hdfs dfs -ls
Found 6 items
drwxr-xr-x   - hadoop supergroup          0 2018-01-14 20:40 EMP_COLUMN_WHERE
drwxr-xr-x   - hadoop supergroup          0 2018-01-14 20:49 STU_COLUMN_QUERY
drwxr-xr-x   - hadoop supergroup          0 2018-01-14 20:45 STU_COLUMN_WHERE
drwxr-xr-x   - hadoop supergroup          0 2018-01-14 21:10 STU_option_file
drwxr-xr-x   - hadoop supergroup          0 2018-01-14 20:24 sal
drwxr-xr-x   - hadoop supergroup          0 2018-01-15 03:08 sal_demo3
</code></pre> 
<p><strong>问题</strong>：执行person_job的时候，需要输入数据库的密码，怎么样能不输入密码呢？</p> 
<ul><li>配置sqoop-site.xml</li></ul> 
<pre><code class="prism language-shell"> <span class="token operator">&lt;</span>property<span class="token operator">&gt;</span>
     <span class="token operator">&lt;</span>name<span class="token operator">&gt;</span>sqoop.metastore.client.record.password<span class="token operator">&lt;</span>/name<span class="token operator">&gt;</span>
     <span class="token operator">&lt;</span>value<span class="token operator">&gt;</span>true<span class="token operator">&lt;</span>/value<span class="token operator">&gt;</span>
     <span class="token operator">&lt;</span>description<span class="token operator">&gt;</span>If true, allow saved passwords <span class="token keyword">in</span> the metastore.
     <span class="token operator">&lt;</span>/description<span class="token operator">&gt;</span>
<span class="token operator">&lt;</span>/property<span class="token operator">&gt;</span> 
</code></pre> 
<h4><a id="_696"></a>最后我们看看常用脚本把</h4> 
<pre><code class="prism language-shell"><span class="token shebang important">#!/bin/bash</span>

<span class="token comment">#Hive2Pg</span>

IP<span class="token operator">=</span>localhost
Database<span class="token operator">=</span>dufault
Driver<span class="token operator">=</span>jdbc:postgresql

pg_connection<span class="token operator">=</span><span class="token variable">${Driver}</span>://<span class="token variable">${IP}</span>/<span class="token variable">${Database}</span>
pg_username<span class="token operator">=</span>root
pg_password<span class="token operator">=</span>123456

hive_db<span class="token operator">=</span>default
hive_table<span class="token operator">=</span>hive_table
hive_columns<span class="token operator">=</span>id,name,age
 
 
<span class="token comment">#需要导出的数据pg表名</span>
export_table_name<span class="token operator">=</span>pg_test
 
 
<span class="token comment">#需要导出的数据pg列名</span>
export_table_columns<span class="token operator">=</span>id,name,age

 
<span class="token comment">#需要导出到pg的数据的临时文件目录</span>
sqoop_export_data_dir<span class="token operator">=</span>/tmp/sqoop/export/<span class="token variable">${export_table_name}</span>
 
hadoop dfs -rm -r <span class="token variable">${sqoop_export_data_dir}</span><span class="token punctuation">;</span>
<span class="token comment">#创建用于导出到pg的临时数据</span>
hive -v -e <span class="token string">"
use <span class="token variable">${hive_db}</span>;
insert overwrite directory '<span class="token variable">${sqoop_export_data_dir}</span>'
select
<span class="token variable">${hive_columns}</span>
from <span class="token variable">${hive_db}</span>.<span class="token variable">${hive_table}</span>;"</span><span class="token punctuation">;</span>

<span class="token comment">#先删除目的数据库的数据</span>
sqoop <span class="token function">eval</span> --connect <span class="token variable">${pg_connection}</span>  \
--username <span class="token variable">${pg_username}</span>  \
--password <span class="token variable">${pg_password}</span> \
--verbose --query <span class="token string">"delete from <span class="token variable">${export_table_name}</span>"</span><span class="token punctuation">;</span>

 
<span class="token comment">#再导出数据</span>
sqoop <span class="token function">export</span> --connect <span class="token variable">${pg_connection}</span> \
--username <span class="token variable">${pg_username}</span> \
--password <span class="token variable">${pg_password}</span> \
--export-dir <span class="token variable">${sqoop_export_data_dir}</span> \
--verbose --num-mappers 1 \
--table <span class="token variable">${export_table_name}</span> \
--columns <span class="token variable">${export_table_columns}</span> \
--input-fields-terminated-by <span class="token string">'\001'</span> \
--input-lines-terminated-by <span class="token string">'\n'</span> \
--input-null-string <span class="token string">'\\N'</span> \
--input-null-non-string <span class="token string">'\\N'</span>
</code></pre>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/be56edc08ffc1fe0df8a0e24ef750630/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Helm使用</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/5611e35ca3a2e72759358a5606ceb2dd/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">微信小程序审核不通过的解决方法</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程爱好者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151260"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>