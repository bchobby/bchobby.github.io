<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>anaconda深度学习环境搭建：tensorflow和pytorch - 编程爱好者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="anaconda深度学习环境搭建：tensorflow和pytorch" />
<meta property="og:description" content="文章目录 1 anaconda1.1 什么是anaconda，它有什么用1.2 安装anaconda 2 搭建深度学习环境2.1 使用pytorch2.1.1 不使用GPU2.1.2 使用GPU 2.2 使用tensorflow2.2.1 不使用GPU2.2.2 使用GPU 3 版本对应关系总结3.1 pytroch版本、python版本对应关系3.2 显卡型号、显卡算力对应关系3.3 cuda版本、显卡算力对应关系3.4 cuda版本、显卡驱动版本对应关系3.5 tensorflow版本、python版本对应关系3.6 tensorflow版本、python版本、cudnn版本、cuda版本对应关系 4 conda换源4.1 清华源4.2 中科大源 想运行深度学习的代码，第一步就是搭建深度学习环境，无论是使用什么框架（pytorch、tensorflow），还是使用什么操作系统（windows，linux）。
运行代码时要想加速训练的话，肯定要使用GPU，一般用户大多数都是用nvidia显卡，而这时就需要配置cuda、cudnn啥的，而手动配置比较麻烦，需要先去官网下载，还得配置环境变量啥的。所以本文介绍使用anaconda配置深度学习环境的方法。
1 anaconda 1.1 什么是anaconda，它有什么用 简单的说，anaconda是一个环境管理和包管理的工具，是一个跨平台的软件，可以用它方便的创建、切换python虚拟环境，为python虚拟环境安装第三方包。主要命令是conda，可使用这个命令来实现环境的创建、切换和包的安装。
除了anaconda，其实还有一个miniconda，miniconda可以看作是anaconda的精简版，它只允许使用conda命令进行操作，而不提供图形界面和其它anaconda具有的功能（比如jupyter notebook啥的）。如果没有图形界面操作需要的话，可以安装miniconda，miniconda安装包比较小，安装之后占用的空间也小。
当然，如果不喜欢anaconda的话，只用python解释器也行，使用python也可以创建虚拟环境，再激活相应的虚拟环境，再安装相应的深度学习框架和第三方包，使用GPU的话，还需要手动配置cuda啥的，这样比较麻烦。使用conda只是比较方便而已。
1.2 安装anaconda 进入anaconda官网，根据自己的操作系统选择相应的安装文件或安装脚本下载即可。
具体安装过程不再详述，按照提示操作即可。
2 搭建深度学习环境 2.1 使用pytorch pytorch版本和python版本对应关系
torchtorchvisionpythonmain / nightlymain / nightly&gt;=3.7, &lt;=3.101.12.00.13.0&gt;=3.7, &lt;=3.101.11.00.12.0&gt;=3.7, &lt;=3.101.10.20.11.3&gt;=3.6, &lt;=3.91.10.10.11.2&gt;=3.6, &lt;=3.91.10.00.11.1&gt;=3.6, &lt;=3.91.9.10.10.1&gt;=3.6, &lt;=3.91.9.00.10.0&gt;=3.6, &lt;=3.91.8.20.9.2&gt;=3.6, &lt;=3.91.8.10.9.1&gt;=3.6, &lt;=3.91.8.00.9.0&gt;=3.6, &lt;=3.91.7.10.8.2&gt;=3.6, &lt;=3.91.7.00.8.1&gt;=3.6, &lt;=3.81.7.00.8.0&gt;=3.6, &lt;=3.81.6.00.7.0&gt;=3.6, &lt;=3.81.5.10.6.1&gt;=3.5, &lt;=3.81.5.00.6.0&gt;=3.5, &lt;=3.81.4.00.5.0==2.7, &gt;=3.5, &lt;=3.81.3.10.4.2==2.7, &gt;=3." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bchobby.github.io/posts/855419f920cba7f358a7e2f721c404e4/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-10-17T09:03:36+08:00" />
<meta property="article:modified_time" content="2022-10-17T09:03:36+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程爱好者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程爱好者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">anaconda深度学习环境搭建：tensorflow和pytorch</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#1_anaconda_4" rel="nofollow">1 anaconda</a></li><li><ul><li><a href="#11_anaconda_5" rel="nofollow">1.1 什么是anaconda，它有什么用</a></li><li><a href="#12_anaconda_11" rel="nofollow">1.2 安装anaconda</a></li></ul> 
  </li><li><a href="#2__16" rel="nofollow">2 搭建深度学习环境</a></li><li><ul><li><a href="#21_pytorch_18" rel="nofollow">2.1 使用pytorch</a></li><li><ul><li><a href="#211__GPU_49" rel="nofollow">2.1.1 不使用GPU</a></li><li><a href="#212_GPU_69" rel="nofollow">2.1.2 使用GPU</a></li></ul> 
   </li><li><a href="#22_tensorflow_218" rel="nofollow">2.2 使用tensorflow</a></li><li><ul><li><a href="#221_GPU_223" rel="nofollow">2.2.1 不使用GPU</a></li><li><a href="#222_GPU_277" rel="nofollow">2.2.2 使用GPU</a></li></ul> 
  </li></ul> 
  </li><li><a href="#3__381" rel="nofollow">3 版本对应关系总结</a></li><li><ul><li><a href="#31_pytrochpython_382" rel="nofollow">3.1 pytroch版本、python版本对应关系</a></li><li><a href="#32__384" rel="nofollow">3.2 显卡型号、显卡算力对应关系</a></li><li><a href="#33_cuda_386" rel="nofollow">3.3 cuda版本、显卡算力对应关系</a></li><li><a href="#34_cuda_388" rel="nofollow">3.4 cuda版本、显卡驱动版本对应关系</a></li><li><a href="#35_tensorflowpython_390" rel="nofollow">3.5 tensorflow版本、python版本对应关系</a></li><li><a href="#36_tensorflowpythoncudnncuda_392" rel="nofollow">3.6 tensorflow版本、python版本、cudnn版本、cuda版本对应关系</a></li></ul> 
  </li><li><a href="#4_conda_395" rel="nofollow">4 conda换源</a></li><li><ul><li><a href="#41__398" rel="nofollow">4.1 清华源</a></li><li><a href="#42__400" rel="nofollow">4.2 中科大源</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<blockquote> 
 <p>想运行深度学习的代码，第一步就是搭建深度学习环境，无论是使用什么框架（pytorch、tensorflow），还是使用什么操作系统（windows，linux）。<br> 运行代码时要想加速训练的话，肯定要使用GPU，一般用户大多数都是用nvidia显卡，而这时就需要配置cuda、cudnn啥的，而手动配置比较麻烦，需要先去官网下载，还得配置环境变量啥的。所以本文介绍使用anaconda配置深度学习环境的方法。</p> 
</blockquote> 
<h2><a id="1_anaconda_4"></a>1 anaconda</h2> 
<h3><a id="11_anaconda_5"></a>1.1 什么是anaconda，它有什么用</h3> 
<p>简单的说，anaconda是一个环境管理和包管理的工具，是一个跨平台的软件，可以用它方便的创建、切换python虚拟环境，为python虚拟环境安装第三方包。主要命令是conda，可使用这个命令来实现环境的创建、切换和包的安装。</p> 
<p>除了anaconda，其实还有一个miniconda，miniconda可以看作是anaconda的精简版，它只允许使用conda命令进行操作，而不提供图形界面和其它anaconda具有的功能（比如jupyter notebook啥的）。如果没有图形界面操作需要的话，可以安装miniconda，miniconda安装包比较小，安装之后占用的空间也小。</p> 
<p>当然，如果不喜欢anaconda的话，只用python解释器也行，使用python也可以创建虚拟环境，再激活相应的虚拟环境，再安装相应的深度学习框架和第三方包，使用GPU的话，还需要手动配置cuda啥的，这样比较麻烦。使用conda只是比较方便而已。</p> 
<h3><a id="12_anaconda_11"></a>1.2 安装anaconda</h3> 
<p>进入<a href="https://www.anaconda.com/" rel="nofollow">anaconda官网</a>，根据自己的操作系统选择相应的安装文件或安装脚本下载即可。<br> <img src="https://images2.imgbox.com/34/c7/qavxkm6a_o.png" alt="在这里插入图片描述"><br> 具体安装过程不再详述，按照提示操作即可。</p> 
<h2><a id="2__16"></a>2 搭建深度学习环境</h2> 
<h3><a id="21_pytorch_18"></a>2.1 使用pytorch</h3> 
<p><span id="id1"></span><br> <a href="https://github.com/pytorch/vision#installation">pytorch版本和python版本对应关系</a></p> 
<table><thead><tr><th><code>torch</code></th><th><code>torchvision</code></th><th><code>python</code></th></tr></thead><tbody><tr><td><code>main</code> / <code>nightly</code></td><td><code>main</code> / <code>nightly</code></td><td><code>&gt;=3.7</code>, <code>&lt;=3.10</code></td></tr><tr><td><code>1.12.0</code></td><td><code>0.13.0</code></td><td><code>&gt;=3.7</code>, <code>&lt;=3.10</code></td></tr><tr><td><code>1.11.0</code></td><td><code>0.12.0</code></td><td><code>&gt;=3.7</code>, <code>&lt;=3.10</code></td></tr><tr><td><code>1.10.2</code></td><td><code>0.11.3</code></td><td><code>&gt;=3.6</code>, <code>&lt;=3.9</code></td></tr><tr><td><code>1.10.1</code></td><td><code>0.11.2</code></td><td><code>&gt;=3.6</code>, <code>&lt;=3.9</code></td></tr><tr><td><code>1.10.0</code></td><td><code>0.11.1</code></td><td><code>&gt;=3.6</code>, <code>&lt;=3.9</code></td></tr><tr><td><code>1.9.1</code></td><td><code>0.10.1</code></td><td><code>&gt;=3.6</code>, <code>&lt;=3.9</code></td></tr><tr><td><code>1.9.0</code></td><td><code>0.10.0</code></td><td><code>&gt;=3.6</code>, <code>&lt;=3.9</code></td></tr><tr><td><code>1.8.2</code></td><td><code>0.9.2</code></td><td><code>&gt;=3.6</code>, <code>&lt;=3.9</code></td></tr><tr><td><code>1.8.1</code></td><td><code>0.9.1</code></td><td><code>&gt;=3.6</code>, <code>&lt;=3.9</code></td></tr><tr><td><code>1.8.0</code></td><td><code>0.9.0</code></td><td><code>&gt;=3.6</code>, <code>&lt;=3.9</code></td></tr><tr><td><code>1.7.1</code></td><td><code>0.8.2</code></td><td><code>&gt;=3.6</code>, <code>&lt;=3.9</code></td></tr><tr><td><code>1.7.0</code></td><td><code>0.8.1</code></td><td><code>&gt;=3.6</code>, <code>&lt;=3.8</code></td></tr><tr><td><code>1.7.0</code></td><td><code>0.8.0</code></td><td><code>&gt;=3.6</code>, <code>&lt;=3.8</code></td></tr><tr><td><code>1.6.0</code></td><td><code>0.7.0</code></td><td><code>&gt;=3.6</code>, <code>&lt;=3.8</code></td></tr><tr><td><code>1.5.1</code></td><td><code>0.6.1</code></td><td><code>&gt;=3.5</code>, <code>&lt;=3.8</code></td></tr><tr><td><code>1.5.0</code></td><td><code>0.6.0</code></td><td><code>&gt;=3.5</code>, <code>&lt;=3.8</code></td></tr><tr><td><code>1.4.0</code></td><td><code>0.5.0</code></td><td><code>==2.7</code>, <code>&gt;=3.5</code>, <code>&lt;=3.8</code></td></tr><tr><td><code>1.3.1</code></td><td><code>0.4.2</code></td><td><code>==2.7</code>, <code>&gt;=3.5</code>, <code>&lt;=3.7</code></td></tr><tr><td><code>1.3.0</code></td><td><code>0.4.1</code></td><td><code>==2.7</code>, <code>&gt;=3.5</code>, <code>&lt;=3.7</code></td></tr><tr><td><code>1.2.0</code></td><td><code>0.4.0</code></td><td><code>==2.7</code>, <code>&gt;=3.5</code>, <code>&lt;=3.7</code></td></tr><tr><td><code>1.1.0</code></td><td><code>0.3.0</code></td><td><code>==2.7</code>, <code>&gt;=3.5</code>, <code>&lt;=3.7</code></td></tr><tr><td><code>&lt;=1.0.1</code></td><td><code>0.2.2</code></td><td><code>==2.7</code>, <code>&gt;=3.5</code>, <code>&lt;=3.7</code></td></tr></tbody></table> 
<p>这个表是目前为止所有版本的对应关系，需要注意的是随着时间的推移，此表内容会被更新，因此最新信息请移步<a href="https://github.com/pytorch/vision#installation">官方链接</a>查看。</p> 
<h4><a id="211__GPU_49"></a>2.1.1 不使用GPU</h4> 
<p>进入<a href="https://pytorch.org/get-started/locally/" rel="nofollow">pytorch官网</a><br> <img src="https://images2.imgbox.com/af/af/CaJvQBnf_o.png" alt="在这里插入图片描述"><br> 比如<strong>使用1.12.0版本的torch</strong>，那么从上表可知，选择的python版本要<code>&gt;=3.7, &lt;=3.10</code>，那么便可以使用如下命令操作</p> 
<pre><code># 进入anaconda会自动激活base环境。我们要做的是创建自己的虚拟环境并激活，然后再使用
# 这里的python版本只要符合表中要求即可
(base) root@server:~# conda create --name torch-env python=3.9 -y
(base) root@server:~# conda activate torch-env
(torch-env) root@server:~# 
</code></pre> 
<p>在<a href="https://pytorch.org/get-started/locally/" rel="nofollow">官网界面</a>根据实际情况进行相应选择即可。下面最后一行是安装命令，原样执行即可</p> 
<pre><code># 执行之前要先激活对应的虚拟环境
(torch-env) root@server:~# conda install pytorch torchvision torchaudio cpuonly -c pytorch
</code></pre> 
<h4><a id="212_GPU_69"></a>2.1.2 使用GPU</h4> 
<p>需要注意的是，如果使用GPU，则还需要搞清楚自己使用的显卡型号、显卡驱动版本。因为不同的显卡算力不同，不同版本cuda支持的显卡算力也不同，cuda版本和显卡驱动版本也有关系。</p> 
<p><span id="id2"></span><br> 1、<a href="https://developer.nvidia.com/zh-cn/cuda-gpus#compute" rel="nofollow">显卡型号及算力</a>。以下是部分图示。<br> <img src="https://images2.imgbox.com/00/7e/k6pB2XFa_o.png" alt="在这里插入图片描述"><br> <span id="id3"></span><br> 2、<a href="https://docs.nvidia.com/cuda/ampere-compatibility-guide/index.html#building-applications-with-ampere-support" rel="nofollow">不同版本cuda支持的GPU算力</a></p> 
<pre><code>The nvcc compiler included with versions 10.x (10.0, 10.1 and 10.2) of the CUDA Toolkit 
can generate cubins native to the Volta and Turing architectures (compute capability 7.x).

With versions 11.0 of the CUDA Toolkit, nvcc can generate cubin native to the NVIDIA 
Ampere GPU architecture (compute capability 8.0). 
</code></pre> 
<p>简单的说</p> 
<table><thead><tr><th>cuda版本</th><th>支持的GPU算力</th></tr></thead><tbody><tr><td>10.x</td><td>7.x</td></tr><tr><td>11.0</td><td>8.0</td></tr></tbody></table> 
<p><span id="id4"></span><br> 3、<a href="https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html" rel="nofollow">cuda版本和显卡驱动对应关系</a></p> 
<table><thead><tr><th align="left">CUDA Toolkit</th><th align="left">Linux x86_64 Driver Version</th><th align="left">Windows x86_64 Driver Version</th></tr></thead><tbody><tr><td align="left">CUDA 11.7 GA</td><td align="left">&gt;=515.43.04</td><td align="left">&gt;=516.01</td></tr><tr><td align="left">CUDA 11.6 Update 2</td><td align="left">&gt;=510.47.03</td><td align="left">&gt;=511.65</td></tr><tr><td align="left">CUDA 11.6 Update 1</td><td align="left">&gt;=510.47.03</td><td align="left">&gt;=511.65</td></tr><tr><td align="left">CUDA 11.6 GA</td><td align="left">&gt;=510.39.01</td><td align="left">&gt;=511.23</td></tr><tr><td align="left">CUDA 11.5 Update 2</td><td align="left">&gt;=495.29.05</td><td align="left">&gt;=496.13</td></tr><tr><td align="left">CUDA 11.5 Update 1</td><td align="left">&gt;=495.29.05</td><td align="left">&gt;=496.13</td></tr><tr><td align="left">CUDA 11.5 GA</td><td align="left">&gt;=495.29.05</td><td align="left">&gt;=496.04</td></tr><tr><td align="left">CUDA 11.4 Update 4</td><td align="left">&gt;=470.82.01</td><td align="left">&gt;=472.50</td></tr><tr><td align="left">CUDA 11.4 Update 3</td><td align="left">&gt;=470.82.01</td><td align="left">&gt;=472.50</td></tr><tr><td align="left">CUDA 11.4 Update 2</td><td align="left">&gt;=470.57.02</td><td align="left">&gt;=471.41</td></tr><tr><td align="left">CUDA 11.4 Update 1</td><td align="left">&gt;=470.57.02</td><td align="left">&gt;=471.41</td></tr><tr><td align="left">CUDA 11.4.0 GA</td><td align="left">&gt;=470.42.01</td><td align="left">&gt;=471.11</td></tr><tr><td align="left">CUDA 11.3.1 Update 1</td><td align="left">&gt;=465.19.01</td><td align="left">&gt;=465.89</td></tr><tr><td align="left">CUDA 11.3.0 GA</td><td align="left">&gt;=465.19.01</td><td align="left">&gt;=465.89</td></tr><tr><td align="left">CUDA 11.2.2 Update 2</td><td align="left">&gt;=460.32.03</td><td align="left">&gt;=461.33</td></tr><tr><td align="left">CUDA 11.2.1 Update 1</td><td align="left">&gt;=460.32.03</td><td align="left">&gt;=461.09</td></tr><tr><td align="left">CUDA 11.2.0 GA</td><td align="left">&gt;=460.27.03</td><td align="left">&gt;=460.82</td></tr><tr><td align="left">CUDA 11.1.1 Update 1</td><td align="left">&gt;=455.32</td><td align="left">&gt;=456.81</td></tr><tr><td align="left">CUDA 11.1 GA</td><td align="left">&gt;=455.23</td><td align="left">&gt;=456.38</td></tr><tr><td align="left">CUDA 11.0.3 Update 1</td><td align="left">&gt;= 450.51.06</td><td align="left">&gt;= 451.82</td></tr><tr><td align="left">CUDA 11.0.2 GA</td><td align="left">&gt;= 450.51.05</td><td align="left">&gt;= 451.48</td></tr><tr><td align="left">CUDA 11.0.1 RC</td><td align="left">&gt;= 450.36.06</td><td align="left">&gt;= 451.22</td></tr><tr><td align="left">CUDA 10.2.89</td><td align="left">&gt;= 440.33</td><td align="left">&gt;= 441.22</td></tr><tr><td align="left">CUDA 10.1 (10.1.105 general release, and updates)</td><td align="left">&gt;= 418.39</td><td align="left">&gt;= 418.96</td></tr><tr><td align="left">CUDA 10.0.130</td><td align="left">&gt;= 410.48</td><td align="left">&gt;= 411.31</td></tr><tr><td align="left">CUDA 9.2 (9.2.148 Update 1)</td><td align="left">&gt;= 396.37</td><td align="left">&gt;= 398.26</td></tr><tr><td align="left">CUDA 9.2 (9.2.88)</td><td align="left">&gt;= 396.26</td><td align="left">&gt;= 397.44</td></tr><tr><td align="left">CUDA 9.1 (9.1.85)</td><td align="left">&gt;= 390.46</td><td align="left">&gt;= 391.29</td></tr><tr><td align="left">CUDA 9.0 (9.0.76)</td><td align="left">&gt;= 384.81</td><td align="left">&gt;= 385.54</td></tr><tr><td align="left">CUDA 8.0 (8.0.61 GA2)</td><td align="left">&gt;= 375.26</td><td align="left">&gt;= 376.51</td></tr><tr><td align="left">CUDA 8.0 (8.0.44)</td><td align="left">&gt;= 367.48</td><td align="left">&gt;= 369.30</td></tr><tr><td align="left">CUDA 7.5 (7.5.16)</td><td align="left">&gt;= 352.31</td><td align="left">&gt;= 353.66</td></tr><tr><td align="left">CUDA 7.0 (7.0.28)</td><td align="left">&gt;= 346.46</td><td align="left">&gt;= 347.62</td></tr></tbody></table> 
<p>一般来说，高版本是兼容低版本的，也就是说<code>cuda10.x</code>支持的显卡，<code>cuda11.x</code>肯定支持；<code>cuda11.2.x</code>支持的，<code>cuda11.7.x</code>肯定支持。所以，到底该怎么确定这些版本呢？</p> 
<ol><li>查看自己GPU型号，确定GPU算力。</li><li>把自己的显卡驱动升到最新版本（不说最新，至少版本别太旧）。</li><li>确定cuda版本。这里一个原则是，<strong>选择框架支持的较新的cuda版本</strong>，或许觉得自己显卡型号旧，算力低，没关系，直接往高版本搞，人家cuda版本都能支持8.x的算力了，支持你5.x、6.x、7.x那不绰绰有余？</li><li>确定pytorch框架版本。</li><li>确定python版本。python版本的选择取决于框架版本。</li></ol> 
<p>下面举个例子。<br> 1、确定显卡型号</p> 
<pre><code>(torch-env) root@server:~# nvidia-smi -L
GPU 0: NVIDIA GeForce RTX 2080 Ti (UUID: GPU-***-***-***-***-***)
GPU 1: NVIDIA GeForce RTX 2080 Ti (UUID: GPU-***-***-***-***-***)
GPU 2: NVIDIA GeForce RTX 2080 Ti (UUID: GPU-***-***-***-***-***)
GPU 3: NVIDIA GeForce RTX 2080 Ti (UUID: GPU-***-***-***-***-***)
GPU 4: NVIDIA GeForce RTX 2080 Ti (UUID: GPU-***-***-***-***-***)
GPU 5: NVIDIA GeForce RTX 2080 Ti (UUID: GPU-***-***-***-***-***)
</code></pre> 
<p>可以看到，这里的显卡型号为<code>NVIDIA GeForce RTX 2080 Ti</code>，根据上面那个表可以看出，此显卡算力为<code>7.5</code>。</p> 
<p>2、选择合适的显卡驱动。<br> 直接更新到最新吧。</p> 
<p>3、确定cuda版本<br> 由步骤1可知，目标版本的cuda支持的算力要高于7.5。只要深度学习框架支持，选择较新版本的cuda肯定不会错。这里暂定选择<code>11.x</code>版本的cuda。</p> 
<p>4、确定pytoch版本</p> 
<p>用conda搜索一下软件源有的cuda</p> 
<pre><code>(torch-env) root@server:~# conda search cudatoolkit
Loading channels: done
# Name                       Version           Build  Channel
cudatoolkit                      7.5               0  anaconda/pkgs/free
cudatoolkit                      7.5               2  anaconda/pkgs/free
cudatoolkit                      8.0               1  anaconda/pkgs/free
cudatoolkit                      8.0               3  anaconda/pkgs/free
cudatoolkit                      9.0      h13b8566_0  anaconda/pkgs/main
cudatoolkit                      9.0      h13b8566_0  pkgs/main
cudatoolkit                      9.2               0  anaconda/pkgs/main
cudatoolkit                      9.2               0  pkgs/main
cudatoolkit                 10.0.130               0  anaconda/pkgs/main
cudatoolkit                 10.0.130               0  pkgs/main
cudatoolkit                 10.1.168               0  anaconda/pkgs/main
cudatoolkit                 10.1.168               0  pkgs/main
cudatoolkit                 10.1.243      h6bb024c_0  anaconda/pkgs/main
cudatoolkit                 10.1.243      h6bb024c_0  pkgs/main
cudatoolkit                  10.2.89      hfd86e86_0  anaconda/pkgs/main
cudatoolkit                  10.2.89      hfd86e86_0  pkgs/main
cudatoolkit                  10.2.89      hfd86e86_1  anaconda/pkgs/main
cudatoolkit                  10.2.89      hfd86e86_1  pkgs/main
cudatoolkit                 11.0.221      h6bb024c_0  anaconda/pkgs/main
cudatoolkit                 11.0.221      h6bb024c_0  pkgs/main
cudatoolkit                   11.3.1      h2bc3f7f_2  anaconda/pkgs/main
cudatoolkit                   11.3.1      h2bc3f7f_2  pkgs/main
</code></pre> 
<p>进入<a href="https://pytorch.org/get-started/locally/" rel="nofollow">pytorch官网</a><br> <img src="https://images2.imgbox.com/14/b6/6ouTjl7O_o.png" alt="在这里插入图片描述"></p> 
<p>pytorch支持的最新的<code>cuda 11.6</code>支持的显卡算力肯定够了，但是conda软件源最高只有<code>cuda 11.3</code>因此<strong>这里选择cuda 11.3</strong></p> 
<p>5、确定python版本<br> 比如<strong>使用1.12.0版本的torch</strong>，那么从对应关系表可知，选择的python版本要<code>&gt;=3.7, &lt;=3.10</code>。</p> 
<p>整个安装过程如下所示：</p> 
<pre><code># 进入anaconda会自动激活base环境。我们要做的是创建自己的虚拟环境并激活，然后再使用
# 这里的python版本只要符合表中要求即可
(base) root@server:~# conda create --name torch-env python=3.9 -y
(base) root@server:~# conda activate torch-env
(torch-env) root@server:~# conda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch
</code></pre> 
<p>查看框架版本和GPU是否可用</p> 
<pre><code># 进入python环境
(torch-env) root@server:~# python
&gt;&gt;&gt; import torch
&gt;&gt;&gt;
&gt;&gt;&gt; torch.__version__
***
&gt;&gt;&gt;
&gt;&gt;&gt; torch.cuda.is_available()
True
</code></pre> 
<h3><a id="22_tensorflow_218"></a>2.2 使用tensorflow</h3> 
<p><a href="https://tensorflow.google.cn/install?hl=en" rel="nofollow">tensorflow官网</a><br> 这里只说明TensorFlow 2的搭建步骤。<br> TensorFlow 2 packages require a pip version &gt;19.0 (or &gt;20.3 for macOS).<br> <span id="id5"></span></p> 
<h4><a id="221_GPU_223"></a>2.2.1 不使用GPU</h4> 
<p><a href="https://tensorflow.google.cn/install/source_windows?hl=en#cpu" rel="nofollow">tensorflow版本、python版本对应关系</a></p> 
<table><thead><tr><th align="left">Version</th><th align="left">Python version</th></tr></thead><tbody><tr><td align="left">tensorflow-2.9.0</td><td align="left">3.7-3.10</td></tr><tr><td align="left">tensorflow-2.8.0</td><td align="left">3.7-3.10</td></tr><tr><td align="left">tensorflow-2.7.0</td><td align="left">3.7-3.9</td></tr><tr><td align="left">tensorflow-2.6.0</td><td align="left">3.6-3.9</td></tr><tr><td align="left">tensorflow-2.5.0</td><td align="left">3.6-3.9</td></tr><tr><td align="left">tensorflow-2.4.0</td><td align="left">3.6-3.8</td></tr><tr><td align="left">tensorflow-2.3.0</td><td align="left">3.5-3.8</td></tr><tr><td align="left">tensorflow-2.2.0</td><td align="left">3.5-3.8</td></tr><tr><td align="left">tensorflow-2.1.0</td><td align="left">3.5-3.7</td></tr><tr><td align="left">tensorflow-2.0.0</td><td align="left">3.5-3.7</td></tr><tr><td align="left">tensorflow-1.15.0</td><td align="left">3.5-3.7</td></tr><tr><td align="left">tensorflow-1.14.0</td><td align="left">3.5-3.7</td></tr><tr><td align="left">tensorflow-1.13.0</td><td align="left">3.5-3.7</td></tr><tr><td align="left">tensorflow-1.12.0</td><td align="left">3.5-3.6</td></tr><tr><td align="left">tensorflow-1.11.0</td><td align="left">3.5-3.6</td></tr><tr><td align="left">tensorflow-1.10.0</td><td align="left">3.5-3.6</td></tr><tr><td align="left">tensorflow-1.9.0</td><td align="left">3.5-3.6</td></tr><tr><td align="left">tensorflow-1.8.0</td><td align="left">3.5-3.6</td></tr><tr><td align="left">tensorflow-1.7.0</td><td align="left">3.5-3.6</td></tr><tr><td align="left">tensorflow-1.6.0</td><td align="left">3.5-3.6</td></tr><tr><td align="left">tensorflow-1.5.0</td><td align="left">3.5-3.6</td></tr><tr><td align="left">tensorflow-1.4.0</td><td align="left">3.5-3.6</td></tr><tr><td align="left">tensorflow-1.3.0</td><td align="left">3.5-3.6</td></tr><tr><td align="left">tensorflow-1.2.0</td><td align="left">3.5-3.6</td></tr><tr><td align="left">tensorflow-1.1.0</td><td align="left">3.5</td></tr><tr><td align="left">tensorflow-1.0.0</td><td align="left">3.5</td></tr></tbody></table> 
<p>1、安装最新稳定版tensorflow</p> 
<pre><code>(base) root@server:~# conda create --name tf29-py39 python=3.9 -y
(base) root@server:~# conda activate tf29-py39

# Requires the latest pip
(tf29-py39) root@server:~# pip install --upgrade pip

# Current stable release for CPU and GPU
(tf29-py39) root@server:~# pip install tensorflow
</code></pre> 
<p>2、安装指定版tensorflow</p> 
<pre><code>(base) root@server:~# conda create --name tf24-py38 python=3.8 -y
(base) root@server:~# conda activate tf24-py38
(tf24-py38) root@server:~# pip install --upgrade pip
(tf24-py38) root@server:~# pip install tensorflow==2.4
</code></pre> 
<p><span id="id6"></span></p> 
<h4><a id="222_GPU_277"></a>2.2.2 使用GPU</h4> 
<p><a href="https://tensorflow.google.cn/install/source_windows?hl=en#gpu" rel="nofollow">tensorflow版本、python版本、cudnn版本、cuda版本对应关系</a></p> 
<table><thead><tr><th align="left">Version</th><th align="left">Python version</th><th align="left">cuDNN</th><th align="left">CUDA</th></tr></thead><tbody><tr><td align="left">tensorflow_gpu-2.9.0</td><td align="left">3.7-3.10</td><td align="left">8.1</td><td align="left">11.2</td></tr><tr><td align="left">tensorflow_gpu-2.8.0</td><td align="left">3.7-3.10</td><td align="left">8.1</td><td align="left">11.2</td></tr><tr><td align="left">tensorflow_gpu-2.7.0</td><td align="left">3.7-3.9</td><td align="left">8.1</td><td align="left">11.2</td></tr><tr><td align="left">tensorflow_gpu-2.6.0</td><td align="left">3.6-3.9</td><td align="left">8.1</td><td align="left">11.2</td></tr><tr><td align="left">tensorflow_gpu-2.5.0</td><td align="left">3.6-3.9</td><td align="left">8.1</td><td align="left">11.2</td></tr><tr><td align="left">tensorflow_gpu-2.4.0</td><td align="left">3.6-3.8</td><td align="left">8.0</td><td align="left">11.0</td></tr><tr><td align="left">tensorflow_gpu-2.3.0</td><td align="left">3.5-3.8</td><td align="left">7.6</td><td align="left">10.1</td></tr><tr><td align="left">tensorflow_gpu-2.2.0</td><td align="left">3.5-3.8</td><td align="left">7.6</td><td align="left">10.1</td></tr><tr><td align="left">tensorflow_gpu-2.1.0</td><td align="left">3.5-3.7</td><td align="left">7.6</td><td align="left">10.1</td></tr><tr><td align="left">tensorflow_gpu-2.0.0</td><td align="left">3.5-3.7</td><td align="left">7.4</td><td align="left">10</td></tr><tr><td align="left">tensorflow_gpu-1.15.0</td><td align="left">3.5-3.7</td><td align="left">7.4</td><td align="left">10</td></tr><tr><td align="left">tensorflow_gpu-1.14.0</td><td align="left">3.5-3.7</td><td align="left">7.4</td><td align="left">10</td></tr><tr><td align="left">tensorflow_gpu-1.13.0</td><td align="left">3.5-3.7</td><td align="left">7.4</td><td align="left">10</td></tr><tr><td align="left">tensorflow_gpu-1.12.0</td><td align="left">3.5-3.6</td><td align="left">7.2</td><td align="left">9.0</td></tr><tr><td align="left">tensorflow_gpu-1.11.0</td><td align="left">3.5-3.6</td><td align="left">7</td><td align="left">9</td></tr><tr><td align="left">tensorflow_gpu-1.10.0</td><td align="left">3.5-3.6</td><td align="left">7</td><td align="left">9</td></tr><tr><td align="left">tensorflow_gpu-1.9.0</td><td align="left">3.5-3.6</td><td align="left">7</td><td align="left">9</td></tr><tr><td align="left">tensorflow_gpu-1.8.0</td><td align="left">3.5-3.6</td><td align="left">7</td><td align="left">9</td></tr><tr><td align="left">tensorflow_gpu-1.7.0</td><td align="left">3.5-3.6</td><td align="left">7</td><td align="left">9</td></tr><tr><td align="left">tensorflow_gpu-1.6.0</td><td align="left">3.5-3.6</td><td align="left">7</td><td align="left">9</td></tr><tr><td align="left">tensorflow_gpu-1.5.0</td><td align="left">3.5-3.6</td><td align="left">7</td><td align="left">9</td></tr><tr><td align="left">tensorflow_gpu-1.4.0</td><td align="left">3.5-3.6</td><td align="left">6</td><td align="left">8</td></tr><tr><td align="left">tensorflow_gpu-1.3.0</td><td align="left">3.5-3.6</td><td align="left">6</td><td align="left">8</td></tr><tr><td align="left">tensorflow_gpu-1.2.0</td><td align="left">3.5-3.6</td><td align="left">5.1</td><td align="left">8</td></tr><tr><td align="left">tensorflow_gpu-1.1.0</td><td align="left">3.5</td><td align="left">5.1</td><td align="left">8</td></tr><tr><td align="left">tensorflow_gpu-1.0.0</td><td align="left">3.5</td><td align="left">5.1</td><td align="left">8</td></tr></tbody></table> 
<p>使用gpu的话只需要再额外安装cudnn、cuda就行了。<br> 1、首先按不使用GPU的安装方法安装tensorflow框架<br> 2、安装cudnn、cudatoolkit。因为此二者只和框架版本有关，因此选择的cudnn、cudatoolkit版本按照上表中要求的版本安装即可。一般来说，只要大版本一样，即可使用。</p> 
<pre><code>(tf29-py39) root@server:~# conda search cudnn
Loading channels: done
# Name                       Version           Build  Channel
cudnn                            6.0               0  anaconda/pkgs/free
cudnn                          7.1.4       cuda8.0_0  anaconda/pkgs/main
cudnn                          7.1.4       cuda8.0_0  pkgs/main
......
cudnn                          7.6.5      cuda10.2_0  anaconda/pkgs/main
cudnn                          7.6.5      cuda10.2_0  pkgs/main
cudnn                          7.6.5       cuda9.0_0  anaconda/pkgs/main
cudnn                          7.6.5       cuda9.0_0  pkgs/main
cudnn                          7.6.5       cuda9.2_0  anaconda/pkgs/main
cudnn                          7.6.5       cuda9.2_0  pkgs/main
cudnn                          8.2.1      cuda11.3_0  anaconda/pkgs/main
cudnn                          8.2.1      cuda11.3_0  pkgs/main

(tf29-py39) root@server:~# conda search cudatoolkit
Loading channels: done
# Name                       Version           Build  Channel
cudatoolkit                      7.5               0  anaconda/pkgs/free
cudatoolkit                      7.5               2  anaconda/pkgs/free
cudatoolkit                      8.0               1  anaconda/pkgs/free
cudatoolkit                      8.0               3  anaconda/pkgs/free
cudatoolkit                      9.0      h13b8566_0  anaconda/pkgs/main
cudatoolkit                      9.0      h13b8566_0  pkgs/main
cudatoolkit                      9.2               0  anaconda/pkgs/main
cudatoolkit                      9.2               0  pkgs/main
cudatoolkit                 10.0.130               0  anaconda/pkgs/main
cudatoolkit                 10.0.130               0  pkgs/main
cudatoolkit                 10.1.168               0  anaconda/pkgs/main
cudatoolkit                 10.1.168               0  pkgs/main
cudatoolkit                 10.1.243      h6bb024c_0  anaconda/pkgs/main
cudatoolkit                 10.1.243      h6bb024c_0  pkgs/main
cudatoolkit                  10.2.89      hfd86e86_0  anaconda/pkgs/main
cudatoolkit                  10.2.89      hfd86e86_0  pkgs/main
cudatoolkit                  10.2.89      hfd86e86_1  anaconda/pkgs/main
cudatoolkit                  10.2.89      hfd86e86_1  pkgs/main
cudatoolkit                 11.0.221      h6bb024c_0  anaconda/pkgs/main
cudatoolkit                 11.0.221      h6bb024c_0  pkgs/main
cudatoolkit                   11.3.1      h2bc3f7f_2  anaconda/pkgs/main
cudatoolkit                   11.3.1      h2bc3f7f_2  pkgs/main

# 虽然tensorflow2.9要求cudnn8.1、cuda11.2，但是查询发现没有这两个版本的软件包，
# 只有cudnn8.2、cuda11.3，因此这里选择这两个版本。
# 不指定版本直接安装即可。会默认安装可用的最高版本。
(tf29-py39) root@server:~# conda install cudnn cudatoolkit -y
</code></pre> 
<pre><code>(tf29-py39) root@server:~# conda list |grep -i -E "cudnn|cudatoolkit"
cudatoolkit               11.3.1               h59b6b97_2    https://mirrors.ustc.edu.cn/anaconda/pkgs/main
cudnn                     8.2.1                cuda11.3_0    https://mirrors.ustc.edu.cn/anaconda/pkgs/main
</code></pre> 
<p>查看框架版本和GPU是否可用</p> 
<pre><code># 进入python环境
(tf29-py39) root@server:~# python
&gt;&gt;&gt; import tensorflow as tf
&gt;&gt;&gt;
&gt;&gt;&gt; tf.__version__
***
&gt;&gt;&gt;
&gt;&gt;&gt; tf.config.list_physical_devices("GPU")
***
</code></pre> 
<h2><a id="3__381"></a>3 版本对应关系总结</h2> 
<h3><a id="31_pytrochpython_382"></a>3.1 pytroch版本、python版本对应关系</h3> 
<p><a href="#id1" rel="nofollow">pytroch版本、python版本对应关系</a></p> 
<h3><a id="32__384"></a>3.2 显卡型号、显卡算力对应关系</h3> 
<p><a href="#id2" rel="nofollow">显卡型号、显卡算力对应关系</a></p> 
<h3><a id="33_cuda_386"></a>3.3 cuda版本、显卡算力对应关系</h3> 
<p><a href="#id3" rel="nofollow">cuda版本、显卡算力对应关系</a></p> 
<h3><a id="34_cuda_388"></a>3.4 cuda版本、显卡驱动版本对应关系</h3> 
<p><a href="#id4" rel="nofollow">cuda版本、显卡驱动版本对应关系</a></p> 
<h3><a id="35_tensorflowpython_390"></a>3.5 tensorflow版本、python版本对应关系</h3> 
<p><a href="#id5" rel="nofollow">tensorflow版本、python版本对应关系</a></p> 
<h3><a id="36_tensorflowpythoncudnncuda_392"></a>3.6 tensorflow版本、python版本、cudnn版本、cuda版本对应关系</h3> 
<p><a href="#id6" rel="nofollow">tensorflow版本、python版本、cudnn版本、cuda版本对应关系</a></p> 
<h2><a id="4_conda_395"></a>4 conda换源</h2> 
<p>为conda换国内的软件源，可以提高包的下载速度，下面列举几个可用的国内源</p> 
<h3><a id="41__398"></a>4.1 清华源</h3> 
<p><a href="https://mirror.tuna.tsinghua.edu.cn/help/anaconda/" rel="nofollow">清华anaconda源</a></p> 
<h3><a id="42__400"></a>4.2 中科大源</h3> 
<p><a href="https://mirrors.ustc.edu.cn/help/anaconda.html" rel="nofollow">中科大anaconda源</a></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/91be60a67c079a104b398d0a9734bd01/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">MathType 提示需要一个新版本的MT Extra(True Type)字体</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/8d3871b3bda7758551992cf20e18cbfb/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">使用SOLIDWORKS方程式绘制渐开线齿轮</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程爱好者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151260"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>