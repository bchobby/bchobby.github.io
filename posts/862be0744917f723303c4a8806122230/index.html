<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>核主元分析 KPCA及matlab代码 - 编程爱好者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="核主元分析 KPCA及matlab代码" />
<meta property="og:description" content="前言 发现一篇很好的分享KPCA代码的文章 转载链接： f核主元分析 (Kernel Principal Component Analysis , KPCA) – MATLAB中文论坛 (ilovematlab.cn)
原博主处有打包matlab代码 对于简单的数据降维，可参考：
用matlab实现kpca（核主成分分析法）_Bbei的博客-CSDN博客_matlabkpca
kpca思路和pca很像，可以了解 MATLAB实例：PCA（主成成分分析）详解_FDA_sq的博客-CSDN博客_matlab pca
KPCA简介 KPCA、PCA应用：
降维特征提取去噪故障检测 假设训练数据由矩阵𝑋𝑛×𝑚表示，𝑚代表训练数据的大小，𝑛代表训练数据中特征向量的维度，KPCA具体实现过程如下： Step1：利用核函数计算核矩阵𝑲=[𝐾𝑖𝑗]𝑚×𝑚 Step2：核矩阵𝑲的中心化 Step3：对中心化核矩阵𝑲𝒄𝒆𝒏𝒕𝒆𝒓进行特征值分解 Step4：特征向量𝛼的标准化 Step5：提取训练数据的主成分 Step6：提取测试数据的主成分 KPCA的性能取决于核函数、核参数的选择。常用的核函数有线性核函数(Linear)、径向基(Radial Basis Function, RBF)和积分径向基(The Integrated Radial Basis Function, IRBF)核函数。当使用线性核函数时，KPCA退化为PCA。
主要功能
易于使用的 API支持基于 KPCA 的数据降维、特征提取、数据重构支持基于 KPCA 的故障检测和故障诊断支持多种核函数 (linear, gaussian, polynomial, sigmoid, laplacian)支持基于主元贡献率或给定数字的降维维度/主元个数选取 注意 仅支持基于高斯核函数的故障诊断核函数的参数对KPCA 模型的性能影响很大此代码仅供参考 使用说明 1. KPCA的建模过程（故障检测）： （1）获取训练数据（工业过程数据需要进行标准化处理）
（2）计算核矩阵
（3）核矩阵中心化
（4）特征值分解
（5）特征向量的标准化处理
（6）主元个数的选取
（7）计算非线性主成分（即降维结果或者特征提取结果）
（8）SPE和T2统计量的控制限计算
function model = kpca_train(X,options) % DESCRIPTION % Kernel principal component analysis (KPCA) % % mappedX = kpca_train(X,options) % % INPUT % X Training samples (N*d) % N: number of samples % d: number of features % options Parameters setting % % OUTPUT % model KPCA model % % % Created on 9th November, 2018, by Kepeng Qiu." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bchobby.github.io/posts/862be0744917f723303c4a8806122230/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-05-21T09:45:17+08:00" />
<meta property="article:modified_time" content="2022-05-21T09:45:17+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程爱好者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程爱好者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">核主元分析 KPCA及matlab代码</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h3><strong>前言 </strong></h3> 
<p>发现一篇很好的分享KPCA代码的文章 </p> 
<p>转载链接： </p> 
<p><a href="https://www.ilovematlab.cn/forum.php?mod=viewthread&amp;s_tid=followedthread&amp;tid=560380" rel="nofollow" title="f核主元分析 (Kernel Principal Component Analysis , KPCA) – MATLAB中文论坛 (ilovematlab.cn)">f核主元分析 (Kernel Principal Component Analysis , KPCA) – MATLAB中文论坛 (ilovematlab.cn)</a></p> 
<p>原博主处有打包matlab代码 </p> 
<p>对于简单的数据降维，可参考：</p> 
<p><a href="https://blog.csdn.net/weixin_41094533/article/details/90265263" title="用matlab实现kpca（核主成分分析法）_Bbei的博客-CSDN博客_matlabkpca">用matlab实现kpca（核主成分分析法）_Bbei的博客-CSDN博客_matlabkpca</a></p> 
<p>kpca思路和pca很像，可以了解  <a href="https://blog.csdn.net/FDA_sq/article/details/122009888" title="MATLAB实例：PCA（主成成分分析）详解_FDA_sq的博客-CSDN博客_matlab pca">MATLAB实例：PCA（主成成分分析）详解_FDA_sq的博客-CSDN博客_matlab pca</a></p> 
<p></p> 
<h3>KPCA简介</h3> 
<p style="margin-left:.0001pt;text-align:justify;">KPCA、PCA应用：</p> 
<ul><li style="text-align:left;"><span style="background-color:#ffffff;"><span style="color:#333333;">降维</span></span></li><li style="text-align:left;"><span style="background-color:#ffffff;"><span style="color:#333333;">特征提取</span></span></li><li style="text-align:left;"><span style="background-color:#ffffff;"><span style="color:#333333;">去噪</span></span></li><li style="text-align:left;"><span style="background-color:#ffffff;"><span style="color:#333333;">故障检测</span></span></li></ul> 
<p>假设训练数据由矩阵𝑋𝑛×𝑚表示，𝑚代表训练数据的大小，𝑛代表训练数据中特征向量的维度，KPCA具体实现过程如下： </p> 
<pre><code>Step1：利用核函数计算核矩阵𝑲=[𝐾𝑖𝑗]𝑚×𝑚
Step2：核矩阵𝑲的中心化
Step3：对中心化核矩阵𝑲𝒄𝒆𝒏𝒕𝒆𝒓进行特征值分解
Step4：特征向量𝛼的标准化
Step5：提取训练数据的主成分
Step6：提取测试数据的主成分</code></pre> 
<p style="margin-left:.0001pt;text-align:justify;">KPCA的性能取决于核函数、核参数的选择。常用的核函数有线性核函数(Linear)、径向基(Radial Basis Function, RBF)和积分径向基(The Integrated Radial Basis Function, IRBF)核函数。当使用线性核函数时，KPCA退化为PCA。</p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<h3><strong>主要功能</strong><br>  </h3> 
<ul style="margin-left:14px;"><li>易于使用的 API</li><li>支持基于 KPCA 的数据降维、特征提取、数据重构</li><li>支持基于 KPCA 的故障检测和故障诊断</li><li>支持多种核函数 (linear, gaussian, polynomial, sigmoid, laplacian)</li><li>支持基于主元贡献率或给定数字的降维维度/主元个数选取</li></ul> 
<h3><br><strong>注意</strong></h3> 
<ul style="margin-left:14px;"><li>仅支持基于高斯核函数的故障诊断</li><li>核函数的参数对KPCA 模型的性能影响很大</li><li>此代码仅供参考</li></ul> 
<h3><br><strong>使用说明</strong></h3> 
<h4><strong>1. KPCA的建模过程（故障检测）：</strong></h4> 
<p>（1）获取训练数据（工业过程数据需要进行标准化处理）<br> （2）计算核矩阵<br> （3）核矩阵中心化<br> （4）特征值分解<br> （5）特征向量的标准化处理<br> （6）主元个数的选取<br> （7）计算非线性主成分（即降维结果或者特征提取结果）<br> （8）SPE和T2统计量的控制限计算</p> 
<pre><code>function model = kpca_train(X,options)
% DESCRIPTION
% Kernel principal component analysis (KPCA)
%
%       mappedX = kpca_train(X,options)
%
% INPUT
%   X            Training samples (N*d)
%                N: number of samples
%                d: number of features
%   options      Parameters setting
%
% OUTPUT
%   model        KPCA model
%
%
% Created on 9th November, 2018, by Kepeng Qiu.



% number of training samples
L = size(X,1);

% Compute the kernel matrix
K = computeKM(X,X,options.sigma);

% Centralize the kernel matrix
unit = ones(L,L)/L;
K_c = K-unit*K-K*unit+unit*K*unit;

% Solve the eigenvalue problem
[V_s,D] = eigs(K_c/L);
lambda = diag(D);

% Normalize the eigenvalue
% V_s = V ./ sqrt(L*lambda)';

% Compute the numbers of principal component


% Extract the nonlinear component
if options.type == 1 % fault detection
    dims = find(cumsum(lambda/sum(lambda)) &gt;= 0.85,1, 'first');
else
    dims = options.dims;
end
mappedX  = K_c* V_s(:,1:dims) ;

% Store the results
model.mappedX =  mappedX ;
model.V_s = V_s;
model.lambda = lambda;
model.K_c = K_c;
model.L = L;
model.dims = dims;
model.X = X;
model.K = K;
model.unit = unit;
model.sigma = options.sigma;

% Compute the threshold
model.beta = options.beta;% corresponding probabilities
[SPE_limit,T2_limit] = comtupeLimit(model);
model.SPE_limit = SPE_limit;
model.T2_limit = T2_limit;

end</code></pre> 
<p> </p> 
<h4><strong>2. KPCA的测试过程：</strong></h4> 
<p>（1）获取测试数据（工业过程数据需要利用训练数据的均值和标准差进行标准化处理）<br> （2）计算核矩阵<br> （3）核矩阵中心化<br> （4）计算非线性主成分（即降维结果或者特征提取结果）<br> （5）SPE和T2统计量的计算</p> 
<pre><code>function [SPE,T2,mappedY] = kpca_test(model,Y)
% DESCRIPTION
% Compute the T2 statistic, SPE statistic,and the nonlinear component of Y
%
%       [SPE,T2,mappedY] = kpca_test(model,Y)
%
% INPUT
%   model       KPCA model
%   Y           test data
%
% OUTPUT
%   SPE         the SPE statistic 
%   T2          the T2 statistic
%   mappedY     the nonlinear component of Y
%
% Created on 9th November, 2018, by Kepeng Qiu.


% Compute Hotelling's T2 statistic
% T2 = diag(model.mappedX/diag(model.lambda(1:model.dims))*model.mappedX');

% the number of test samples
L = size(Y,1);

% Compute the kernel matrix
Kt = computeKM(Y,model.X,model.sigma ); 

% Centralize the kernel matrix
unit = ones(L,model.L)/model.L; 
Kt_c = Kt-unit*model.K-Kt*model.unit+unit*model.K*model.unit; 

% Extract the nonlinear component
mappedY = Kt_c*model.V_s(:,1:model.dims);

% Compute Hotelling's T2 statistic
T2 = diag(mappedY/diag(model.lambda(1:model.dims))*mappedY');

% Compute the squared prediction error (SPE)
SPE = sum((Kt_c*model.V_s).^2,2)-sum(mappedY.^2 ,2);

end</code></pre> 
<h4><strong>3. demo1: 降维、特征提取</strong></h4> 
<p>(1) 源代码</p> 
<pre><code>% Demo1: dimensionality reduction or feature extraction 
% ---------------------------------------------------------------------%
clc
clear all
close all

addpath(genpath(pwd))

% 4 circles
load circledata

% 
X = circledata;
for i = 1:4
    scatter(X(1+250*(i-1):250*i,1),X(1+250*(i-1):250*i,2))
    hold on
end

% Parameters setting
options.sigma = 5;   % kernel width
options.dims  = 2;   % output dimension
options.type  = 0;   % 0:dimensionality reduction or feature extraction
                     % 1:fault detection
options.beta  = 0.9; % corresponding probabilities (for ault detection)
options.cpc  = 0.85; % Principal contribution rate (for ault detection)


% Train KPCA model
model = kpca_train(X,options);

figure
for i = 1:4
    scatter(model.mappedX(1+250*(i-1):250*i,1), ... 
        model.mappedX(1+250*(i-1):250*i,2))
    hold on
end
</code></pre> 
<p>（2）结果 （分别为原图和特征提取后的图）</p> 
<p class="img-center"><img alt="" height="304" src="https://images2.imgbox.com/6f/8b/oeqa1sGe_o.png" width="406"></p> 
<p></p> 
<p></p> 
<p class="img-center"><img alt="" height="292" src="https://images2.imgbox.com/a8/0c/YAAsXyOK_o.png" width="390"></p> 
<p></p> 
<h4><strong>4. demo2: 故障检测（需要调节核宽度、主元贡献率和置信度等参数来提高故障检测效果）</strong></h4> 
<p>（1）源代码</p> 
<pre><code>% Demo2: Fault detection
% X: training samples
% Y: test samples

% Improve the performance of fault detection by adjusting parameters
% 1. options.sigma = 16;   % kernel width
% 2. options.beta          % corresponding probabilities 
% 3. options.cpc  ;        % principal contribution rate


% ---------------------------------------------------------------------%
clc
clear all
close all

addpath(genpath(pwd))

%
X = rand(200,10);
Y = rand(100,10);
Y(20:40,:) = rand(21,10)+3;
Y(60:80,:) = rand(21,10)*3;

% Normalization (if necessary)
% mu = mean(X);
% st = std(X);
% X = zscore(X);
% Y = bsxfun(@rdivide,bsxfun(@minus,Y,mu),st);

% Parameters setting
options.sigma = 16;   % kernel width
options.dims  = 2;   % output dimension
options.type  = 1;   % 0:dimensionality reduction or feature extraction
                     % 1:fault detection
options.beta  = 0.9; % corresponding probabilities (for ault detection)
options.cpc  = 0.85; % principal contribution rate (for ault detection)

% Train KPCA model
model = kpca_train(X,options);

% Test a new sample Y (vector of matrix)
[SPE,T2,mappedY] = kpca_test(model,Y);

% Plot the result
plotResult(model.SPE_limit,SPE);
plotResult(model.T2_limit,T2);
</code></pre> 
<p>（2）结果（分别是SPE统计量和T2统计量的结果图）</p> 
<p class="img-center"><img alt="" height="344" src="https://images2.imgbox.com/d6/52/1tlovec9_o.png" width="459"></p> 
<h4></h4> 
<p class="img-center"><img alt="" height="328" src="https://images2.imgbox.com/f8/17/c76IAbzR_o.png" width="438"></p> 
<h4></h4> 
<h4></h4> 
<h3>更新：</h3> 
<h4><br><strong> 01 核函数</strong></h4> 
<h4>类 Kernel 用于计算核函数矩阵：</h4> 
<pre><code>%{
type -

linear : k(x,y) = x'*y
polynomial : k(x,y) = (γ*x'*y+c)^d
gaussian : k(x,y) = exp(-γ*||x-y||^2)
sigmoid : k(x,y) = tanh(γ*x'*y+c)
laplacian : k(x,y) = exp(-γ*||x-y||)


degree - d
offset - c
gamma - γ
%}
kernel = Kernel('type', 'gaussian', 'gamma', value);
kernel = Kernel('type', 'polynomial', 'degree', value);
kernel = Kernel('type', 'linear');
kernel = Kernel('type', 'sigmoid', 'gamma', value);
kernel = Kernel('type', 'laplacian', 'gamma', value);</code></pre> 
<p>例如，计算 X 和 Y 的高斯核函数矩阵：</p> 
<pre><code>X = rand(5, 2);
Y = rand(3, 2);
kernel = Kernel('type', 'gaussian', 'gamma', 2);
kernelMatrix = kernel.computeMatrix(X, Y);
&gt;&gt; kernelMatrix

kernelMatrix =

    0.5684    0.5607    0.4007
    0.4651    0.8383    0.5091
    0.8392    0.7116    0.9834
    0.4731    0.8816    0.8052
    0.5034    0.9807    0.7274</code></pre> 
<h4><strong>02. 数据降维</strong></h4> 
<p>以 helix 数据为例：</p> 
<pre><code>clc
clear all
close all
addpath(genpath(pwd))

load('.\data\helix.mat', 'data')
kernel = Kernel('type', 'gaussian', 'gamma', 2);
parameter = struct('numComponents', 2, ...
                   'kernelFunc', kernel);
% build a KPCA object
kpca = KernelPCA(parameter);
% train KPCA model
kpca.train(data);

%　mapping data
mappingData = kpca.score;

% Visualization
kplot = KernelPCAVisualization();
% visulize the mapping data
kplot.score(kpca)</code></pre> 
<p>训练结果为：</p> 
<pre><code>*** KPCA model training finished ***
running time            = 0.2798 seconds
kernel function         = gaussian 
number of samples       = 1000 
number of features      = 3 
number of components    = 2 
number of T2 alarm      = 135 
number of SPE alarm     = 0 
accuracy of T2          = 86.5000% 
accuracy of SPE         = 100.0000%</code></pre> 
<p>香蕉型数据的降维结果：</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/a0/4f/02rBSuc9_o.png"></p> 
<h4><strong>03. 数据重构</strong></h4> 
<p>同心圆数据的重构结果：</p> 
<pre><code>clc
clear all
close all
addpath(genpath(pwd))

load('.\data\circle.mat', 'data')
kernel = Kernel('type', 'gaussian', 'gamma', 0.2);
parameter = struct('numComponents', 2, ...
                   'kernelFunc', kernel);
% build a KPCA object
kpca = KernelPCA(parameter);
% train KPCA model
kpca.train(data);

%　reconstructed data
reconstructedData = kpca.newData;

% Visualization
kplot = KernelPCAVisualization();
kplot.reconstruction(kpca)</code></pre> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/33/ab/kl5Tis8L_o.png"></p> 
<h4><strong>04. 主元个数的确定</strong></h4> 
<p>提供了两种方式来确定主元个数：<strong>主元贡献率</strong>和<strong>给定的数量</strong><br><br><strong>第一种：主元贡献率 （取值 0~1 之间）</strong><br><br> 通过键值对<strong> 'numComponents' - value</strong> 来设置。比如，将主元贡献率设置为 <strong><span style="color:#9932cc;">0.75</span></strong>：</p> 
<pre><code>clc
clear all
close all
addpath(genpath(pwd))

load('.\data\TE.mat', 'trainData')
kernel = Kernel('type', 'gaussian', 'gamma', 1/128^2);

parameter = struct('numComponents', 0.75, ...
                   'kernelFunc', kernel);
% build a KPCA object
kpca = KernelPCA(parameter);
% train KPCA model
kpca.train(trainData);

% Visualization
kplot = KernelPCAVisualization();
kplot.cumContribution(kpca)</code></pre> 
<p class="img-center"><img alt="" height="308" src="https://images2.imgbox.com/b9/34/Tt2MiaS4_o.png" width="616"></p> 
<p>从上图可以看出，当主元个数为 <strong>21 </strong>的时候，主元贡献率为<strong> 75.2656%</strong>， 超过了给定的阈值（<strong>0.75）</strong>。<br><br><strong><strong>第二种：给定的数目</strong></strong><br><br> 同样通过键值对 <strong>'numComponents' - value </strong>来设置。比如，将主元个数设置为 <strong>24</strong>：</p> 
<pre><code>clc
clear all
close all
addpath(genpath(pwd))

load('.\data\TE.mat', 'trainData')
kernel = Kernel('type', 'gaussian', 'gamma', 1/128^2);

parameter = struct('numComponents', 24, ...
                   'kernelFunc', kernel);
% build a KPCA object
kpca = KernelPCA(parameter);
% train KPCA model
kpca.train(trainData);

% Visualization
kplot = KernelPCAVisualization();
kplot.cumContribution(kpca)</code></pre> 
<p class="img-center"><img alt="" height="279" src="https://images2.imgbox.com/4e/f1/BTgBcp9X_o.png" width="558"></p> 
<p>从上图可以看出，当主元个数为 <strong>24 </strong>的时候，主元贡献率为 <strong>80.2539%</strong>。<br>  </p> 
<h4><br><strong>05. 故障检测</strong></h4> 
<p><strong>​​​​​</strong>数据来源于 TE 过程：<br>  </p> 
<pre><code>clc
clear all
close all
addpath(genpath(pwd))

load('.\data\TE.mat', 'trainData', 'testData')
kernel = Kernel('type', 'gaussian', 'gamma', 1/128^2);
parameter = struct('numComponents', 0.65, ...
                   'kernelFunc', kernel);
               
% build a KPCA object
kpca = KernelPCA(parameter);
% train KPCA model
kpca.train(trainData);
% test KPCA model
results = kpca.test(testData);

% Visualization
kplot = KernelPCAVisualization();
kplot.cumContribution(kpca)
kplot.trainResults(kpca)
kplot.testResults(kpca, results)</code></pre> 
<p>训练的结果为</p> 
<pre><code>*** KPCA model training finished ***
running time            = 0.0986 seconds
kernel function         = gaussian 
number of samples       = 500 
number of features      = 52 
number of components    = 16 
number of T2 alarm      = 16 
number of SPE alarm     = 17 
accuracy of T2          = 96.8000% 
accuracy of SPE         = 96.6000% </code></pre> 
<p class="img-center"><img alt="" height="467" src="https://images2.imgbox.com/c4/72/NjEtwtwO_o.png" width="623"></p> 
<p>测试的结果为</p> 
<pre><code>*** KPCA model test finished ***
running time            = 0.0312 seconds
number of test data     = 960 
number of T2 alarm      = 799 
number of SPE alarm     = 851 </code></pre> 
<p class="img-center"><img alt="" height="448" src="https://images2.imgbox.com/bb/73/OHZ3gBqs_o.png" width="598"></p> 
<h4><strong>06. 故障诊断</strong></h4> 
<p>故障诊断通过键值对 <strong>'diganosis' - value </strong>来进行设置。<br> 比如对某个采样点（假设为500）出现的故障进行诊断，则： 'diagnosis', [500, 500]<br> 比如对某个时间段（假设为300-500）出现的故障进行诊断，则： 'diagnosis', [300, 500]<br><br> 具体代码为</p> 
<pre><code>clc
clear all
close all
addpath(genpath(pwd))

load('.\data\TE.mat', 'trainData', 'testData')
kernel = Kernel('type', 'gaussian', 'gamma', 1/128^2);

parameter = struct('numComponents', 0.65, ...
                   'kernelFunc', kernel,...
                   'diagnosis', [300, 500]);
               
% build a KPCA object
kpca = KernelPCA(parameter);
% train KPCA model
kpca.train(trainData);
% test KPCA model
results = kpca.test(testData);

% Visualization
kplot = KernelPCAVisualization();
kplot.cumContribution(kpca)
kplot.trainResults(kpca)
kplot.testResults(kpca, results)
kplot.diagnosis(results)</code></pre> 
<p>故障诊断结果为</p> 
<pre><code>*** Fault diagnosis ***
Fault diagnosis start...
Fault diagnosis finished.
running time            = 18.2738 seconds
start point             = 300 
ending point            = 500 
fault variables (T2)    = 44   1   4 
fault variables (SPE)   = 1  44  18 </code></pre> 
<p class="img-center"><img alt="" height="447" src="https://images2.imgbox.com/88/33/O57p39z9_o.png" width="596"></p> 
<p>可以看出，在300-500时间段，给出的故障变量参考为： 44，1（T2）;  1，44（SPE）。</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/cceb17bbf619540d5205009813b8df9a/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">STM32简介（系统结构、引脚定义……）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/81fe71c1ff2dc7f6390b60a1fa4149ca/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Spring Cloud Ribbon源码解析</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程爱好者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151260"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>