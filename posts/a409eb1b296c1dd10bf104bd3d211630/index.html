<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>####好好好###图神经网络系统介绍与总结分析 - 编程爱好者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="####好好好###图神经网络系统介绍与总结分析" />
<meta property="og:description" content="图神经网络算法将深度神经网络的运算(如卷积、梯度计算)与迭代图传播结合在一起：每个顶点的特征都是由其邻居顶点的特征结合一组深度神经网络来计算。
但是, 现有的深度学习框架不能扩展和执行图传播模型，因此缺乏高效训练图神经网络的能力，并且现有框架一般采用数据/模型并行来分布式训练深度神经网络，这种并行计算方法难以直接应用于图神经网络，因此限制了训练大规模图神经网络的能力。
而现有的图处理系统虽然能够表示迭代图传播模型，并能有效支持大规模图的迭代计算，但是缺乏支持神经网络计算的关键能力，如张量抽象、自动微分等。
因此，为了支持图神经网络在大规模图上的应用，以及对更复杂图神经网络结构的探索，开发针对图神经网络的训练系统是十分有必要的。
图神经网络系统介绍与总结分析​
mp.weixin.qq.com/s/q0V5vHqQzijTKzXIk0TNOw正在上传…重新上传取消
目前具有代表性的图神经网络框架：DGL、PyTorch Geometric、NeuGraph、EnGN、Euler、PSGraph、AliGraph、Roc、AGL、PGL.
DGL是易于使用，高性能且可扩展的Python库，用于图结构的深度学习，能够与主流的深度学习框架集成，例如Tensorflow、PyTorch、MXNet。 PyTorch Geometric是基于PyTorch构建的深度学习库，用于处理非结构化数据的深度学习。 NeuGraph是一种将数据流系统和图处理系统结合起来训练图神经网络的框架, 它构建在现有的数据流引擎之上，使用Python和C&#43;&#43;作为开发语言。 EnGN是一种以边为中心，专门用于大规模图神经网络训练的加速器。 Euler与PSGraph是一个与深度学习工具集成的大规模分布式图学习框架，支持用户在数十亿点数百亿边的图上进行模型训练。 AliGraph是由阿里巴巴团队开发的采样建模训练一体化的图神经网络平台。 Roc是一种用于快速图神经网络训练的分布式多GPU框架。 AGL是用于工业用途图学习的集成系统, 利用传统基础架构(MapReduce、参数服务器)实现了容错性和一致性。 PGL (paddle graph learning)是由百度开发的基于PaddlePaddle的高效灵活的图学习框架。 1. 图神经网络系统介绍 1.1 DGL DGL是用于图结构深度学习的Python库，通过与主流的深度学习框架集成，能够实现从传统的张量运算到图运算的自由转换。DGL提供基于消息传递的编程模型来完成图上的计算，结合消息融合等优化技术使系统达到了比较好的性能。
DGL的API主要有两部分，一是消息函数：
二是累和函数：
其中， 代表边k的属性向量， 代表顶点i的属性向量，是边k的源顶点属性向量， 是边k的目的顶点属性向量， 代表边k上的消息，t代表迭代次数。 是一个消息函数，定义在边上，通过将边的特征与两端的顶点特征组合来生成“消息”。 是在每个顶点上定义的更新函数，通过使用reduce操作汇总其传入的消息来更新顶点特征。在图神经网络中，这些功能由神经网络模块进行参数化，⊕可以是求和运算，也可以是均值，最大值、最小值或LSTM网络，s.t. rk=i表示对目的顶点为i的所有消息进行聚合操作。
消息张量的大小正比于图中边的数量，因而当图增大时，消息张量消耗的内存空间也会显著上升。为了避免生成消息张量带来的额外存储开销，DGL实现了消息融合技术，将send函数和recv函数合并成了 sendandrecv 。
1.2 PyTorch Geometric PyTorch Geometric，是一个基于PyTorch构建的深度学习库，可以对非结构化数据进行建模和训练。该库利用专用CUDA内核实现了高性能训练。
PyTorch Geometric提供一个简单的消息传递API，将卷积算子推广到不规则域，具体表示为：
其中, ⊕表示可微置换不变函数，如求和、均值或最大值。整个模型可以通过gather和scatter顶点特征以及对其进行矢量化的元素计算来实现。
通过这个消息传递模型，用户只需要定义消息函数和更新函数，以及选择聚合方案⊕，就可以设计新的图神经网络模型。该库采用COO格式编码边索引，一个维度表示源顶点，另一个维度表示目标顶点，这种存储格式非常适用于消息传递模型，能够快速获取顶点对应的源顶点的信息。与通过矩阵乘法实现的方法相比，使用消息传递模型能够达到更好的性能。
1.3 NeuGraph NeuGraph提出了一种新的框架，根据图神经网络是将标准神经网络与迭代图传播结合起来的这一特点，NeuGraph在数据流中引入以顶点为中心的消息传递模型，将图模型和数据流模型结合，来支持并行图神经网络计算。NeuGraph还将图计算的优化方法如数据分区、调度，引入到了数据流框架中，来支持高效的图神经网络训练。
NeuGraph提出了一种新的处理模型SAGA-NN，它将数据流和顶点编程模式相结合来表示图神经网络的计算。SAGA-NN将前向计算分为4个阶段: Scatter、ApplyEdge、Gather和ApplyVertex。
ApplyEdge和ApplyVertex提供了两个用户定义函数，供用户在边和顶点上声明神经网络计算。ApplyEdge函数定义每个边上的计算，以edge和W作为输入，其中edge是指边数据，W包含图神经网络模型的可学习参数。ApplyVertex函数定义了顶点的计算，它以顶点张量、顶点聚合累积量和可学习参数W作为输入，并在应用神经网络模型后返回新的顶点表示。Scatter和Gather执行数据传播和收集，由系统隐式触发和执行。
SAGA-NN中的顶点程序采用以顶点为中心的编程模型来表达图神经网络的计算，对图神经网络中的通用阶段进行建模，并在图计算和数据流调度中实现优化。
NeuGraph在数据流抽象的基础上引入了特定的图分区方法，可以解决GPU内存的物理限制问题。通过2D图分区方法，NeuGraph将顶点数据分割成P个大小相等的不相交顶点块，并将邻接矩阵分为P×P个边块。通过将图数据分割成块，在逐个处理边块信息时，只需要边块所对应的源顶点块和目标顶点块即可。在训练过程中, 与顶点块或边块相关的一些中间特征数据将用于反向传播。
为了节省GPU内存，它们在前向计算期间交换到主机内存，在反向传播期间交换回。NeuGraph为降低主机和GPU内存之间的数据传输做了一系列优化：在处理边块E时，NeuGraph设计了一个过滤器，来过滤每个顶点块内的必要顶点，并将其传输到GPU中；通过一种局部感知的图划分算法，NeuGraph将连接同一顶点的边尽可能地压缩到一个块内，通过这种方法，NeuGraph可以获得更好的顶点数据访问局部；NeuGraph设计流水线调度进一步重叠数据传输和计算，以隐藏传输延迟。
1.4 EnGN EnGN是一种处理大规模图神经网络的专用加速器架构，并且EnGN提出了一种使用专用架构的以边为中心的数据流模型。EnGN将常见的图神经网络计算模式抽象为特征提取，聚合和更新3个阶段。
在特征提取阶段，神经网络来压缩图中每个顶点的属性。聚合阶段通过聚合在特征提取中生成的每个顶点的邻居属性，来产生统一的输出特征，其中聚合函数的选择包括各种算术运算，例如max，min和add。在传播迭代结束时，更新阶段会利用学习到的参数进一步压缩聚合阶段中获得的输出特征，并在输出之前将非线性激活函数或GRU/LSTM函数应用于图的每个顶点。
在以边为中心的数据路模型基础上，EnGN集成了一个神经图处理单元(NGPU)，能够在统一的体系结构中执行特征提取，聚合和更新操作。它具有一个PE数组，每个PE单元都包含一个本地寄存器，用于存储临时结果并充当PE间通信的中介。
EnGN提出了图属性感知(GPA)数据流，来分离顶点的输入属性和硬件计算结构。以这种方式，PE阵列的同一列中的每个PE负责顶点属性的单个维，而同一行中的每个PE处理单个顶点。输入顶点属性的尺寸变得独立于硬件体系结构，并且可以连续地注入到PE阵列中，而与阵列大小和属性尺寸无关。通过这种方式，处理单元可以处理具有任意尺寸属性的顶点。RER (ring-edge-reduce)阵列同一列中的每个PE连接到环形网络中的邻居，同一列中的每个PE仅与其两个最近的邻居(北, 南)通信。PE将其数据发送到北部邻居，并接收从南部邻居发送的数据以进行汇总。以此方式，PE可以基于环型数据流从边解析的控制信号来选择要聚合的相关顶点。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bchobby.github.io/posts/a409eb1b296c1dd10bf104bd3d211630/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-05-05T14:19:56+08:00" />
<meta property="article:modified_time" content="2022-05-05T14:19:56+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程爱好者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程爱好者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">####好好好###图神经网络系统介绍与总结分析</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>图神经网络算法将深度神经网络的运算(如卷积、梯度计算)与迭代图传播结合在一起：每个顶点的特征都是由其邻居顶点的特征结合一组深度神经网络来计算。</p> 
<p>但是, 现有的深度学习框架不能扩展和执行图传播模型，因此缺乏高效训练图神经网络的能力，并且现有框架一般采用数据/模型并行来分布式训练深度神经网络，这种并行计算方法难以直接应用于图神经网络，因此限制了训练大规模图神经网络的能力。</p> 
<p>而现有的图处理系统虽然能够表示迭代图传播模型，并能有效支持大规模图的迭代计算，但是缺乏支持神经网络计算的关键能力，如张量抽象、自动微分等。</p> 
<p>因此，为了支持图神经网络在大规模图上的应用，以及对更复杂图神经网络结构的探索，开发针对图神经网络的训练系统是十分有必要的。</p> 
<p><a href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/q0V5vHqQzijTKzXIk0TNOw" rel="nofollow" title="图神经网络系统介绍与总结分析​">图神经网络系统介绍与总结分析​</a></p> 
<p><a href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/q0V5vHqQzijTKzXIk0TNOw" rel="nofollow" title="mp.weixin.qq.com/s/q0V5vHqQzijTKzXIk0TNOw正在上传…重新上传取消">mp.weixin.qq.com/s/q0V5vHqQzijTKzXIk0TNOw正在上传…重新上传取消</a></p> 
<p>目前具有代表性的图神经网络框架：DGL、PyTorch Geometric、NeuGraph、EnGN、Euler、PSGraph、AliGraph、Roc、AGL、PGL.</p> 
<blockquote>
  DGL是易于使用，高性能且可扩展的Python库，用于图结构的深度学习，能够与主流的深度学习框架集成，例如Tensorflow、PyTorch、MXNet。 
 <br> PyTorch Geometric是基于PyTorch构建的深度学习库，用于处理非结构化数据的深度学习。 
 <br> NeuGraph是一种将数据流系统和图处理系统结合起来训练图神经网络的框架, 它构建在现有的数据流引擎之上，使用Python和C++作为开发语言。 
 <br> EnGN是一种以边为中心，专门用于大规模图神经网络训练的加速器。 
 <br> Euler与PSGraph是一个与深度学习工具集成的大规模分布式图学习框架，支持用户在数十亿点数百亿边的图上进行模型训练。 
 <br> AliGraph是由阿里巴巴团队开发的采样建模训练一体化的图神经网络平台。 
 <br> Roc是一种用于快速图神经网络训练的分布式多GPU框架。 
 <br> AGL是用于工业用途图学习的集成系统, 利用传统基础架构(MapReduce、参数服务器)实现了容错性和一致性。 
 <br> PGL (paddle graph learning)是由百度开发的基于PaddlePaddle的高效灵活的图学习框架。 
</blockquote> 
<h3 id="h_457134189_0"><strong>1. 图神经网络系统介绍</strong></h3> 
<h4 id="h_457134189_1"><strong>1.1 DGL</strong></h4> 
<p>DGL是用于图结构深度学习的Python库，通过与主流的深度学习框架集成，能够实现从传统的张量运算到图运算的自由转换。DGL提供基于消息传递的编程模型来完成图上的计算，结合消息融合等优化技术使系统达到了比较好的性能。</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/1b/42/Fod1BdHq_o.png"></p> 
<p>DGL的API主要有两部分，一是消息函数：</p> 
<p>二是累和函数：</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/9a/01/0OqLmO6I_o.png"></p> 
<p>其中， 代表边k的属性向量， 代表顶点i的属性向量，是边k的源顶点属性向量， 是边k的目的顶点属性向量， 代表边k上的消息，t代表迭代次数。 是一个消息函数，定义在边上，通过将边的特征与两端的顶点特征组合来生成“消息”。 是在每个顶点上定义的更新函数，通过使用reduce操作汇总其传入的消息来更新顶点特征。在图神经网络中，这些功能由神经网络模块进行参数化，⊕可以是求和运算，也可以是均值，最大值、最小值或LSTM网络，s.t. rk=i表示对目的顶点为i的所有消息进行聚合操作。</p> 
<p>消息张量的大小正比于图中边的数量，因而当图增大时，消息张量消耗的内存空间也会显著上升。为了避免生成消息张量带来的额外存储开销，DGL实现了消息融合技术，将send函数和recv函数合并成了 send<em>and</em>recv 。</p> 
<h4 id="h_457134189_2"><strong>1.2 PyTorch Geometric</strong></h4> 
<p>PyTorch Geometric，是一个基于PyTorch构建的深度学习库，可以对非结构化数据进行建模和训练。该库利用专用CUDA内核实现了高性能训练。</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/33/f9/q9kl52s3_o.png"></p> 
<p>PyTorch Geometric提供一个简单的消息传递API，将卷积算子推广到不规则域，具体表示为：</p> 
<p>其中, ⊕表示可微置换不变函数，如求和、均值或最大值。整个模型可以通过gather和scatter顶点特征以及对其进行矢量化的元素计算来实现。</p> 
<p>通过这个消息传递模型，用户只需要定义消息函数和更新函数，以及选择聚合方案⊕，就可以设计新的图神经网络模型。该库采用COO格式编码边索引，一个维度表示源顶点，另一个维度表示目标顶点，这种存储格式非常适用于消息传递模型，能够快速获取顶点对应的源顶点的信息。与通过矩阵乘法实现的方法相比，使用消息传递模型能够达到更好的性能。</p> 
<h4 id="h_457134189_3"><strong>1.3 NeuGraph</strong></h4> 
<p>NeuGraph提出了一种新的框架，根据图神经网络是将标准神经网络与迭代图传播结合起来的这一特点，NeuGraph在数据流中引入以顶点为中心的消息传递模型，将图模型和数据流模型结合，来支持并行图神经网络计算。NeuGraph还将图计算的优化方法如数据分区、调度，引入到了数据流框架中，来支持高效的图神经网络训练。</p> 
<p>NeuGraph提出了一种新的处理模型SAGA-NN，它将数据流和顶点编程模式相结合来表示图神经网络的计算。SAGA-NN将前向计算分为4个阶段: Scatter、ApplyEdge、Gather和ApplyVertex。</p> 
<p>ApplyEdge和ApplyVertex提供了两个用户定义函数，供用户在边和顶点上声明神经网络计算。ApplyEdge函数定义每个边上的计算，以<em>edge</em>和<em>W</em>作为输入，其中<em>edge</em>是指边数据，<em>W</em>包含图神经网络模型的可学习参数。ApplyVertex函数定义了顶点的计算，它以顶点张量、顶点聚合累积量和可学习参数<em>W</em>作为输入，并在应用神经网络模型后返回新的顶点表示。Scatter和Gather执行数据传播和收集，由系统隐式触发和执行。</p> 
<p>SAGA-NN中的顶点程序采用以顶点为中心的编程模型来表达图神经网络的计算，对图神经网络中的通用阶段进行建模，并在图计算和数据流调度中实现优化。</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/91/26/p8GHdwoL_o.png"></p> 
<p>NeuGraph在数据流抽象的基础上引入了特定的图分区方法，可以解决GPU内存的物理限制问题。通过2D图分区方法，NeuGraph将顶点数据分割成<em>P</em>个大小相等的不相交顶点块，并将邻接矩阵分为<em>P</em>×<em>P</em>个边块。通过将图数据分割成块，在逐个处理边块信息时，只需要边块所对应的源顶点块和目标顶点块即可。在训练过程中, 与顶点块或边块相关的一些中间特征数据将用于反向传播。</p> 
<p>为了节省GPU内存，它们在前向计算期间交换到主机内存，在反向传播期间交换回。NeuGraph为降低主机和GPU内存之间的数据传输做了一系列优化：在处理边块E时，NeuGraph设计了一个过滤器，来过滤每个顶点块内的必要顶点，并将其传输到GPU中；通过一种局部感知的图划分算法，NeuGraph将连接同一顶点的边尽可能地压缩到一个块内，通过这种方法，NeuGraph可以获得更好的顶点数据访问局部；NeuGraph设计流水线调度进一步重叠数据传输和计算，以隐藏传输延迟。</p> 
<h4 id="h_457134189_4"><strong>1.4 EnGN</strong></h4> 
<p>EnGN是一种处理大规模图神经网络的专用加速器架构，并且EnGN提出了一种使用专用架构的以边为中心的数据流模型。EnGN将常见的图神经网络计算模式抽象为<strong>特征提取，聚合和更新</strong>3个阶段。</p> 
<p>在特征提取阶段，神经网络来压缩图中每个顶点的属性。聚合阶段通过聚合在特征提取中生成的每个顶点的邻居属性，来产生统一的输出特征，其中聚合函数的选择包括各种算术运算，例如max，min和add。在传播迭代结束时，更新阶段会利用学习到的参数进一步压缩聚合阶段中获得的输出特征，并在输出之前将非线性激活函数或GRU/LSTM函数应用于图的每个顶点。</p> 
<p>在以边为中心的数据路模型基础上，EnGN集成了一个神经图处理单元(NGPU)，能够在统一的体系结构中执行特征提取，聚合和更新操作。它具有一个PE数组，每个PE单元都包含一个本地寄存器，用于存储临时结果并充当PE间通信的中介。</p> 
<p>EnGN提出了图属性感知(GPA)数据流，来分离顶点的输入属性和硬件计算结构。以这种方式，PE阵列的同一列中的每个PE负责顶点属性的单个维，而同一行中的每个PE处理单个顶点。输入顶点属性的尺寸变得独立于硬件体系结构，并且可以连续地注入到PE阵列中，而与阵列大小和属性尺寸无关。通过这种方式，处理单元可以处理具有任意尺寸属性的顶点。RER (ring-edge-reduce)阵列同一列中的每个PE连接到环形网络中的邻居，同一列中的每个PE仅与其两个最近的邻居(北, 南)通信。PE将其数据发送到北部邻居，并接收从南部邻居发送的数据以进行汇总。以此方式，PE可以基于环型数据流从边解析的控制信号来选择要聚合的相关顶点。</p> 
<h4 id="h_457134189_5"><strong>1.5 Euler</strong></h4> 
<p>Euler是集成了深度学习系统TensorFlow的基于CPU的分布式图神经网络框架，支持图分割和高效稳定的分布式训练，可以轻松支持数十亿点、数百亿边的计算规模。Euler系统抽象为图引擎、图操作算子、算法实现3个部分，可以快速地扩展一个图学习算法。</p> 
<p>该系统整体可以分为3层：最底层的分布式图引擎，中间层图语义的算子，高层的图表示学习算法。</p> 
<p>在底层图引擎部分，Euler采用了分布式存储的架构，整个图在引擎内部用哈希方法切分为多个子图，每个计算节点被分配一个或几个子图。在进行迭代图广播时，顶层操作被分解为多个对子图的操作，并由各个计算节点并行执行，充分利用了各个计算节点的计算能力。在中间层Euler提供了多种图操作的算子，如全局带权采样点和边，基于给定顶点的邻居操作等等。利用灵活的图操作算子，Euler不仅支持传统的以图为中心的学习模式，且可以把基于图的学习方法结合到传统的学习任务中，实现端到端训练。Euler在算法层内置了多种常见算法以及几种创新算法，如Scalable-GCN，一种加速GCN训练的方法。</p> 
<h4 id="h_457134189_6"><strong>1.6 AliGraph</strong></h4> 
<p>AliGraph是由阿里巴巴开发的图神经网络系统，AliGraph总体上由5层组成，如图2，其中存储层、采样层和操作层构成了系统的基础，算法层和应用层构建在前3层的基础之上。其中存储层应用了多种技术来存储大规模原始图数据，以满足多种图操作和算法对快速数据访问的要求，即结构化存储和属性特定存储，图分区和某些重要顶点邻居的缓存。</p> 
<p>在采样层Aligraph对采样操作进行了有针对性的优化，将采样方法分为Traverse， Neighborhood和Negative这3类，并提出了一种无锁方法来在分布式环境中执行采样操作。运算符层提供了Aggregate和Combine等常见运算符的优化实现。</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/d4/ca/e6dzxMn9_o.png"></p> 
<p>▲ AliGraph系统架构</p> 
<p>AliGraph建立在分布式环境中，因此整个图被划分并分别存储在不同的节点中。图分区的目标是最大程度地减少顶点在不同计算节点中的交叉边的数量。系统实现了4种内置的图形分区算法：METIS、顶点切割和边缘切割分区、二维分区、流式分区策略。</p> 
<p>除此之外，为了进一步降低通信开销，AliGraph提出了一种在本地缓存重要顶点邻居的优化方法，但顶点邻居过多会导致存储成本增加。通过对顶点重要程度的度量，AliGraph可以在通信成本和存储成本之间做到很好的平衡。并且AliGraph证明了只需要缓存少量重要顶点即可实现通信成本的显著降低。</p> 
<h4 id="h_457134189_7"><strong>1.7 Roc</strong></h4> 
<p>Roc是用于快速图神经网络训练的分布式多GPU框架。其性能提升得益于Roc的图分区和内存管理优化实现。系统利用多计算节点多GPU的计算资源在完整的现实世界图上训练大型图神经网络模型，来达到更好的性能和可扩展性。</p> 
<p>图神经网络算法将计算密集型深度神经网络操作与数据密集型图传播混合在一起，因此在分布式环境中实现负载均衡的图分区是非常困难的。Roc使用在线线性回归模型来对图分区进行建模。在图神经网络架构的训练阶段，Roc建立了一种成本模型，用于预测在输入图上执行图神经网络操作的执行时间，成本模型既包含与图相关的部分，如图中顶点和边的数量，也包含与硬件相关的部分，如执行该操作的GPU内存访问的次数。</p> 
<p>在图神经网络的每次训练迭代期间，Roc使用成本模型来预测计算图分区，并使用图分区的结果来并行化训练。在每次训练迭代结束时，子图的实际运行时间将发送回Roc图分区模块，该程序通过最小化实际运行时间与预测运行时间之间的差异来更新成本模型。Roc还将GPU内存管理形式化为成本最小化问题：给定输入图，图神经网络结构和GPU设备，找到张量子集以缓存在GPU内存中，最大程度地减少CPU和GPU之间的数据传输。为了快速求解成本模型，Roc引入了动态规划算法以快速找到全局最优解。</p> 
<h4 id="h_457134189_8"><strong>1.8 PSGraph</strong></h4> 
<p>PSGraph使用Spark和PyTorch作为资源管理和计算平台，使用参数服务器架构作为分布式训练架构。PSGraph通过参数服务器为Spark提供支持，以有效地训练数十亿规模的图数据，并将PyTorch集成到Spark中来实现神经网络的训练。PSGraph由参数服务器、计算引擎和主节点构成。</p> 
<p>参数服务器用于存储高维数据和模型，它支持不同的数据结构，除此之外，PSGraph还为用户提供实现新数据结构的接口，支持按行索引和列索引的数据分区方式，提供不同的同步协议以控制工作进程之间的同步，以及实现多种常用运算符来操作参数服务器上的数据，每个参数服务器定期将本地数据分区存储到HDFS。计算引擎由Spark和PyTorch实现，用于存储数据、计算并创建参数服务器代理来管理Spark和参数服务器之间的数据通信。主节点负责资源分配、任务监视和故障恢复。</p> 
<h4 id="h_457134189_9"><strong>1.9 AGL</strong></h4> 
<p>AGL是用于工业用途图学习的集成系统。在AGL系统中图神经网络的计算构建于消息传递模型基础之上，其迭代图传播过程使用MapReduce来实现。在训练图神经网络阶段，AGL通过构造k-hop邻域，来提供信息完整的子图，通过从边合并邻居的消息来计算每个顶点的嵌入。AGL将原始图分解成子图，来使每个顶点的计算图可以独立于其他顶点。</p> 
<p>AGL的核心有3个模块：GraphFlat，GraphTrainer和GraphInfer。</p> 
<p>GraphFlat是基于消息传递的高效分布式图生成器，用于生成顶点的<em>K</em>阶邻域信息，<em>K</em>阶邻域信息包含每个目标顶点完整<em>K</em>阶子图和所有顶点的属性信息。由于<em>K</em>阶邻域包含训练每个目标顶点的所有信息，因此AGL可以选择将其中一部分而不是整个图加载到内存中，从而实现完全的并行计算。GraphTrainer利用许多技术来减少I/O的开销，并在训练图神经网络模型期间优化浮点计算，在实际工业场景中能获得较高的近线性加速。GraphInfer，这是一个分布式推断模块，可将<em>K</em>层图神经网络模型分成<em>K</em>个切片，并基于MapReduce的计算模式来完成高效的预测推理。</p> 
<h4 id="h_457134189_10"><strong>1.10 PGL</strong></h4> 
<p>PGL是由百度开发的基于PaddlePaddle的高效灵活的图学习框架。PGL实现了高度并行的图神经网络消息传递机制，并依托于自研的分布式图引擎以及大规模参数服务器PaddleFleet，可以支持十亿节点百亿边的超大规模图训练。</p> 
<p>PGL总体上由3层组成，最底层分布式图引擎、分布式图训练模块以及分布式参数服务器PaddleFleet。</p> 
<p>底层分布式图引擎以图切片的形式存储超大规模图，提供图信息访问、子图采样等操作算子，由上层模型调用。PGL预置了丰富的图学习模型，这些模型涵盖了同构与异构、图表示学习与图神经网络等样例。分布式参数服务器PaddleFleet提供了一种高效的参数更新策略：GeoSSD，在全异步的条件下进行参数更新，降低了节点间通信对训练速度的影响。PGL采用类似于DGL的消息传递范式构建图神经网络的接口，能够帮助用户快速构建自定义图神经网络，用户只需要编写send和recv函数即可。</p> 
<p>目前，PGL提供两种聚合方法。一种是Scatter-Gather，用于常规聚合计算。另一种是基于LodTensor特性实现的并行通用的消息聚合方法。PGL将消息组织为PaddlePaddle中的LodTensor，将消息作为可变长度序列进行拼接，并引入一个索引数据结构来记录张量序列，利用LodTensor的特性可以快速的执行并行聚合。此外，PGL还支持异构图学习，可以对包含多个节点类型和多个边类型的异构图进行建模，并且可以描述不同类型之间的复杂连接。</p> 
<h3 id="h_457134189_11"><strong>2. 图神经网络系统总结和分析</strong></h3> 
<p>本节从系统架构、处理模型、图分区策略、通信优化策略、以及社区活跃度与系统易用性方面，对现有图神经网络系统进行分析和对比，并从多个维度对系统的特点进行总结，以表格的形式清晰的展示系统的共性与不同，来为研究人员提供有效参考。</p> 
<h4 id="h_457134189_12"><strong>2.1 系统架构</strong></h4> 
<p>DGL和PyTorch Geometric都是结合现有的深度学习框架来实现的，并且针对图神经网络的特点做了多种优化，达到了很好的性能。结合现有深度学习框架来实现的系统，更加方便用户使用，能够帮助其更快地实现图神经网络模型。但结合现有深度学习框架来实现的系统，在针对图操作的优化上有很多局限性。</p> 
<p>NeuGraph采用了一种新的架构，将图模型和数据流模型结合起来，以支持高效的图神经网络训练，这种架构既弥补了现有数据流引擎不能有效地支持图计算的缺点，又弥补了图引擎不能支持数据流编程模型的缺点。</p> 
<p>EnGN在统一的处理模型基础上，开发了一个定制的EnGN加速器，它集成了一个神经图处理单元(NGPU)，可以在统一的体系结构中执行特征提取，聚合和更新操作。EnGN的专用加速器突破了硬件结构的限制，相比于其他系统配备的多个CPU或GPU，大大降低了成本和能源开销。</p> 
<p>AliGraph、Euler和PGL的架构类似，都采用分层架构，构建于现有数据流框架之上，并且都构建在CPU平台上。Roc将图神经网络的计算分布在多个计算节点上，每个计算节点可以包含多个GPU，每个计算节点在子图上执行图神经网络的训练，并与CPU通信来获得输入张量并保存中间结果。</p> 
<p>Roc采用分布式多GPU的架构不仅解决了单节点系统对于大规模图的限制，并且比基于CPU的系统更高效。AGL、PSGraph都是利用现有大数据处理系统和参数服务器的并行体系结构来组建的基于CPU的分布式图神经网络训练框架，这些系统具有良好的容错性和可伸缩性。</p> 
<h4 id="h_457134189_13"><strong>2.2 处理模型</strong></h4> 
<p>DGL和PyTorch Geometric通过使用面向图的消息传递接口包装深度学习系统，来支持针对图神经网络的编程。</p> 
<p>这种消息传递模型很好地表示了图上的数据流动，整个模型分为两步。</p> 
<p>第1步：“消息”生成操作，这个操作定义在每个边上，通过将边的特征与两端顶点特征组合为每一条边生成一条“消息”。</p> 
<p>第2步：更新操作，定义在每个顶点上，通过汇总顶点入边传入的消息来更新顶点特征。通过系统提供的消息传递接口，用户可以快速实现图神经网络的原型制作。</p> 
<p>PGL也采用消息传递范式构建图神经网络的接口，并提供多种聚合方法，提高了并行处理效率。</p> 
<p>NeuGraph提出了一种新的处理模型SAGA-NN，提高了在顶点和边上执行批量操作的灵活性，提供了在图计算和数据流调度中实现优化的机会，提高了系统性能。</p> 
<p>EnGN提供一种以边为中心的处理模型，将图神经网络的计算抽象为特征提取，聚合和更新3个阶段。EnGN与其他3个系统不同，在处理模型基础上定制了针对图神经网络的加速器，不依赖于现有的深度学习系统，并拥有独特的数据流处理方法。EnGN优化了顶点数据和边数据移动的内存访问模式。对于大图中的源顶点数据访问，采用图切片技术，并确保对源节点的访问仅引起对连续内存地址的访问。对于聚合和更新阶段中的随机目标顶点访问，EnGN利用哈希边数据布局和多级缓存方法来避免写冲突并提高片上缓冲器中的数据命中率。</p> 
<h4 id="h_457134189_14"><strong>2.3 图分区策略</strong></h4> 
<p>平衡的图分区是实现分布式图神经网络系统的关键之一。</p> 
<p>Euler采用简单的哈希方法将图的顶点进行分片，这种分片方式使各个节点拥有目标顶点的数量基本一致，但是在每个顶点的子图中拥有的邻居数量是不同的，所以每个节点的计算负载并不均衡。</p> 
<p>AliGraph则提供了多种内置的图分区算法供用户选择，比如适合处理稀疏图的METIS方法，适合稠密图的点割和边割方法，这种方法虽然为用户提供了多种选择，但需要用户自己去判断使用哪种分区方式，给用户造成很大不便。Roc采用一种在线线性回归模型来优化图分区。这种基于线性回归的图分区方法在图神经网络系统中能够达到比传统分区更好的性能。</p> 
<h4 id="h_457134189_15"><strong>2.4 通信优化策略</strong></h4> 
<p>针对通信开销影响分布式系统性能的问题，Euler采用的是缓存对应顶点<em>k</em>阶内的邻居顶点信息，这种方式虽然直接避免了计算节点之间的通信，但是造成了很严重的内存浪费，并且在幂律分布的图中还会使各个计算节点之间负载不均衡。AGL采用的策略和Euler相同，但是AGL提出了重新索引的策略来均衡负载。</p> 
<p>AliGraph提出了一种缓存重要顶点的邻居的方法来降低通信开销，同时提出了一种对顶点重要性的度量标准，既能有效减低通信开销，又防止产生巨大的存储成本，避免资源浪费。</p> 
<p>ROC引入了代价模型，可以最大程度地减少CPU和GPU之间的数据传输。这种动态的方法突破了手动优化的局限，将影响通信的多种因素综合考虑，从而更好的降低通信成本，提高系统性能。</p> 
<p>PGL的分布式参数服务器提供了一种高效的参数更新策略：GeoSSD，在全异步的条件下进行参数更新，并重叠模型训练与节点通信，在保证模型效果的前提下提升了训练效率。</p> 
<h4 id="h_457134189_16"><strong>2.5 社区活跃度与系统易用性</strong></h4> 
<p>PyTorch Geometric、DGL、AliGraph、Euler、PSGraph、PGL为开源系统，这里的社区活跃度以GitHub上讨论区的数量为标准，这其中最活跃的社区为PyTorch Geometric。</p> 
<p>在系统易用性方面, 从配置文件的完整度、对其他系统的依赖度、用户使用的方便度多个角度综合考量，这其中DGL和PyTorch Geometric的易用性排在前列，而Euler与PSGraph虽然给出了配置文件，但在配置系统时，需要配置其他多个依赖包，并且数据处理过程繁琐，不易用户使用。</p> 
<p>本文为系统的社区活跃度和易用性给出星级评价, 星级越高, 系统在这两方面表现越好, 其中空白符号表示系统未开源。本文对目前的图神经网络系统从多个维度进行了综合分析，对这些系统的共同特性进行提取，并总结归纳，见表1</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/87/d5/ok0LYvJz_o.png"></p> 
<p>▲ 系统总结</p> 
<blockquote> 
 <em>赵港, 王千阁, 姚烽, 张岩峰, 于戈. 大规模图神经网络系统综述. 软件学报, 2022, 33(1): 150-170. <a href="https://link.zhihu.com/?target=http%3A//www.jos.org.cn/1000-9825/6311.htm" rel="nofollow" title="http://www.jos.org.cn/1000-9825/6311.htm">http://www.jos.org.cn/1000-9825/6311.htm</a></em> 
</blockquote>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b0bbce7c18b7dd686037a0f8eaec716f/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">idea 社区版设置 vm options 参数</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/d3ce302be7fffa8a39f490a60c09fc00/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">PDF 缩略图无法正常显示 解决办法</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程爱好者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151260"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>