<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>HuggingFace Datasets来写一个数据加载脚本 - 编程爱好者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="HuggingFace Datasets来写一个数据加载脚本" />
<meta property="og:description" content="HuggingFace Datasets上传本地文件作为训练数据 这两天用自己的数据来做训练，看到datasets库中的教程，进行翻译，记下如何使用本地/私有数据集。
文章目录 HuggingFace Datasets上传本地文件作为训练数据前言编写数据集加载脚本（Writing a dataset loading script）添加数据集元数据（Adding dataset metadata）下载数据文件并组织拆分(Downloading data files and organizing splits)在每个分割中生成样本（Generating the samples in each split）指定几个数据集配置(Specifying several dataset configurations)指定默认数据集配置(Specifying a default dataset configuration)测试数据集加载脚本(Testing the dataset loading script)数据集参考脚本(Dataset scripts of reference) 示例结果演示 前言 在前面Bert的微调中，加载数据的方式是
from datasets import load_dataset, load_metric datasets = load_dataset(&#34;squad_v2&#34; if squad_v2 else &#34;squad&#34;) 获得打印的结构是：
DatasetDict({ train: Dataset({ features: [&#39;id&#39;, &#39;title&#39;, &#39;context&#39;, &#39;question&#39;, &#39;answers&#39;], num_rows: 87599 }) validation: Dataset({ features: [&#39;id&#39;, &#39;title&#39;, &#39;context&#39;, &#39;question&#39;, &#39;answers&#39;], num_rows: 10570 }) }) 打印出来一个示例就是：" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bchobby.github.io/posts/b617edc2838f942b7f64dacdc5e3a3e5/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-03-02T21:24:20+08:00" />
<meta property="article:modified_time" content="2021-03-02T21:24:20+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程爱好者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程爱好者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">HuggingFace Datasets来写一个数据加载脚本</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-github-gist">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="HuggingFace_Datasets_0"></a>HuggingFace Datasets上传本地文件作为训练数据</h2> 
<p><font color="#999AAA">这两天用自己的数据来做训练，看到datasets库中的教程，进行翻译，记下如何使用本地/私有数据集。</font></p> 
<p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#HuggingFace_Datasets_0" rel="nofollow">HuggingFace Datasets上传本地文件作为训练数据</a></li><li><a href="#_9" rel="nofollow">前言</a></li><li><a href="#Writing_a_dataset_loading_script_50" rel="nofollow">编写数据集加载脚本（Writing a dataset loading script）</a></li><li><ul><li><a href="#Adding_dataset_metadata_67" rel="nofollow">添加数据集元数据（Adding dataset metadata）</a></li><li><a href="#Downloading_data_files_and_organizing_splits_170" rel="nofollow">下载数据文件并组织拆分(Downloading data files and organizing splits)</a></li><li><a href="#Generating_the_samples_in_each_split_216" rel="nofollow">在每个分割中生成样本（Generating the samples in each split）</a></li><li><a href="#Specifying_several_dataset_configurations_257" rel="nofollow">指定几个数据集配置(Specifying several dataset configurations)</a></li><li><a href="#Specifying_a_default_dataset_configuration_329" rel="nofollow">指定默认数据集配置(Specifying a default dataset configuration)</a></li><li><a href="#Testing_the_dataset_loading_script_336" rel="nofollow">测试数据集加载脚本(Testing the dataset loading script)</a></li><li><a href="#Dataset_scripts_of_reference_350" rel="nofollow">数据集参考脚本(Dataset scripts of reference)</a></li></ul> 
  </li><li><a href="#_356" rel="nofollow">示例</a></li><li><ul><li><a href="#_514" rel="nofollow">结果演示</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<hr color="#000000" size='1"'> 
<h2><a id="_9"></a>前言</h2> 
<p>在前面Bert的微调中，加载数据的方式是</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset<span class="token punctuation">,</span> load_metric
datasets <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"squad_v2"</span> <span class="token keyword">if</span> squad_v2 <span class="token keyword">else</span> <span class="token string">"squad"</span><span class="token punctuation">)</span>
</code></pre> 
<p>获得打印的结构是：</p> 
<pre><code>DatasetDict({
    train: Dataset({
        features: ['id', 'title', 'context', 'question', 'answers'],
        num_rows: 87599
    })
    validation: Dataset({
        features: ['id', 'title', 'context', 'question', 'answers'],
        num_rows: 10570
    })
})

</code></pre> 
<p>打印出来一个示例就是：</p> 
<pre><code>datasets["train"][0]
--------------------------------------------------------------------
输出: {'answers': {'answer_start': [515], 'text': ['Saint Bernadette Soubirous']},

 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend "Venite Ad Me Omnes". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',
 
 'id': '5733be284776f41900661182',
 
 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',
 
 'title': 'University_of_Notre_Dame'}

</code></pre> 
<p><strong>那么使用load_dataset方法加载本地数据呢？ 什么样的数据都可以加载吗？</strong> 结论当然是可以的，仅仅需要自己写个脚本就可以了，下面先翻译HuggingFace Datasets关于 <strong>Writing a dataset loading script</strong>的官方教程，然后我会写一个自己的示例。(翻译部分是机翻+纠错，我也是自己学习，不免有些错误，不懂的地方可以参考<a href="https://huggingface.co/docs/datasets/add_dataset.html" rel="nofollow">原文档</a>)</p> 
<h2><a id="Writing_a_dataset_loading_script_50"></a>编写数据集加载脚本（Writing a dataset loading script）</h2> 
<p>希望使用本地/私有数据文件，而 CSV/JSON/txt的通用数据标识符(请参阅本地文件)对于您的用例来说是不够的。</p> 
<p>在编写新的数据集加载脚本时，可以从<a href="https://github.com/huggingface/datasets/blob/master/templates/new_dataset_script.py">数据集加载脚本的模板</a>开始。你可以在 github 仓库的 templates 文件夹中找到这个模板。</p> 
<p>下面是生成数据集所涉及的类和方法的一个快速概述:</p> 
<p><img src="https://images2.imgbox.com/ee/c3/cj20a9go_o.jpg" alt="在这里插入图片描述"><br> 左边是在库内部创建<code>datasets.Dataset</code>实例的一般结构。在右边，是每个特定数据集的加载脚本。要创建一个新的数据集的加载脚本，一般需要在<code>datasets.DatasetBuilder</code>类指定三个方法:</p> 
<ul><li><code>datasets.DatasetBuilder._info()</code> 负责将数据集的元数据指定为<code>datasets.DatasetInfo</code>数据类型，尤其是<code>datasets.Features</code>定义了数据集每一列的名字和类型，</li><li><code>datasets.DatasetBuilder._split_generator()</code>负责加载或检索数据文件，通过 splits 和在需要时生成过程定义特定的参数组织文件</li><li><code>datasets.DatasetBuilder._generate_examples()</code>负责加载 split 过的文件和生成在<code>features</code>格式的示例</li></ul> 
<p>可选的，数据集加载脚本可以定义一个数据集要使用的配置，这个配置文件是<code>datasets.DatasetBuilder</code>从<code>datasets.BuilderConfig</code>继承的。这样的类允许我们自定义构建处理，例如，运行选择数据特定的子集或者加载数据集时使用特定的方法处理数据。</p> 
<ul><li>关于命名的注意: 数据集类(dataset class)应该是驼峰命名法(camel case, 首字母大小)， 而数据集的名称使用蛇形命名法(snake case，小写加下划线 ‘_’)。例如：数据集book_corpus是class BookCorpus(datasets.GeneratorBasedBuilder)</li></ul> 
<h3><a id="Adding_dataset_metadata_67"></a>添加数据集元数据（Adding dataset metadata）</h3> 
<p><code>datasets.DatasetBuilder._info()</code> 方法负责将数据集元数据指定为<code>datasets.DatasetInfo</code>数据类型。尤其是<code>datasets.Features</code>定义了数据集每一列的名称。<code>datasets.DatasetInfo</code>是一组预定义的数据，无法扩展。完整的属性列表可以在包引用(package reference)中找到。</p> 
<p>需要指定的最重要属性:</p> 
<ul><li><code>datasets.DatasetInfo.features</code>: <code>datasets.Features</code>实例，用于定义数据集的每一列的名称和类型，以及示例的一般结构(general organization)，</li><li><code>datasets.DatasetInfo.description</code>: 描述数据集的str，</li><li><code>datasets.DatasetInfo.citation</code>: 包含数据集引用的 BibTex 格式的 str，引用该数据集的方式包含在通信中，</li><li><code>datasets.DatasetInfo.homepage</code>: 一个包含数据集原始主页 URL 的 str。</li></ul> 
<p>例如，这里的<code>datasets.DatasetBuilder._info()</code>是SQuAD数据集的示例，来着 <a href="https://github.com/huggingface/datasets/blob/master/datasets/squad/squad.py">squad数据集加载脚本</a></p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">_info</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> datasets<span class="token punctuation">.</span>DatasetInfo<span class="token punctuation">(</span>
        description<span class="token operator">=</span>_DESCRIPTION<span class="token punctuation">,</span>
        features<span class="token operator">=</span>datasets<span class="token punctuation">.</span>Features<span class="token punctuation">(</span>
            <span class="token punctuation">{<!-- --></span>
                <span class="token string">"id"</span><span class="token punctuation">:</span> datasets<span class="token punctuation">.</span>Value<span class="token punctuation">(</span><span class="token string">"string"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token string">"title"</span><span class="token punctuation">:</span> datasets<span class="token punctuation">.</span>Value<span class="token punctuation">(</span><span class="token string">"string"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token string">"context"</span><span class="token punctuation">:</span> datasets<span class="token punctuation">.</span>Value<span class="token punctuation">(</span><span class="token string">"string"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token string">"question"</span><span class="token punctuation">:</span> datasets<span class="token punctuation">.</span>Value<span class="token punctuation">(</span><span class="token string">"string"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token string">"answers"</span><span class="token punctuation">:</span> datasets<span class="token punctuation">.</span>features<span class="token punctuation">.</span>Sequence<span class="token punctuation">(</span>
                    <span class="token punctuation">{<!-- --></span><span class="token string">"text"</span><span class="token punctuation">:</span> datasets<span class="token punctuation">.</span>Value<span class="token punctuation">(</span><span class="token string">"string"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"answer_start"</span><span class="token punctuation">:</span> datasets<span class="token punctuation">.</span>Value<span class="token punctuation">(</span><span class="token string">"int32"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">}</span>
                <span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token comment"># No default supervised_keys (as we have to pass both question</span>
        <span class="token comment"># and context as input).</span>
        supervised_keys<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
        homepage<span class="token operator">=</span><span class="token string">"https://rajpurkar.github.io/SQuAD-explorer/"</span><span class="token punctuation">,</span>
        citation<span class="token operator">=</span>_CITATION<span class="token punctuation">,</span>
    <span class="token punctuation">)</span>
</code></pre> 
<p><code>datasets.Features</code>定义了每个示例的结构，并可以定义具有各种类型字段的任意嵌套对象。关于可用<code>feature</code>的更多细节可以在数据集特性<a href="https://huggingface.co/docs/datasets/master/features.html" rel="nofollow">指南</a>和数据集包参考中找到。在 GitHub 存储库提供的<a href="https://github.com/huggingface/datasets/tree/master/datasets">各种数据集脚本</a>中也可以找到许多特性的例子，甚至可以在<a href="https://huggingface.co/datasets/viewer/" rel="nofollow">数据集查看器(datasets viewer)</a>上直接检查。</p> 
<p>以下是SQuAD数据集的特性，例如，它取自SQuAD数据集加载脚本:</p> 
<pre><code class="prism language-bash">datasets.Features<span class="token punctuation">(</span>
    <span class="token punctuation">{<!-- --></span>
        <span class="token string">"id"</span><span class="token keyword">:</span> datasets.Value<span class="token punctuation">(</span><span class="token string">"string"</span><span class="token punctuation">)</span>,
        <span class="token string">"title"</span><span class="token keyword">:</span> datasets.Value<span class="token punctuation">(</span><span class="token string">"string"</span><span class="token punctuation">)</span>,
        <span class="token string">"context"</span><span class="token keyword">:</span> datasets.Value<span class="token punctuation">(</span><span class="token string">"string"</span><span class="token punctuation">)</span>,
        <span class="token string">"question"</span><span class="token keyword">:</span> datasets.Value<span class="token punctuation">(</span><span class="token string">"string"</span><span class="token punctuation">)</span>,
        <span class="token string">"answers"</span><span class="token keyword">:</span> datasets.Sequence<span class="token punctuation">(</span>
            <span class="token punctuation">{<!-- --></span><span class="token string">"text"</span><span class="token keyword">:</span> datasets.Value<span class="token punctuation">(</span><span class="token string">"string"</span><span class="token punctuation">)</span>,
            <span class="token string">"answer_start"</span><span class="token keyword">:</span> datasets.Value<span class="token punctuation">(</span><span class="token string">"int32"</span><span class="token punctuation">)</span>,
            <span class="token punctuation">}</span>
        <span class="token punctuation">)</span>,
    <span class="token punctuation">}</span>
<span class="token punctuation">)</span>
</code></pre> 
<p>在上面的介绍中，这些特性基本上是不言而喻的。这里的一个特定行为是给“ answers”中的 Sequence 字段提供了一个子字段字典。正如上面提到的，在这种情况下，这个特性实际上被转换为一个列表字典(而不是我们在这个特性中读到的字典列表)。这一点在SQuAD数据集加载脚本, 通过最后的生成方法产生的例子的结构中得到了证实:</p> 
<pre><code class="prism language-bash">answer_starts <span class="token operator">=</span> <span class="token punctuation">[</span>answer<span class="token punctuation">[</span><span class="token string">"answer_start"</span><span class="token punctuation">]</span> <span class="token keyword">for</span> answer <span class="token keyword">in</span> qa<span class="token punctuation">[</span><span class="token string">"answers"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
answers <span class="token operator">=</span> <span class="token punctuation">[</span>answer<span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span>.strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> answer <span class="token keyword">in</span> qa<span class="token punctuation">[</span><span class="token string">"answers"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>

yield id_, <span class="token punctuation">{<!-- --></span>
    <span class="token string">"title"</span><span class="token keyword">:</span> title,
    <span class="token string">"context"</span><span class="token keyword">:</span> context,
    <span class="token string">"question"</span><span class="token keyword">:</span> question,
    <span class="token string">"id"</span><span class="token keyword">:</span> id_,
    <span class="token string">"answers"</span><span class="token keyword">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">"answer_start"</span><span class="token keyword">:</span> answer_starts, <span class="token string">"text"</span><span class="token keyword">:</span> answers,<span class="token punctuation">}</span>,
<span class="token punctuation">}</span>
</code></pre> 
<p>这里的"answers" 相应地提供了一个列表的字典，而不是一个字典的列表。</p> 
<p>让我们来看看另一个来自 Race(<a href="https://huggingface.co/datasets/race" rel="nofollow">large-scale reading comprehension dataset Race</a>) 的特征例子:</p> 
<pre><code class="prism language-bash">features<span class="token operator">=</span>datasets.Features<span class="token punctuation">(</span>
    <span class="token punctuation">{<!-- --></span>
        <span class="token string">"article"</span><span class="token keyword">:</span> datasets.Value<span class="token punctuation">(</span><span class="token string">"string"</span><span class="token punctuation">)</span>,
        <span class="token string">"answer"</span><span class="token keyword">:</span> datasets.Value<span class="token punctuation">(</span><span class="token string">"string"</span><span class="token punctuation">)</span>,
        <span class="token string">"question"</span><span class="token keyword">:</span> datasets.Value<span class="token punctuation">(</span><span class="token string">"string"</span><span class="token punctuation">)</span>,
        <span class="token string">"options"</span><span class="token keyword">:</span> datasets.features.Sequence<span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token string">"option"</span><span class="token keyword">:</span> datasets.Value<span class="token punctuation">(</span><span class="token string">"string"</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">)</span>
</code></pre> 
<p>下面是数据集中相应的第一个例子:</p> 
<pre><code class="prism language-python"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> <span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">'race'</span><span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token punctuation">{<!-- --></span><span class="token string">'article'</span><span class="token punctuation">:</span> 'My husband <span class="token keyword">is</span> a born shopper<span class="token punctuation">.</span> He loves to look at things <span class="token operator">and</span> to touch them<span class="token punctuation">.</span> He likes to compare prices between the same items <span class="token keyword">in</span> different shops<span class="token punctuation">.</span> He would never think of buying anything without looking around <span class="token keyword">in</span> several
 <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
 sadder<span class="token punctuation">.</span> When he saw me he said<span class="token punctuation">,</span> <span class="token string">"I\'m sorry, Mum. I have forgotten to buy oranges and the meat. I only remembered to buy six eggs, but I\'ve dropped three of them."</span>'<span class="token punctuation">,</span>
 <span class="token string">'answer'</span><span class="token punctuation">:</span> <span class="token string">'C'</span><span class="token punctuation">,</span>
 <span class="token string">'question'</span><span class="token punctuation">:</span> <span class="token string">'The husband likes shopping because   _  .'</span><span class="token punctuation">,</span>
 <span class="token string">'options'</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span>
    <span class="token string">'option'</span><span class="token punctuation">:</span><span class="token punctuation">[</span><span class="token string">'he has much money.'</span><span class="token punctuation">,</span>
              <span class="token string">'he likes the shops.'</span><span class="token punctuation">,</span>
              <span class="token string">'he likes to compare the prices between the same items.'</span><span class="token punctuation">,</span>
              <span class="token string">'he has nothing to do but shopping.'</span>
            <span class="token punctuation">]</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<h3><a id="Downloading_data_files_and_organizing_splits_170"></a>下载数据文件并组织拆分(Downloading data files and organizing splits)</h3> 
<p><code>datasets.DatasetBuilder._split_generator()</code>方法负责下载(或者检索本地数据文件)，根据分片(splits)进行组织，并在需要时生成过程中定义特定的参数</p> 
<p>此方法以<code>datasets.DownloadManager</code>作为输入,这是一个实用程序，可用于下载文件（如果它们是本地文件或已经在缓存中，则可以从本地文件系统中检索它们）并返回一个<code>datasets.SplitGenerator</code>列表。<code>datasets.SplitGenerator</code>是一个简单的数据类型，包含split和关键字参数的名称DatasetBuilder._generate_examples() 方法将在下一部分中详细介绍。</p> 
<p>这些参数可以特定于每个split，并且，通常至少包括要为每个拆分加载的数据文件的本地路径</p> 
<ul><li>Using local data files: 如果你的数据不是在线，而是本地数据文件，那么<code>datasets.BuilderConfig</code>特别提供了两个参数。这两个参数是<code>data_dir</code>和<code>data_files</code>可以自由地用于提供目录路径或文件路径。这两个属性可以在调用<code>datasets.load_dataset()</code>时使用相关关键字参数，例如:<code>dataset = datasets.load_dataset('my_script', data_files='my_local_data_file.csv')</code>,并且，这个值通过访问<code>self.config.data_dir</code>和<code>self.config.data_files</code>在<code>datasets.DatasetBuilder._split_generator()</code></li></ul> 
<p>查看<a href="https://github.com/huggingface/datasets/blob/master/datasets/text/text.py">text file loading script</a> 使用<code>datasets.BuilderConfig.data_files</code>的简单示例。</p> 
<p>让我们来看<code>datasets.DatasetBuilder._split_generator()</code>方法的一个简单的示例。我们来看一个squad数据集加载脚本的例子:</p> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">Squad</span><span class="token punctuation">(</span>datasets<span class="token punctuation">.</span>GeneratorBasedBuilder<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""SQUAD: The Stanford Question Answering Dataset. Version 1.1."""</span>

    _URL <span class="token operator">=</span> <span class="token string">"https://rajpurkar.github.io/SQuAD-explorer/dataset/"</span>
    _URLS <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
        <span class="token string">"train"</span><span class="token punctuation">:</span> _URL <span class="token operator">+</span> <span class="token string">"train-v1.1.json"</span><span class="token punctuation">,</span>
        <span class="token string">"dev"</span><span class="token punctuation">:</span> _URL <span class="token operator">+</span> <span class="token string">"dev-v1.1.json"</span><span class="token punctuation">,</span>
    <span class="token punctuation">}</span>

    <span class="token keyword">def</span> <span class="token function">_split_generators</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dl_manager<span class="token punctuation">:</span> datasets<span class="token punctuation">.</span>DownloadManager<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> List<span class="token punctuation">[</span>datasets<span class="token punctuation">.</span>SplitGenerator<span class="token punctuation">]</span><span class="token punctuation">:</span>
        urls_to_download <span class="token operator">=</span> self<span class="token punctuation">.</span>_URLS
        downloaded_files <span class="token operator">=</span> dl_manager<span class="token punctuation">.</span>download_and_extract<span class="token punctuation">(</span>urls_to_download<span class="token punctuation">)</span>

        <span class="token keyword">return</span> <span class="token punctuation">[</span>
            datasets<span class="token punctuation">.</span>SplitGenerator<span class="token punctuation">(</span>name<span class="token operator">=</span>datasets<span class="token punctuation">.</span>Split<span class="token punctuation">.</span>TRAIN<span class="token punctuation">,</span> gen_kwargs<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">"filepath"</span><span class="token punctuation">:</span> downloaded_files<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            datasets<span class="token punctuation">.</span>SplitGenerator<span class="token punctuation">(</span>name<span class="token operator">=</span>datasets<span class="token punctuation">.</span>Split<span class="token punctuation">.</span>VALIDATION<span class="token punctuation">,</span> gen_kwargs<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">"filepath"</span><span class="token punctuation">:</span> downloaded_files<span class="token punctuation">[</span><span class="token string">"dev"</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">]</span>
</code></pre> 
<p>正如您所看到的，此方法首先为 SQuAD 的原始数据文件准备 URL。这个字典然后提供给<code>datasets.DownloadManager.download_and_extract()</code>方法，它将负责下载或者从本地文件系统索引文件，并且返回具有相同类型和组织结构的对象(这里是字典) 。<code>datasets.DownloadManager.download_and_extract()</code>能够获得输入的 URL/PATH 或者 URLs/paths字典，并返回具有相同结构的对象(单个 URL/路径、 URL/路径的列表或字典)和本地文件的路径。此方法还负责提取 tar、 gzip 和 zip 压缩文档。</p> 
<ul><li>注意: 除了<code>datasets.DownloadManager.download_and_extract()</code>和<code>datasets.DownloadManager.download_custom()</code>,<code>datasets.DownloadManager</code>类还通过几种方法提供了对下载和提取过程的更细粒度控制，这些方法包括:<code>datasets.DownloadManager.download()</code>, <code>datasets.DownloadManager.extract()</code> 和 <code>datasets.DownloadManager.iter_archive()</code>。请参考数据集上的包参考 <code>datasets.DownloadManager</code>了解这些方法的详细信息。</li></ul> 
<p>数据文件下载后, <code>datasets.DatasetBuilder._split_generator（）</code> 方法的下一个任务是对每个<code>datasets.DatasetBuilder._generate_examples()</code>方法调用的结果来准备使用<code>datasets.SplitGenerator</code>。我们将在下一个会话中详细介绍。</p> 
<p><code>datasets.SplitGenerator</code>是一个简单的数据类型，包括:</p> 
<ul><li> <p><code>name</code>(string): 关于分割(split)的名称（如果可能），可以使用数据集中提供的标准分割名称。Split可以使用：datasets.Split.TRAIN，datasets.Split.VALIDATION和datasets.Split.TEST，</p> </li><li> <p><code>gen_kwargs</code>(dict): 关键字参数(keywords arguments)提供给<code>datasets.DatasetBuilder._generate_examples()</code>方法生成分割中的示例。这些参数可以特定于每个分割，通常至少包含要为每个拆分加载的数据文件的本地路径，如上面的SQuAD示例所示。</p> </li></ul> 
<h3><a id="Generating_the_samples_in_each_split_216"></a>在每个分割中生成样本（Generating the samples in each split）</h3> 
<p><code>datasets.DatasetBuilder._generate_examples()</code>是负责读取数据文件以进行分割，并产生示例，这些示例是在<code>datasets.DatasetBuilder._info()</code>设置的特定的feature格式。</p> 
<p><code>datasets.DatasetBuilder._generate_examples()</code>的输入参数是由gen_kwargs字典定义的由之前详细介绍的<code>datasets.DatasetBuilder._split_generator()</code>方法。</p> 
<p>再一次，让我们以squad数据集加载<a href="https://github.com/huggingface/datasets/blob/master/datasets/squad/squad.py">脚本</a>的简单示例为例：</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">_generate_examples</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> filepath<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""This function returns the examples in the raw (text) form."""</span>
    logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">"generating examples from = %s"</span><span class="token punctuation">,</span> filepath<span class="token punctuation">)</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>filepath<span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        squad <span class="token operator">=</span> json<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span>
        <span class="token keyword">for</span> article <span class="token keyword">in</span> squad<span class="token punctuation">[</span><span class="token string">"data"</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
            title <span class="token operator">=</span> article<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"title"</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token keyword">for</span> paragraph <span class="token keyword">in</span> article<span class="token punctuation">[</span><span class="token string">"paragraphs"</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
                context <span class="token operator">=</span> paragraph<span class="token punctuation">[</span><span class="token string">"context"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
                <span class="token keyword">for</span> qa <span class="token keyword">in</span> paragraph<span class="token punctuation">[</span><span class="token string">"qas"</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
                    question <span class="token operator">=</span> qa<span class="token punctuation">[</span><span class="token string">"question"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
                    id_ <span class="token operator">=</span> qa<span class="token punctuation">[</span><span class="token string">"id"</span><span class="token punctuation">]</span>

                    answer_starts <span class="token operator">=</span> <span class="token punctuation">[</span>answer<span class="token punctuation">[</span><span class="token string">"answer_start"</span><span class="token punctuation">]</span> <span class="token keyword">for</span> answer <span class="token keyword">in</span> qa<span class="token punctuation">[</span><span class="token string">"answers"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
                    answers <span class="token operator">=</span> <span class="token punctuation">[</span>answer<span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> answer <span class="token keyword">in</span> qa<span class="token punctuation">[</span><span class="token string">"answers"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>

                    <span class="token comment"># Features currently used are "context", "question", and "answers".</span>
                    <span class="token comment"># Others are extracted here for the ease of future expansions.</span>
                    <span class="token keyword">yield</span> id_<span class="token punctuation">,</span> <span class="token punctuation">{<!-- --></span>
                        <span class="token string">"title"</span><span class="token punctuation">:</span> title<span class="token punctuation">,</span>
                        <span class="token string">"context"</span><span class="token punctuation">:</span> context<span class="token punctuation">,</span>
                        <span class="token string">"question"</span><span class="token punctuation">:</span> question<span class="token punctuation">,</span>
                        <span class="token string">"id"</span><span class="token punctuation">:</span> id_<span class="token punctuation">,</span>
                        <span class="token string">"answers"</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">"answer_start"</span><span class="token punctuation">:</span> answer_starts<span class="token punctuation">,</span> <span class="token string">"text"</span><span class="token punctuation">:</span> answers<span class="token punctuation">,</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
                    <span class="token punctuation">}</span>
</code></pre> 
<p>输入参数是<code>datasets.DatasetBuilder._split_generator()</code>方法返回的每个<code>dataset.SplitGenerator</code>的gen_kwargs中提供的文件路径。</p> 
<p>该方法读取并解析输入文件，并生成一个由id_(可以是任意的，但应该是唯一的(为了向后兼容TensorFlow数据集)和一个示例组成的元组。该示例是一个具有与<code>datasets.DatasetBuilder._info()</code>中定义的特性相同的结构和元素类型的字典。</p> 
<ul><li>注意:由于生成数据集是基于python生成器的，因此它不会将所有数据加载到内存中，因此它可以处理相当大的数据集。但是，在刷新到磁盘上的数据集文件之前，生成的示例存储在ArrowWriter缓冲区中，以便分批写入它们。如果您的数据集的样本占用了大量内存(带有图像或视频)，那么请确保为数据集生成器类的_writer_batch_size类属性指定一个低值。我们建议不要超过200MB。</li></ul> 
<h3><a id="Specifying_several_dataset_configurations_257"></a>指定几个数据集配置(Specifying several dataset configurations)</h3> 
<p>有时，希望提供对数据集的多个子集的访问，例如，如果数据集包含几种语言或由不同的子集组成，或者希望提供几种构建示例的方法。</p> 
<p>这可以通过定义一个特定的<code>datasets.BuilderConfig</code>类，并提供这个类的预定义实例供用户选择来实现。<br> 基本<code>dataset.BuilderConfig</code>类非常简单，只包含以下属性:</p> 
<ul><li><code>name</code>(str)是数据集配置的名字。例如，如果不同的配置特定于不同的语言，则使用语言名来配置,</li><li><code>version</code>可选的版本标识符,</li><li><code>data_dir</code>(str)用于存储包含数据文件的本地文件夹的路径,</li><li><code>data_files</code>(Union[Dict, List])可用于存储本地数据文件的路径,</li><li><code>description</code>(str) 可以用来对配置进行长篇描述.</li></ul> 
<p><code>datasets.BuilderConfig</code>仅作为一个信息容器使用，这些信息可以通过在<code>datasets.DatasetBuilder</code>实例的self.Config属性中访问来在<code>datasets.DatasetBuilder</code>中构建数据集。</p> 
<p>有两种方法来填充<code>datasets.BuilderConfig</code>类或子类的属性:</p> 
<ul><li> <p>可以在数据集的<code>datasets.DatasetBuilder.BUILDER_CONFIGS</code>属性中设置预定义的<code>datasets.BuilderConfig</code>类或子类列表。然后可以通过将其名称作为name关键字提供给datasets.load_dataset()来选择每个特定的配置，</p> </li><li> <p>当调用<code>datasets.load_dataset()</code>时，所有不是特定于<code>datassets.load_dataset()</code>方法的关键字参数将用于设置<code>datasets.BuilderConfig</code>类的相关属性，并在选择特定配置时覆盖预定义的属性。</p> </li></ul> 
<p>让我们看一个从CSV文件加载<a href="https://github.com/huggingface/datasets/blob/master/datasets/csv/csv.py">脚本</a>改编的示例。</p> 
<p>假设我们需要两种简单的方式来加载CSV文件:使用“，”作为分隔符(我们将此配置称为’comma’)或使用“;”作为分隔符(我们将此配置称为’semi-colon’)。</p> 
<p>我们可以用delimiter属性定义一个自定义配置:</p> 
<pre><code class="prism language-python">@dataclass
<span class="token keyword">class</span> <span class="token class-name">CsvConfig</span><span class="token punctuation">(</span>datasets<span class="token punctuation">.</span>BuilderConfig<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""BuilderConfig for CSV."""</span>
    delimiter<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> <span class="token boolean">None</span>
</code></pre> 
<p>然后在DatasetBuilder中定义几个预定义的配置:</p> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">Csv</span><span class="token punctuation">(</span>datasets<span class="token punctuation">.</span>ArrowBasedBuilder<span class="token punctuation">)</span><span class="token punctuation">:</span>
    BUILDER_CONFIG_CLASS <span class="token operator">=</span> CsvConfig
    BUILDER_CONFIGS <span class="token operator">=</span> <span class="token punctuation">[</span>CsvConfig<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'comma'</span><span class="token punctuation">,</span>
                                 description<span class="token operator">=</span><span class="token string">"Load CSV using ',' as a delimiter"</span><span class="token punctuation">,</span>
                                 delimiter<span class="token operator">=</span><span class="token string">','</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                       CsvConfig<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'semi-colon'</span><span class="token punctuation">,</span>
                                 description<span class="token operator">=</span><span class="token string">"Load CSV using a semi-colon as a delimiter"</span><span class="token punctuation">,</span>
                                 delimiter<span class="token operator">=</span><span class="token string">';'</span><span class="token punctuation">)</span><span class="token punctuation">]</span>

    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>

    <span class="token keyword">def</span> self<span class="token punctuation">.</span>_generate_examples<span class="token punctuation">(</span><span class="token builtin">file</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token builtin">file</span><span class="token punctuation">)</span> <span class="token keyword">as</span> csvfile<span class="token punctuation">:</span>
            data <span class="token operator">=</span> csv<span class="token punctuation">.</span>reader<span class="token punctuation">(</span>csvfile<span class="token punctuation">,</span> delimiter <span class="token operator">=</span> self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>delimiter<span class="token punctuation">)</span>
            <span class="token keyword">for</span> i<span class="token punctuation">,</span> row <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">yield</span> i<span class="token punctuation">,</span> row
</code></pre> 
<p>这里我们可以看到如何使用<code>self.config.delimiter</code>属性来控制读取CSV文件。</p> 
<p>数据集加载脚本的用户将能够选择一种或另一种方式来加载带有配置名称的CSV文件，甚至可以通过直接设置分隔符属性来选择完全不同的方式。例如使用这样的命令:</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset
dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">'my_csv_loading_script'</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'comma'</span><span class="token punctuation">,</span> data_files<span class="token operator">=</span><span class="token string">'my_file.csv'</span><span class="token punctuation">)</span>
dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">'my_csv_loading_script'</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'semi-colon'</span><span class="token punctuation">,</span> data_files<span class="token operator">=</span><span class="token string">'my_file.csv'</span><span class="token punctuation">)</span>
dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">'my_csv_loading_script'</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'comma'</span><span class="token punctuation">,</span> delimiter<span class="token operator">=</span><span class="token string">'\t'</span><span class="token punctuation">,</span> data_files<span class="token operator">=</span><span class="token string">'my_file.csv'</span><span class="token punctuation">)</span>
</code></pre> 
<p>在最后一种情况下，配置设置的分隔符将被指定为<code>load_dataset</code>参数的分隔符覆盖。</p> 
<p>虽然在这种情况下使用配置属性来控制数据文件的读取/解析，但配置属性可以在处理的任何阶段使用，特别是:</p> 
<ul><li>要控制在<code>datasets.DatasetBuilder._info()</code>方法中设置的<code>datasets.DatasetInfo</code>属性，例如特性，</li><li>要控制在<code>datasets.DatasetBuilder._split_generator()</code>方法中下载的文件，例如根据配置定义的语言属性选择不同的url</li></ul> 
<p>在<a href="https://github.com/huggingface/datasets/blob/master/datasets/super_glue/super_glue.py">Super-GLUE加载脚本</a>中可以找到一个带有一些预定义配置的自定义配置类的例子，该脚本通过配置提供了对SuperGLUE基准测试的各种子数据集的控制。另一个例子是<a href="https://github.com/huggingface/datasets/blob/master/datasets/wikipedia/wikipedia.py">Wikipedia加载脚本</a>，它通过配置提供对Wikipedia数据集语言的控制。</p> 
<h3><a id="Specifying_a_default_dataset_configuration_329"></a>指定默认数据集配置(Specifying a default dataset configuration)</h3> 
<p>当用户加载具有多个结构的数据集时，他们必须指定一个结构名，否则会引发ValueError。对于一些数据集，最好指定一个默认结构，如果用户没有指定，它将被加载。</p> 
<p>这可以通过<code>datasets.DatasetBuilder.DEFAULT_CONFIG_NAME</code>属性完成。通过将此属性设置为一个数据集配置的名称，在用户没有指定结构名称的情况下，该结构将被加载。</p> 
<p>这个特性是可选的，应该只在默认配置对数据集有意义的地方使用。例如，许多跨语言数据集对于每种语言都有不同的配置。在这种情况下，创建一个可以作为默认配置的聚合配置可能是有意义的。这实际上会默认加载数据集的所有语言，除非用户指定了特定的语言。有关示例，请参阅<a href="https://github.com/huggingface/datasets/blob/master/datasets/polyglot_ner/polyglot_ner.py">通晓多种语言的NER加载脚本</a>。</p> 
<h3><a id="Testing_the_dataset_loading_script_336"></a>测试数据集加载脚本(Testing the dataset loading script)</h3> 
<p>一旦你完成了创建或调整数据集加载脚本，你可以通过给出数据集加载脚本的路径在本地尝试它:</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset
dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">'PATH/TO/MY/SCRIPT.py'</span><span class="token punctuation">)</span>
</code></pre> 
<p>如果您的数据集有几个配置，或者需要指定到本地数据文件的路径，您可以相应地使用datasets.load_dataset()的参数:</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset
dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">'PATH/TO/MY/SCRIPT.py'</span><span class="token punctuation">,</span> <span class="token string">'my_configuration'</span><span class="token punctuation">,</span>  data_files<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">'train'</span><span class="token punctuation">:</span> <span class="token string">'my_train_file.txt'</span><span class="token punctuation">,</span> <span class="token string">'validation'</span><span class="token punctuation">:</span> <span class="token string">'my_validation_file.txt'</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="Dataset_scripts_of_reference_350"></a>数据集参考脚本(Dataset scripts of reference)</h3> 
<p>数据集共享相同的格式是很常见的。因此，可能已经存在一个数据集脚本，您可以从中获得一些灵感来帮助您编写自己的数据集脚本。</p> 
<p>可以随意重用他们的部分代码，并根据自己的情况进行调整:<br> 直接贴<a href="https://huggingface.co/docs/datasets/add_dataset.html" rel="nofollow">原文地址</a>，拉到最下面就好</p> 
<h2><a id="_356"></a>示例</h2> 
<p>这是一个在本地上的数据集，它的一个示例为：</p> 
<pre><code class="prism language-python">webqa_data <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span><span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'./data/WebQA.json'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf8'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python">webqa_data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
<span class="token punctuation">{<!-- --></span><span class="token string">'passages'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">{<!-- --></span><span class="token string">'answer'</span><span class="token punctuation">:</span> <span class="token string">''</span><span class="token punctuation">,</span> <span class="token string">'passage'</span><span class="token punctuation">:</span> <span class="token string">'商王朝最后一个君王叫纣，最早以亳为都城。'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{<!-- --></span><span class="token string">'answer'</span><span class="token punctuation">:</span> <span class="token string">''</span><span class="token punctuation">,</span> <span class="token string">'passage'</span><span class="token punctuation">:</span> <span class="token string">'纣：中国商代最后一位君主。'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{<!-- --></span><span class="token string">'answer'</span><span class="token punctuation">:</span> <span class="token string">'纣王'</span><span class="token punctuation">,</span>
   <span class="token string">'passage'</span><span class="token punctuation">:</span> <span class="token string">'商王朝最后一个君王叫帝辛，也就是纣王，商王朝都成在殷商，商王朝灭亡的一场战役是牧野之战，商王朝灭了，建立了周朝。'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{<!-- --></span><span class="token string">'answer'</span><span class="token punctuation">:</span> <span class="token string">''</span><span class="token punctuation">,</span>
   <span class="token string">'passage'</span><span class="token punctuation">:</span> <span class="token string">'答：第一个是秦始皇，首称“朕”、并六国、统度量衡、焚书坑儒、造长城等、是一个暴君也是一个雄才伟略的大作为君王。最后一个是清朝宣统帝，爱新觉罗．溥仪，为日本人控制建立伪满政权，写了本自传。'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{<!-- --></span><span class="token string">'answer'</span><span class="token punctuation">:</span> <span class="token string">''</span><span class="token punctuation">,</span> <span class="token string">'passage'</span><span class="token punctuation">:</span> <span class="token string">'鸣条一战，夏师败绩，夏桀奔南巢而死，成汤则成为商代的第一位君王。'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{<!-- --></span><span class="token string">'answer'</span><span class="token punctuation">:</span> <span class="token string">''</span><span class="token punctuation">,</span> <span class="token string">'passage'</span><span class="token punctuation">:</span> <span class="token string">'最后一个君王叫杰朝都在殷商战役不知道商灭亡后建立周朝'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{<!-- --></span><span class="token string">'answer'</span><span class="token punctuation">:</span> <span class="token string">''</span><span class="token punctuation">,</span> <span class="token string">'passage'</span><span class="token punctuation">:</span> <span class="token string">'他在位期间致力于修明政治，统一中国北方，政绩显著，是十六国时期许多封建帝王中最杰出君王。'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{<!-- --></span><span class="token string">'answer'</span><span class="token punctuation">:</span> <span class="token string">''</span><span class="token punctuation">,</span>
   <span class="token string">'passage'</span><span class="token punctuation">:</span> <span class="token string">'中国皇帝（君王）包括正统朝代和少数民族建立的政权，还有一些政变、夺权所建立的政权，再加上农民起义建立的政权，中国皇帝共有１０００多位呢！附：南越、东越、闽越、东瓯、匈奴、突厥、回纥（回鹘）、吐蕃、高昌、于阗、柔然、吐谷浑、渤海国（大震）、南诏（大蒙、大礼、大封民）、大长和、大天兴、大义宁、大理国（前理汉武帝刘彻、后理）、大中、东夏（大真）（以上不包括十六国时期和五代十国时期的少数民族政权）其中云南列朝自世隆以下【南诏（大蒙、大礼、大封民）、大长和、大天兴、大义宁、大理国（前理、后理）、大中】和东夏（大真）的君主称皇帝；南越（吕后时）、于阗（五代时）的君主一度称皇帝；南越、东越、闽越、东瓯、高昌、于阗、吐谷浑、渤海国（大震）作为中原王朝的藩属国，君主称王；匈奴的君主称单于；回纥（回鹘）、柔然的君主称可汗；吐蕃的君主称赞普。'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{<!-- --></span><span class="token string">'answer'</span><span class="token punctuation">:</span> <span class="token string">''</span><span class="token punctuation">,</span> <span class="token string">'passage'</span><span class="token punctuation">:</span> <span class="token string">'中国第一个有记载有国号的王朝是夏，最后一个国王是桀。'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{<!-- --></span><span class="token string">'answer'</span><span class="token punctuation">:</span> <span class="token string">''</span><span class="token punctuation">,</span> <span class="token string">'passage'</span><span class="token punctuation">:</span> <span class="token string">'周朝是中国第三个也是最后一个世袭分封制王朝'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{<!-- --></span><span class="token string">'answer'</span><span class="token punctuation">:</span> <span class="token string">''</span><span class="token punctuation">,</span> <span class="token string">'passage'</span><span class="token punctuation">:</span> <span class="token string">'仲壬亦称中壬、燕壬、工壬、其壬、南壬，姓子名庸，是中国商朝的一位君王。'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{<!-- --></span><span class="token string">'answer'</span><span class="token punctuation">:</span> <span class="token string">''</span><span class="token punctuation">,</span>
   <span class="token string">'passage'</span><span class="token punctuation">:</span> <span class="token string">'在中国汉代的历史学家司马迁的着作《史记》中记载，商代最后一个国王纣的兄弟箕子在周武王伐纣后，带着商代的礼仪和制度到了朝鲜半岛北部，被那里的人民推举为国君，并得到周朝的承认。'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{<!-- --></span><span class="token string">'answer'</span><span class="token punctuation">:</span> <span class="token string">''</span><span class="token punctuation">,</span> <span class="token string">'passage'</span><span class="token punctuation">:</span> <span class="token string">'君王已成了历史名词，中国再不会有皇帝，留下大量史料让后人去挖掘。'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{<!-- --></span><span class="token string">'answer'</span><span class="token punctuation">:</span> <span class="token string">''</span><span class="token punctuation">,</span>
   <span class="token string">'passage'</span><span class="token punctuation">:</span> <span class="token string">'后人称他在贞观年间的统治为“贞观之治”。【丰功伟绩】1、他不拘一格（敌人、穷人、坏人）的用人，对人材的使用及领导达到了极高的境遇；2、他独具慧眼，看到了个人力量的不足，充分认识到君王如石、良臣如匠，方有美玉问世，对大臣的各项进步之言豁达的予以采纳；3、不独断专行、初步确立了三权分立、互相监督的政治管理制度，规定法令甚至包括自己（影响国家政策的那一部份）旨意需门下省审查副署后方可生效发布，保证了政策的可行性、及时发现并纠正/杜绝了不良政策对国家及人民的违害与影响；4、认识到人命至重、不可妄杀的法政政策，规定死刑需三复奏（外地五复奏）复审批准后方可行刑，这就不难认人们想起贞观四年（630年---中国的丰年）全国叛死刑才29人、贞观六年（632年）全国死刑犯290人，太宗审查时令全部290人回家团年、待来年秋收后回来复刑，结果290人均准时到来、无一人逃亡（现在有人说那是太宗广布法网，那290人是跑不掉才回来受死的，我说这人真是不动脑子，想想那时的法网严还是现在的法网严，那现在逃狱是不是100%呢，那又是为什么呢！！！）。5、太宗朝武功之盛，除太高丽战争上没有取得战略胜利外都取得了辉煌的胜利（突厥、吐谷浑、高昌、安西四镇、漠北薛延陀等），这与当时的国力、军队战斗力、整体战略、用人选将与配合默契、过程协调一致等重要因素是分不开的，因此在中华历史上的名将名相中，贞观朝占有相当的比例，在中华军事史上，贞观朝的战例也多被引用；6、气吞天下的“天可汗”气质，李世民多次以少吓多，经典之役就是在渭水单骑吓退突厥10万精骑，就对比宋真宗在寇准一在坚持和请求下才免强在大军护卫下到达澶州南城，而又要战战兢兢的马上要回去是何等的天壤之别啊！7、胸怀大局、四海一统的民族和外交政策，太宗朝的民族和外交政策取得了辉煌的胜利，四海之内只要知道中国的均努力内附，以唐为荣，乐不思蜀，他们不但同唐人一样可以自由自在的生存，还可以做官，著名的少数民族将领阿史那社尔、执思失力、契毕何力乃至后世的高仙芝、李光弼等都为唐朝做出了杰出贡献，在他们身上正好反映出李世民民族政策的光辉，现在的唐人、唐人街也正时那时繁荣富强、威甲四海、文礼之邦的生动写照；8、完善科举制度、大力兴办学校、重视教育活动、普及官吏选聘、当时的国子学、太学之盛、地方也有不少学校，如此才不难想起当时的教化呢，同时当时的科举也规范化、考选公平，以进士科最为杰出，如此才有太宗见新科进士鱼贯而出，喜言“天下英雄'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{<!-- --></span><span class="token string">'answer'</span><span class="token punctuation">:</span> <span class="token string">''</span><span class="token punctuation">,</span>
   <span class="token string">'passage'</span><span class="token punctuation">:</span> <span class="token string">'中国皇帝（君王）包括正统朝代和少数民族建立的政权，还有一些政变、夺权所建立的政权，再加上农民起义建立的政权，中国皇帝共有１０００多位呢！'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{<!-- --></span><span class="token string">'answer'</span><span class="token punctuation">:</span> <span class="token string">''</span><span class="token punctuation">,</span>
   <span class="token string">'passage'</span><span class="token punctuation">:</span> <span class="token string">'答：中国皇帝（君王）包括正统朝代和少数民族建立的政权，还有一些政变、夺权所建立的政权，再加上农民起义建立的政权，中国皇帝共有１０００多位呢！附：南越、东越、闽越、东瓯、匈奴、突厥、回纥（回鹘）、吐蕃、高昌、于阗、柔然、吐谷浑、渤海...'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{<!-- --></span><span class="token string">'answer'</span><span class="token punctuation">:</span> <span class="token string">''</span><span class="token punctuation">,</span>
   <span class="token string">'passage'</span><span class="token punctuation">:</span> <span class="token string">'中国经历的漫长封建社会自公元前221年秦王赢政称"皇帝"始,至1912年最后一个封建皇帝溥仪在辛亥革命的炮火中宣布退位止.长达2132年.在这期间,封建皇帝总数为494人,在位时间最长的皇帝是清康熙帝和乾隆帝,在位时间最短的是金末帝完颜承麟,从即位到被杀,不足半日.'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{<!-- --></span><span class="token string">'answer'</span><span class="token punctuation">:</span> <span class="token string">''</span><span class="token punctuation">,</span>
   <span class="token string">'passage'</span><span class="token punctuation">:</span> <span class="token string">'皇朝的终结中国最后一个君主专制政府——清朝在1911年的辛亥革命中被推翻，取而代之的是共和政体中华民国（正式成立于1912年1月1日）。'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{<!-- --></span><span class="token string">'answer'</span><span class="token punctuation">:</span> <span class="token string">''</span><span class="token punctuation">,</span> <span class="token string">'passage'</span><span class="token punctuation">:</span> <span class="token string">'桀：桀是夏朝最后一个国王，名履癸，是中国历史上有名的暴虐、荒淫的国君之一。'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{<!-- --></span><span class="token string">'answer'</span><span class="token punctuation">:</span> <span class="token string">''</span><span class="token punctuation">,</span> <span class="token string">'passage'</span><span class="token punctuation">:</span> <span class="token string">'中国第一个王朝是夏，夏的最后一个皇帝是桀。'</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
 <span class="token string">'question'</span><span class="token punctuation">:</span> <span class="token string">'中国商代最后一个君王是谁?'</span><span class="token punctuation">,</span>
 <span class="token string">'id'</span><span class="token punctuation">:</span> <span class="token string">'Q_IR_VAL_000000#TEST'</span><span class="token punctuation">}</span>
</code></pre> 
<p>先是一个列表(list)，列表中每个元素是一个字典，每个字典中有[‘passages’, ‘question’, ‘id’]三个关键字。</p> 
<pre><code class="prism language-python">webqa_data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
dict_keys<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'passages'</span><span class="token punctuation">,</span> <span class="token string">'question'</span><span class="token punctuation">,</span> <span class="token string">'id'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<p>passages中对应的是一个列表，列表中的元素是dict_keys([‘answer’, ‘passage’])</p> 
<p>然后我自己写了一个脚本</p> 
<p>为了增加可读性，把许可证和描述的关键字设置为空</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> __future__ <span class="token keyword">import</span> absolute_import<span class="token punctuation">,</span> division<span class="token punctuation">,</span> print_function

<span class="token keyword">import</span> csv
<span class="token keyword">import</span> json
<span class="token keyword">import</span> os

<span class="token keyword">import</span> datasets
_CITATION <span class="token operator">=</span>  “”    <span class="token comment"># 来自论文或arxiv</span>
_DESCRIPTION <span class="token operator">=</span> “”    <span class="token comment"># 任务描述</span>
_HOMEPAGE <span class="token operator">=</span> ”“    <span class="token comment"># 链接</span>
_LICENSE <span class="token operator">=</span> ”“    <span class="token comment"># 链接</span>

_URLs <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>    <span class="token comment"># 本地文件的路径</span>
    <span class="token string">'train'</span><span class="token punctuation">:</span> <span class="token string">"./data/qatrain.json"</span><span class="token punctuation">,</span>
    <span class="token string">'dev'</span><span class="token punctuation">:</span> <span class="token string">"./data/qavalid.json"</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>下面是在模板中填写自己的数据集：</p> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">Webqa</span><span class="token punctuation">(</span>datasets<span class="token punctuation">.</span>GeneratorBasedBuilder<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""TODO: Short description of my dataset."""</span>

    VERSION <span class="token operator">=</span> datasets<span class="token punctuation">.</span>Version<span class="token punctuation">(</span><span class="token string">"1.1.0"</span><span class="token punctuation">)</span>
    BUILDER_CONFIGS <span class="token operator">=</span> <span class="token punctuation">[</span>
        datasets<span class="token punctuation">.</span>BuilderConfig<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">"Plain_text"</span><span class="token punctuation">,</span> version<span class="token operator">=</span>VERSION<span class="token punctuation">,</span> description<span class="token operator">=</span><span class="token string">"Plain text"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">]</span>    <span class="token comment"># 对数据集的概述</span>
    
    <span class="token keyword">def</span> <span class="token function">_info</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> datasets<span class="token punctuation">.</span>DatasetInfo<span class="token punctuation">(</span>
            <span class="token comment"># 这是将出现在“数据集”页面上的描述。</span>
            description<span class="token operator">=</span>_DESCRIPTION<span class="token punctuation">,</span>
            <span class="token comment"># 这定义了数据集的不同列及其类型</span>
            features<span class="token operator">=</span>datasets<span class="token punctuation">.</span>Features<span class="token punctuation">(</span>
                <span class="token punctuation">{<!-- --></span>
                    <span class="token string">"id"</span><span class="token punctuation">:</span> datasets<span class="token punctuation">.</span>Value<span class="token punctuation">(</span><span class="token string">"string"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    <span class="token string">"question"</span><span class="token punctuation">:</span> datasets<span class="token punctuation">.</span>Value<span class="token punctuation">(</span><span class="token string">"string"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    <span class="token string">"passage"</span><span class="token punctuation">:</span> datasets<span class="token punctuation">.</span>Value<span class="token punctuation">(</span><span class="token string">"string"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    <span class="token string">"answer"</span><span class="token punctuation">:</span> datasets<span class="token punctuation">.</span>Value<span class="token punctuation">(</span><span class="token string">"string"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token punctuation">}</span>
            <span class="token punctuation">)</span><span class="token punctuation">,</span>     <span class="token comment"># 这一部分定义了输出关键字的类型，和要输出的关键字</span>
            supervised_keys<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
            homepage<span class="token operator">=</span>_HOMEPAGE<span class="token punctuation">,</span>
            license<span class="token operator">=</span>_LICENSE<span class="token punctuation">,</span>
            citation<span class="token operator">=</span>_CITATION<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">_split_generators</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dl_manager<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""Returns SplitGenerators."""</span>
        <span class="token comment"># 这个方法用来下载/提取数据，依据configurations分割数据</span>
        <span class="token comment"># 如果可能有几种配置(在BUILDER_CONFIGS中列出)，则用户选择的配置在self.config.name中</span>
        
        <span class="token comment"># dl_manager is a datasets.download.DownloadManager 用来下载和抽取url</span>
        <span class="token comment"># 它可以接受任何类型或嵌套的list/dict，并将返回相同的结构，也可以将url替换为本地文件的路径。</span>
        <span class="token comment"># 默认情况下，将提取归档文件，并返回到提取归档文件的缓存文件夹的路径，而不是归档文件</span>
        data_dir <span class="token operator">=</span> dl_manager<span class="token punctuation">.</span>download_and_extract<span class="token punctuation">(</span>_URLs<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>data_dir<span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token punctuation">[</span>
            datasets<span class="token punctuation">.</span>SplitGenerator<span class="token punctuation">(</span>
                name<span class="token operator">=</span>datasets<span class="token punctuation">.</span>Split<span class="token punctuation">.</span>TRAIN<span class="token punctuation">,</span>
                <span class="token comment"># These kwargs will be passed to _generate_examples kwargs将会传参给_generate_examples</span>
                gen_kwargs<span class="token operator">=</span><span class="token punctuation">{<!-- --></span>
                    <span class="token string">"filepath"</span><span class="token punctuation">:</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_dir<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    <span class="token string">"split"</span><span class="token punctuation">:</span> <span class="token string">"train"</span><span class="token punctuation">,</span>
                <span class="token punctuation">}</span><span class="token punctuation">,</span>
            <span class="token punctuation">)</span><span class="token punctuation">,</span>
            datasets<span class="token punctuation">.</span>SplitGenerator<span class="token punctuation">(</span>
                name<span class="token operator">=</span>datasets<span class="token punctuation">.</span>Split<span class="token punctuation">.</span>VALIDATION<span class="token punctuation">,</span>
                <span class="token comment"># These kwargs will be passed to _generate_examples</span>
                gen_kwargs<span class="token operator">=</span><span class="token punctuation">{<!-- --></span>
                    <span class="token string">"filepath"</span><span class="token punctuation">:</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_dir<span class="token punctuation">[</span><span class="token string">"dev"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    <span class="token string">"split"</span><span class="token punctuation">:</span> <span class="token string">"dev"</span><span class="token punctuation">,</span>
                <span class="token punctuation">}</span><span class="token punctuation">,</span>
            <span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">_generate_examples</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> filepath<span class="token punctuation">,</span> split<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">""" Yields examples. """</span>
        <span class="token comment"># 这个方法将接收在前面的' _split_generators '方法中定义的' gen_kwargs '作为参数。</span>
        <span class="token comment"># It is in charge of opening the given file and yielding (key, example) tuples from the dataset</span>
        <span class="token comment"># The key is not important, it's more here for legacy reason (legacy from tfds)</span>
        <span class="token comment"># 它负责打开给定的文件并从数据集生成元组(键，示例)</span>
        <span class="token comment"># key是不重要的，更多的是为了传承</span>

        <span class="token comment"># 这里就是根据自己的数据集来整理</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>filepath<span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            data <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>f<span class="token punctuation">)</span>
            <span class="token keyword">for</span> questions <span class="token keyword">in</span> data<span class="token punctuation">:</span>    <span class="token comment"># 读列表中的其中第一个字典</span>
                id_ <span class="token operator">=</span> questions<span class="token punctuation">[</span><span class="token string">'id'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
                question <span class="token operator">=</span> questions<span class="token punctuation">[</span><span class="token string">'question'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
                passages <span class="token operator">=</span> questions<span class="token punctuation">[</span><span class="token string">'passages'</span><span class="token punctuation">]</span>
                <span class="token keyword">for</span> passage_n <span class="token keyword">in</span> passages<span class="token punctuation">:</span>
                    answer <span class="token operator">=</span> passage_n<span class="token punctuation">[</span><span class="token string">'answer'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
                    passage <span class="token operator">=</span> passage_n<span class="token punctuation">[</span><span class="token string">'passage'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
                        
                    <span class="token keyword">yield</span> id_<span class="token punctuation">,</span> <span class="token punctuation">{<!-- --></span>
                        <span class="token string">"id"</span><span class="token punctuation">:</span> id_<span class="token punctuation">,</span>
                        <span class="token string">"question"</span><span class="token punctuation">:</span> question<span class="token punctuation">,</span>
                        <span class="token string">"passage"</span><span class="token punctuation">:</span> passage<span class="token punctuation">,</span>
                        <span class="token string">"answer"</span><span class="token punctuation">:</span>answer
                    <span class="token punctuation">}</span>
</code></pre> 
<h3><a id="_514"></a>结果演示</h3> 
<p>然后我们来演示这个读的效果：</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset
dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"./qascript.py"</span><span class="token punctuation">,</span> data_files<span class="token operator">=</span><span class="token string">'./data/qatrain.json'</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/1b/e2/vrbdGgH5_o.png" alt="在这里插入图片描述"><br> 可以看到，在经过一番周折后，效果还是不错的。</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/82c9dacde14be2c4df46b01ee1d6443c/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">js校验远端图片是否存在</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/3b11c97fb2fbdf26698c288ce9bca69d/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">linux安装cv2踩坑</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程爱好者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151260"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>