<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>FCN图像分割【飞桨】class2(附代码和注释） - 编程爱好者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="FCN图像分割【飞桨】class2(附代码和注释）" />
<meta property="og:description" content="FCN 全卷积网络 上图是一个FCN-32s网络的结构图。在这个网络中，图片经过骨干网络（VGG Network）提取特征后，得到长宽缩小32倍的特征图，随后直接将特征图上采样32倍，得到和输入图片一样大小的分割图。
是不是特别简单直接。别看这个网络设计的这么简单，但确实可以得到分割图。
当然，因为是直接将特征图上采样32倍，这种方式得到的分割精度不会很高。
为了提高分割精度，作者还提出将骨干网络的中间层提取出来，与上述分割结果融合，得到最终的输出结果。这样就可以得到FCN-16s, FCN-8s, FCN-4s以及FCN-2s网络。
上图展示的是FCN-8s网络，该网络将Pool3和Pool4的输出取出，与FCN-32s的输出结果融合，得到最终的分割图。具体的融合方式见下图：
首先将FC7（FCN-32s的输出）上采样2倍，与Pool4输出结果相加，得到与Pool4融合的特征图。随后将这个特征图再上采样2倍，与Pool3层的结果相加，得到融合了Pool4、Pool3信息的特征图。再将这个特征图上采样8倍，经过一个softmax层，就得到了与输入图片一样大小的分割图。因为最终上采样8倍，所以称为FCN-8s。
import numpy as np import paddle.fluid as fluid from paddle.fluid.dygraph import to_variable from paddle.fluid.dygraph import Conv2D from paddle.fluid.dygraph import Conv2DTranspose from paddle.fluid.dygraph import Dropout from paddle.fluid.dygraph import BatchNorm from paddle.fluid.dygraph import Pool2D from paddle.fluid.dygraph import Linear from vgg import VGG16BN class FCN8s(fluid.dygraph.Layer):#本质上是复杂的basic_model def __init__(self, num_classes=59): super(FCN8s, self).__init__()#初始化父类 backbone=VGG16BN(pretrained=False)#选择vgg作为backbone #backbone指的是网络的主干网络，对图像进行特征提取（常见的有vggnet，resnet，谷歌的inception），这一部分是整个CV任务的根基 self.layer1=backbone.layer1#直接从vgg中拿就好了 self.layer1[0].conv._padding=[100,100] self.pool1=Pool2D(pool_size=2,pool_stride=2,ceil_mode=True)#ceil_mode我们应对不同尺寸的输入时取整等操作 self.layer2=backbone.layer2 self.pool2=Pool2D(pool_size=2,pool_stride=2,ceil_mode=True) self.layer3=backbone.layer3 self.pool3=Pool2D(pool_size=2,pool_stride=2,ceil_mode=True) self.layer4=backbone.layer4 self.pool4=Pool2D(pool_size=2,pool_stride=2,ceil_mode=True) self." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bchobby.github.io/posts/c24523f0b5fa05e4f2fd1ff1f83e5bad/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-07-26T11:30:18+08:00" />
<meta property="article:modified_time" content="2022-07-26T11:30:18+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程爱好者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程爱好者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">FCN图像分割【飞桨】class2(附代码和注释）</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h3>FCN 全卷积网络</h3> 
<p> </p> 
<p><img alt="" height="154" src="https://images2.imgbox.com/5a/70/Jy7xq1W3_o.png" width="909"></p> 
<p></p> 
<p>上图是一个FCN-32s网络的结构图。在这个网络中，图片经过骨干网络（VGG Network）提取特征后，得到长宽缩小32倍的特征图，随后直接将特征图上采样32倍，得到和输入图片一样大小的分割图。</p> 
<p>是不是特别简单直接。别看这个网络设计的这么简单，但确实可以得到分割图。</p> 
<p>当然，因为是直接将特征图上采样32倍，这种方式得到的分割精度不会很高。</p> 
<p>为了提高分割精度，作者还提出将骨干网络的中间层提取出来，与上述分割结果融合，得到最终的输出结果。这样就可以得到FCN-16s, FCN-8s, FCN-4s以及FCN-2s网络。</p> 
<p><img alt="" height="356" src="https://images2.imgbox.com/bf/03/ycAnfRci_o.png" width="924"></p> 
<p>上图展示的是FCN-8s网络，该网络将Pool3和Pool4的输出取出，与FCN-32s的输出结果融合，得到最终的分割图。具体的融合方式见下图：</p> 
<p><img alt="" height="386" src="https://images2.imgbox.com/d1/20/z7HTRTST_o.png" width="845"></p> 
<p>首先将FC7（FCN-32s的输出）上采样2倍，与Pool4输出结果相加，得到与Pool4融合的特征图。随后将这个特征图再上采样2倍，与Pool3层的结果相加，得到融合了Pool4、Pool3信息的特征图。再将这个特征图上采样8倍，经过一个softmax层，就得到了与输入图片一样大小的分割图。因为最终上采样8倍，所以称为FCN-8s。</p> 
<pre><code class="language-python">import numpy as np
import paddle.fluid as fluid
from paddle.fluid.dygraph import to_variable
from paddle.fluid.dygraph import Conv2D
from paddle.fluid.dygraph import Conv2DTranspose
from paddle.fluid.dygraph import Dropout
from paddle.fluid.dygraph import BatchNorm
from paddle.fluid.dygraph import Pool2D
from paddle.fluid.dygraph import Linear
from vgg import VGG16BN


class FCN8s(fluid.dygraph.Layer):#本质上是复杂的basic_model
    def __init__(self, num_classes=59):
        super(FCN8s, self).__init__()#初始化父类
        backbone=VGG16BN(pretrained=False)#选择vgg作为backbone
        #backbone指的是网络的主干网络，对图像进行特征提取（常见的有vggnet，resnet，谷歌的inception），这一部分是整个CV任务的根基
        self.layer1=backbone.layer1#直接从vgg中拿就好了
        self.layer1[0].conv._padding=[100,100]
        self.pool1=Pool2D(pool_size=2,pool_stride=2,ceil_mode=True)#ceil_mode我们应对不同尺寸的输入时取整等操作
        self.layer2=backbone.layer2
        self.pool2=Pool2D(pool_size=2,pool_stride=2,ceil_mode=True)
        self.layer3=backbone.layer3
        self.pool3=Pool2D(pool_size=2,pool_stride=2,ceil_mode=True)
        self.layer4=backbone.layer4
        self.pool4=Pool2D(pool_size=2,pool_stride=2,ceil_mode=True)
        self.layer5=backbone.layer5
        self.pool5=Pool2D(pool_size=2,pool_stride=2,ceil_mode=True)
        #这里我们只取到5,6和7是FC层，我们用conv来替代
        self.fc6=Conv2D(512,4096,7,act='relu')
        self.fc7=Conv2D(4096,4096,1,act='relu')
        self.drop6=Dropout()
        self.drop7=Dropout()
        #score用是把feature map的通道数跟分割图一样
        self.score=Conv2D(4096,num_classes,1)#1X1卷积用来做分割，跟basicmodel中一样
        self.score_pool3=Conv2D(256,num_classes,1)
        self.score_pool4=Conv2D(512,num_classes,1)

        #上采样（2倍、2倍、8倍）
        self.up_output=Conv2DTranspose(num_channels=num_classes,
                                        num_filters=num_classes,
                                        filter_size=4,
                                        stride=2,
                                        bias_attr=False)
        self.up_pool4=Conv2DTranspose(num_channels=num_classes,
                                        num_filters=num_classes,
                                        filter_size=4,
                                        stride=2,
                                        bias_attr=False)   
        self.up_final=Conv2DTranspose(num_channels=num_classes,
                                        num_filters=num_classes,
                                        filter_size=16,
                                        stride=8,
                                        bias_attr=False)                    

    def forward(self,inputs):
        x=self.layer1(inputs)
        x=self.pool1(x)#1/2
        x=self.layer2(x)
        x=self.pool2(x)#1/4
        x=self.layer3(x)
        x=self.pool3(x)#1/8
        pool3=x
        x=self.layer4(x)
        x=self.pool4(x)#1/16
        pool4=x
        x=self.layer5(x)
        x=self.pool5(x)#1/32

        x=self.fc6(x)
        x=self.drop6(x)
        x=self.fc7(x)
        x=self.drop7(x)

        x=self.score(x)#做分割图按类别数的1X1卷积
        x=self.up_output(x)#上采样2倍

        up_output=x#变成了1/16的feature map
        x=self.score_pool4(pool4)#变成与分割类别数一样的feature map

        x = x[:, :, 5:5+up_output.shape[2], 5:5+up_output.shape[3]]#相加之前做padding（实际为clop），主要目的是为了让模型的尺寸shape一样

        up_pool4 = x                # 保存和类别数通道一致的pool4
        x = up_pool4 + up_output    # FC7上采样后 + pool4，目的：融合更多的通道信息 
        x = self.up_pool4(x)        # 再一次上采样：2 × （2 × FC7 + pool4）
        up_pool4 = x                # 保存 2 × （2 × FC7 + pool4）

        x = self.score_pool3(pool3) # 把pool3的feature map的通道变成和分割类别数一致

        x = x[:, :, 9:9+up_pool4.shape[2], 9:9+up_pool4.shape[3]]   # padding，其中5、9、31是根据论文的设置的，0也可以
        up_pool3=x # 1/8          # 保存和类别数通道一致的pool3
        x=up_pool3+up_pool4 # pool3 + 2 × （2 × FC7 + pool4）
        x = self.up_final(x) # 最终的8倍上采样：8 × （pool3 + 2 × （2 × FC7 + pool4））

        x = x[:, :, 31:31+inputs.shape[2], 31:31+inputs.shape[3]]

        return x

def main():
    with fluid.dygraph.guard():
        x_data = np.random.rand(2, 3, 512, 512).astype(np.float32)
        x = to_variable(x_data)
        model = FCN8s(num_classes=59)
        model.eval()
        pred = model(x)
        print(pred.shape)


if __name__ == '__main__':
    main()</code></pre> 
<p></p> 
<p style="margin-left:.0001pt;text-align:justify;">上采样的三个操作：</p> 
<p style="margin-left:.0001pt;text-align:justify;">1、unsample</p> 
<p style="margin-left:.0001pt;text-align:justify;">看到unsample或者interpolate要反应过来是将feature map变大</p> 
<p style="margin-left:.0001pt;text-align:justify;">双线性插值：</p> 
<pre><code class="language-python">#上采样——双线性插值法


import paddle.fluid as fluid
import numpy as np
np.set_printoptions(precision=2)

def main():
    with fluid.dygraph.guard(fluid.CPUPlace()):#调用paddle动态图
        data=np.array([1,2],#输入数据，把2x2的图放大到4x4
                      [3,4]).astype(np.float32)
        data=data[np.newaxis,np.newaxis,:,:]#把np.array的维度变为符合我们深度学习框架用的
        #tensor一般是四维，很少有五维
        data=fluid.dygraph.to_variable(data)#放到cpu或者gpu上去
        out=fluid.layers.interpolate(data,out_shape=(4,4),aligin_corners=True)
        #输入的是我们的数据也就是1x1x2x2的data,这里我们把他放大到4x4
        out=out.numpy()#从cpu上拿回来转为numpy
        print(out.squeeze((0,1)))#去掉newaxis</code></pre> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p>2、Unpooling</p> 
<p style="margin-left:.0001pt;text-align:justify;">Pooling的反向操作</p> 
<p style="margin-left:.0001pt;text-align:justify;"><img alt="" height="424" src="https://images2.imgbox.com/e9/7a/laPGMspx_o.png" width="692"></p> 
<p> 3、Transpose conv</p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"><img alt="" height="374" src="https://images2.imgbox.com/b8/a2/6jWTVNoV_o.png" width="692"></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;">卷积的原理：</p> 
<p style="margin-left:.0001pt;text-align:justify;"><img alt="" height="369" src="https://images2.imgbox.com/ee/2a/8pZvWw5z_o.png" width="693"> 反卷积：</p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p> <img alt="" height="520" src="https://images2.imgbox.com/33/b0/oaXDdTO6_o.png" width="641"></p> 
<p style="margin-left:.0001pt;text-align:justify;">stride是卷积核移动的距离</p> 
<p style="margin-left:.0001pt;text-align:justify;">总结：三个方法都是用来将feature map变大</p> 
<p style="margin-left:.0001pt;text-align:justify;"><img alt="" height="330" src="https://images2.imgbox.com/2d/ce/lGe49X8R_o.png" width="692"></p> 
<p></p> 
<p></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/83422ec8f44b6a594002f1de8d939c83/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">因果推断-重要概念：ATE/CATE/ITE/ATT</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/9c630fc6699551958708e124c160d2ab/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Qt编译mysql驱动-总结</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程爱好者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151260"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>