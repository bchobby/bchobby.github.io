<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Lasso回归 - 编程爱好者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Lasso回归" />
<meta property="og:description" content="维数灾难 高维数据 何谓高维数据？高维数据指数据的维度很高，甚至远大于样本量的个数。高维数据的明显的表现是：在空间中数据是非常稀疏的，与空间的维数相比样本量总是显得非常少。 在分析高维数据过程中碰到最大的问题就是维数的膨胀，也就是通常所说的“维数灾难”问题。研究表明，随着维数的增长，分析所需的空间样本数会呈指数增长。 如下所示，当数据空间维度由1增加为3，最明显的变化是其所需样本增加；换言之，当样本量确定时，样本密度将会降低，从而样本呈稀疏状态。假设样本量n=12,单个维度宽度为3，那在一维空间下，样本密度为12/3=4，在二维空间下，样本分布空间大小为3*3，则样本密度为12/9=1.33，在三维空间下样本密度为12/27=0.44。 设想一下，当数据空间为更高维时，X=[ x1 x 1 , x2 x 2 ,…., xn x n ]会怎么样？ 需要更多的样本，样本随着数据维度的增加呈指数型增长；数据变得更稀疏，导致数据灾难；在高维数据空间，预测将变得不再容易；导致模型过拟合。 维数灾难在分类问题中的体现 具体例子可以参考 机器学习:分类问题中的“维数灾难”
数据降维 对于高维数据，维数灾难所带来的过拟合问题，其解决思路是：1）增加样本量；2）减少样本特征，而对于现实情况，会存在所能获取到的样本数据量有限的情况，甚至远小于数据维度，即：d&gt;&gt;n。如证券市场交易数据、多媒体图形图像视频数据、航天航空采集数据、生物特征数据等。 主成分分析作为一种数据降维方法，其出发点是通过整合原本的单一变量来得到一组新的综合变量，综合变量所代表的意义丰富且变量间互不相关，综合变量包含了原变量大部分的信息，这些综合变量称为主成分。主成分分析是在保留所有原变量的基础上，通过原变量的线性组合得到主成分，选取少数主成分就可保留原变量的绝大部分信息，这样就可用这几个主成分来代替原变量，从而达到降维的目的。
但是，主成分分析法只适用于数据空间维度小于样本量的情况，当数据空间维度很高时，将不再适用。
Lasso是另一种数据降维方法，该方法不仅适用于线性情况，也适用于非线性情况。Lasso是基于惩罚方法对样本数据进行变量选择，通过对原本的系数进行压缩，将原本很小的系数直接压缩至0，从而将这部分系数所对应的变量视为非显著性变量，将不显著的变量直接舍弃。
Lasso回归 普通线性模型 惩罚方法 Lasso方法 Ridge方法 图形比较 以二维数据空间为例，说明lasso和Ridge两种方法的差异，左图对应于Lasso方法，右图对应于Ridge方法。 如上图所示，两个图是对应于两种方法的等高线与约束域。红色的椭圆代表的是随着 λ λ 的变化所得到的残差平方和， βˆ β ^ 为椭圆的中心点，为对应普通线性模型的最小二乘估计。左右两个图的区别在于约束域，即对应的蓝色区域。 等高线和约束域的切点就是目标函数的最优解，Ridge方法对应的约束域是圆，其切点只会存在于圆周上，不会与坐标轴相切，则在任一维度上的取值都不为0，因此没有稀疏；对于Lasso方法,其约束域是正方形，会存在与坐标轴的切点，使得部分维度特征权重为0，因此很容易产生稀疏的结果。 所以，Lasso方法可以达到变量选择的效果，将不显著的变量系数压缩至0，而Ridge方法虽然也对原本的系数进行了一定程度的压缩，但是任一系数都不会压缩至0，最终模型保留了所有的变量。
代码块 #加载模块 import numpy as np import matplotlib.pyplot as plt import time from sklearn.linear_model import Lasso from sklearn.metrics import r2_score from sklearn.linear_model import LassoCV from sklearn." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bchobby.github.io/posts/c2cfc45d55a2e67669b6892d2c41d71b/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2018-06-10T18:02:52+08:00" />
<meta property="article:modified_time" content="2018-06-10T18:02:52+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程爱好者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程爱好者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Lasso回归</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h3 id="维数灾难">维数灾难</h3> 
<h5 id="高维数据">高维数据</h5> 
<p>何谓高维数据？高维数据指数据的维度很高，甚至远大于样本量的个数。高维数据的明显的表现是：在空间中数据是非常稀疏的，与空间的维数相比样本量总是显得非常少。 <br> 在分析高维数据过程中碰到最大的问题就是维数的膨胀，也就是通常所说的<strong>“维数灾难”</strong>问题。研究表明，随着维数的增长，分析所需的空间样本数会呈指数增长。 <br> 如下所示，当数据空间维度由1增加为3，最明显的变化是其所需样本增加；换言之，当样本量确定时，样本密度将会降低，从而样本呈稀疏状态。假设样本量n=12,单个维度宽度为3，那在一维空间下，样本密度为12/3=4，在二维空间下，样本分布空间大小为3*3，则样本密度为12/9=1.33，在三维空间下样本密度为12/27=0.44。 <br> <strong>设想一下，当数据空间为更高维时，X=[<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-1-Frame" tabindex="0" style="position: relative;"> 
    
    <span class="math" id="MathJax-Span-1" style="width: 1.201em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.992em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.565em, 1000.99em, 2.451em, -999.997em); top: -2.133em; left: 0em;"><span class="mrow" id="MathJax-Span-2"><span class="msubsup" id="MathJax-Span-3"><span style="display: inline-block; position: relative; width: 0.992em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-4" style="font-family: MathJax_Math-italic;">x</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.576em;"><span class="mn" id="MathJax-Span-5" style="font-size: 70.7%; font-family: MathJax_Main;">1</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.138em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 0.816em;"></span></span> 
   <span class="MJX_Assistive_MathML"> 
     
      
      
        x 
       
      
        1 
       
      
    </span></span><script type="math/tex" id="MathJax-Element-1">x_1</script>,<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-2-Frame" tabindex="0" style="position: relative;"> 
    
    <span class="math" id="MathJax-Span-6" style="width: 1.201em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.992em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.565em, 1000.99em, 2.451em, -999.997em); top: -2.133em; left: 0em;"><span class="mrow" id="MathJax-Span-7"><span class="msubsup" id="MathJax-Span-8"><span style="display: inline-block; position: relative; width: 0.992em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-9" style="font-family: MathJax_Math-italic;">x</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.576em;"><span class="mn" id="MathJax-Span-10" style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.138em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 0.816em;"></span></span> 
   <span class="MJX_Assistive_MathML"> 
     
      
      
        x 
       
      
        2 
       
      
    </span></span><script type="math/tex" id="MathJax-Element-2">x_2</script>,….,<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-3-Frame" tabindex="0" style="position: relative;"> 
    
    <span class="math" id="MathJax-Span-11" style="width: 1.357em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.096em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.565em, 1001.1em, 2.451em, -999.997em); top: -2.133em; left: 0em;"><span class="mrow" id="MathJax-Span-12"><span class="msubsup" id="MathJax-Span-13"><span style="display: inline-block; position: relative; width: 1.096em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-14" style="font-family: MathJax_Math-italic;">x</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.576em;"><span class="mi" id="MathJax-Span-15" style="font-size: 70.7%; font-family: MathJax_Math-italic;">n</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.138em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 0.878em;"></span></span> 
   <span class="MJX_Assistive_MathML"> 
     
      
      
        x 
       
      
        n 
       
      
    </span></span><script type="math/tex" id="MathJax-Element-3">x_n</script>]会怎么样？</strong> <br> <img src="https://images2.imgbox.com/be/71/Yv2VfRqA_o.png" alt="样本数据维度由一维增加为三维" title=""></p> 
<ol><li>需要更多的样本，样本随着数据维度的增加呈指数型增长；</li><li>数据变得更稀疏，导致数据灾难；</li><li>在高维数据空间，预测将变得不再容易；</li><li>导致模型过拟合。</li></ol> 
<h5 id="维数灾难在分类问题中的体现">维数灾难在分类问题中的体现</h5> 
<p>具体例子可以参考 <a href="https://www.linuxidc.com/Linux/2016-01/127857.htm" rel="nofollow">机器学习:分类问题中的“维数灾难”</a></p> 
<h3 id="数据降维">数据降维</h3> 
<p>对于高维数据，维数灾难所带来的过拟合问题，其解决思路是：1）增加样本量；2）减少样本特征，而对于现实情况，会存在所能获取到的样本数据量有限的情况，甚至远小于数据维度，即：d&gt;&gt;n。如证券市场交易数据、多媒体图形图像视频数据、航天航空采集数据、生物特征数据等。 <br> 主成分分析作为一种数据降维方法，其出发点是通过整合原本的单一变量来得到一组新的综合变量，综合变量所代表的意义丰富且变量间互不相关，综合变量包含了原变量大部分的信息，这些综合变量称为主成分。主成分分析是在保留所有原变量的基础上，通过原变量的线性组合得到主成分，选取少数主成分就可保留原变量的绝大部分信息，这样就可用这几个主成分来代替原变量，从而达到降维的目的。</p> 
<p><strong>但是，主成分分析法只适用于数据空间维度小于样本量的情况，当数据空间维度很高时，将不再适用。</strong></p> 
<p>Lasso是另一种数据降维方法，该方法不仅适用于线性情况，也适用于非线性情况。Lasso是基于惩罚方法对样本数据进行变量选择，通过对原本的系数进行压缩，将原本很小的系数直接压缩至0，从而将这部分系数所对应的变量视为非显著性变量，将不显著的变量直接舍弃。</p> 
<h3 id="lasso回归">Lasso回归</h3> 
<h5 id="普通线性模型">普通线性模型</h5> 
<p><img src="https://images2.imgbox.com/46/64/ERTIkRKZ_o.png" alt="这里写图片描述" title=""></p> 
<h5 id="惩罚方法">惩罚方法</h5> 
<p><img src="https://images2.imgbox.com/3a/02/KarkOobr_o.png" alt="这里写图片描述" title=""></p> 
<h5 id="lasso方法">Lasso方法</h5> 
<p><img src="https://images2.imgbox.com/4e/56/07Eb65aZ_o.png" alt="这里写图片描述" title=""></p> 
<h5 id="ridge方法">Ridge方法</h5> 
<p><img src="https://images2.imgbox.com/ac/b5/Zl8zthx9_o.png" alt="这里写图片描述" title=""> <br> <img src="https://images2.imgbox.com/22/53/cFORuqPx_o.png" alt="这里写图片描述" title=""></p> 
<h5 id="图形比较">图形比较</h5> 
<p><img src="https://images2.imgbox.com/93/0a/VbPUnLob_o.png" alt="这里写图片描述" title=""> <br> 以二维数据空间为例，说明lasso和Ridge两种方法的差异，左图对应于Lasso方法，右图对应于Ridge方法。 <br> 如上图所示，两个图是对应于两种方法的等高线与约束域。红色的椭圆代表的是随着<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-4-Frame" tabindex="0" style="position: relative;"> 
   
   <span class="math" id="MathJax-Span-16" style="width: 0.732em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.305em, 1000.52em, 2.294em, -999.997em); top: -2.133em; left: 0em;"><span class="mrow" id="MathJax-Span-17"><span class="mi" id="MathJax-Span-18" style="font-family: MathJax_Math-italic;">λ</span></span><span style="display: inline-block; width: 0px; height: 2.138em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.003em;"></span></span> 
  <span class="MJX_Assistive_MathML"> 
    
    
      λ 
     
   </span></span><script type="math/tex" id="MathJax-Element-4"> \lambda</script>的变化所得到的残差平方和，<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-5-Frame" tabindex="0" style="position: relative;"> 
   
   <span class="math" id="MathJax-Span-19" style="width: 0.836em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(0.94em, 1000.68em, 2.503em, -999.997em); top: -2.133em; left: 0em;"><span class="mrow" id="MathJax-Span-20"><span class="texatom" id="MathJax-Span-21"><span class="mrow" id="MathJax-Span-22"><span class="munderover" id="MathJax-Span-23"><span style="display: inline-block; position: relative; width: 0.68em; height: 0px;"><span style="position: absolute; clip: rect(3.128em, 1000.58em, 4.378em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-24" style="font-family: MathJax_Math-italic;">β<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.128em, 1000.58em, 3.596em, -999.997em); top: -4.268em; left: 0.107em;"><span class="mo" id="MathJax-Span-25" style=""><span style="font-family: MathJax_Size1;">ˆ</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.138em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.566em;"></span></span> 
  <span class="MJX_Assistive_MathML"> 
    
     
      
      
        β 
       
      
        ^ 
       
      
     
   </span></span><script type="math/tex" id="MathJax-Element-5">\widehat{\beta}</script>为椭圆的中心点，为对应普通线性模型的最小二乘估计。左右两个图的区别在于约束域，即对应的蓝色区域。 <br> 等高线和约束域的切点就是目标函数的最优解，Ridge方法对应的约束域是圆，其切点只会存在于圆周上，不会与坐标轴相切，则在任一维度上的取值都不为0，因此没有稀疏；对于Lasso方法,其约束域是正方形，会存在与坐标轴的切点，使得部分维度特征权重为0，因此很容易产生稀疏的结果。 <br> 所以，Lasso方法可以达到变量选择的效果，将不显著的变量系数压缩至0，而Ridge方法虽然也对原本的系数进行了一定程度的压缩，但是任一系数都不会压缩至0，最终模型保留了所有的变量。</p> 
<h4 id="代码块">代码块</h4> 
<pre class="prettyprint"><code class="language-python hljs "><span class="hljs-comment">#加载模块</span>
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> time
<span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> Lasso
<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> r2_score
<span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LassoCV
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split

<span class="hljs-comment"># 生成稀疏样本数据</span>
np.random.seed(int(time.time()))

<span class="hljs-comment"># 生成系数数据，样本为50个，参数为300维</span>
n_samples, n_features = <span class="hljs-number">50</span>, <span class="hljs-number">300</span>

<span class="hljs-comment"># 模拟服从正态分布的样本数据</span>
X = np.random.randn(n_samples, n_features)

<span class="hljs-comment"># 每个变量对应的系数</span>
coef = <span class="hljs-number">2</span> * np.random.randn(n_features)

<span class="hljs-comment"># 变量的下标</span>
inds = np.arange(n_features)

<span class="hljs-comment"># 变量下标随机排列</span>
np.random.shuffle(inds)

<span class="hljs-comment"># 仅仅保留10个变量的系数，其他系数全部设置为0,生成稀疏参数</span>
coef[inds[<span class="hljs-number">10</span>:]] = <span class="hljs-number">0</span>

<span class="hljs-comment"># 得到目标值，y</span>
y = np.dot(X, coef)

<span class="hljs-comment"># 为y添加噪声</span>
y += <span class="hljs-number">0.01</span> * np.random.normal((n_samples,))

<span class="hljs-comment"># 将数据分为训练集和测试集</span>
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=<span class="hljs-number">0.25</span>,random_state=<span class="hljs-number">14</span>)

<span class="hljs-comment"># LassoCV: 基于坐标下降法的Lasso交叉验证,这里使用20折交叉验证法选择最佳alpha</span>
print(<span class="hljs-string">"使用坐标轴下降法计算参数正则化路径:"</span>)
model = LassoCV(cv=<span class="hljs-number">20</span>).fit(X, y)

<span class="hljs-comment"># 最终alpha的结果，因为有的alpha实在是太小了，所以使用负对数形式表示</span>
m_log_alphas = -np.log10(model.alphas_)

<span class="hljs-string">"""
由于这里使用的是20折交叉验证,所以model.mse_path_有20列；
model.mse_path_中每一列，是对应交叉验证，在alpha选择不同值的时候，其对应的均方误差（mean square error）；
模型最终选择的alpha是所有交叉验证结果的平均值中，最小的那个平均的均方误差对应的alpha。
"""</span>

<span class="hljs-comment"># 作出交叉验证不同的alpha取值对应的MSE的轨迹图</span>

plt.figure()
ymin, ymax = <span class="hljs-number">500</span>, <span class="hljs-number">1500</span>
plt.plot(m_log_alphas, model.mse_path_, <span class="hljs-string">':'</span>)
plt.plot(m_log_alphas, model.mse_path_.mean(axis=-<span class="hljs-number">1</span>), <span class="hljs-string">'k'</span>,
         label=<span class="hljs-string">'Average across the folds'</span>, linewidth=<span class="hljs-number">2</span>)
plt.axvline(-np.log10(model.alpha_), linestyle=<span class="hljs-string">'--'</span>, color=<span class="hljs-string">'k'</span>,
            label=<span class="hljs-string">'alpha: CV estimate'</span>)

plt.legend()
plt.xlabel(<span class="hljs-string">'-log(alpha)'</span>)
plt.ylabel(<span class="hljs-string">'Mean square error'</span>)
plt.title(<span class="hljs-string">'Mean square error on each fold: coordinate descent'</span>)
plt.axis(<span class="hljs-string">'tight'</span>)
plt.ylim(ymin, ymax)

<span class="hljs-comment"># Lasso 回归的参数</span>
alpha = model.alpha_
lasso = Lasso(max_iter=<span class="hljs-number">10000</span>, alpha=alpha)

<span class="hljs-comment"># 基于训练数据，得到的模型的测试结果,这里使用的是坐标轴下降算法（coordinate descent）</span>
y_pred_lasso = lasso.fit(X_train, y_train).predict(X_test)

<span class="hljs-comment"># 这里是R2可决系数（coefficient of determination）</span>
<span class="hljs-comment"># 回归平方和（RSS）在总变差（TSS）中所占的比重称为可决系数</span>
<span class="hljs-comment"># 可决系数可以作为综合度量回归模型对样本观测值拟合优度的度量指标。</span>
<span class="hljs-comment"># 可决系数越大，说明在总变差中由模型作出了解释的部分占的比重越大，模型拟合优度越好。</span>
<span class="hljs-comment"># 反之可决系数小，说明模型对样本观测值的拟合程度越差。</span>
<span class="hljs-comment"># R2可决系数最好的效果是1。</span>
r2_score_lasso = r2_score(y_test, y_pred_lasso)

print(<span class="hljs-string">"测试集上的R2可决系数 :{:2f}"</span> .format(r2_score_lasso))

plt.plot(lasso.coef_, label=<span class="hljs-string">'Lasso coefficients'</span>)
plt.plot(coef, <span class="hljs-string">'--'</span>, label=<span class="hljs-string">'original coefficients'</span>)
plt.legend(loc=<span class="hljs-string">'best'</span>)

plt.show()

</code></pre>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/f3d3e79a7741e21e42a5ad6754d7bfe6/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">嵌入式测试大赛实例解析</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/1331ea513b2d40b135ead3653697b350/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">windows下配置apache&#43;php环境</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程爱好者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151260"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>