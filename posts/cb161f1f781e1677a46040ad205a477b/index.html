<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>高光谱图像分类--HybridSN: Exploring 3-D–2-DCNN Feature Hierarchy for Hyperspectral Image Classification - 编程爱好者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="高光谱图像分类--HybridSN: Exploring 3-D–2-DCNN Feature Hierarchy for Hyperspectral Image Classification" />
<meta property="og:description" content="《HybridSN: Exploring 3-D–2-DCNN Feature Hierarchy for Hyperspectral Image Classification》
S. K. Roy, G. Krishna, S. R. Dubey, B. B. Chaudhuri HybridSN: Exploring 3-D–2-D CNN Feature Hierarchy for Hyperspectral Image Classification, IEEE GRSL 2020
这篇论文构建了一个 混合网络 （3D卷积&#43;2D卷积）解决高光谱图像分类问题。
Q:3D卷积和2D卷积的区别?
首先两者都是多通道卷积，而3D卷积比2D卷积多一个深度信息，本质上是一样的，因为2D卷积可以默认深度信息为1。
2D卷积 shape：(batch_size, channel, height, weight)
3D卷积shape：(batch_size, channel, depth, height, weight)
模型网络结构 三维卷积部分：
conv1：（1, 30, 25, 25）， 8个 7x3x3 的卷积核 ==&gt;（8, 24, 23, 23）
conv2：（8, 24, 23, 23）， 16个 5x3x3 的卷积核 ==&gt;（16, 20, 21, 21）" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bchobby.github.io/posts/cb161f1f781e1677a46040ad205a477b/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-01-04T15:54:19+08:00" />
<meta property="article:modified_time" content="2021-01-04T15:54:19+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程爱好者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程爱好者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">高光谱图像分类--HybridSN: Exploring 3-D–2-DCNN Feature Hierarchy for Hyperspectral Image Classification</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p><strong>《HybridSN: Exploring 3-D–2-DCNN Feature Hierarchy for Hyperspectral Image Classification》</strong></p> 
<p>S. K. Roy, G. Krishna, S. R. Dubey, B. B. Chaudhuri HybridSN: Exploring 3-D–2-D CNN Feature Hierarchy for Hyperspectral Image Classification, IEEE GRSL 2020</p> 
<p><strong>这篇论文构建了一个 混合网络 （3D卷积+2D卷积）解决高光谱图像分类问题。</strong><br> <strong>Q:3D卷积和2D卷积的区别?</strong><br> 首先两者都是多通道卷积，而3D卷积比2D卷积多一个深度信息，本质上是一样的，因为2D卷积可以默认深度信息为1。<br> 2D卷积 shape：(batch_size, channel, height, weight)<br> 3D卷积shape：(batch_size, channel, depth, height, weight)</p> 
<h2><a id="_10"></a>模型网络结构</h2> 
<p><img src="https://images2.imgbox.com/48/48/O9YufcrO_o.png" alt="在这里插入图片描述"></p> 
<p><strong>三维卷积部分：</strong><br> conv1：（1, 30, 25, 25）， 8个 7x3x3 的卷积核 ==&gt;（8, 24, 23, 23）<br> conv2：（8, 24, 23, 23）， 16个 5x3x3 的卷积核 ==&gt;（16, 20, 21, 21）<br> conv3：（16, 20, 21, 21），32个 3x3x3 的卷积核 ==&gt;（32, 18, 19, 19）<br> <strong>二维卷积</strong><br> 把前面的 32*18 reshape 一下，得到 （576, 19, 19）<br> 接下来是一个 flatten 操作，变为 18496 维的向量<br> 接下来依次为256，128节点的全连接层，都使用比例为0.4的 Dropout<br> 最后输出为 16 个节点，是最终的分类类别数</p> 
<h3><a id="_23"></a>网络结构</h3> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">HybridSN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token builtin">super</span><span class="token punctuation">(</span>HybridSN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>conv3d_1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
        nn<span class="token punctuation">.</span>Conv3d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>BatchNorm3d<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>conv3d_2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
        nn<span class="token punctuation">.</span>Conv3d<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>BatchNorm3d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span> 
    self<span class="token punctuation">.</span>conv3d_3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
        nn<span class="token punctuation">.</span>Conv3d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>BatchNorm3d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>

    self<span class="token punctuation">.</span>conv2d_4 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
        nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">576</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">18496</span><span class="token punctuation">,</span><span class="token number">256</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token number">128</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>fc3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span><span class="token number">16</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.4</span><span class="token punctuation">)</span>

  <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    out <span class="token operator">=</span> self<span class="token punctuation">.</span>conv3d_1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    out <span class="token operator">=</span> self<span class="token punctuation">.</span>conv3d_2<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
    out <span class="token operator">=</span> self<span class="token punctuation">.</span>conv3d_3<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
    out <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2d_4<span class="token punctuation">(</span>out<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>out<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">19</span><span class="token punctuation">,</span><span class="token number">19</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    out <span class="token operator">=</span> out<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>out<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
    out <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>out<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    out <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>out<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    out <span class="token operator">=</span> self<span class="token punctuation">.</span>fc3<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
    <span class="token keyword">return</span> out
</code></pre> 
<h3><a id="_65"></a>开始训练</h3> 
<pre><code class="prism language-python"><span class="token comment"># 使用GPU训练，可以在菜单 "代码执行工具" -&gt; "更改运行时类型" 里进行设置</span>
device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda:0"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span>

<span class="token comment"># 网络放到GPU上</span>
net <span class="token operator">=</span> HybridSN<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span>

<span class="token comment"># 开始训练</span>
total_loss <span class="token operator">=</span> <span class="token number">0</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
        inputs <span class="token operator">=</span> inputs<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        <span class="token comment"># 优化器梯度归零</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 正向传播 +　反向传播 + 优化 </span>
        outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        total_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'[Epoch: %d]   [loss avg: %.4f]   [current loss: %.4f]'</span> <span class="token operator">%</span><span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> total_loss<span class="token operator">/</span><span class="token punctuation">(</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Finished Training'</span><span class="token punctuation">)</span>
</code></pre> 
<blockquote> 
 <p>[Epoch: 1] [loss avg: 19.6715] [current loss: 1.9873]<br> [Epoch: 2] [loss avg: 15.6281] [current loss: 1.0401]<br> [Epoch: 3] [loss avg: 13.1159] [current loss: 0.8418]<br> [Epoch: 4] [loss avg: 11.2389] [current loss: 0.5678]<br> [Epoch: 5] [loss avg: 9.6885] [current loss: 0.3103]<br> [Epoch: 6] [loss avg: 8.4845] [current loss: 0.2024]<br> [Epoch: 7] [loss avg: 7.5417] [current loss: 0.1180]<br> [Epoch: 8] [loss avg: 6.7961] [current loss: 0.2098]<br> [Epoch: 9] [loss avg: 6.1619] [current loss: 0.2179]<br> [Epoch: 10] [loss avg: 5.6341] [current loss: 0.0968]<br> [Epoch: 11] [loss avg: 5.1822] [current loss: 0.1244]<br> [Epoch: 12] [loss avg: 4.7971] [current loss: 0.0295]<br> [Epoch: 13] [loss avg: 4.4596] [current loss: 0.0777]<br> [Epoch: 14] [loss avg: 4.1665] [current loss: 0.0476]<br> [Epoch: 15] [loss avg: 3.9178] [current loss: 0.0910]<br> [Epoch: 16] [loss avg: 3.6988] [current loss: 0.0331]<br> [Epoch: 17] [loss avg: 3.5068] [current loss: 0.0327]<br> [Epoch: 18] [loss avg: 3.3333] [current loss: 0.0324]<br> [Epoch: 19] [loss avg: 3.1683] [current loss: 0.0548]<br> [Epoch: 20] [loss avg: 3.0232] [current loss: 0.0196]<br> [Epoch: 21] [loss avg: 2.8877] [current loss: 0.0215]<br> [Epoch: 22] [loss avg: 2.7742] [current loss: 0.0244]<br> [Epoch: 23] [loss avg: 2.6641] [current loss: 0.0139]<br> [Epoch: 24] [loss avg: 2.5632] [current loss: 0.0097]<br> [Epoch: 26] [loss avg: 2.3853] [current loss: 0.0657]<br> [Epoch: 27] [loss avg: 2.3084] [current loss: 0.0164]<br> [Epoch: 28] [loss avg: 2.2347] [current loss: 0.0143]<br> [Epoch: 29] [loss avg: 2.1671] [current loss: 0.0189]<br> [Epoch: 30] [loss avg: 2.1063] [current loss: 0.0331]<br> [Epoch: 31] [loss avg: 2.0429] [current loss: 0.0220]<br> [Epoch: 32] [loss avg: 1.9878] [current loss: 0.0173]<br> [Epoch: 33] [loss avg: 1.9329] [current loss: 0.0154]<br> [Epoch: 34] [loss avg: 1.8801] [current loss: 0.0306]<br> [Epoch: 35] [loss avg: 1.8305] [current loss: 0.0442]<br> [Epoch: 36] [loss avg: 1.7823] [current loss: 0.0077]<br> [Epoch: 37] [loss avg: 1.7399] [current loss: 0.0359]<br> [Epoch: 38] [loss avg: 1.6970] [current loss: 0.0004]<br> [Epoch: 39] [loss avg: 1.6546] [current loss: 0.0198]<br> [Epoch: 40] [loss avg: 1.6153] [current loss: 0.0126]<br> [Epoch: 41] [loss avg: 1.5795] [current loss: 0.0608]<br> [Epoch: 42] [loss avg: 1.5454] [current loss: 0.0296]<br> [Epoch: 43] [loss avg: 1.5121] [current loss: 0.0053]<br> [Epoch: 44] [loss avg: 1.4795] [current loss: 0.0325]<br> [Epoch: 45] [loss avg: 1.4492] [current loss: 0.0058]<br> [Epoch: 46] [loss avg: 1.4193] [current loss: 0.0130]<br> [Epoch: 47] [loss avg: 1.3904] [current loss: 0.0055]<br> [Epoch: 48] [loss avg: 1.3622] [current loss: 0.0013]<br> [Epoch: 49] [loss avg: 1.3354] [current loss: 0.0110]<br> [Epoch: 50] [loss avg: 1.3093] [current loss: 0.0041]<br> [Epoch: 51] [loss avg: 1.2845] [current loss: 0.0004]<br> [Epoch: 52] [loss avg: 1.2607] [current loss: 0.0028]<br> [Epoch: 53] [loss avg: 1.2375] [current loss: 0.0109]<br> [Epoch: 54] [loss avg: 1.2150] [current loss: 0.0010]<br> [Epoch: 55] [loss avg: 1.1934] [current loss: 0.0008]<br> [Epoch: 56] [loss avg: 1.1725] [current loss: 0.0011]<br> [Epoch: 57] [loss avg: 1.1524] [current loss: 0.0044]<br> [Epoch: 58] [loss avg: 1.1331] [current loss: 0.0012]<br> [Epoch: 59] [loss avg: 1.1151] [current loss: 0.0092]<br> [Epoch: 60] [loss avg: 1.0982] [current loss: 0.0035]<br> [Epoch: 61] [loss avg: 1.0822] [current loss: 0.0062]<br> [Epoch: 62] [loss avg: 1.0671] [current loss: 0.0412]<br> [Epoch: 63] [loss avg: 1.0517] [current loss: 0.0006]<br> [Epoch: 64] [loss avg: 1.0367] [current loss: 0.0206]<br> [Epoch: 65] [loss avg: 1.0213] [current loss: 0.0052]<br> [Epoch: 66] [loss avg: 1.0071] [current loss: 0.0027]<br> [Epoch: 67] [loss avg: 0.9940] [current loss: 0.0268]<br> [Epoch: 68] [loss avg: 0.9807] [current loss: 0.0500]<br> [Epoch: 69] [loss avg: 0.9686] [current loss: 0.0058]<br> [Epoch: 70] [loss avg: 0.9561] [current loss: 0.0032]<br> [Epoch: 71] [loss avg: 0.9454] [current loss: 0.0004]<br> [Epoch: 72] [loss avg: 0.9352] [current loss: 0.0764]<br> [Epoch: 73] [loss avg: 0.9268] [current loss: 0.0020]<br> [Epoch: 74] [loss avg: 0.9178] [current loss: 0.0977]<br> [Epoch: 75] [loss avg: 0.9097] [current loss: 0.0547]<br> [Epoch: 76] [loss avg: 0.8997] [current loss: 0.0115]<br> [Epoch: 77] [loss avg: 0.8921] [current loss: 0.0407]<br> [Epoch: 78] [loss avg: 0.8830] [current loss: 0.0063]<br> [Epoch: 79] [loss avg: 0.8748] [current loss: 0.0147]<br> [Epoch: 80] [loss avg: 0.8664] [current loss: 0.0070]<br> [Epoch: 81] [loss avg: 0.8570] [current loss: 0.0042]<br> [Epoch: 82] [loss avg: 0.8473] [current loss: 0.0022]<br> [Epoch: 83] [loss avg: 0.8382] [current loss: 0.0274]<br> [Epoch: 84] [loss avg: 0.8300] [current loss: 0.0600]<br> [Epoch: 85] [loss avg: 0.8209] [current loss: 0.0004]<br> [Epoch: 86] [loss avg: 0.8125] [current loss: 0.0008]<br> [Epoch: 87] [loss avg: 0.8038] [current loss: 0.0005]<br> [Epoch: 88] [loss avg: 0.7961] [current loss: 0.0016]<br> [Epoch: 89] [loss avg: 0.7889] [current loss: 0.0196]<br> [Epoch: 90] [loss avg: 0.7812] [current loss: 0.0037]<br> [Epoch: 91] [loss avg: 0.7748] [current loss: 0.0013]<br> [Epoch: 92] [loss avg: 0.7674] [current loss: 0.0358]<br> [Epoch: 93] [loss avg: 0.7600] [current loss: 0.0045]<br> [Epoch: 94] [loss avg: 0.7533] [current loss: 0.0483]<br> [Epoch: 95] [loss avg: 0.7462] [current loss: 0.0121]<br> [Epoch: 96] [loss avg: 0.7389] [current loss: 0.0052]<br> [Epoch: 97] [loss avg: 0.7316] [current loss: 0.0117]<br> [Epoch: 98] [loss avg: 0.7260] [current loss: 0.0028]<br> [Epoch: 99] [loss avg: 0.7200] [current loss: 0.0115]<br> [Epoch: 100] [loss avg: 0.7136] [current loss: 0.0001]<br> Finished Training</p> 
</blockquote> 
<h3><a id="_196"></a>模型测试</h3> 
<pre><code class="prism language-python">count <span class="token operator">=</span> <span class="token number">0</span>
<span class="token comment"># 模型测试</span>
<span class="token keyword">for</span> inputs<span class="token punctuation">,</span> _ <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span>
    inputs <span class="token operator">=</span> inputs<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
    outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
    outputs <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> count <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        y_pred_test <span class="token operator">=</span>  outputs
        count <span class="token operator">=</span> <span class="token number">1</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        y_pred_test <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span> <span class="token punctuation">(</span>y_pred_test<span class="token punctuation">,</span> outputs<span class="token punctuation">)</span> <span class="token punctuation">)</span>

<span class="token comment"># 生成分类报告</span>
classification <span class="token operator">=</span> classification_report<span class="token punctuation">(</span>ytest<span class="token punctuation">,</span> y_pred_test<span class="token punctuation">,</span> digits<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>classification<span class="token punctuation">)</span>
</code></pre> 
<pre><code>     precision    recall  f1-score   support
     0.0     0.9444    0.8293    0.8831        41
     1.0     0.9769    0.9525    0.9645      1285
     2.0     0.9723    0.9853    0.9787       747
     3.0     0.9947    0.8779    0.9327       213
     4.0     0.9861    0.9793    0.9827       435
     5.0     0.9877    0.9802    0.9840       657
     6.0     1.0000    0.9600    0.9796        25
     7.0     0.9817    1.0000    0.9908       430
     8.0     0.7727    0.9444    0.8500        18
     9.0     0.9875    0.9909    0.9892       875
    10.0     0.9725    0.9910    0.9816      2210
    11.0     0.9499    0.9588    0.9543       534
    12.0     0.9572    0.9676    0.9624       185
    13.0     0.9887    0.9965    0.9926      1139
    14.0     0.9826    0.9741    0.9783       347
    15.0     0.8933    0.7976    0.8428        84
 accuracy                               0.9767      9225
 macro avg     0.9593    0.9491    0.9529      9225
weighted avg     0.9768    0.9767    0.9765      9225
</code></pre> 
<p>准确率达到了97.67.<br> <strong>Q:通过上文中训练网络，然后多测试几次，会发现每次分类的结果都不一样，请思考为什么？</strong><br> A: 网络的全连接层中使用了 nn.Dropout，网络层的节点会随机失活。因此测试的时候没有启用测试模式。<br> 解决方法：</p> 
<p>训练时：</p> 
<pre><code class="prism language-python">net<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span> 
</code></pre> 
<p>测试时：</p> 
<pre><code class="prism language-python">net<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="_253"></a>显示分类结果</h3> 
<pre><code class="prism language-python"><span class="token comment"># load the original image</span>
X <span class="token operator">=</span> sio<span class="token punctuation">.</span>loadmat<span class="token punctuation">(</span><span class="token string">'Indian_pines_corrected.mat'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">'indian_pines_corrected'</span><span class="token punctuation">]</span>
y <span class="token operator">=</span> sio<span class="token punctuation">.</span>loadmat<span class="token punctuation">(</span><span class="token string">'Indian_pines_gt.mat'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">'indian_pines_gt'</span><span class="token punctuation">]</span>

height <span class="token operator">=</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
width <span class="token operator">=</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>

X <span class="token operator">=</span> applyPCA<span class="token punctuation">(</span>X<span class="token punctuation">,</span> numComponents<span class="token operator">=</span> pca_components<span class="token punctuation">)</span>
X <span class="token operator">=</span> padWithZeros<span class="token punctuation">(</span>X<span class="token punctuation">,</span> patch_size<span class="token operator">//</span><span class="token number">2</span><span class="token punctuation">)</span>

<span class="token comment"># 逐像素预测类别</span>
outputs <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>height<span class="token punctuation">,</span>width<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>height<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>width<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> <span class="token builtin">int</span><span class="token punctuation">(</span>y<span class="token punctuation">[</span>i<span class="token punctuation">,</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">continue</span>
        <span class="token keyword">else</span> <span class="token punctuation">:</span>
            image_patch <span class="token operator">=</span> X<span class="token punctuation">[</span>i<span class="token punctuation">:</span>i<span class="token operator">+</span>patch_size<span class="token punctuation">,</span> j<span class="token punctuation">:</span>j<span class="token operator">+</span>patch_size<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
            image_patch <span class="token operator">=</span> image_patch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>image_patch<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>image_patch<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> image_patch<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
            X_test_image <span class="token operator">=</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span>image_patch<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>                                   
            prediction <span class="token operator">=</span> net<span class="token punctuation">(</span>X_test_image<span class="token punctuation">)</span>
            prediction <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>prediction<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
            outputs<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">=</span> prediction<span class="token operator">+</span><span class="token number">1</span>
    <span class="token keyword">if</span> i <span class="token operator">%</span> <span class="token number">20</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'... ... row '</span><span class="token punctuation">,</span> i<span class="token punctuation">,</span> <span class="token string">' handling ... ...'</span><span class="token punctuation">)</span>
</code></pre> 
<blockquote> 
 <p>… … row 0 handling … …<br> … … row 20 handling … …<br> … … row 40 handling … …<br> … … row 60 handling … …<br> … … row 80 handling … …<br> … … row 100 handling … …<br> … … row 120 handling … …<br> … … row 140 handling … …</p> 
</blockquote> 
<pre><code class="prism language-python">predict_image <span class="token operator">=</span> spectral<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>classes <span class="token operator">=</span> outputs<span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">)</span><span class="token punctuation">,</span>figsize <span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>原始代码结果：<br> <img src="https://images2.imgbox.com/de/85/LhtlRaKL_o.png" alt="在这里插入图片描述"><br> 增加训练测试模式代码结果：<br> <img src="https://images2.imgbox.com/76/f4/SauiJo1P_o.png" alt="在这里插入图片描述"></p> 
<p>可以看出分类效果也明显变好了。</p> 
<h3><a id="_301"></a>加入注意力机制</h3> 
<p><strong>Q:如果想要进一步提升高光谱图像的分类性能，可以如何使用注意力机制?</strong></p> 
<pre><code class="prism language-python">class_num <span class="token operator">=</span> <span class="token number">16</span>
<span class="token comment"># 通道注意力机制</span>
<span class="token keyword">class</span> <span class="token class-name">ChannelAttention</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_planes<span class="token punctuation">,</span> ratio<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>ChannelAttention<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>avg_pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>AdaptiveAvgPool2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>max_pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
 
        self<span class="token punctuation">.</span>fc1   <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_planes<span class="token punctuation">,</span> in_planes <span class="token operator">//</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>relu1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc2   <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_planes <span class="token operator">//</span> <span class="token number">16</span><span class="token punctuation">,</span> in_planes<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
 
        self<span class="token punctuation">.</span>sigmoid <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>
 
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        avg_out <span class="token operator">=</span> self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>self<span class="token punctuation">.</span>relu1<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>self<span class="token punctuation">.</span>avg_pool<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        max_out <span class="token operator">=</span> self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>self<span class="token punctuation">.</span>relu1<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>self<span class="token punctuation">.</span>max_pool<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        out <span class="token operator">=</span> avg_out <span class="token operator">+</span> max_out
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
        
<span class="token comment"># 空间注意力机制</span>
<span class="token keyword">class</span> <span class="token class-name">SpatialAttention</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>SpatialAttention<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
 
        <span class="token keyword">assert</span> kernel_size <span class="token keyword">in</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'kernel size must be 3 or 7'</span>
        padding <span class="token operator">=</span> <span class="token number">3</span> <span class="token keyword">if</span> kernel_size <span class="token operator">==</span> <span class="token number">7</span> <span class="token keyword">else</span> <span class="token number">1</span>
 
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> kernel_size<span class="token punctuation">,</span> padding<span class="token operator">=</span>padding<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>sigmoid <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>
 
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        avg_out <span class="token operator">=</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>x<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        max_out<span class="token punctuation">,</span> _ <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>avg_out<span class="token punctuation">,</span> max_out<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

<span class="token keyword">class</span> <span class="token class-name">HybridSN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_classes<span class="token punctuation">,</span> self_attention<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token builtin">super</span><span class="token punctuation">(</span>HybridSN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>conv3d_1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
        nn<span class="token punctuation">.</span>Conv3d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>BatchNorm3d<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>
    
    self<span class="token punctuation">.</span>self_attention <span class="token operator">=</span> self_attention   <span class="token comment">#默认</span>
    
    self<span class="token punctuation">.</span>conv3d_2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
        nn<span class="token punctuation">.</span>Conv3d<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>BatchNorm3d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span> 
    self<span class="token punctuation">.</span>conv3d_3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
        nn<span class="token punctuation">.</span>Conv3d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>BatchNorm3d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>

    <span class="token keyword">if</span> self_attention<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>channel_attention_1 <span class="token operator">=</span> ChannelAttention<span class="token punctuation">(</span><span class="token number">576</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>spatial_attention_1 <span class="token operator">=</span> SpatialAttention<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">)</span>

    self<span class="token punctuation">.</span>conv2d_4 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
        nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">576</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>

    <span class="token keyword">if</span> self_attention<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>channel_attention_1 <span class="token operator">=</span> ChannelAttention<span class="token punctuation">(</span><span class="token number">576</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>spatial_attention_1 <span class="token operator">=</span> SpatialAttention<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">)</span>
    
    self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">18496</span><span class="token punctuation">,</span><span class="token number">256</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token number">128</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>fc3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span><span class="token number">16</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.4</span><span class="token punctuation">)</span>

  <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    out <span class="token operator">=</span> self<span class="token punctuation">.</span>conv3d_1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    out <span class="token operator">=</span> self<span class="token punctuation">.</span>conv3d_2<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
    out <span class="token operator">=</span> self<span class="token punctuation">.</span>conv3d_3<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
    out <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2d_4<span class="token punctuation">(</span>out<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>out<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">19</span><span class="token punctuation">,</span><span class="token number">19</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    out <span class="token operator">=</span> out<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>out<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
    out <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>out<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    out <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>out<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    out <span class="token operator">=</span> self<span class="token punctuation">.</span>fc3<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
    <span class="token keyword">return</span> out 

<span class="token comment"># 随机输入，测试网络结构是否通</span>
<span class="token comment"># x = torch.randn(1, 1, 30, 25, 25)</span>
<span class="token comment"># net = HybridSN()</span>
<span class="token comment"># y = net(x)</span>
<span class="token comment"># print(y.shape)</span>
</code></pre> 
<p>测试准确率明显提高到了 98.51<br> <img src="https://images2.imgbox.com/1b/65/E0eIJaC1_o.png" alt="在这里插入图片描述"><br> 结果图片：<br> <img src="https://images2.imgbox.com/27/84/sEOha2Zh_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/16b8eb6b04f96d7d7133b891519a2b04/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Spring Cloud Alibaba-在nacos环境下整合dubbo</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/c9350b2bc9b068c2faa61f409b422d1e/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">MATLAB函数  zp2tf详解</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程爱好者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151260"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>