<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>äº’è”ç½‘åŠ ç«èµ› åŸºäºCNNå®ç°è°£è¨€æ£€æµ‹ - python æ·±åº¦å­¦ä¹  æœºå™¨å­¦ä¹  - ç¼–ç¨‹çˆ±å¥½è€…åšå®¢</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="äº’è”ç½‘åŠ ç«èµ› åŸºäºCNNå®ç°è°£è¨€æ£€æµ‹ - python æ·±åº¦å­¦ä¹  æœºå™¨å­¦ä¹ " />
<meta property="og:description" content="æ–‡ç« ç›®å½• 1 å‰è¨€1.1 èƒŒæ™¯ 2 æ•°æ®é›†3 å®ç°è¿‡ç¨‹4 CNNç½‘ç»œå®ç°5 æ¨¡å‹è®­ç»ƒéƒ¨åˆ†6 æ¨¡å‹è¯„ä¼°7 é¢„æµ‹ç»“æœ8 æœ€å 1 å‰è¨€ ğŸ”¥ ä¼˜è´¨ç«èµ›é¡¹ç›®ç³»åˆ—ï¼Œä»Šå¤©è¦åˆ†äº«çš„æ˜¯
åŸºäºCNNå®ç°è°£è¨€æ£€æµ‹
è¯¥é¡¹ç›®è¾ƒä¸ºæ–°é¢–ï¼Œé€‚åˆä½œä¸ºç«èµ›è¯¾é¢˜æ–¹å‘ï¼Œå­¦é•¿éå¸¸æ¨èï¼
ğŸ§¿ æ›´å¤šèµ„æ–™, é¡¹ç›®åˆ†äº«ï¼š
https://gitee.com/dancheng-senior/postgraduate
1.1 èƒŒæ™¯ ç¤¾äº¤åª’ä½“çš„å‘å±•åœ¨åŠ é€Ÿä¿¡æ¯ä¼ æ’­çš„åŒæ—¶ï¼Œä¹Ÿå¸¦æ¥äº†è™šå‡è°£è¨€ä¿¡æ¯çš„æ³›æ»¥ï¼Œå¾€å¾€ä¼šå¼•å‘è¯¸å¤šä¸å®‰å®šå› ç´ ï¼Œå¹¶å¯¹ç»æµå’Œç¤¾ä¼šäº§ç”Ÿå·¨å¤§çš„å½±å“ã€‚
2 æ•°æ®é›† æœ¬é¡¹ç›®æ‰€ä½¿ç”¨çš„æ•°æ®æ˜¯ä»æ–°æµªå¾®åšä¸å®ä¿¡æ¯ä¸¾æŠ¥å¹³å°æŠ“å–çš„ä¸­æ–‡è°£è¨€æ•°æ®ï¼Œæ•°æ®é›†ä¸­å…±åŒ…å«1538æ¡è°£è¨€å’Œ1849æ¡éè°£è¨€ã€‚
å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œæ¯æ¡æ•°æ®å‡ä¸ºjsonæ ¼å¼ï¼Œå…¶ä¸­textå­—æ®µä»£è¡¨å¾®åšåŸæ–‡çš„æ–‡å­—å†…å®¹ã€‚
æ¯ä¸ªæ–‡ä»¶å¤¹é‡Œåˆæœ‰å¾ˆå¤šæ–°é—»æ–‡æœ¬ã€‚
æ¯ä¸ªæ–‡æœ¬åˆæ˜¯jsonæ ¼å¼ï¼Œå…·ä½“å†…å®¹å¦‚ä¸‹ï¼š
3 å®ç°è¿‡ç¨‹ æ­¥éª¤å…¥ä¸‹ï¼š
*ï¼ˆ1ï¼‰è§£å‹æ•°æ®ï¼Œè¯»å–å¹¶è§£ææ•°æ®ï¼Œç”Ÿæˆall_data.txt
*ï¼ˆ2ï¼‰ç”Ÿæˆæ•°æ®å­—å…¸ï¼Œå³dict.txt
*ï¼ˆ3ï¼‰ç”Ÿæˆæ•°æ®åˆ—è¡¨ï¼Œå¹¶è¿›è¡Œè®­ç»ƒé›†ä¸éªŒè¯é›†çš„åˆ’åˆ†ï¼Œtrain_list.txt ã€eval_list.txt
*ï¼ˆ4ï¼‰å®šä¹‰è®­ç»ƒæ•°æ®é›†æä¾›å™¨train_readerå’ŒéªŒè¯æ•°æ®é›†æä¾›å™¨eval_reader
import zipfile import os import io import random import json import matplotlib.pyplot as plt import numpy as np import paddle import paddle.fluid as fluid from paddle.fluid.dygraph.nn import Conv2D, Linear, Embedding from paddle." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bchobby.github.io/posts/cf6239453bd40bb62d1b1e0261a29ccc/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-29T15:29:14+08:00" />
<meta property="article:modified_time" content="2023-12-29T15:29:14+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="ç¼–ç¨‹çˆ±å¥½è€…åšå®¢" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">ç¼–ç¨‹çˆ±å¥½è€…åšå®¢</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">äº’è”ç½‘åŠ ç«èµ› åŸºäºCNNå®ç°è°£è¨€æ£€æµ‹ - python æ·±åº¦å­¦ä¹  æœºå™¨å­¦ä¹ </h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>æ–‡ç« ç›®å½•</h4> 
 <ul><li><a href="#1__3" rel="nofollow">1 å‰è¨€</a></li><li><ul><li><a href="#11__15" rel="nofollow">1.1 èƒŒæ™¯</a></li></ul> 
  </li><li><a href="#2__19" rel="nofollow">2 æ•°æ®é›†</a></li><li><a href="#3__34" rel="nofollow">3 å®ç°è¿‡ç¨‹</a></li><li><a href="#4_CNN_254" rel="nofollow">4 CNNç½‘ç»œå®ç°</a></li><li><a href="#5__362" rel="nofollow">5 æ¨¡å‹è®­ç»ƒéƒ¨åˆ†</a></li><li><a href="#6__425" rel="nofollow">6 æ¨¡å‹è¯„ä¼°</a></li><li><a href="#7__469" rel="nofollow">7 é¢„æµ‹ç»“æœ</a></li><li><a href="#8__510" rel="nofollow">8 æœ€å</a></li></ul> 
</div> 
<p></p> 
<h2><a id="1__3"></a>1 å‰è¨€</h2> 
<p>ğŸ”¥ ä¼˜è´¨ç«èµ›é¡¹ç›®ç³»åˆ—ï¼Œä»Šå¤©è¦åˆ†äº«çš„æ˜¯</p> 
<p><strong>åŸºäºCNNå®ç°è°£è¨€æ£€æµ‹</strong></p> 
<p>è¯¥é¡¹ç›®è¾ƒä¸ºæ–°é¢–ï¼Œé€‚åˆä½œä¸ºç«èµ›è¯¾é¢˜æ–¹å‘ï¼Œå­¦é•¿éå¸¸æ¨èï¼</p> 
<p>ğŸ§¿ <strong>æ›´å¤šèµ„æ–™, é¡¹ç›®åˆ†äº«ï¼š</strong></p> 
<p><a href="https://gitee.com/dancheng-senior/postgraduate" rel="nofollow">https://gitee.com/dancheng-senior/postgraduate</a></p> 
<h3><a id="11__15"></a>1.1 èƒŒæ™¯</h3> 
<p>ç¤¾äº¤åª’ä½“çš„å‘å±•åœ¨åŠ é€Ÿä¿¡æ¯ä¼ æ’­çš„åŒæ—¶ï¼Œä¹Ÿå¸¦æ¥äº†è™šå‡è°£è¨€ä¿¡æ¯çš„æ³›æ»¥ï¼Œå¾€å¾€ä¼šå¼•å‘è¯¸å¤šä¸å®‰å®šå› ç´ ï¼Œå¹¶å¯¹ç»æµå’Œç¤¾ä¼šäº§ç”Ÿå·¨å¤§çš„å½±å“ã€‚</p> 
<h2><a id="2__19"></a>2 æ•°æ®é›†</h2> 
<p>æœ¬é¡¹ç›®æ‰€ä½¿ç”¨çš„æ•°æ®æ˜¯ä»æ–°æµªå¾®åšä¸å®ä¿¡æ¯ä¸¾æŠ¥å¹³å°æŠ“å–çš„ä¸­æ–‡è°£è¨€æ•°æ®ï¼Œæ•°æ®é›†ä¸­å…±åŒ…å«1538æ¡è°£è¨€å’Œ1849æ¡éè°£è¨€ã€‚</p> 
<p>å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œæ¯æ¡æ•°æ®å‡ä¸ºjsonæ ¼å¼ï¼Œå…¶ä¸­textå­—æ®µä»£è¡¨å¾®åšåŸæ–‡çš„æ–‡å­—å†…å®¹ã€‚</p> 
<p><img src="https://images2.imgbox.com/c3/49/oqV4YlcY_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p>æ¯ä¸ªæ–‡ä»¶å¤¹é‡Œåˆæœ‰å¾ˆå¤šæ–°é—»æ–‡æœ¬ã€‚</p> 
<p><img src="https://images2.imgbox.com/31/1f/FxWsgIIK_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"><br> æ¯ä¸ªæ–‡æœ¬åˆæ˜¯jsonæ ¼å¼ï¼Œå…·ä½“å†…å®¹å¦‚ä¸‹ï¼š</p> 
<p><img src="https://images2.imgbox.com/84/06/PlW1K6KY_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h2><a id="3__34"></a>3 å®ç°è¿‡ç¨‹</h2> 
<p>æ­¥éª¤å…¥ä¸‹ï¼š</p> 
<p>*ï¼ˆ1ï¼‰è§£å‹æ•°æ®ï¼Œè¯»å–å¹¶è§£ææ•°æ®ï¼Œç”Ÿæˆall_data.txt<br> *ï¼ˆ2ï¼‰ç”Ÿæˆæ•°æ®å­—å…¸ï¼Œå³dict.txt<br> *ï¼ˆ3ï¼‰ç”Ÿæˆæ•°æ®åˆ—è¡¨ï¼Œå¹¶è¿›è¡Œè®­ç»ƒé›†ä¸éªŒè¯é›†çš„åˆ’åˆ†ï¼Œtrain_list.txt ã€eval_list.txt<br> *ï¼ˆ4ï¼‰å®šä¹‰è®­ç»ƒæ•°æ®é›†æä¾›å™¨train_readerå’ŒéªŒè¯æ•°æ®é›†æä¾›å™¨eval_reader</p> 
<pre><code>import zipfile
import os
import io
import random
import json
import matplotlib.pyplot as plt
import numpy as np
import paddle
import paddle.fluid as fluid
from paddle.fluid.dygraph.nn import Conv2D, Linear, Embedding
from paddle.fluid.dygraph.base import to_variable

#è§£å‹åŸå§‹æ•°æ®é›†ï¼Œå°†Rumor_Dataset.zipè§£å‹è‡³dataç›®å½•ä¸‹
src_path="/home/aistudio/data/data36807/Rumor_Dataset.zip" #è¿™é‡Œå¡«å†™è‡ªå·±é¡¹ç›®æ‰€åœ¨çš„æ•°æ®é›†è·¯å¾„
target_path="/home/aistudio/data/Chinese_Rumor_Dataset-master"
if(not os.path.isdir(target_path)):
    z = zipfile.ZipFile(src_path, 'r')
    z.extractall(path=target_path)
    z.close()

#åˆ†åˆ«ä¸ºè°£è¨€æ•°æ®ã€éè°£è¨€æ•°æ®ã€å…¨éƒ¨æ•°æ®çš„æ–‡ä»¶è·¯å¾„
rumor_class_dirs = os.listdir(target_path+"éå¼€æºæ•°æ®é›†") # è¿™é‡Œå¡«å†™è‡ªå·±é¡¹ç›®æ‰€åœ¨çš„æ•°æ®é›†è·¯å¾„
non_rumor_class_dirs = os.listdir(target_path+"éå¼€æºæ•°æ®é›†")
original_microblog = target_path+"éå¼€æºæ•°æ®é›†"
#è°£è¨€æ ‡ç­¾ä¸º0ï¼Œéè°£è¨€æ ‡ç­¾ä¸º1
rumor_label="0"
non_rumor_label="1"

#åˆ†åˆ«ç»Ÿè®¡è°£è¨€æ•°æ®ä¸éè°£è¨€æ•°æ®çš„æ€»æ•°
rumor_num = 0
non_rumor_num = 0
all_rumor_list = []
all_non_rumor_list = []

#è§£æè°£è¨€æ•°æ®
for rumor_class_dir in rumor_class_dirs: 
    if(rumor_class_dir != '.DS_Store'):
        #éå†è°£è¨€æ•°æ®ï¼Œå¹¶è§£æ
        with open(original_microblog + rumor_class_dir, 'r') as f:
            rumor_content = f.read()
        rumor_dict = json.loads(rumor_content)
        all_rumor_list.append(rumor_label+"\t"+rumor_dict["text"]+"\n")
        rumor_num +=1
#è§£æéè°£è¨€æ•°æ®
for non_rumor_class_dir in non_rumor_class_dirs: 
    if(non_rumor_class_dir != '.DS_Store'):
        with open(original_microblog + non_rumor_class_dir, 'r') as f2:
            non_rumor_content = f2.read()
        non_rumor_dict = json.loads(non_rumor_content)
        all_non_rumor_list.append(non_rumor_label+"\t"+non_rumor_dict["text"]+"\n")
        non_rumor_num +=1
        
print("è°£è¨€æ•°æ®æ€»é‡ä¸ºï¼š"+str(rumor_num))
print("éè°£è¨€æ•°æ®æ€»é‡ä¸ºï¼š"+str(non_rumor_num))

#å…¨éƒ¨æ•°æ®è¿›è¡Œä¹±åºåå†™å…¥all_data.txt
data_list_path="/home/aistudio/data/"
all_data_path=data_list_path + "all_data.txt"
all_data_list = all_rumor_list + all_non_rumor_list

random.shuffle(all_data_list)

#åœ¨ç”Ÿæˆall_data.txtä¹‹å‰ï¼Œé¦–å…ˆå°†å…¶æ¸…ç©º
with open(all_data_path, 'w') as f:
    f.seek(0)
    f.truncate() 
    
with open(all_data_path, 'a') as f:
    for data in all_data_list:
        f.write(data) 
print('all_data.txtå·²ç”Ÿæˆ')
</code></pre> 
<p>â€‹</p> 
<p><img src="https://images2.imgbox.com/57/9f/Fug9o0eh_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p><strong>æ¥ä¸‹æ¥å°±æ˜¯ç”Ÿæˆæ•°æ®å­—å…¸ã€‚</strong></p> 
<p>â€‹<br> # ç”Ÿæˆæ•°æ®å­—å…¸<br> def create_dict(data_path, dict_path):<br> with open(dict_path, â€˜wâ€™) as f:<br> f.seek(0)<br> f.truncate()</p> 
<pre><code>    dict_set = set()
    # è¯»å–å…¨éƒ¨æ•°æ®
    with open(data_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    # æŠŠæ•°æ®ç”Ÿæˆä¸€ä¸ªå…ƒç»„
    for line in lines:
        content = line.split('\t')[-1].replace('\n', '')
        for s in content:
            dict_set.add(s)
    # æŠŠå…ƒç»„è½¬æ¢æˆå­—å…¸ï¼Œä¸€ä¸ªå­—å¯¹åº”ä¸€ä¸ªæ•°å­—
    dict_list = []
    i = 0
    for s in dict_set:
        dict_list.append([s, i])
        i += 1
    # æ·»åŠ æœªçŸ¥å­—ç¬¦
    dict_txt = dict(dict_list)
    end_dict = {"": i}
    dict_txt.update(end_dict)
    # æŠŠè¿™äº›å­—å…¸ä¿å­˜åˆ°æœ¬åœ°ä¸­
    with open(dict_path, 'w', encoding='utf-8') as f:
        f.write(str(dict_txt))
    print("æ•°æ®å­—å…¸ç”Ÿæˆå®Œæˆï¼",'\t','å­—å…¸é•¿åº¦ä¸ºï¼š',len(dict_list))
</code></pre> 
<p>æˆ‘ä»¬å¯ä»¥æŸ¥çœ‹ä¸€ä¸‹dict_txtçš„å†…å®¹</p> 
<p><img src="https://images2.imgbox.com/d5/d9/AqPYeRnV_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p>æ¥ä¸‹æ¥å°±æ˜¯æ•°æ®åˆ—è¡¨çš„ç”Ÿæˆ</p> 
<p>â€‹<br> # åˆ›å»ºåºåˆ—åŒ–è¡¨ç¤ºçš„æ•°æ®,å¹¶æŒ‰ç…§ä¸€å®šæ¯”ä¾‹åˆ’åˆ†è®­ç»ƒæ•°æ®ä¸éªŒè¯æ•°æ®<br> def create_data_list(data_list_path):</p> 
<pre><code>    with open(os.path.join(data_list_path, 'dict.txt'), 'r', encoding='utf-8') as f_data:
        dict_txt = eval(f_data.readlines()[0])

    with open(os.path.join(data_list_path, 'all_data.txt'), 'r', encoding='utf-8') as f_data:
        lines = f_data.readlines()
    
    i = 0
    with open(os.path.join(data_list_path, 'eval_list.txt'), 'a', encoding='utf-8') as f_eval,\
    open(os.path.join(data_list_path, 'train_list.txt'), 'a', encoding='utf-8') as f_train:
        for line in lines:
            title = line.split('\t')[-1].replace('\n', '')
            lab = line.split('\t')[0]
            t_ids = ""
            if i % 8 == 0:
                for s in title:
                    temp = str(dict_txt[s])
                    t_ids = t_ids + temp + ','
                t_ids = t_ids[:-1] + '\t' + lab + '\n'
                f_eval.write(t_ids)
            else:
                for s in title:
                    temp = str(dict_txt[s])
                    t_ids = t_ids + temp + ','
                t_ids = t_ids[:-1] + '\t' + lab + '\n'
                f_train.write(t_ids)
            i += 1
        
    print("æ•°æ®åˆ—è¡¨ç”Ÿæˆå®Œæˆï¼")
</code></pre> 
<p><strong>å®šä¹‰æ•°æ®è¯»å–å™¨</strong></p> 
<p>â€‹<br> def data_reader(file_path, phrase, shuffle=False):<br> all_data = []<br> with io.open(file_path, â€œrâ€, encoding=â€˜utf8â€™) as fin:<br> for line in fin:<br> cols = line.strip().split(â€œ\tâ€)<br> if len(cols) != 2:<br> continue<br> label = int(cols[1])</p> 
<pre><code>            wids = cols[0].split(",")
            all_data.append((wids, label))

    if shuffle:
        if phrase == "train":
            random.shuffle(all_data)

    def reader():
        for doc, label in all_data:
            yield doc, label
    return reader

class SentaProcessor(object):
    def __init__(self, data_dir,):
        self.data_dir = data_dir
        
    def get_train_data(self, data_dir, shuffle):
        return data_reader((self.data_dir + "train_list.txt"), 
                            "train", shuffle)

    def get_eval_data(self, data_dir, shuffle):
        return data_reader((self.data_dir + "eval_list.txt"), 
                            "eval", shuffle)

    def data_generator(self, batch_size, phase='train', shuffle=True):
        if phase == "train":
            return paddle.batch(
                self.get_train_data(self.data_dir, shuffle),
                batch_size,
                drop_last=True)
        elif phase == "eval":
            return paddle.batch(
                self.get_eval_data(self.data_dir, shuffle),
                batch_size,
                drop_last=True)
        else:
            raise ValueError(
                "Unknown phase, which should be in ['train', 'eval']")
</code></pre> 
<p>æ€»ä¹‹åœ¨æ•°æ®å¤„ç†è¿™ä¸€å—éœ€è¦æˆ‘ä»¬æ³¨æ„çš„æ˜¯ä¸€å…±ç”Ÿæˆä»¥ä¸‹çš„å‡ ä¸ªæ–‡ä»¶ã€‚</p> 
<p><img src="https://images2.imgbox.com/06/fc/0qhuAHkL_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h2><a id="4_CNN_254"></a>4 CNNç½‘ç»œå®ç°</h2> 
<p>æ¥ä¸‹æ¥å°±æ˜¯æ„å»ºä»¥åŠé…ç½®å·ç§¯ç¥ç»ç½‘ç»œ(Convolutional Neural Networks,<br> CNN)ï¼Œå¼€ç¯‡ä¹Ÿè¯´äº†ï¼Œå…¶å®è¿™é‡Œæœ‰å¾ˆå¤šæ¨¡å‹çš„é€‰æ‹©ï¼Œä¹‹æ‰€ä»¥é€‰æ‹©CNNæ˜¯å› ä¸ºè®©æˆ‘ä»¬ç†Ÿæ‚‰CNNçš„ç›¸å…³å®ç°ã€‚ è¾“å…¥è¯å‘é‡åºåˆ—ï¼Œäº§ç”Ÿä¸€ä¸ªç‰¹å¾å›¾ï¼ˆfeature<br> mapï¼‰ï¼Œå¯¹ç‰¹å¾å›¾é‡‡ç”¨æ—¶é—´ç»´åº¦ä¸Šçš„æœ€å¤§æ± åŒ–ï¼ˆmax pooling over<br> timeï¼‰æ“ä½œå¾—åˆ°æ­¤å·ç§¯æ ¸å¯¹åº”çš„æ•´å¥è¯çš„ç‰¹å¾ï¼Œæœ€åï¼Œå°†æ‰€æœ‰å·ç§¯æ ¸å¾—åˆ°çš„ç‰¹å¾æ‹¼æ¥èµ·æ¥å³ä¸ºæ–‡æœ¬çš„å®šé•¿å‘é‡è¡¨ç¤ºï¼Œå¯¹äºæ–‡æœ¬åˆ†ç±»é—®é¢˜ï¼Œå°†å…¶è¿æ¥è‡³softmaxå³æ„å»ºå‡ºå®Œæ•´çš„æ¨¡å‹ã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œæˆ‘ä»¬ä¼šä½¿ç”¨å¤šä¸ªå·ç§¯æ ¸æ¥å¤„ç†å¥å­ï¼Œçª—å£å¤§å°ç›¸åŒçš„å·ç§¯æ ¸å †å èµ·æ¥å½¢æˆä¸€ä¸ªçŸ©é˜µï¼Œè¿™æ ·å¯ä»¥æ›´é«˜æ•ˆçš„å®Œæˆè¿ç®—ã€‚å¦å¤–ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä½¿ç”¨çª—å£å¤§å°ä¸åŒçš„å·ç§¯æ ¸æ¥å¤„ç†å¥å­ã€‚å…·ä½“çš„æµç¨‹å¦‚ä¸‹ï¼š</p> 
<p><img src="https://images2.imgbox.com/29/c6/NKj0JTnu_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"><br> é¦–å…ˆæˆ‘ä»¬æ„å»ºå•å±‚CNNç¥ç»ç½‘ç»œã€‚</p> 
<p>â€‹</p> 
<pre><code class="prism language-python">

    <span class="token comment">#å•å±‚</span>
    <span class="token keyword">class</span> <span class="token class-name">SimpleConvPool</span><span class="token punctuation">(</span>fluid<span class="token punctuation">.</span>dygraph<span class="token punctuation">.</span>Layer<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>
                     num_channels<span class="token punctuation">,</span> <span class="token comment"># é€šé“æ•°</span>
                     num_filters<span class="token punctuation">,</span>  <span class="token comment"># å·ç§¯æ ¸æ•°é‡</span>
                     filter_size<span class="token punctuation">,</span>  <span class="token comment"># å·ç§¯æ ¸å¤§å°</span>
                     batch_size<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment"># 16</span>
            <span class="token builtin">super</span><span class="token punctuation">(</span>SimpleConvPool<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>batch_size <span class="token operator">=</span> batch_size
            self<span class="token punctuation">.</span>_conv2d <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span>num_channels <span class="token operator">=</span> num_channels<span class="token punctuation">,</span>
                num_filters <span class="token operator">=</span> num_filters<span class="token punctuation">,</span>
                filter_size <span class="token operator">=</span> filter_size<span class="token punctuation">,</span>
                act<span class="token operator">=</span><span class="token string">'tanh'</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>_pool2d <span class="token operator">=</span> fluid<span class="token punctuation">.</span>dygraph<span class="token punctuation">.</span>Pool2D<span class="token punctuation">(</span>
                pool_size <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">150</span> <span class="token operator">-</span> filter_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                pool_type <span class="token operator">=</span> <span class="token string">'max'</span><span class="token punctuation">,</span>
                pool_stride<span class="token operator">=</span><span class="token number">1</span>
            <span class="token punctuation">)</span>
    
        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># print('SimpleConvPool_inputsæ•°æ®çº¬åº¦',inputs.shape) # [16, 1, 148, 128]</span>
            x <span class="token operator">=</span> self<span class="token punctuation">.</span>_conv2d<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
            x <span class="token operator">=</span> self<span class="token punctuation">.</span>_pool2d<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
            x <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>x<span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            <span class="token keyword">return</span> x



    <span class="token keyword">class</span> <span class="token class-name">CNN</span><span class="token punctuation">(</span>fluid<span class="token punctuation">.</span>dygraph<span class="token punctuation">.</span>Layer<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token builtin">super</span><span class="token punctuation">(</span>CNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>dict_dim <span class="token operator">=</span> train_parameters<span class="token punctuation">[</span><span class="token string">"vocab_size"</span><span class="token punctuation">]</span>
            self<span class="token punctuation">.</span>emb_dim <span class="token operator">=</span> <span class="token number">128</span>   <span class="token comment">#embçº¬åº¦</span>
            self<span class="token punctuation">.</span>hid_dim <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">32</span><span class="token punctuation">]</span>  <span class="token comment">#å·ç§¯æ ¸æ•°é‡</span>
            self<span class="token punctuation">.</span>fc_hid_dim <span class="token operator">=</span> <span class="token number">96</span>  <span class="token comment">#fcå‚æ•°çº¬åº¦</span>
            self<span class="token punctuation">.</span>class_dim <span class="token operator">=</span> <span class="token number">2</span>    <span class="token comment">#åˆ†ç±»æ•°</span>
            self<span class="token punctuation">.</span>channels <span class="token operator">=</span> <span class="token number">1</span>     <span class="token comment">#è¾“å…¥é€šé“æ•°</span>
            self<span class="token punctuation">.</span>win_size <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">]</span><span class="token punctuation">]</span>  <span class="token comment"># å·ç§¯æ ¸å°ºå¯¸</span>
            self<span class="token punctuation">.</span>batch_size <span class="token operator">=</span> train_parameters<span class="token punctuation">[</span><span class="token string">"batch_size"</span><span class="token punctuation">]</span> 
            self<span class="token punctuation">.</span>seq_len <span class="token operator">=</span> train_parameters<span class="token punctuation">[</span><span class="token string">"padding_size"</span><span class="token punctuation">]</span>
            self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> Embedding<span class="token punctuation">(</span> 
                size<span class="token operator">=</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>dict_dim <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>emb_dim<span class="token punctuation">]</span><span class="token punctuation">,</span>
                dtype<span class="token operator">=</span><span class="token string">'float32'</span><span class="token punctuation">,</span> 
                is_sparse<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>_simple_conv_pool_1 <span class="token operator">=</span> SimpleConvPool<span class="token punctuation">(</span>
                self<span class="token punctuation">.</span>channels<span class="token punctuation">,</span>
                self<span class="token punctuation">.</span>hid_dim<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                self<span class="token punctuation">.</span>win_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                batch_size<span class="token operator">=</span>self<span class="token punctuation">.</span>batch_size<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>_fc1 <span class="token operator">=</span> Linear<span class="token punctuation">(</span>input_dim <span class="token operator">=</span> self<span class="token punctuation">.</span>hid_dim<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                output_dim <span class="token operator">=</span> self<span class="token punctuation">.</span>fc_hid_dim<span class="token punctuation">,</span>
                                act<span class="token operator">=</span><span class="token string">"tanh"</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>_fc_prediction <span class="token operator">=</span> Linear<span class="token punctuation">(</span>input_dim <span class="token operator">=</span> self<span class="token punctuation">.</span>fc_hid_dim<span class="token punctuation">,</span>
                                        output_dim <span class="token operator">=</span> self<span class="token punctuation">.</span>class_dim<span class="token punctuation">,</span>
                                        act<span class="token operator">=</span><span class="token string">"softmax"</span><span class="token punctuation">)</span>
    
        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    
            emb <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span> <span class="token comment"># [2400, 128]</span>
            <span class="token comment"># print('CNN_emb',emb.shape)  </span>
            emb <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>   <span class="token comment"># [16, 1, 150, 128]</span>
                emb<span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>channels <span class="token punctuation">,</span> self<span class="token punctuation">.</span>seq_len<span class="token punctuation">,</span> self<span class="token punctuation">.</span>emb_dim<span class="token punctuation">]</span><span class="token punctuation">)</span>
            <span class="token comment"># print('CNN_emb',emb.shape)</span>
            conv_3 <span class="token operator">=</span> self<span class="token punctuation">.</span>_simple_conv_pool_1<span class="token punctuation">(</span>emb<span class="token punctuation">)</span>
            fc_1 <span class="token operator">=</span> self<span class="token punctuation">.</span>_fc1<span class="token punctuation">(</span>conv_3<span class="token punctuation">)</span>
            prediction <span class="token operator">=</span> self<span class="token punctuation">.</span>_fc_prediction<span class="token punctuation">(</span>fc_1<span class="token punctuation">)</span>
            <span class="token keyword">if</span> label <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                acc <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>accuracy<span class="token punctuation">(</span>prediction<span class="token punctuation">,</span> label<span class="token operator">=</span>label<span class="token punctuation">)</span>
                <span class="token keyword">return</span> prediction<span class="token punctuation">,</span> acc
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                <span class="token keyword">return</span> prediction



</code></pre> 
<p>æ¥ä¸‹æ¥å°±æ˜¯å‚æ•°çš„é…ç½®ï¼Œä¸è¿‡ä¸ºäº†åœ¨æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­æ›´ç›´è§‚çš„æŸ¥çœ‹æˆ‘ä»¬è®­ç»ƒçš„å‡†ç¡®ç‡ï¼Œæˆ‘ä»¬é¦–å…ˆåˆ©ç”¨pythonçš„matplotlib.pypltå‡½æ•°å®ç°ä¸€ä¸ªå¯è§†åŒ–å›¾ï¼Œå…·ä½“çš„å®ç°å¦‚ä¸‹ï¼š</p> 
<p>â€‹<br> def draw_train_process(iters, train_loss, train_accs):<br> title=â€œtraining loss/training accsâ€<br> plt.title(title, fontsize=24)<br> plt.xlabel(â€œiterâ€, fontsize=14)<br> plt.ylabel(â€œloss/accâ€, fontsize=14)<br> plt.plot(iters, train_loss, color=â€˜redâ€™, label=â€˜training lossâ€™)<br> plt.plot(iters, train_accs, color=â€˜greenâ€™, label=â€˜training accsâ€™)<br> plt.legend()<br> plt.grid()<br> plt.show()</p> 
<h2><a id="5__362"></a>5 æ¨¡å‹è®­ç»ƒéƒ¨åˆ†</h2> 
<p>â€‹<br> def train():<br> with fluid.dygraph.guard(place = fluid.CUDAPlace(0)): # å› ä¸ºè¦è¿›è¡Œå¾ˆå¤§è§„æ¨¡çš„è®­ç»ƒï¼Œå› æ­¤æˆ‘ä»¬ç”¨çš„æ˜¯GPUï¼Œå¦‚æœæ²¡æœ‰å®‰è£…GPUçš„å¯ä»¥ä½¿ç”¨ä¸‹é¢ä¸€å¥ï¼ŒæŠŠè¿™å¥ä»£ç æ³¨é‡Šæ‰å³å¯<br> # with fluid.dygraph.guard(place = fluid.CPUPlace()):</p> 
<pre><code>        processor = SentaProcessor( data_dir="data/")
    
        train_data_generator = processor.data_generator(
            batch_size=train_parameters["batch_size"],
            phase='train',
            shuffle=True)
            
        model = CNN()
        sgd_optimizer = fluid.optimizer.Adagrad(learning_rate=train_parameters["adam"],parameter_list=model.parameters())
        steps = 0
        Iters,total_loss, total_acc = [], [], []
        for eop in range(train_parameters["epoch"]):
            for batch_id, data in enumerate(train_data_generator()):
                steps += 1
                #è½¬æ¢ä¸º variable ç±»å‹
                doc = to_variable(
                    np.array([
                        np.pad(x[0][0:train_parameters["padding_size"]],  #å¯¹å¥å­è¿›è¡Œpaddingï¼Œå…¨éƒ¨å¡«è¡¥ä¸ºå®šé•¿150
                              (0, train_parameters["padding_size"] - len(x[0][0:train_parameters["padding_size"]])),
                               'constant',
                              constant_values=(train_parameters["vocab_size"])) # ç”¨  çš„id è¿›è¡Œå¡«è¡¥
                        for x in data
                    ]).astype('int64').reshape(-1))
                #è½¬æ¢ä¸º variable ç±»å‹
                label = to_variable(
                    np.array([x[1] for x in data]).astype('int64').reshape(
                        train_parameters["batch_size"], 1))

                model.train() #ä½¿ç”¨è®­ç»ƒæ¨¡å¼
                prediction, acc = model(doc, label)
                loss = fluid.layers.cross_entropy(prediction, label)
                avg_loss = fluid.layers.mean(loss)
                avg_loss.backward()
                sgd_optimizer.minimize(avg_loss)
                model.clear_gradients()
                
                if steps % train_parameters["skip_steps"] == 0:
                    Iters.append(steps)
                    total_loss.append(avg_loss.numpy()[0])
                    total_acc.append(acc.numpy()[0])
                    print("eop: %d, step: %d, ave loss: %f, ave acc: %f" %
                         (eop, steps,avg_loss.numpy(),acc.numpy()))
                if steps % train_parameters["save_steps"] == 0:
                    save_path = train_parameters["checkpoints"]+"/"+"save_dir_" + str(steps)
                    print('save model to: ' + save_path)
                    fluid.dygraph.save_dygraph(model.state_dict(),
                                                   save_path)
                # break
    draw_train_process(Iters, total_loss, total_acc)
</code></pre> 
<p>è®­ç»ƒçš„è¿‡ç¨‹ä»¥åŠè®­ç»ƒçš„ç»“æœå¦‚ä¸‹ï¼š</p> 
<p><img src="https://images2.imgbox.com/22/38/kGtPP6P9_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h2><a id="6__425"></a>6 æ¨¡å‹è¯„ä¼°</h2> 
<p>â€‹<br> def to_eval():<br> with fluid.dygraph.guard(place = fluid.CUDAPlace(0)):<br> processor = SentaProcessor(data_dir=â€œdata/â€) #å†™è‡ªå·±çš„è·¯å¾„</p> 
<pre><code>        eval_data_generator = processor.data_generator(
                batch_size=train_parameters["batch_size"],
                phase='eval',
                shuffle=False)

        model_eval = CNN() #ç¤ºä¾‹åŒ–æ¨¡å‹
        model, _ = fluid.load_dygraph("data//save_dir_180.pdparams") #å†™è‡ªå·±çš„è·¯å¾„
        model_eval.load_dict(model)

        model_eval.eval() # åˆ‡æ¢ä¸ºevalæ¨¡å¼
        total_eval_cost, total_eval_acc = [], []
        for eval_batch_id, eval_data in enumerate(eval_data_generator()):
            eval_np_doc = np.array([np.pad(x[0][0:train_parameters["padding_size"]],
                                    (0, train_parameters["padding_size"] -len(x[0][0:train_parameters["padding_size"]])),
                                    'constant',
                                    constant_values=(train_parameters["vocab_size"]))
                            for x in eval_data
                            ]).astype('int64').reshape(-1)
            eval_label = to_variable(
                                    np.array([x[1] for x in eval_data]).astype(
                                    'int64').reshape(train_parameters["batch_size"], 1))
            eval_doc = to_variable(eval_np_doc)
            eval_prediction, eval_acc = model_eval(eval_doc, eval_label)
            loss = fluid.layers.cross_entropy(eval_prediction, eval_label)
            avg_loss = fluid.layers.mean(loss)
            total_eval_cost.append(avg_loss.numpy()[0])
            total_eval_acc.append(eval_acc.numpy()[0])

    print("Final validation result: ave loss: %f, ave acc: %f" %
        (np.mean(total_eval_cost), np.mean(total_eval_acc) ))   
</code></pre> 
<p>è¯„ä¼°å‡†ç¡®ç‡å¦‚ä¸‹ï¼š</p> 
<p><img src="https://images2.imgbox.com/bf/93/EjvRapk0_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h2><a id="7__469"></a>7 é¢„æµ‹ç»“æœ</h2> 
<p>â€‹<br> # è·å–æ•°æ®<br> def load_data(sentence):<br> # è¯»å–æ•°æ®å­—å…¸<br> with open(â€˜data/dict.txtâ€™, â€˜râ€™, encoding=â€˜utf-8â€™) as f_data:<br> dict_txt = eval(f_data.readlines()[0])<br> dict_txt = dict(dict_txt)<br> # æŠŠå­—ç¬¦ä¸²æ•°æ®è½¬æ¢æˆåˆ—è¡¨æ•°æ®<br> keys = dict_txt.keys()<br> data = []<br> for s in sentence:<br> # åˆ¤æ–­æ˜¯å¦å­˜åœ¨æœªçŸ¥å­—ç¬¦<br> if not s in keys:<br> s = â€˜â€™<br> data.append(int(dict_txt[s]))<br> return data</p> 
<pre><code>train_parameters["batch_size"] = 1
lab = [ 'è°£è¨€', 'éè°£è¨€']
 
with fluid.dygraph.guard(place = fluid.CUDAPlace(0)):
    
    data = load_data('å…´ä»å¿ä»Šå¤©æŠ¢å°å­©æ²¡æŠ¢èµ°ï¼ŒæŠŠå­©å­æ¯äº²æ…äº†ä¸€åˆ€ï¼Œçœ‹è§è¿™è½¦çš„æ³¨æ„äº†ï¼ŒçœŸäº‹ï¼Œè½¦ç‰Œå·è¾½HFM055ï¼ï¼ï¼ï¼ï¼èµ¶ç´§æ•£æ’­ï¼ éƒ½åˆ«å¸¦å­©å­å‡ºå»çè½¬æ‚ äº† å°¤å…¶åˆ«è®©è€äººè‡ªå·±å¸¦å­©å­å‡ºå» å¤ªå±é™©äº† æ³¨æ„äº†ï¼ï¼ï¼ï¼è¾½HFM055åŒ—äº¬ç°ä»£æœ—åŠ¨ï¼Œåœ¨å„å­¦æ ¡é—¨å£æŠ¢å°å­©ï¼ï¼ï¼110å·²ç» è¯å®ï¼ï¼å…¨å¸‚é€šç¼‰ï¼ï¼')
    data_np = np.array(data)
    data_np = np.array(np.pad(data_np,(0,150-len(data_np)),"constant",constant_values =train_parameters["vocab_size"])).astype('int64').reshape(-1)

    infer_np_doc = to_variable(data_np)
   
    model_infer = CNN()
    model, _ = fluid.load_dygraph("data/save_dir_900.pdparams")
    model_infer.load_dict(model)
    model_infer.eval()
    result = model_infer(infer_np_doc)
    print('é¢„æµ‹ç»“æœä¸ºï¼š', lab[np.argmax(result.numpy())])
</code></pre> 
<p><img src="https://images2.imgbox.com/4c/6f/0osozEQA_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h2><a id="8__510"></a>8 æœ€å</h2> 
<p>ğŸ§¿ <strong>æ›´å¤šèµ„æ–™, é¡¹ç›®åˆ†äº«ï¼š</strong></p> 
<p><a href="https://gitee.com/dancheng-senior/postgraduate" rel="nofollow">https://gitee.com/dancheng-senior/postgraduate</a></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/2d73cce6669c178e825a9f4098ce2fcf/" rel="prev">
			<span class="pager__subtitle">Â«&thinsp;Previous</span>
			<p class="pager__title">Oracleå‡½æ•°ã€è¯¦ç»† &amp;&amp; åŒ…æ‹¬ä¸¾ä¾‹ã€‘</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/5ad3942a5be2cd417787f0302167e9fe/" rel="next">
			<span class="pager__subtitle">Next&thinsp;Â»</span>
			<p class="pager__title">flink generic log-based incremental checkpoints è®¾è®¡</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 ç¼–ç¨‹çˆ±å¥½è€…åšå®¢.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151260"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>