<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>DolphinDB SQL 案例教程 - 编程爱好者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="DolphinDB SQL 案例教程" />
<meta property="og:description" content="本教程重点介绍了一些常见场景下的SQL编写案例，通过优化前后性能对比或正确编写方法介绍，说明DolphinDB SQL脚本的使用技巧，案例共分四类：条件过滤相关案例、分布式表相关案例、分组计算相关案例及元编程相关案例，具体案例可在下方目录快速浏览。
目录
1 测试环境说明
2 条件过滤相关案例
2.1 where 条件子句使用 in 关键字
2.2 分组数据过滤
2.3 where 条件子句使用逗号或 and
2.3.1 过滤条件与序列无关
2.3.2 过滤条件与序列有关
3 分布式表相关案例
3.1 分区剪枝
3.2 GROUP BY并行查询
3.3 分组查询使用 map 关键字
4 分组计算相关案例
4.1 查询最新的 N 条记录
4.2 计算滑动 VWAP
4.3 计算累积 VWAP
4.4 计算 N 股 VWAP
4.5 分段统计股票价格变化率
4.6 计算不同连续区间的最值
4.7 不同聚合方式计算指标
4.8 计算股票收益波动率
4.9 计算股票组合的价值
4.10 根据成交量切分时间窗口
4.11 股票因子归整
4.12 根据交易额统计单子类型
5 元编程相关案例
5.1 动态生成 SQL 语句案例 1" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bchobby.github.io/posts/d39d7c351453d1b5ea8344efc94c997d/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-03-31T14:36:04+08:00" />
<meta property="article:modified_time" content="2022-03-31T14:36:04+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程爱好者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程爱好者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">DolphinDB SQL 案例教程</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p style="text-align:justify;">本教程重点介绍了一些常见场景下的SQL编写案例，通过优化前后性能对比或正确编写方法介绍，说明DolphinDB SQL脚本的使用技巧，案例共分四类：<strong>条件过滤相关案例</strong>、<strong>分布式表相关案例</strong>、<strong>分组计算相关案例</strong>及<strong>元编程相关案例</strong>，具体案例可在下方目录快速浏览。</p> 
<p id="main-toc"><strong>目录</strong></p> 
<p id="h_477025819_0-toc" style="margin-left:40px;"><a href="#h_477025819_0" rel="nofollow">1 测试环境说明</a></p> 
<p id="h_477025819_1-toc" style="margin-left:40px;"><a href="#h_477025819_1" rel="nofollow">2 条件过滤相关案例</a></p> 
<p id="h_477025819_2-toc" style="margin-left:80px;"><a href="#h_477025819_2" rel="nofollow">2.1 where 条件子句使用 in 关键字</a></p> 
<p id="h_477025819_3-toc" style="margin-left:80px;"><a href="#h_477025819_3" rel="nofollow">2.2 分组数据过滤</a></p> 
<p id="h_477025819_4-toc" style="margin-left:80px;"><a href="#h_477025819_4" rel="nofollow">2.3 where 条件子句使用逗号或 and</a></p> 
<p id="h_477025819_5-toc" style="margin-left:80px;"><a href="#h_477025819_5" rel="nofollow">2.3.1 过滤条件与序列无关</a></p> 
<p id="h_477025819_6-toc" style="margin-left:80px;"><a href="#h_477025819_6" rel="nofollow">2.3.2 过滤条件与序列有关</a></p> 
<p id="h_477025819_7-toc" style="margin-left:40px;"><a href="#h_477025819_7" rel="nofollow">3 分布式表相关案例</a></p> 
<p id="h_477025819_8-toc" style="margin-left:80px;"><a href="#h_477025819_8" rel="nofollow">3.1 分区剪枝</a></p> 
<p id="h_477025819_9-toc" style="margin-left:80px;"><a href="#h_477025819_9" rel="nofollow">3.2 GROUP BY并行查询</a></p> 
<p id="h_477025819_10-toc" style="margin-left:80px;"><a href="#h_477025819_10" rel="nofollow">3.3 分组查询使用 map 关键字</a></p> 
<p id="h_477025819_11-toc" style="margin-left:40px;"><a href="#h_477025819_11" rel="nofollow">4 分组计算相关案例</a></p> 
<p id="h_477025819_12-toc" style="margin-left:80px;"><a href="#h_477025819_12" rel="nofollow">4.1 查询最新的 N 条记录</a></p> 
<p id="h_477025819_13-toc" style="margin-left:80px;"><a href="#h_477025819_13" rel="nofollow">4.2 计算滑动 VWAP</a></p> 
<p id="h_477025819_14-toc" style="margin-left:80px;"><a href="#h_477025819_14" rel="nofollow">4.3 计算累积 VWAP</a></p> 
<p id="h_477025819_15-toc" style="margin-left:80px;"><a href="#h_477025819_15" rel="nofollow">4.4 计算 N 股 VWAP</a></p> 
<p id="h_477025819_16-toc" style="margin-left:80px;"><a href="#h_477025819_16" rel="nofollow">4.5 分段统计股票价格变化率</a></p> 
<p id="h_477025819_17-toc" style="margin-left:80px;"><a href="#h_477025819_17" rel="nofollow">4.6 计算不同连续区间的最值</a></p> 
<p id="h_477025819_18-toc" style="margin-left:80px;"><a href="#h_477025819_18" rel="nofollow">4.7 不同聚合方式计算指标</a></p> 
<p id="h_477025819_19-toc" style="margin-left:80px;"><a href="#h_477025819_19" rel="nofollow">4.8 计算股票收益波动率</a></p> 
<p id="h_477025819_20-toc" style="margin-left:80px;"><a href="#h_477025819_20" rel="nofollow">4.9 计算股票组合的价值</a></p> 
<p id="h_477025819_21-toc" style="margin-left:80px;"><a href="#h_477025819_21" rel="nofollow">4.10 根据成交量切分时间窗口</a></p> 
<p id="h_477025819_22-toc" style="margin-left:80px;"><a href="#h_477025819_22" rel="nofollow">4.11 股票因子归整</a></p> 
<p id="h_477025819_23-toc" style="margin-left:80px;"><a href="#h_477025819_23" rel="nofollow">4.12 根据交易额统计单子类型</a></p> 
<p id="h_477025819_24-toc" style="margin-left:40px;"><a href="#h_477025819_24" rel="nofollow">5 元编程相关案例</a></p> 
<p id="h_477025819_25-toc" style="margin-left:80px;"><a href="#h_477025819_25" rel="nofollow">5.1 动态生成 SQL 语句案例 1</a></p> 
<p id="h_477025819_26-toc" style="margin-left:80px;"><a href="#h_477025819_26" rel="nofollow">5.2 动态生成 SQL 语句案例 2</a></p> 
<hr id="hr-toc"> 
<p></p> 
<h3 id="h_477025819_0"><strong>1 测试环境说明</strong></h3> 
<p>处理器：Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz</p> 
<p>核数：64</p> 
<p>内存：512 GB</p> 
<p>操作系统：CentOS Linux release 7.9</p> 
<p>License：免费版License，CPU 2核，内存 8GB</p> 
<p>DolphinDB Server 版本：DolphinDB_Linux64_V2.00.4，单节点模式部署</p> 
<p>DolphinDB GUI 版本：DolphinDB_GUI_V1.30.15</p> 
<p>以下章节案例中所用到的2020年06月测试数据为上交所 Level-1 快照数据，基于真实数据结构模拟2000只股票快照数据，基于 OLAP 与 TSDB 存储引擎的建库建表、数据模拟、数据插入脚本如下：</p> 
<pre><code class="language-cpp">model = table(1:0, `SecurityID`DateTime`PreClosePx`OpenPx`HighPx`LowPx`LastPx`Volume`Amount`BidPrice1`BidPrice2`BidPrice3`BidPrice4`BidPrice5`BidOrderQty1`BidOrderQty2`BidOrderQty3`BidOrderQty4`BidOrderQty5`OfferPrice1`OfferPrice2`OfferPrice3`OfferPrice4`OfferPrice5`OfferQty1`OfferQty2`OfferQty3`OfferQty4`OfferQty5, [SYMBOL, DATETIME, DOUBLE, DOUBLE, DOUBLE, DOUBLE, DOUBLE, LONG, DOUBLE, DOUBLE, DOUBLE, DOUBLE, DOUBLE, DOUBLE, LONG, LONG, LONG, LONG, LONG, DOUBLE, DOUBLE, DOUBLE, DOUBLE, DOUBLE, LONG, LONG, LONG, LONG, LONG])
​
// OLAP 存储引擎建库建表
dbDate = database("", VALUE, 2020.06.01..2020.06.07)
dbSecurityID = database("", HASH, [SYMBOL, 10])
db = database("dfs://Level1", COMPO, [dbDate, dbSecurityID])
createPartitionedTable(db, model, `Snapshot, `DateTime`SecurityID)
​
// TSDB 存储引擎建库建表
dbDate = database("", VALUE, 2020.06.01..2020.06.07)
dbSymbol = database("", HASH, [SYMBOL, 10])
db = database("dfs://Level1_TSDB", COMPO, [dbDate, dbSymbol], engine="TSDB")
createPartitionedTable(db, model, `Snapshot, `DateTime`SecurityID, sortColumns=`SecurityID`DateTime)
​
def mockHalfDayData(Date, StartTime) {
    t_SecurityID = table(format(600001..602000, "000000") + ".SH" as SecurityID)
    t_DateTime = table(concatDateTime(Date, StartTime + 1..2400 * 3) as DateTime)
    t = cj(t_SecurityID, t_DateTime)
    size = t.size()
    return  table(t.SecurityID as SecurityID, t.DateTime as DateTime, rand(100.0, size) as PreClosePx, rand(100.0, size) as OpenPx, rand(100.0, size) as HighPx, rand(100.0, size) as LowPx, rand(100.0, size) as LastPx, rand(10000, size) as Volume, rand(100000.0, size) as Amount, rand(100.0, size) as BidPrice1, rand(100.0, size) as BidPrice2, rand(100.0, size) as BidPrice3, rand(100.0, size) as BidPrice4, rand(100.0, size) as BidPrice5, rand(100000, size) as BidOrderQty1, rand(100000, size) as BidOrderQty2, rand(100000, size) as BidOrderQty3, rand(100000, size) as BidOrderQty4, rand(100000, size) as BidOrderQty5, rand(100.0, size) as OfferPrice1, rand(100.0, size) as OfferPrice2, rand(100.0, size) as OfferPrice3, rand(100.0, size) as OfferPrice4, rand(100.0, size) as OfferPrice5, rand(100000, size) as OfferQty1, rand(100000, size) as OfferQty2, rand(100000, size) as OfferQty3, rand(100000, size) as OfferQty4, rand(100000, size) as OfferQty5)
}
​
def mockData(DateVector, StartTimeVector) {
    for(Date in DateVector) {
        for(StartTime in StartTimeVector) {
            data = mockHalfDayData(Date, StartTime)
​
            // OLAP 存储引擎分布式表插入模拟数据
            loadTable("dfs://Level1", "Snapshot").append!(data)
​
            // TSDB 存储引擎分布式表插入模拟数据
            loadTable("dfs://Level1_TSDB", "Snapshot").append!(data)
        }
    }
}
​
mockData(2020.06.01..2020.06.02, 09:30:00 13:00:00)
</code></pre> 
<h3 id="h_477025819_1"><strong>2 条件过滤相关案例</strong></h3> 
<p>where 条件子句包含一个或多个条件表达式，根据表达式指定的过滤条件，可以过滤出满足需求的记录。</p> 
<p>条件表达式中可以使用 DolphinDB 内置函数，如聚合、序列、向量函数，也可以使用用户自定义函数。需要注意的是，DolphinDB 不支持在分布式查询的 where 子句中使用聚合函数，如sum、count。因为执行聚合函数之前，分布式查询需要通过 where 子句来筛选相关分区的数据，达到分区剪枝的效果，减少查询耗时。如果聚合函数出现在where子句中，则分布式查询不能缩窄相关分区范围。</p> 
<h4 id="h_477025819_2"><strong>2.1 where 条件子句使用 in 关键字</strong></h4> 
<p><strong>场景：数据表 t1 含有股票的某些信息，数据表 t2 含有股票的行业信息，需要根据股票的行业信息进行过滤。</strong></p> 
<p>首先，载入测试数据库中的表 “Snapshot” 赋给变量 t1，并模拟构建行业信息数据表 t2，示例如下：</p> 
<pre><code class="language-cpp">t1 = loadTable("dfs://Level1", "Snapshot")
SecurityIDs = exec distinct SecurityID from t1 where date(DateTime) = 2020.06.01
t2 = table(SecurityIDs as SecurityID, 
           take(`Mul`IoT`Eco`Csm`Edu`Food, SecurityIDs.size()) as Industry)
</code></pre> 
<p><strong>优化前：</strong></p> 
<p>将数据表 t1 与数据表 t2 根据 SecurityID 字段进行 left join，然后指定 where 条件进行过滤，示例如下：</p> 
<pre><code class="language-cpp">timer res1 = select SecurityID, DateTime 
             from lj(t1, t2, `SecurityID) 
             where date(DateTime) = 2020.06.01, Industry=`Edu
</code></pre> 
<p><strong>查询耗时 336 ms。</strong></p> 
<p>需要注意的是，以上脚本中的 <a href="https://link.zhihu.com/?target=https%3A//www.dolphindb.cn/cn/help/200/ProgrammingStatements/timer.html" rel="nofollow" title="timer">timer</a> 函数通常用于计算一行或一段脚本的执行时间，该时间指的是脚本在 DolphinDB Server 端的运行耗时，而不包括脚本运行结果集返回到客户端的耗时。若结果集数据量过大，序列化/反序列化以及网络传输的耗时可能会远远超过脚本在服务器上的运行耗时。</p> 
<p><strong>优化后：</strong></p> 
<p>从数据表 t2 获取行业为 “Edu” 的股票代码向量，并使用 in 关键字指定条件范围，示例如下：</p> 
<pre><code class="language-cpp">SecurityIDs = exec SecurityID from t2 where Industry="Edu"
timer res2 = select SecurityID, DateTime 
             from t1 
             where date(DateTime) = 2020.06.01, SecurityID in SecurityIDs
</code></pre> 
<p><strong>查询耗时 72 ms。</strong></p> 
<pre><code class="language-cpp">each(eqObj, res1.values(), res2.values()) // true
</code></pre> 
<p>each 函数对表的每列分别通过 eqObj 比较，返回均为 true，说明优化前后返回的结果相同。但与优化前写法相比，优化后写法查询性能提升约4倍。这是因为，在 SQL 语句中，表连接的耗时远高于 where 子句中的过滤条件的耗时，因此在能够使用字典或 in 关键字的情况下应避免使用 join。</p> 
<h4 id="h_477025819_3"><strong>2.2 分组数据过滤</strong></h4> 
<p><strong>场景：截取单日全市场股票交易快照数据，筛选出每只股票交易量最大的前 25% 的记录。</strong></p> 
<p>首先，载入测试数据库表并将该表对象赋值给变量 snapshot ，之后可以直接引用变量 snapshot ，示例如下：</p> 
<pre><code class="language-cpp">snapshot = loadTable("dfs://Level1", "Snapshot")
</code></pre> 
<p>使用 context by 对于股票分组，并根据 Volume 字段计算 75% 分位点的线性插值作为最小值，示例如下：</p> 
<pre><code class="language-cpp">timer res1 = select * from snapshot 
             where date(DateTime) = 2020.06.01 
             context by SecurityID having Volume &gt;= percentile(Volume, 75, "linear")
</code></pre> 
<p>context by 是 DolphinDB SQL 引入的一个关键词，用于分组计算。与 group by 用于聚合不同，context by 只是对数据分组而不做聚合操作，因此不改变数据的记录数。</p> 
<p>having 子句总是跟在 group by 或者 context by 后，用来将结果进行过滤，只返回满足指定条件的聚合函数值的组结果。having 与 group by 搭配使用时，表示是否输出某个组的结果。having 与 context by 搭配使用时，既可以表示是否输出这个组的结果，也可以表示输出组中的哪些行。</p> 
<p><strong>场景：承接以上场景，选出每只股票交易量最大的 25% 的记录后，计算 LastPx 的标准差。</strong></p> 
<p><strong>优化前：</strong></p> 
<p>使用 context by 对股票分组，并根据 Volume 字段计算 75% 位置处的线性插值作为过滤条件的最小值，再根据 group by 对股票分组，并计算标准差，最后使用 order by 对于股票排序，示例如下：</p> 
<pre><code class="language-cpp">timer select std(LastPx) as std from (
      select SecurityID, LastPx from snapshot 
      where date(DateTime) = 2020.06.01 
      context by SecurityID 
      having Volume &gt;= percentile(Volume, 75, "linear")) 
      group by SecurityID 
      order by SecurityID
</code></pre> 
<p><strong>耗时 242 ms。</strong></p> 
<p><strong>优化后：</strong></p> 
<p>使用 group by 对股票分组，aggrTopN 高阶函数选择交易量最大的 25% 的记录，并计算标准差。示例如下：</p> 
<pre><code class="language-cpp">timer select aggrTopN(std, LastPx, Volume, 0.25, false) as std from snapshot 
      where date(DateTime) = 2020.06.01 
      group by SecurityID 
      order by SecurityID
</code></pre> 
<p><strong>耗时 124 ms。</strong></p> 
<p>优化前先把数据分组并进行过滤，合并数据后再分组计算聚合值。优化后，在数据分组后，直接进行过滤和聚合，减少了中间步骤，从而提升了性能。</p> 
<h4 id="h_477025819_4"><strong>2.3 where 条件子句使用逗号或 and</strong></h4> 
<p>where 子句中多条件如果使用 “,” 进行连接时，在查询时会按照顺序对 “,” 前的条件层层进行过滤；若使用 and 进行连接时，会对所有条件在原表内分别进行筛选后再将结果取交集。</p> 
<p>下面将通过几个示例，比较使用 and 和逗号再不同场景下进行条件过滤的异同。</p> 
<p>首先，产生模拟数据，示例如下：</p> 
<pre><code class="language-cpp">N = 10000000
t = table(take(2019.01.01..2019.01.03, N) as date,            
          take(`C`MS`MS`MS`IBM`IBM`IBM`C`C$SYMBOL, N) as sym, 
          take(49.6 29.46 29.52 30.02 174.97 175.23 50.76 50.32 51.29, N) as price, 
          take(2200 1900 2100 3200 6800 5400 1300 2500 8800, N) as qty)
</code></pre> 
<p>根据过滤条件是否使用序列相关函数，如 deltas, ratios, ffill, move, prev, cumsum 等，可以分为以下两种情况。</p> 
<h4 id="h_477025819_5"><strong>2.3.1 过滤条件与序列无关</strong></h4> 
<p>示例代码如下：</p> 
<pre><code class="language-cpp">timer(10) t1 = select * from t where qty &gt; 2000, date = 2019.01.02, sym = `C
timer(10) t2 = select * from t where qty &gt; 2000 and date = 2019.01.02 and sym = `C
​
each(eqObj, t1.values(), t2.values()) // true
</code></pre> 
<p><strong>以上两个查询耗时分别为902 ms、930 ms。</strong>此时，使用逗号与 and 的查询性能相差不大。</p> 
<p>测试不同条件先后顺序对于查询性能与查询结果的影响，示例代码如下：</p> 
<pre><code class="language-cpp">timer(10) t3 = select * from t where date = 2019.01.02, sym = `C, qty &gt; 2000
timer(10) t4 = select * from t where date = 2019.01.02 and sym = `C and qty &gt; 2000
​
each(eqObj, t1.values(), t3.values()) // true
each(eqObj, t2.values(), t4.values()) // true
</code></pre> 
<p><strong>以上两个查询耗时分别为669 ms、651 ms。</strong>此时，使用逗号与 and 的查询性能相差不大。</p> 
<p>说明过滤条件与序列无关时，条件先后顺序对于查询结果无影响。但性能方面 t3(t4) 较 t1(t2) 提升约30%，这是因为 date 字段比 qty 字段筛选性更强。</p> 
<h4 id="h_477025819_6"><strong>2.3.2 过滤条件与序列有关</strong></h4> 
<p>示例代码如下：</p> 
<pre><code class="language-cpp">timer(10) t1 = select * from t where ratios(qty) &gt; 1, date = 2019.01.02, sym = `C
timer(10) t2 = select * from t where ratios(qty) &gt; 1 and date = 2019.01.02 and sym = `C
​
each(eqObj, t1.values(), t2.values()) // true
</code></pre> 
<p><strong>以上两个查询耗时分别为1503 ms、1465 ms。</strong></p> 
<p>此时，使用逗号与 and 的查询性能相差无几。序列条件作为第一个条件，使用逗号连接时，首先按照原表中数据的顺序进行计算，后面条件与序列无关，所以查询结果与 and 连接时保持一致。</p> 
<p>测试不同条件先后顺序对于查询性能与查询结果的影响，示例代码如下：</p> 
<pre><code class="language-cpp">timer(10) t3 = select * from t where date = 2019.01.02, sym = `C, ratios(qty) &gt; 1
timer(10) t4 = select * from t where date = 2019.01.02 and sym = `C and ratios(qty) &gt; 1
​
each(eqObj, t2.values(), t4.values()) // true
each(eqObj, t1.values(), t3.values()) // false
</code></pre> 
<p>以上两个查询耗时分别为507 ms、1433 ms，第一个each函数返回均为true，即 t2 与 t4 查询结果相同；第二个each 函数返回均为 false，即 t1 与 t3 查询结果不同。</p> 
<p>说明过滤条件与序列相关时，对于使用 and 连接的查询语句，条件先后顺序对于查询结果无影响，性能方面亦无差别；对于使用逗号的查询语句，序列条件在后，性能虽有提升，但查询结果不同。</p> 
<p><strong>综合上述测试结果分析可知：</strong></p> 
<ul><li>过滤条件与序列无关时，使用逗号或 and 均可，这是因为系统内部对于 and 做了优化，即将 and 转换为逗号，逗号会按照条件先后顺序层层过滤，因此条件先后顺序不同，执行查询时会有所差别，建议尽可能将过滤能力较强的条件放在前面，以减少后面过滤条件需要查询的数据量；</li><li>过滤条件与序列相关时，必须使用 and，会对所有过滤条件在原表内分别筛选，再将过滤结果取交集，因此条件先后顺序不影响查询结果与性能。</li></ul> 
<h3 id="h_477025819_7"><strong>3 分布式表相关案例</strong></h3> 
<p>分布式查询和普通查询的语法并无差异，理解分布式查询的工作原理有助于编写高效的 SQL 查询语句。系统首先根据 where 条件子句确定查询涉及的分区，然后分解查询语句为多个子查询，并把子查询发送到相关分区所在的位置(map)，最后在发起节点汇总所有分区的查询结果(merge)，并进行进一步的查询(reduce)。</p> 
<h4 id="h_477025819_8"><strong>3.1 分区剪枝</strong></h4> 
<p><strong>场景：查询每只股票在某个时间范围内的记录数目。</strong></p> 
<p>首先，载入测试数据库下的表 “Snapshot” 并将该表对象赋值给变量 snapshot，示例如下：</p> 
<pre><code class="language-cpp">snapshot = loadTable("dfs://Level1", "Snapshot")
</code></pre> 
<p><strong>优化前：</strong></p> 
<p>where条件子句根据日期过滤时，使用temporalFormat函数对于日期进行格式转换，如下：</p> 
<pre><code class="language-cpp">timer t1 = select count(*) from snapshot 
           where temporalFormat(DateTime, "yyyy.MM.dd") &gt;= "2020.06.01" and temporalFormat(DateTime, "yyyy.MM.dd") &lt;= "2020.06.02" 
           group by SecurityID 
</code></pre> 
<p><strong>查询耗时 4145 ms。</strong></p> 
<p><strong>优化后：</strong></p> 
<p>使用 date 函数将 DateTime 字段转换为 DATE 类型，如下：</p> 
<pre><code class="language-cpp">timer t2 = select count(*) from snapshot 
           where date(DateTime) between 2020.06.01 : 2020.06.02 group by SecurityID 
</code></pre> 
<p><strong>查询耗时 92 ms。</strong></p> 
<pre><code class="language-cpp">each(eqObj, t1.values(), t2.values()) // true
</code></pre> 
<p>与优化前写法相比，查询性能提升数十倍。DolphinDB 在解决海量数据的存取时，并不提供行级的索引，而是将分区作为数据库的物理索引。系统在执行分布式查询时，首先根据 where 条件确定需要的分区。大多数分布式查询只涉及分布式表的部分分区，系统无需全表扫描，从而节省大量时间。但若不能根据 where 条件确定分区，进行全表扫描，就会大大降低查询性能。</p> 
<p>可以看到以上优化前的脚本，分区字段套用了 temporalFormat 函数先对所有日期进行转换，因此系统无法做分区剪枝。</p> 
<p>下面例举了部分其它导致系统 <strong>无法做分区剪枝 </strong>的案例：</p> 
<p>例1：对分区字段进行运算。</p> 
<pre><code class="language-cpp">select count(*) from snapshot where date(DateTime) + 1 &gt; 2020.06.01
</code></pre> 
<p>例2：使用链式比较。</p> 
<pre><code class="language-cpp">select count(*) from snapshot where 2020.06.01 &lt; date(DateTime) &lt; 2020.06.03
</code></pre> 
<p>例3：过滤条件未使用分区字段。</p> 
<pre><code class="language-cpp">select count(*) from snapshot where Volume &lt; 500
</code></pre> 
<p>例4：与分区字段比较时使用其它列。AnnouncementDate字段非snapshot表中字段，此处仅为举例说明。</p> 
<pre><code class="language-cpp">select count(*) from snapshot where date(DateTime) &lt; AnnouncementDate - 3
</code></pre> 
<h4 id="h_477025819_9"><strong>3.2 GROUP BY并行查询</strong></h4> 
<p><strong>场景：对在某个时间范围内所有股票，标记涨跌，并计算第一档行情买卖双方报价之差、总交易量等指标。</strong></p> 
<p>首先，载入测试数据库中的表，示例如下：</p> 
<pre><code class="language-cpp">snapshot = loadTable("dfs://Level1", "Snapshot")
</code></pre> 
<p><strong>优化前：</strong></p> 
<p>首先，筛选 2020年06月01日09:30:00 以后的数据，收盘价高于开盘价的记录，标志位设置为1；否则，标志位设置为0，将结果赋给一个内存表。然后，使用 group by 子句根据 SecurityID, DateTime, Flag三个字段分组，并统计分组内 OfferPrice1 的记录数以及 Volume 的和，示例如下：</p> 
<pre><code class="language-cpp">timer {
    tmp_t = select *, iif(LastPx &gt; OpenPx, 1, 0) as Flag 
            from snapshot 
            where date(DateTime) = 2020.06.01, second(DateTime) &gt;= 09:30:00
    t1 = select iif(max(OfferPrice1) - min(BidPrice1) == 0, 0, 1) as Price1Diff, count(OfferPrice1) as OfferPrice1Count, sum(Volume) as Volumes 
            from tmp_t 
            group by SecurityID, date(DateTime) as Date, Flag
}
</code></pre> 
<p><strong>查询耗时 6249 ms。</strong></p> 
<p><strong>优化后：</strong></p> 
<p>不再引入中间内存表，直接从分布式表进行查询计算。示例如下：</p> 
<pre><code class="language-cpp">timer t2 = select iif(max(OfferPrice1) - min(BidPrice1) == 0, 0, 1) as Price1Diff, count(OfferPrice1) as OfferPrice1Count, sum(Volume) as Volumes 
            from snapshot 
            where date(DateTime) = 2020.06.01, second(DateTime) &gt;= 09:30:00 
            group by SecurityID, date(DateTime) as Date, iif(LastPx &gt; OpenPx, 1, 0) as Flag
</code></pre> 
<p><strong>查询耗时 1112 ms。</strong></p> 
<pre><code class="language-cpp">each(eqObj, t1.values(), (select * from t2 order by SecurityID, Date, Flag).values()) // true
</code></pre> 
<p>与优化前写法相比，优化后写法查询性能提升<strong>约 6 倍</strong>。</p> 
<p>性能的提升来自于两个方面：</p> 
<p>（1）优化前的写法先把分区数据合并到一个内存表，然后再用 group by 分组计算，比优化后的写法多了合并与拆分的两个步骤。</p> 
<p>（2）优化后的写法直接对分布式表进行分组计算，充分利用 CPU 多核并行计算。而优化前的写法合并成一个内存表后，只利用单核进行分组计算。</p> 
<p><strong>作为一个通用规则，对于分布式表的查询和计算，尽可能不要生成中间结果，直接在原始的分布式表上做计算，性能最优。</strong></p> 
<h4 id="h_477025819_10"><strong>3.3 分组查询使用 map 关键字</strong></h4> 
<p><strong>场景：查询每只股票每分钟的记录数目。</strong></p> 
<p>首先，载入测试数据库表：</p> 
<pre><code class="language-cpp">snapshot = loadTable("dfs://Level1", "Snapshot")
</code></pre> 
<p><strong>优化前：</strong></p> 
<pre><code class="language-cpp">timer result = select count(*) from snapshot group by SecurityID, bar(DateTime, 60)
</code></pre> 
<p><strong>查询耗时 996 ms。</strong></p> 
<p><strong>优化后：</strong></p> 
<p>使用map关键字。</p> 
<pre><code class="language-cpp">timer result = select count(*) from snapshot group by SecurityID, bar(DateTime, 60) map
</code></pre> 
<p><strong>查询耗时 864 ms。与优化前写法相比，查询性能提升约10%~20%。</strong></p> 
<p>优化前分组查询或计算时分为两个步骤：</p> 
<ul><li>每个分区内部计算；</li><li>所有分区的结果进行进一步计算，以确保最终结果的正确。</li></ul> 
<p>如果分区的粒度大于分组的粒度，那么第一步骤完全可以保证结果的正确。此场景中，一级分区为粒度为“天”，大于分组的粒度”分钟”，可以使用 map 关键字，避免第二步骤的计算开销，从而提升查询性能。</p> 
<h3 id="h_477025819_11"><strong>4 分组计算相关案例</strong></h3> 
<h4 id="h_477025819_12"><strong>4.1 查询最新的 N 条记录</strong></h4> 
<p><strong>场景：获取每只股票最新的10条记录。</strong></p> 
<p>仅对2020年06月01日的数据进行分组求 TOP 10。context by 子句对数据进行分组，返回结果中每一组的行数和组内元素数量相同，再结合 csort 和 top 关键字，可以获取每组数据的最新记录。以行数为960万行的数据为例：</p> 
<p><strong>OLAP 存储引擎：</strong></p> 
<pre><code class="language-cpp">timer t1 = select * from loadTable("dfs://Level1", "Snapshot") where date(DateTime) = 2020.06.01 context by SecurityID csort DateTime limit -10
</code></pre> 
<p><strong>查询耗时 4289 ms。</strong></p> 
<p><strong>TSDB 存储引擎：</strong></p> 
<pre><code class="language-cpp">timer t2 = select * from loadTable("dfs://Level1_TSDB", "Snapshot") where date(DateTime) = 2020.06.01 context by SecurityID csort DateTime limit -10 
</code></pre> 
<p><strong>查询耗时 1122 ms。</strong></p> 
<pre><code class="language-cpp">each(eqObj, t1.values(), t2.values()) //true
</code></pre> 
<p>TSDB 是 DolphinDB 2.0 版本推出的存储引擎，引入了排序列，相当于对分区内部建立了一个索引。因此对于时间相关、单点查询场景，性能较OLAP存储引擎会有进一步提升。</p> 
<p><strong>此例中，TSDB 存储引擎的查询性能较 OLAP 存储引擎提升约 4 倍。</strong></p> 
<p>context by 是 DolphinDB SQL 独有的创新，是对标准 SQL 语句的拓展。在关系型数据库管理系统中，一张表由行的集合组成，行之间没有顺序。可以使用如 min, max, avg, stdev 等聚合函数来对行进行分组，但是不能对分组内的行使用序列相关的聚合函数，比如first, last等，或者使用顺序敏感的滑动窗口函数和累积计算函数，如cumsum, cummax, ratios, deltas等。</p> 
<p>DolphinDB 使用列式存储引擎，因此能更好地支持对时间序列的数据进行处理，而其特有的 context by 子句使组内处理时间序列数据更加方便。</p> 
<h4 id="h_477025819_13"><strong>4.2 计算滑动 VWAP</strong></h4> 
<p><strong>场景：一个内存表包含3000只股票，每只股票10000条记录，使用循环与 context by 两种方法分别计算mwavg (移动加权平均，Moving Weighted Average)，比较二者性能差异。</strong></p> 
<p>首先，产生模拟数据，示例如下：</p> 
<pre><code class="language-cpp">syms = format(1..3000, "SH000000")
N = 10000
t = cj(table(syms as symbol), table(rand(100.0, N) as price, rand(10000, N) as volume))
</code></pre> 
<p><strong>优化前</strong>：</p> 
<p>使用循环，每一次取出某只股票相应的10000条记录的价格、交易量字段，计算 <a href="https://link.zhihu.com/?target=https%3A//www.dolphindb.cn/cn/help/FunctionsandCommands/FunctionReferences/m/mwavg.html" rel="nofollow" title="mwavg">mwavg</a>，共执行3000次，然后合并每一次的计算结果。</p> 
<pre><code class="language-cpp">arr = array(ANY, syms.size())
​
timer {
    for(i in 0 : syms.size()) {
        price_vec = exec price from t where symbol = syms[i]
        volume_vec = exec volume from t where symbol = syms[i]
        arr[i] = mwavg(price_vec, volume_vec, 4)
    }
    res1 = reduce(join, arr)
}
</code></pre> 
<p><strong>查询耗时 25 min。</strong></p> 
<p><strong>优化后</strong>：</p> 
<p>使用 context by，根据股票分组，每个分组内部分别计算 mwavg。</p> 
<pre><code class="language-cpp">timer res2 = select mwavg(price, volume, 4) from t 
               context by symbol
</code></pre> 
<p><strong>查询耗时 3176 ms。</strong></p> 
<pre><code class="language-cpp">each(eqObj, res1, res2[`mwavg_price]) // true
</code></pre> 
<p><strong>两种方法的性能相差约 400 多倍。</strong></p> 
<p>原因是，context by 仅对全表数据扫描一次，并对所有股票分组，再对每组分别进行计算；而 for 循环每一次循环都要扫描全表以获取某只股票相应的10000记录，所以耗时较长。</p> 
<h4 id="h_477025819_14"><strong>4.3 计算累积 VWAP</strong></h4> 
<p><strong>场景：每分钟计算每只股票自开盘到现在的所有交易的 vwap (交易量加权平均价格，Volume Weighted Average Price)。</strong></p> 
<p>首先，载入测试数据库表：</p> 
<pre><code class="language-cpp">snapshot = loadTable("dfs://Level1", "Snapshot")
</code></pre> 
<p>使用 group by 对股票分组，再对时间做分钟聚合并使用 cgroup by 分组，计算 vwap；然后使用 order by 子句对分组计算结果排序，最后对每只股票分别计算累计值。</p> 
<pre><code class="language-cpp">timer result = select wavg(LastPx, Volume) as vwap 
               from snapshot 
               group by SecurityID 
               cgroup by minute(DateTime) as Minute 
               order by SecurityID, Minute
</code></pre> 
<p><strong>查询耗时 1499 ms。</strong></p> 
<p>cgroup by (cumulative group) 为 DolphinDB SQL 独有的功能，是对标准 SQL 语句的拓展，可以进行累计分组计算，第一次计算使用第一组记录，第二次计算使用前两组记录，第三次计算使用前三组记录，以此类推。</p> 
<p>使用cgroup by时，必须同时使用 order by 对分组计算结果进行排序。cgroup by 的 SQL 语句仅支持以下聚合函数：sum, sum2, sum3, sum4, prod, max, min, first, last, count, size, avg, std, var, skew, kurtosis, wsum, wavg, corr, covar, contextCount, contextSum, contextSum2。</p> 
<h4 id="h_477025819_15"><strong>4.4 计算 N 股 VWAP</strong></h4> 
<p><strong>场景：计算每只股票最近 1000 shares 相关的所有 trades 的 vwap。</strong></p> 
<p>筛选1000 shares 时可能出现以下情形，如 shares 为100、300、600的3个 trades 之和恰好为1000，或者shares 为900、300两个 trades 之和超过1000。首先需要找到参与计算的 trades，使得 shares 之和恰好超过1000，且保证减掉时间点最新的一个 trade 后，shares 之和小于1000，然后计算一下它们的 vwap。</p> 
<p>首先，产生模拟数据，示例如下：</p> 
<pre><code class="language-cpp">n = 500000
t = table(rand(string(1..4000), n) as sym, rand(10.0, n) as price, rand(500, n) as vol)
</code></pre> 
<p><strong>优化前:</strong></p> 
<p>使用group by对于股票进行分组，针对每只股票分别调用自定义聚合函数 lastVolPx1，针对所有 trades 采用循环计算，并判断 shares 是否恰好超过 bound，最后计算 vwag。如下：</p> 
<pre><code class="language-cpp">defg lastVolPx1(price, vol, bound) {
    size = price.size()
    cumSum = 0
    for(i in 0:size) {
        cumSum = cumSum + vol[size - 1 - i]
        if(cumSum &gt;= bound) {
            price_tmp = price.subarray(size - 1 - i :)
            vol_tmp = vol.subarray(size - 1 - i :)
            return wavg(price_tmp, vol_tmp)
        }
        if(i == size - 1 &amp;&amp; cumSum &lt; bound) {
            return wavg(price, vol)
        }
    }
}
​
timer lastVolPx_t1 = select lastVolPx1(price, vol, 1000) as lastVolPx from t group by sym
</code></pre> 
<p><strong>查询耗时 187 ms。</strong></p> 
<p><strong>优化后:</strong></p> 
<p>使用 group by 对股票进行分组，针对每支股票分别调用自定义聚合函数 lastVolPx2，计算累积交易量向量，以及恰好满足 shares 大于 bound 的起始位置，最后计算 vwag。如下：</p> 
<pre><code class="language-cpp">defg lastVolPx2(price, vol, bound) {
    cumVol = vol.cumsum()
    if(cumVol.tail() &lt;= bound)
        return wavg(price, vol)
    else {
        start = (cumVol &lt;= cumVol.tail() - bound).sum()
        return wavg(price.subarray(start:), vol.subarray(start:))
    }
}
​
timer lastVolPx_t2 = select lastVolPx2(price, vol, 1000) as lastVolPx from t group by sym
</code></pre> 
<p><strong>查询耗时 73 ms。</strong></p> 
<pre><code class="language-cpp">each(eqObj, lastVolPx_t1.values(), lastVolPx_t2.values()) // true
</code></pre> 
<p>与优化前写法相比，lastVolPx2 使用了向量化编程方法，性能提升一倍多。因此，编写 DolphinDB SQL 时，应当尽可能地使用向量化函数，避免使用循环。</p> 
<h4 id="h_477025819_16"><strong>4.5 分段统计股票价格变化率</strong></h4> 
<p><strong>场景：已知股票市场快照数据，根据其中某个字段，分段统计并计算每只股票价格变化率。</strong></p> 
<p>仅对2020年06月01日的数据举例说明。首先，使用 group by 对股票以及 OfferPrice1 字段连续相同的数据分组，然后计算每只股票第一档价格的变化率，示例如下：</p> 
<pre><code class="language-cpp">timer t = select last(OfferPrice1) \ first(OfferPrice1) - 1 
          from loadTable("dfs://Level1", "Snapshot") 
          where date(DateTime) = 2020.06.01 
          group by SecurityID, segment(OfferPrice1, false) 
</code></pre> 
<p><strong>查询耗时 511 ms。</strong></p> 
<p><a href="https://link.zhihu.com/?target=https%3A//www.dolphindb.cn/cn/help/FunctionsandCommands/FunctionReferences/s/segment.html" rel="nofollow" title="segment">segment</a> 函数用于向量分组，将连续相同的元素分为一组，返回与输入向量等长的向量。下一个案例中也使用了segment 函数分组，以展示该函数在连续区间分组计算时的易用性。</p> 
<h4 id="h_477025819_17"><strong>4.6 计算不同连续区间的最值</strong></h4> 
<p><strong>场景：期望根据某个字段的值，获取大于或等于目标值的连续区间窗口，并在每个窗口内取该字段最大值的第一条记录。</strong></p> 
<p>首先，产生模拟数据，示例如下：</p> 
<pre><code class="language-cpp">t = table(2021.09.29 + 0..15 as date, 
          0 0 0.3 0.3 0 0.5 0.3 0.5 0 0 0.3 0 0.4 0.6 0.6 0 as value)
targetVal = 0.3
</code></pre> 
<p><strong>优化前：</strong></p> 
<p>自定义一个函数 generateGrp，如果当前值大于或等于目标值，记录下当前记录对应的分组 ID；如果下一条记录的值小于目标值，分组 ID 加 １，以保证不同的连续数据划分到不同的分组。</p> 
<pre><code class="language-cpp">def generateGrp(targetVal, val) {
    arr = array(INT, val.size())
    n = 1
    for(i in 0 : val.size()) {
        if(val[i] &gt;= targetVal) {
            arr[i] = n
            if(val[i + 1] &lt; targetVal) n = n + 1
        }
    }
    return arr
}
</code></pre> 
<p>使用 context by 根据分组 ID 分组，并结合 having 语句过滤最大值，limit 语句限制返回第一条记录。</p> 
<pre><code class="language-cpp">timer(1000) {
    tmp = select date, value, generateGrp(targetVal, value) as grp from t
    res1 = select date, value from tmp where grp != 0 
           context by grp 
           having value = max(value) limit 1
}
</code></pre> 
<p><strong>查询耗时 142 ms。</strong></p> 
<p><strong>优化后：</strong></p> 
<p>使用 <a href="https://link.zhihu.com/?target=https%3A//www.dolphindb.cn/cn/help/FunctionsandCommands/FunctionReferences/s/segment.html" rel="nofollow" title="segment">segment</a> 函数结合 context by 语句对大于或等于目标值的连续数据分组，并使用 having 语句过滤。</p> 
<pre><code class="language-cpp">timer(1000) res2 = select * from t 
                   context by segment(value &gt;= targetVal) 
                   having value &gt;= targetVal and value = max(value) limit 1
</code></pre> 
<p><strong>查询耗时 123 ms。</strong></p> 
<pre><code class="language-cpp">each(eqObj, res1.values(), res2.values()) // true
</code></pre> 
<p><strong>与优化前写法相比，优化后写法查询性能提升约 10%。</strong></p> 
<p><a href="https://link.zhihu.com/?target=https%3A//www.dolphindb.cn/cn/help/FunctionsandCommands/FunctionReferences/s/segment.html" rel="nofollow" title="segment">segment</a> 函数一般用于序列相关的分组，与循环相比，性能略有提升，可以化繁为简，使代码更为优雅。</p> 
<h4 id="h_477025819_18"><strong>4.7 不同聚合方式计算指标</strong></h4> 
<p><strong>场景：期望根据不同的标签对于某个字段采用不同的聚合方式</strong>。</p> 
<p>例如，标签为 code1 时，每10分钟取 “max”；标签为 code2 时，每10分钟取 “min”；标签为 code3 时，每10分钟取 “avg”。最后获得一个行转列宽表。</p> 
<p>首先，产生模拟数据，示例如下：</p> 
<pre><code class="language-cpp">N = 1000000
t = table("code" + string(take(1..3, N)) as tag, 
          sort(take([2021.06.28T00:00:00, 2021.06.28T00:10:00, 2021.06.28T00:20:00], N)) as time, 
          take([1.0, 2.0, 9.1, 2.0, 3.0, 9.1, 9.1, 2.0, 3.0], N) as value)
</code></pre> 
<p>构建一个字典，标签为键，函数名称为值。使用 group by 对时间、标签分组，并调用自定义聚合函数，实现对不同标签的 value 进行不同的运算。</p> 
<pre><code class="language-cpp">codes = dict(`code1`code2`code3, [max, min, avg])
​
defg func(tag, value, codes) : codes[tag.first()](value)
 
timer {
    t_tmp = select func(tag, value, codes) as value from t 
            group by tag, interval(time, 10m, "null") as time
    t_result = select value from t_tmp pivot by time, tag
}
</code></pre> 
<p><strong>查询耗时 76 ms。</strong></p> 
<p>上例中使用的 interval 函数只能在 group by 子句中使用，不能单独使用，缺失值的填充方式可以为：prev, post, linear, null, 具体数值和 none。</p> 
<h4 id="h_477025819_19"><strong>4.8 计算股票收益波动率</strong></h4> 
<p><strong>场景：已知某只股票过去十年的日收益率，期望按月计算该股票的波动率。</strong></p> 
<p>首先，产生模拟数据，示例如下：</p> 
<pre><code class="language-cpp">N = 3653
t = table(2011.11.01..2021.10.31 as date, 
          take(`AAPL, N) as code, 
          rand([0.0573, -0.0231, 0.0765, 0.0174, -0.0025, 0.0267, 0.0304, -0.0143, -0.0256, 0.0412, 0.0810, -0.0159, 0.0058, -0.0107, -0.0090, 0.0209, -0.0053, 0.0317, -0.0117, 0.0123], N) as rate)
</code></pre> 
<p>使用 interval 函数对于日期按月分组，并计算标准差。其中，<em>fill</em> 类型为 prev，表示使用前一个值填充缺失值。</p> 
<pre><code class="language-cpp">timer res = select std(rate) from t group by code, interval(month(date), 1, "prev")
</code></pre> 
<p><strong>查询耗时 1.8 ms。</strong></p> 
<h4 id="h_477025819_20"><strong>4.9 计算股票组合的价值</strong></h4> 
<p><strong>场景：进行指数套利交易回测时，计算给定股票组合的价值。</strong></p> 
<p>当数据量极大时，一般数据分析系统进行回测时，对系统内存及速度的要求极高。以下案例，展现了使用 DolphinDB SQL 语言可极为简洁地进行此类计算。</p> 
<p>为了简化起见，假定某个指数仅由两只股票组成：AAPL 与 FB。模拟数据如下：</p> 
<pre><code class="language-cpp">syms = take(`AAPL, 6) join take(`FB, 5)
time = 2019.02.27T09:45:01.000000000 + [146, 278, 412, 445, 496, 789, 212, 556, 598, 712, 989]
prices = 173.27 173.26 173.24 173.25 173.26 173.27 161.51 161.50 161.49 161.50 161.51
quotes = table(take(syms, 100000) as Symbol, 
               take(time, 100000) as Time, 
               take(prices, 100000) as Price)
weights = dict(`AAPL`FB, 0.6 0.4)
ETF = select Symbol, Time, Price*weights[Symbol] as weightedPrice from quotes
</code></pre> 
<p><strong>优化前：</strong></p> 
<p>首先，需要将原始数据表的3列（时间，股票代码，价格）转换为同等长度但是宽度为指数成分股数量加1的数据表，然后向前补充空值（forward fill NULLs），进而计算每行的指数成分股对指数价格的贡献之和。示例如下：</p> 
<pre><code class="language-cpp">timer {
    colAAPL = array(DOUBLE, ETF.Time.size())
    colFB = array(DOUBLE, ETF.Time.size())
    
    for(i in 0:ETF.Time.size()) {
        if(ETF.Symbol[i] == `AAPL) {
            colAAPL[i] = ETF.weightedPrice[i]
            colFB[i] = NULL
        }
        if(ETF.Symbol[i] == `FB) {
            colAAPL[i] = NULL
            colFB[i] = ETF.weightedPrice[i]
        }
    }
    
    ETF_TMP1 = table(ETF.Time, ETF.Symbol, colAAPL, colFB)
    ETF_TMP2 = select last(colAAPL) as colAAPL, last(colFB) as colFB from ETF_TMP1 group by time, Symbol
    ETF_TMP3 = ETF_TMP2.ffill()
    
    t1 = select Time, rowSum(colAAPL, colFB) as rowSum from ETF_TMP3
}
</code></pre> 
<p><strong>以上代码块耗时 713 ms。</strong></p> 
<p><strong>优化后：</strong></p> 
<p>使用 pivot by 子句根据时间、股票代码对于数据表重新排序，将时间作为行，股票代码作为列，然后使用<a href="https://link.zhihu.com/?target=https%3A//dolphindb.cn/cn/help/FunctionsandCommands/FunctionReferences/f/ffill.html" rel="nofollow" title="ffill">ffill</a> 函数填充 NULL 元素，使用 <a href="https://link.zhihu.com/?target=https%3A//dolphindb.cn/cn/help/FunctionsandCommands/FunctionReferences/a/avg.html%253E" rel="nofollow" title="avg">avg</a> 函数计算均值，最后 <a href="https://link.zhihu.com/?target=https%3A//dolphindb.cn/cn/help/FunctionsandCommands/FunctionReferences/r/rowSum.html%253E" rel="nofollow" title="rowSum">rowSum</a> 函数计算每个时间点的股票价值之和，仅需以下一行代码，即可实现上述所有步骤。示例如下：</p> 
<pre><code class="language-cpp">timer t2 = select rowSum(ffill(last(weightedPrice))) from ETF pivot by Time, Symbol
</code></pre> 
<p><strong>查询耗时 23 ms。</strong></p> 
<pre><code class="language-cpp">each(eqObj, t1.values(), t2.values()) //true
</code></pre> 
<p><strong>与优化前写法相比，优化后写法查询性能提升约 30 倍。</strong></p> 
<p>此例中，仅以两只股票举例说明，当股票数量更多时，使用循环遍历的方式更为繁琐，而且性能极低。</p> 
<p>pivot by 是 DolphinDB SQL 独有的功能，是对标准SQL语句的拓展，可以将表中两列或多列的内容按照两个维度重新排列，亦可配合数据转换函数使用。不仅编程简洁，而且无需产生中间过程数据表，有效避免了内存不足的问题，极大地提升了计算速度。</p> 
<p>以下是与此场景类似的另外一个案例，属于物联网典型场景。</p> 
<p><strong>场景：假设一个物联网场景中存在三个测点进行实时数据采集，期望针对每个测点分别计算一分钟均值，再对同一分钟的三个测点均值求和。</strong></p> 
<p>首先，产生模拟数据，示例如下：</p> 
<pre><code class="language-cpp">N = 10000
t = table(take(`id1`id2`id3, N) as id, 
          rand(2021.01.01T00:00:00.000 +  100000 * (1..10000), N) as time, 
          rand(10.0, N) as value)
</code></pre> 
<p>使用 <a href="https://link.zhihu.com/?target=https%3A//dolphindb.cn/cn/help/FunctionsandCommands/FunctionReferences/b/bar.html%253E" rel="nofollow" title="bar">bar</a> 函数对时间做一分钟聚合，并使用 pivot by 子句根据分钟、测点对数据表重新排序，将分钟作为行，测点作为列，然后使用 ffill 函数填充 NULL 元素，使用 avg 函数计算均值，然后再使用 rowSum 函数计算每个时间点的测点值之和。最后使用 group by 子句结合 interval 函数对于缺失值进行填充。</p> 
<pre><code class="language-cpp">timePeriod = 2021.01.01T00:00:00.000 : 2021.01.01T01:00:00.000
timer result = select sum(rowSum) as v from (
               select rowSum(ffill(avg(value))) from t 
               where id in `id1`id2`id3, time 
               between timePeriod 
               pivot by bar(time, 60000) as minute, id) 
               group by interval(minute, 1m, "prev") as minute
</code></pre> 
<p><strong>查询耗时 12 ms。</strong></p> 
<h4 id="h_477025819_21"><strong>4.10 根据成交量切分时间窗口</strong></h4> 
<p><strong>场景：已知股票市场分钟线数据，期望根据成交量对股票在时间上进行切分，最终得到时间窗口不等的若干条数据，包含累计成交量，以及每个窗口的起止时间。</strong></p> 
<p>具体切分规则为：假如期望对某只股票成交量约150万股便进行一次时间切分。切分时，如果当前组加上下一条数据的成交量与150万更接近，则下一条数据加入当前组；否则，从下一条数据开始一个新的组。</p> 
<p>首先，产生模拟数据，示例如下：</p> 
<pre><code class="language-cpp">N = 28
t = table(take(`600000.SH, N) as wind_code, 
          take(2015.02.11, N) as date, 
          take(13:03:00..13:30:00, N) as time, 
          take([288656, 234804, 182714, 371986, 265882, 174778, 153657, 201388, 175937, 138388, 169086, 203013, 261230, 398971, 692212, 494300, 581400, 348160, 250354, 220064, 218116, 458865, 673619, 477386, 454563, 622870, 458177, 880992], N) as volume)
</code></pre> 
<p>根据切分规则，自定义一个累计函数 caclCumVol，如果当前组需要包含下一条数据的成交量，返回新的累计成交量；否则，返回下一条数据的成交量，即开始一个新的组。</p> 
<pre><code class="language-cpp">def caclCumVol(target, cumVol, nextVol) {
    newVal = cumVol + nextVol
    if(newVal &lt; target) return newVal
    else if(newVal - target &gt; target - cumVol) return nextVol
    else return newVal
}
</code></pre> 
<p>使用高阶函数 <a href="https://link.zhihu.com/?target=https%3A//dolphindb.cn/cn/help/Functionalprogramming/TemplateFunctions/accumulate.html" rel="nofollow" title="accumulate">accumulate</a>，迭代地应用 caclCumVol 函数到前一个累计成交量和下一个成交量上。如果累计成交量等于当前一条数据的成交量，则表示开始一个新的组，此时记录下当前这条数据的时间，作为一个窗口的起始时间，否则为空，通过 ffill 填充，使得同一组数据拥有相同的起始时间，最后根据起始时间分组并做聚合计算。</p> 
<pre><code class="language-cpp">timer result = select first(wind_code) as wind_code, first(date) as date, sum(volume) as sum_volume, last(time) as endTime 
               from t 
               group by iif(accumulate(caclCumVol{1500000}, volume) == volume, time, NULL).ffill() as startTime
</code></pre> 
<p><strong>查询耗时 0.9 ms。</strong></p> 
<h4 id="h_477025819_22"><strong>4.11 股票因子归整</strong></h4> 
<p><strong>场景：已知沪深两市某个10分钟因子，分别存储为一张分布式表，另有一张股票清单维度表存储股票代码相关信息。期望从沪市、深市分别取出部分股票代码相应因子，根据股票、日期对于因子做分组归整，并做行列转换。</strong></p> 
<p>首先，自定义一个函数createDBAndTable，用于创建分布式库表，如下：</p> 
<pre><code class="language-cpp">def createDBAndTable(dbName, tableName) {
    if(existsTable(dbName, tableName)) return loadTable(dbName, tableName)
    dbDate = database(, VALUE, 2021.07.01..2021.07.31)
    dbSecurityID = database(, HASH, [SYMBOL, 1])
    db = database(dbName, COMPO, [dbDate, dbSecurityID])
    model = table(1:0, `SecurityID`Date`Time`FactorID`FactorValue, [SYMBOL, DATE, TIME, SYMBOL, DOUBLE])
    return createPartitionedTable(db, model, tableName, `Date`SecurityID)
}
</code></pre> 
<p>执行以下代码，创建两个分布式表、一个维度表，并写入模拟数据，如下：</p> 
<pre><code class="language-cpp">dates = 2020.01.01..2021.10.31
time = join(09:30:00 + 1..12 * 60 * 10, 13:00:00 + 1..12 * 60 * 10)
​
syms = format(1..2000, "000000") + ".SH"
tmp = cj(cj(table(dates), table(time)), table(syms))
t = table(tmp.syms as SecurityID, tmp.dates as Date, tmp.time as Time, take(["Factor01"], tmp.size()) as FactorID, rand(100.0, tmp.size()) as FactorValue)
createDBAndTable("dfs://Factor10MinSH", "Factor10MinSH").append!(t)
​
syms = format(2001..4000, "000000") + ".SZ"
tmp = cj(cj(table(dates), table(time)), table(syms))
t = table(tmp.syms as SecurityID, tmp.dates as Date, tmp.time as Time, take(["Factor01"], tmp.size()) as FactorID, rand(100.0, tmp.size()) as FactorValue)
createDBAndTable("dfs://Factor10MinSZ", "Factor10MinSZ").append!(t)
​
db = database("dfs://infodb", VALUE, 1 2 3)
model = table(1:0, `SecurityID`Info, [SYMBOL, STRING])
if(!existsTable("dfs://infodb", "MdSecurity")) createTable(db, model, "MdSecurity")
loadTable("dfs://infodb", "MdSecurity").append!(
    table(join(format(1..2000, "000000") + ".SH", format(2001..4000, "000000") + ".SZ") as SecurityID, 
          take(string(NULL), 4000) as Info))
</code></pre> 
<p><strong>优化前：</strong></p> 
<p>首先，分别从沪市、深市取出因子 Factor01 在某个时间范围的数据，合并后，再从股票代码维度表中取出需要归整的股票，通过表连接方式对合并结果进行过滤，最后使用 pivot by 子句根据时间、股票代码两个维度重新排列。</p> 
<pre><code class="language-cpp">timer {
    nt1 = select concatDateTime(Date, Time) as TradeTime, SecurityID, FactorValue from loadTable("dfs://Factor10MinSH", "Factor10MinSH") where Date between 2019.01.01 : 2021.10.31, FactorID = "Factor01"
    nt2 = select concatDateTime(Date, Time) as TradeTime, SecurityID, FactorValue from loadTable("dfs://Factor10MinSZ", "Factor10MinSZ") where Date between 2019.01.01 : 2021.10.31, FactorID = "Factor01"
    unt = unionAll(nt1, nt2)
    
    sec = select SecurityID from loadTable("dfs://infodb", "MdSecurity") where substr(SecurityID, 0, 3) in ["001", "003", "005", "007"]
    res = select * from lj(sec, unt, `SecurityID)
​
    res = select FactorValue from res pivot by TradeTime, SecurityID
}
</code></pre> 
<p><strong>查询耗时 6922 ms。</strong></p> 
<p><strong>优化后：</strong></p> 
<p>首先，从股票代码维度表中取出需要归整的股票列表，然后从沪深两市取出因子 Factor01。使用 in 关键字进行过滤，再使用 pivot by 根据时间、股票代码两个维度进行重新排列，最后合并结果。</p> 
<pre><code class="language-cpp">timer {
    sec = exec SecurityID from loadTable("dfs://infodb", "MdSecurity") where substr(SecurityID, 0, 3) in ["001", "003", "005", "007"]
    
    nt1 = select concatDateTime(Date, Time) as TradeTime, SecurityID, FactorValue from loadTable("dfs://Factor10MinSH", "Factor10MinSH") where Date between 2019.01.01 : 2021.10.31, SecurityID in sec, FactorID = "Factor01"
    re1 = panel(nt1.TradeTime, nt1.SecurityID, nt1.FactorValue)
​
    nt2 = select concatDateTime(Date, Time) as TradeTime, SecurityID, FactorValue from loadTable("dfs://Factor10MinSZ", "Factor10MinSZ") where Date between 2019.01.01 : 2021.10.31, SecurityID in sec, FactorID = "Factor01"
    re2 = panel(nt2.TradeTime, nt2.SecurityID, nt2.FactorValue)
​
    res = re1 + re2
}
</code></pre> 
<p><strong>查询耗时 5129 ms。</strong></p> 
<p><strong>与优化前相比，优化后查询性能提升约 20%。</strong></p> 
<p>综合对比上述写法，概括出几个SQL编写技巧：</p> 
<p>（1）尽量避免不必要的表连接；</p> 
<p>（2）尽可能早地使用分区过滤；</p> 
<p>（3）推迟数据的合并。</p> 
<h4 id="h_477025819_23"><strong>4.12 根据交易额统计单子类型</strong></h4> 
<p><strong>场景：对不同日期、不同股票、买单卖单，分别统计某个时间范围内的特大单、大单、中单、小单的累计交易量、交易额。</strong></p> 
<p>具体规则为：交易额小于4万是小单，大于等于4万且小于20万是中单，大于等于20万且小于100万是大单，大于100万是特大单。</p> 
<p>首先，产生模拟数据，示例如下：</p> 
<pre><code class="language-cpp">N = 1000000
t = table(take(2021.11.01..2021.11.15, N) as date, 
          take([09:30:00, 09:35:00, 09:40:00, 09:45:00, 09:47:00, 09:49:00, 09:50:00, 09:55:00, 09:56:00, 10:00:00], N) as time, 
          take(`AAPL`FB`MSFT$SYMBOL, N) as symbol, 
          take([10000, 30000, 50000, 80000, 100000], N) as volume, 
          rand(100.0, N) as price, 
          take(`BUY`SELL$SYMBOL, N) as side)
</code></pre> 
<p><strong>优化前：</strong></p> 
<p>使用 group by 根据日期、股票、买卖方向分组，使用四个查询语句分别计算小单、中单、大单、特大单的累计交易量、交易额，再将结果合并。</p> 
<pre><code class="language-cpp">timer {
    // 小单
    resS = select sum(volume) as volume_sum, sum(volume * price) as amount_sum, 0 as type 
            from t 
            where time &lt;= 10:00:00, volume * price &lt; 40000 
            group by date, symbol, side
    // 中单
    resM = select sum(volume) as volume_sum, sum(volume * price) as amount_sum, 1 as type 
            from t 
            where time &lt;= 10:00:00, 40000 &lt;= volume * price &lt; 200000 
            group by date, symbol, side
    // 大单
    resB = select sum(volume) as volume_sum, sum(volume * price) as amount_sum, 2 as type 
            from t 
            where time &lt;= 10:00:00, 200000 &lt;= volume * price &lt; 1000000 
            group by date, symbol, side
    // 特大单
    resX = select sum(volume) as volume_sum, sum(volume * price) as amount_sum, 3 as type 
            from t 
            where time &lt;= 10:00:00, volume * price &gt;= 1000000 
            group by date, symbol, side
    
    res1 = table(N:0, `date`symbol`side`volume_sum`amount_sum`type, [DATE, SYMBOL, SYMBOL, LONG, DOUBLE, INT])
    res1.append!(resS).append!(resM).append!(resB).append!(resX)
}
</code></pre> 
<p><strong>查询耗时 135 ms。</strong></p> 
<p><strong>第一种优化写法：</strong></p> 
<p>自定义一个函数 getType，使用 iff 函数嵌套方式得到当前成交单子类型，然后使用 group by 对日期、股票、买卖方向、单子类型分组，并计算累计交易量、交易额。</p> 
<pre><code class="language-cpp">def getType(amount) {
    return iif(amount &lt; 40000, 0, iif(amount &gt;= 40000 &amp;&amp; amount &lt; 200000, 1, iif(amount &gt;= 200000 &amp;&amp; amount &lt; 1000000, 2, 3)))
}
​
timer res2 = select sum(volume) as volume_sum, sum(volume*price) as amount_sum 
                from t 
                where time &lt;= 10:00:00
                group by date, symbol, side, getType(volume * price) as type 
</code></pre> 
<p><strong>查询耗时 114 ms。</strong></p> 
<p><strong>与优化前写法相比，优化后写法查询性能提升约 20%。</strong>虽然性能略有提升，但大大简化了代码编写。</p> 
<p>需要注意的是，此处有个优化技巧，group by 后面字段类型为 INT、LONG、SHORT、SYMBOL 时，系统内部进行了优化，查询性能会有一定提升，所以本例中 getType 函数返回类型为 INT。</p> 
<p><strong>第二种优化写法</strong>：</p> 
<pre><code class="language-cpp">range = [0.0, 40000.0, 200000.0, 1000000.0, 100000000.0]
​
timer res3 = select sum(volume) as volume_sum, sum(volume*price) as amount_sum 
                from t 
                where time &lt;= 10:00:00 
                group by date, symbol, side, asof(range, volume*price) as type
</code></pre> 
<p><strong>查询耗时 95 ms。</strong></p> 
<p>与第一种优化写法区别在于，使用 <a href="https://link.zhihu.com/?target=https%3A//www.dolphindb.cn/cn/help/FunctionsandCommands/FunctionReferences/a/asof.html" rel="nofollow" title="asof">asof</a> 函数而非自定义函数，判断交易额落在哪个区间，然后以此分组并计算累计交易量、交易额。</p> 
<pre><code class="language-cpp">each(eqObj, (select date, symbol, side, type, volume_sum, amount_sum 
             from res1 order by date, symbol, side, type).values(), res2.values()) // true
each(eqObj, res2.values(), res3.values()) // true
</code></pre> 
<p>以下是 asof 函数在另外一个场景下的应用。</p> 
<p><strong>场景：针对某个日期、某只股票，统计某一数值列落在不同的区间范围的记录数目。</strong></p> 
<p>首先，产生模拟数据，示例如下：</p> 
<pre><code class="language-cpp">N = 100000
t = table(take(2021.11.01, N) as date, 
          take(`AAPL, N) as code, 
          rand([-5, 5, 10, 15, 20, 25, 100], N) as value)
range = [-9999, 0, 10, 30, 9999]
</code></pre> 
<p><strong>优化前：</strong></p> 
<p>自定义一个函数 generateGrp，遍历不同的区间范围，判断数值列是否包含在当前的区间范围内，区间范围遵循左闭右开原则，并返回一个布尔型向量。如果为 true，表示数值包含在当前的区间范围内，则以下划线连接区间范围的左右边界作为分组 ID；如果为 false，表示数值不包含在当前的区间范围内，则将其置为空字符串。</p> 
<p>然后使用高阶函数 <a href="https://link.zhihu.com/?target=https%3A//www.dolphindb.cn/cn/help/Functionalprogramming/TemplateFunctions/reduce.html" rel="nofollow" title="reduce">reduce</a> 将遍历结果合并，最后使用 group by 根据日期、股票、不同的区间范围分组，并聚合计算记录数目。</p> 
<pre><code class="language-cpp">def generateGrp(range, val) {
    res = array(ANY, range.size()-1)
    for(i in 0 : (range.size()-1)) {
        cond = val &gt;= range[i] &amp;&amp; val &lt; range[i+1]
        res[i] = iif(cond, strReplace(range[i] + "_" + range[i+1], "-", ""), string(NULL))
    }
    return reduce(add, res)
}
​
timer res1 = select count(*) from t group by date, code, generateGrp(range, value) as grp
</code></pre> 
<p><strong>查询耗时 38 ms。</strong></p> 
<p><strong>优化后：</strong></p> 
<p>使用 asof 函数结合 group by 语句对于日期、股票、不同的区间范围分组，并聚合计算记录数目。</p> 
<pre><code class="language-cpp">timer res2 = select count(*) from t 
            group by date, code, asof(range, value) as grp
</code></pre> 
<p><strong>查询耗时 14 ms。</strong></p> 
<p><strong>与优化前写法相比，优化后写法查询性能提升约 2 倍多。</strong></p> 
<p>asof 函数一般用于分段统计，与循环相比，不仅性能大大提升，而且代码更为简洁。下一个案例也是使用了asof 函数用于统计。</p> 
<h3 id="h_477025819_24"><strong>5 元编程相关案例</strong></h3> 
<h4 id="h_477025819_25"><strong>5.1 动态生成 SQL 语句案例 1</strong></h4> 
<p><strong>场景：已知股票市场分钟线数据，使用元编程方式，根据股票、日期分组，每隔 10 分钟做一次聚合计算。</strong></p> 
<p>首先，产生模拟数据，示例如下：</p> 
<pre><code class="language-cpp">N = 10000000
t = table(take(format(1..4000, "000000") + ".SH", N) as SecurityID, 
          take(2021.10.01..2021.10.31, N) as DataDate, 
          take(join(09:30:00 + 1..120 * 60, 13:00:00 + 1..120 * 60), N) as TradeTime, 
          rand(100.0, N) as cal_variable)
min_num = 10
</code></pre> 
<p><strong>优化前：</strong></p> 
<p>查询语句拼接为一个字符串，使用 parseExpr 函数将字符串解析为元代码，再使用 <a href="https://link.zhihu.com/?target=https%3A//www.dolphindb.cn/cn/help/FunctionsandCommands/FunctionReferences/e/eval.html" rel="nofollow" title="eval">eval</a> 函数执行生成的元代码。</p> 
<pre><code class="language-cpp">res = parseExpr("select " + avg + "(cal_variable) as FactorValue from t group by bar(TradeTime, " + min_num + "m) as minute_TradeTime, SecurityID, DataDate").eval()
</code></pre> 
<p><strong>查询耗时 219 ms。</strong></p> 
<p><strong>优化后：</strong></p> 
<p>DolphinDB 内置了 <a href="https://link.zhihu.com/?target=https%3A//www.dolphindb.cn/cn/help/FunctionsandCommands/FunctionReferences/s/sql.html" rel="nofollow" title="sql">sql</a> 函数用于动态生成 SQL 语句，然后使用 eval 函数执行生成的 SQL 语句。其中，<a href="https://link.zhihu.com/?target=https%3A//www.dolphindb.cn/cn/help/FunctionsandCommands/FunctionReferences/s/sqlCol.html" rel="nofollow" title="sqlCol">sqlCol</a> 函数将列名转化为表达式，<a href="https://link.zhihu.com/?target=https%3A//www.dolphindb.cn/cn/help/FunctionsandCommands/FunctionReferences/m/makeCall.html" rel="nofollow" title="makeCall">makeCall</a> 函数指定参数调用 <a href="https://link.zhihu.com/?target=https%3A//www.dolphindb.cn/cn/help/FunctionsandCommands/FunctionReferences/b/bar.html" rel="nofollow" title="bar">bar</a> 函数并生成脚本，<a href="https://link.zhihu.com/?target=https%3A//www.dolphindb.cn/cn/help/FunctionsandCommands/FunctionReferences/s/sqlColAlias.html" rel="nofollow" title="sqlColAlias">sqlColAlias</a> 函数使用元代码和别名定义一个列。</p> 
<pre><code class="language-cpp">groupingCols = [sqlColAlias(makeCall(bar, sqlCol("TradeTime"), duration(min_num.string() + "m")), "minute_TradTime"), sqlCol("SecurityID"), sqlCol("DataDate")]
res = sql(select = sqlCol("cal_variable", funcByName("avg"), "FactorValue"), 
          from = t, groupBy = groupingCols, groupFlag = GROUPBY).eval()
</code></pre> 
<p><strong>查询耗时 200 ms。</strong></p> 
<p>类似地，sqlUpdate 函数用于动态生成 SQL update 语句的元代码，sqlDelete 函数用于动态生成 SQL delete语句的元代码。</p> 
<h4 id="h_477025819_26"><strong>5.2 动态生成 SQL 语句案例 2</strong></h4> 
<p><strong>场景：每天需要执行一组查询，合并查询结果。</strong></p> 
<p>首先，产生模拟数据，示例如下：</p> 
<pre><code class="language-cpp">N = 100000
t = table(take(50982208 51180116 41774759, N) as vn, 
          rand(25 1180 50, N) as bc, 
          take(814 333 666, N) as cc, 
          take(11 12 3, N) as stt, 
          take(2 116 14, N) as vt, 
          take(2020.02.05..2020.02.05, N) as dsl, 
          take(52354079..52354979, N) as mt)
</code></pre> 
<p>例如，每天需要执行一组查询，如下：</p> 
<pre><code class="language-cpp">t1 = select * from t where vn=50982208, bc=25, cc=814, stt=11, vt=2, dsl=2020.02.05, mt &lt; 52355979 order by mt desc limit 1
t2 = select * from t where vn=50982208, bc=25, cc=814, stt=12, vt=2, dsl=2020.02.05, mt &lt; 52355979 order by mt desc limit 1
t3 = select * from t where vn=51180116, bc=25, cc=814, stt=12, vt=2, dsl=2020.02.05, mt &lt; 52354979 order by mt desc limit 1
t4 = select * from t where vn=41774759, bc=1180, cc=333, stt=3, vt=116, dsl=2020.02.05, mt &lt; 52355979 order by mt desc limit 1
​
reduce(unionAll, [t1, t2, t3, t4])
</code></pre> 
<p>以下案例通过元编程动态生成 SQL 语句实现。过滤条件包含的列和排序的列相同，可编写如下自定义函数 bundleQuery 实现相关操作：</p> 
<pre><code class="language-cpp">def bundleQuery(tbl, dt, dtColName, mt, mtColName, filterColValues, filterColNames){
    cnt = filterColValues[0].size()
    filterColCnt = filterColValues.size()
    orderByCol = sqlCol(mtColName)
    selCol = sqlCol("*")
    filters = array(ANY, filterColCnt + 2)
    filters[filterColCnt] = expr(sqlCol(dtColName), ==, dt)
    filters[filterColCnt+1] = expr(sqlCol(mtColName), &lt;, mt)
    
    queries = array(ANY, cnt)
    for(i in 0:cnt) {
        for(j in 0:filterColCnt){
            filters[j] = expr(sqlCol(filterColNames[j]), ==, filterColValues[j][i])
        }
        queries.append!(sql(select=selCol, from=tbl, where=filters, orderBy=orderByCol, ascOrder=false, limit=1))
    }
    return loop(eval, queries).unionAll(false)
}
</code></pre> 
<p>bundleQuery 中各个参数的含义如下：</p> 
<ul><li>tbl 是数据表。</li><li>dt 是过滤条件中日期的值。</li><li>dtColName 是过滤条件中日期列的名称。</li><li>mt 是过滤条件中 mt 的值。</li><li>mtColName 是过滤条件中 mt 列的名称，以及排序列的名称。</li><li>filterColValues 是其他过滤条件中的值，用元组表示，其中的每个向量表示一个过滤条件，每个向量中的元素表示该过滤条件的值。</li><li>filterColNames 是其他过滤条件中的列名，用向量表示。</li></ul> 
<p>上面一组 SQL 语句，相当于执行以下代码：</p> 
<pre><code class="language-cpp">dt = 2020.02.05
dtColName = "dsl"
mt = 52355979
mtColName = "mt"
colNames = `vn`bc`cc`stt`vt
colValues = [50982208 50982208 51180116 41774759, 25 25 25 1180, 814 814 814 333, 11 12 12 3, 2 2 2 116]
​
bundleQuery(t, dt, dtColName, mt, mtColName, colValues, colNames)
</code></pre> 
<p>登录 admin 管理员用户后，执行以下脚本将 bundleQuery 函数定义为函数视图，以确保在集群的任何节点重启系统之后，都可直接调用该函数。</p> 
<pre><code class="language-cpp">addFunctionView(bundleQuery)
</code></pre> 
<p>如果每次都手动编写全部 SQL 语句，工作量大，并且扩展性差，通过元编程动态生成 SQL 语句可以解决这个问题。</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/7631edde76ca7d79f2d8afa589fea1fa/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">学生管理系统(源码)(C语言版)</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/fb0de9e80939862f4e967e3a081fd892/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">js加减乘除丢失精度问题及解决方法</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程爱好者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151260"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>