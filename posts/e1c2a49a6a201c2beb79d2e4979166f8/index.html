<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Flink1.17实战教程（第七篇：Flink SQL） - 编程爱好者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Flink1.17实战教程（第七篇：Flink SQL）" />
<meta property="og:description" content="系列文章目录 Flink1.17实战教程（第一篇：概念、部署、架构）
Flink1.17实战教程（第二篇：DataStream API）
Flink1.17实战教程（第三篇：时间和窗口）
Flink1.17实战教程（第四篇：处理函数）
Flink1.17实战教程（第五篇：状态管理）
Flink1.17实战教程（第六篇：容错机制）
Flink1.17实战教程（第七篇：Flink SQL）
文章目录 系列文章目录1. sql-client准备1.1 基于yarn-session模式1.2 常用配置 2. 流处理中的表2.1 动态表和持续查询2.2 将流转换成动态表2.3 用SQL持续查询2.4 将动态表转换为流 3. 时间属性3.1 事件时间3.2 处理时间 4. DDL（Data Definition Language）数据定义4.1 数据库4.2 表 5. 查询5.0 DataGen &amp; Print5.1 With子句5.2 SELECT &amp; WHERE 子句5.3 SELECT DISTINCT 子句5.4 分组聚合5.5 分组窗口聚合5.6 窗口表值函数（TVF）聚合5.7 Over 聚合5.8 特殊语法 —— TOP-N5.9 特殊语法 —— Deduplication去重5.10 联结（Join）查询5.10.1 常规联结查询5.10.2 间隔联结查询5.10.3 维表联结查询 5.11 Order by 和 limit5.12 SQL Hints5.13 集合操作5.14 系统函数5.15 Module操作 6." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bchobby.github.io/posts/e1c2a49a6a201c2beb79d2e4979166f8/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-27T09:38:32+08:00" />
<meta property="article:modified_time" content="2023-12-27T09:38:32+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程爱好者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程爱好者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Flink1.17实战教程（第七篇：Flink SQL）</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_0"></a>系列文章目录</h2> 
<p><a href="https://blog.csdn.net/qq_43048957/article/details/134683428?spm=1001.2014.3001.5501">Flink1.17实战教程（第一篇：概念、部署、架构）</a><br> <a href="https://blog.csdn.net/qq_43048957/article/details/135153457?spm=1001.2014.3001.5501">Flink1.17实战教程（第二篇：DataStream API）</a><br> <a href="https://blog.csdn.net/qq_43048957/article/details/135214215?spm=1001.2014.3001.5501">Flink1.17实战教程（第三篇：时间和窗口）</a><br> <a href="https://blog.csdn.net/qq_43048957/article/details/135217141?spm=1001.2014.3001.5501">Flink1.17实战教程（第四篇：处理函数）</a><br> <a href="https://blog.csdn.net/qq_43048957/article/details/135220819?spm=1001.2014.3001.5501">Flink1.17实战教程（第五篇：状态管理）</a><br> <a href="https://blog.csdn.net/qq_43048957/article/details/135221998?spm=1001.2014.3001.5501">Flink1.17实战教程（第六篇：容错机制）</a><br> <a href="https://blog.csdn.net/qq_43048957/article/details/135224171?spm=1001.2014.3001.5501">Flink1.17实战教程（第七篇：Flink SQL）</a></p> 
<hr> 
<p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#_0" rel="nofollow">系列文章目录</a></li><li><a href="#1_sqlclient_21" rel="nofollow">1. sql-client准备</a></li><li><ul><li><a href="#11_yarnsession_23" rel="nofollow">1.1 基于yarn-session模式</a></li><li><a href="#12__33" rel="nofollow">1.2 常用配置</a></li></ul> 
  </li><li><a href="#2__63" rel="nofollow">2. 流处理中的表</a></li><li><ul><li><a href="#21__75" rel="nofollow">2.1 动态表和持续查询</a></li><li><a href="#22__92" rel="nofollow">2.2 将流转换成动态表</a></li><li><a href="#23_SQL_96" rel="nofollow">2.3 用SQL持续查询</a></li><li><a href="#24__112" rel="nofollow">2.4 将动态表转换为流</a></li></ul> 
  </li><li><a href="#3__126" rel="nofollow">3. 时间属性</a></li><li><ul><li><a href="#31__135" rel="nofollow">3.1 事件时间</a></li><li><a href="#32__153" rel="nofollow">3.2 处理时间</a></li></ul> 
  </li><li><a href="#4_DDLData_Definition_Language_166" rel="nofollow">4. DDL（Data Definition Language）数据定义</a></li><li><ul><li><a href="#41__168" rel="nofollow">4.1 数据库</a></li><li><a href="#42__207" rel="nofollow">4.2 表</a></li></ul> 
  </li><li><a href="#5__413" rel="nofollow">5. 查询</a></li><li><ul><li><a href="#50_DataGen__Print_414" rel="nofollow">5.0 DataGen &amp; Print</a></li><li><a href="#51_With_452" rel="nofollow">5.1 With子句</a></li><li><a href="#52_SELECT__WHERE__474" rel="nofollow">5.2 SELECT &amp; WHERE 子句</a></li><li><a href="#53_SELECT_DISTINCT__489" rel="nofollow">5.3 SELECT DISTINCT 子句</a></li><li><a href="#54__496" rel="nofollow">5.4 分组聚合</a></li><li><a href="#55__584" rel="nofollow">5.5 分组窗口聚合</a></li><li><a href="#56_TVF_642" rel="nofollow">5.6 窗口表值函数（TVF）聚合</a></li><li><a href="#57_Over__708" rel="nofollow">5.7 Over 聚合</a></li><li><a href="#58___TOPN_786" rel="nofollow">5.8 特殊语法 —— TOP-N</a></li><li><a href="#59___Deduplication_827" rel="nofollow">5.9 特殊语法 —— Deduplication去重</a></li><li><a href="#510_Join_867" rel="nofollow">5.10 联结（Join）查询</a></li><li><ul><li><a href="#5101__871" rel="nofollow">5.10.1 常规联结查询</a></li><li><a href="#5102__933" rel="nofollow">5.10.2 间隔联结查询</a></li><li><a href="#5103__958" rel="nofollow">5.10.3 维表联结查询</a></li></ul> 
   </li><li><a href="#511_Order_by__limit_987" rel="nofollow">5.11 Order by 和 limit</a></li><li><a href="#512_SQL_Hints_1002" rel="nofollow">5.12 SQL Hints</a></li><li><a href="#513__1007" rel="nofollow">5.13 集合操作</a></li><li><a href="#514__1043" rel="nofollow">5.14 系统函数</a></li><li><a href="#515_Module_1096" rel="nofollow">5.15 Module操作</a></li></ul> 
  </li><li><a href="#6__Connector__1145" rel="nofollow">6. 常用 Connector 读写</a></li><li><ul><li><a href="#61_Kafka_1147" rel="nofollow">6.1 Kafka</a></li><li><a href="#62_File_1217" rel="nofollow">6.2 File</a></li><li><a href="#63_JDBCMySQL_1244" rel="nofollow">6.3 JDBC（MySQL）</a></li></ul> 
  </li><li><a href="#7_sqlclient__savepoint_1296" rel="nofollow">7. sql-client 中使用 savepoint</a></li><li><a href="#8_Catalog_1329" rel="nofollow">8. Catalog</a></li><li><ul><li><a href="#81_Catalog_1336" rel="nofollow">8.1 Catalog类型</a></li><li><a href="#82_JdbcCatalogMySQL_1343" rel="nofollow">8.2 JdbcCatalog（MySQL）</a></li><li><a href="#83_HiveCatalog_1386" rel="nofollow">8.3 HiveCatalog</a></li></ul> 
  </li><li><a href="#9_FlinkSQL_1452" rel="nofollow">9. 代码中使用FlinkSQL</a></li><li><ul><li><a href="#91__1453" rel="nofollow">9.1 需要引入的依赖</a></li><li><a href="#92__1484" rel="nofollow">9.2 创建表环境</a></li><li><a href="#93__1514" rel="nofollow">9.3 创建表</a></li><li><a href="#94__1539" rel="nofollow">9.4 表的查询</a></li><li><a href="#95__1609" rel="nofollow">9.5 输出表</a></li><li><a href="#96__1690" rel="nofollow">9.6 表和流的转换</a></li><li><a href="#97_UDF_1831" rel="nofollow">9.7 自定义函数（UDF）</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<hr> 
<p>Table API和SQL是最上层的API，在Flink中这两种API被集成在一起，SQL执行的对象也是Flink中的表（Table），所以我们一般会认为它们是一体的。Flink是批流统一的处理框架，无论是批处理（DataSet API）还是流处理（DataStream API），在上层应用中都可以直接使用Table API或者SQL来实现；这两种API对于一张表执行相同的查询操作，得到的结果是完全一样的。</p> 
<p>需要说明的是，Table API和SQL最初并不完善，在Flink 1.9版本合并阿里巴巴内部版本Blink之后发生了非常大的改变，此后也一直处在快速开发和完善的过程中，直到Flink 1.12版本才基本上做到了功能上的完善。而即使是在目前最新的1.17版本中，Table API和SQL也依然不算稳定，接口用法还在不停调整和更新。所以这部分希望大家重在理解原理和基本用法，具体的API调用可以随时关注官网的更新变化。</p> 
<p>SQL API 是基于 SQL 标准的 Apache Calcite 框架实现的，可通过纯 SQL 来开发和运行一个Flink 任务。<br> <img src="https://images2.imgbox.com/f5/16/euM9MuZs_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="1_sqlclient_21"></a>1. sql-client准备</h2> 
<p>为了方便讲解和演示Flink SQL语法，主要使用Flink提供的sql-client进行操作。</p> 
<h3><a id="11_yarnsession_23"></a>1.1 基于yarn-session模式</h3> 
<p><strong>1）启动Flink</strong></p> 
<pre><code class="prism language-shell">/opt/module/flink-1.17.0/bin/yarn-session.sh <span class="token parameter variable">-d</span>
</code></pre> 
<p><strong>2）启动Flink的sql-client</strong></p> 
<pre><code class="prism language-shell">/opt/module/flink-1.17.0/bin/sql-client.sh embedded <span class="token parameter variable">-s</span> yarn-session
</code></pre> 
<h3><a id="12__33"></a>1.2 常用配置</h3> 
<p><strong>1）结果显示模式</strong></p> 
<pre><code class="prism language-shell"><span class="token comment">#默认table，还可以设置为tableau、changelog</span>
SET sql-client.execution.result-mode<span class="token operator">=</span>tableau<span class="token punctuation">;</span>
</code></pre> 
<p><strong>2）执行环境</strong></p> 
<pre><code class="prism language-shell">SET execution.runtime-mode<span class="token operator">=</span>streaming<span class="token punctuation">;</span> <span class="token comment">#默认streaming，也可以设置batch</span>
</code></pre> 
<p><strong>3）默认并行度</strong></p> 
<pre><code class="prism language-shell">SET <span class="token assign-left variable">parallelism.default</span><span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">;</span>
</code></pre> 
<p><strong>4）设置状态TTL</strong></p> 
<pre><code class="prism language-shell">SET <span class="token assign-left variable">table.exec.state.ttl</span><span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">;</span>
</code></pre> 
<p><strong>5）通过sql文件初始化</strong><br> （1）创建sql文件</p> 
<pre><code class="prism language-shell"><span class="token function">vim</span> conf/sql-client-init.sql

SET sql-client.execution.result-mode<span class="token operator">=</span>tableau<span class="token punctuation">;</span>
CREATE DATABASE mydatabase<span class="token punctuation">;</span>
</code></pre> 
<p>（2）启动时，指定sql文件</p> 
<pre><code class="prism language-shell">/opt/module/flink-1.17.0/bin/sql-client.sh embedded <span class="token parameter variable">-s</span> yarn-session <span class="token parameter variable">-i</span> conf/sql-client-init.sql
</code></pre> 
<h2><a id="2__63"></a>2. 流处理中的表</h2> 
<p>我们可以将关系型表/SQL与流处理做一个对比，如表所示。</p> 
<table><thead><tr><th align="center"></th><th>关系型表/SQL</th><th>流处理</th></tr></thead><tbody><tr><td align="center">处理的数据对象</td><td>字段元组的有界集合</td><td>字段元组的无限序列</td></tr><tr><td align="center">查询（Query）对数据的访问</td><td>可以访问到完整的数据输入</td><td>无法访问到所有数据，必须“持续”等待流式输入</td></tr><tr><td align="center">查询终止条件</td><td>生成固定大小的结果集后终止</td><td>永不停止，根据持续收到的数据不断更新查询结果</td></tr></tbody></table> 
<p>可以看到，其实关系型表和SQL，主要就是针对批处理设计的，这和流处理有着天生的隔阂。接下来我们就来深入探讨一下流处理中表的概念。</p> 
<h3><a id="21__75"></a>2.1 动态表和持续查询</h3> 
<p>流处理面对的数据是连续不断的，这导致了流处理中的“表”跟我们熟悉的关系型数据库中的表完全不同；而基于表执行的查询操作，也就有了新的含义。</p> 
<p><strong>1）动态表（Dynamic Tables）</strong><br> 当流中有新数据到来，初始的表中会插入一行；而基于这个表定义的SQL查询，就应该在之前的基础上更新结果。这样得到的表就会不断地动态变化，被称为“动态表”（Dynamic Tables）。<br> 动态表是Flink在Table API和SQL中的核心概念，它为流数据处理提供了表和SQL支持。我们所熟悉的表一般用来做批处理，面向的是固定的数据集，可以认为是“静态表”；而动态表则完全不同，它里面的数据会随时间变化。</p> 
<p><strong>2）持续查询（Continuous Query）</strong><br> 动态表可以像静态的批处理表一样进行查询操作。由于数据在不断变化，因此基于它定义的SQL查询也不可能执行一次就得到最终结果。这样一来，我们对动态表的查询也就永远不会停止，一直在随着新数据的到来而继续执行。这样的查询就被称作“持续查询”（Continuous Query）。对动态表定义的查询操作，都是持续查询；而持续查询的结果也会是一个动态表。<br> 由于每次数据到来都会触发查询操作，因此可以认为一次查询面对的数据集，就是当前输入动态表中收到的所有数据。这相当于是对输入动态表做了一个“快照”（snapshot），当作有限数据集进行批处理；流式数据的到来会触发连续不断的快照查询，像动画一样连贯起来，就构成了“持续查询”。<br> <img src="https://images2.imgbox.com/ba/b4/G2jxb0N7_o.png" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p>持续查询的步骤如下：<br> （1）流（stream）被转换为动态表（dynamic table）；<br> （2）对动态表进行持续查询（continuous query），生成新的动态表；<br> （3）生成的动态表被转换成流。<br> 这样，只要API将流和动态表的转换封装起来，我们就可以直接在数据流上执行SQL查询，用处理表的方式来做流处理了。</p> 
</blockquote> 
<h3><a id="22__92"></a>2.2 将流转换成动态表</h3> 
<p>如果把流看作一张表，那么流中每个数据的到来，都应该看作是对表的一次插入（Insert）操作，会在表的末尾添加一行数据。因为流是连续不断的，而且之前的输出结果无法改变、只能在后面追加；所以我们其实是通过一个只有插入操作（insert-only）的更新日志（changelog）流，来构建一个表。<br> 例如，当用户点击事件到来时，就对应着动态表中的一次插入（Insert）操作，每条数据就是表中的一行；随着插入更多的点击事件，得到的动态表将不断增长。<br> <img src="https://images2.imgbox.com/80/1f/Dt5EZqqs_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="23_SQL_96"></a>2.3 用SQL持续查询</h3> 
<p><strong>1）更新（Update）查询</strong><br> 我们在代码中定义了一个SQL查询。</p> 
<pre><code class="prism language-java"><span class="token class-name">Table</span> urlCountTable <span class="token operator">=</span> tableEnv<span class="token punctuation">.</span><span class="token function">sqlQuery</span><span class="token punctuation">(</span><span class="token string">"SELECT user, COUNT(url) as cnt FROM EventTable GROUP BY user"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>当原始动态表不停地插入新的数据时，查询得到的urlCountTable会持续地进行更改。由于count数量可能会叠加增长，因此这里的更改操作可以是简单的插入（Insert），也可以是对之前数据的更新（Update）。这种持续查询被称为更新查询（Update Query），更新查询得到的结果表如果想要转换成DataStream，必须调用toChangelogStream()方法。<br> <img src="https://images2.imgbox.com/64/ea/f6w2mTPI_o.png" alt="在这里插入图片描述"><br> <strong>2）追加（Append）查询</strong><br> 上面的例子中，查询过程用到了分组聚合，结果表中就会产生更新操作。如果我们执行一个简单的条件查询，结果表中就会像原始表EventTable一样，只有插入（Insert）操作了。</p> 
<pre><code class="prism language-java"><span class="token class-name">Table</span> aliceVisitTable <span class="token operator">=</span> tableEnv<span class="token punctuation">.</span><span class="token function">sqlQuery</span><span class="token punctuation">(</span><span class="token string">"SELECT url, user FROM EventTable WHERE user = 'Cary'"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>这样的持续查询，就被称为追加查询（Append Query），它定义的结果表的更新日志（changelog）流中只有INSERT操作。<br> <img src="https://images2.imgbox.com/c6/1c/COr9IMX3_o.png" alt="在这里插入图片描述"><br> 由于窗口的统计结果是一次性写入结果表的，所以结果表的更新日志流中只会包含插入INSERT操作，而没有更新UPDATE操作。所以这里的持续查询，依然是一个追加（Append）查询。结果表result如果转换成DataStream，可以直接调用toDataStream()方法。</p> 
<h3><a id="24__112"></a>2.4 将动态表转换为流</h3> 
<p>与关系型数据库中的表一样，动态表也可以通过插入（Insert）、更新（Update）和删除（Delete）操作，进行持续的更改。将动态表转换为流或将其写入外部系统时，就需要对这些更改操作进行编码，通过发送编码消息的方式告诉外部系统要执行的操作。在Flink中，Table API和SQL支持三种编码方式：</p> 
<ul><li>仅追加（Append-only）流<br> 仅通过插入（Insert）更改来修改的动态表，可以直接转换为“仅追加”流。这个流中发出的数据，其实就是动态表中新增的每一行。</li><li>撤回（Retract）流<br> 撤回流是包含两类消息的流，添加（add）消息和撤回（retract）消息。<br> 具体的编码规则是：INSERT插入操作编码为add消息；DELETE删除操作编码为retract消息；而UPDATE更新操作则编码为被更改行的retract消息，和更新后行（新行）的add消息。这样，我们可以通过编码后的消息指明所有的增删改操作，一个动态表就可以转换为撤回流了。<br> <img src="https://images2.imgbox.com/78/c0/wAk1AMkF_o.png" alt="在这里插入图片描述"></li><li>更新插入（Upsert）流<br> 更新插入流中只包含两种类型的消息：更新插入（upsert）消息和删除（delete）消息。<br> 所谓的“upsert”其实是“update”和“insert”的合成词，所以对于更新插入流来说，INSERT插入操作和UPDATE更新操作，统一被编码为upsert消息；而DELETE删除操作则被编码为delete消息。<br> <img src="https://images2.imgbox.com/6f/be/nUoeCgdh_o.png" alt="在这里插入图片描述"><br> 需要注意的是，在代码里将动态表转换为DataStream时，只支持仅追加（append-only）和撤回（retract）流，我们调用toChangelogStream()得到的其实就是撤回流。而连接到外部系统时，则可以支持不同的编码方法，这取决于外部系统本身的特性。</li></ul> 
<h2><a id="3__126"></a>3. 时间属性</h2> 
<p>基于时间的操作（比如时间窗口），需要定义相关的时间语义和时间数据来源的信息。在Table API和SQL中，会给表单独提供一个逻辑上的时间字段，专门用来在表处理程序中指示时间。</p> 
<p>所以所谓的时间属性（time attributes），其实就是每个表模式结构（schema）的一部分。它可以在创建表的DDL里直接定义为一个字段，也可以在DataStream转换成表时定义。一旦定义了时间属性，它就可以作为一个普通字段引用，并且可以在基于时间的操作中使用。</p> 
<p>时间属性的数据类型必须为TIMESTAMP，它的行为类似于常规时间戳，可以直接访问并且进行计算。</p> 
<p>按照时间语义的不同，可以把时间属性的定义分成事件时间（event time）和处理时间（processing time）两种情况。</p> 
<h3><a id="31__135"></a>3.1 事件时间</h3> 
<p>事件时间属性可以在创建表DDL中定义，增加一个字段，通过WATERMARK语句来定义事件时间属性。具体定义方式如下：</p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> EventTable<span class="token punctuation">(</span>
  <span class="token keyword">user</span> STRING<span class="token punctuation">,</span>
  url STRING<span class="token punctuation">,</span>
  ts <span class="token keyword">TIMESTAMP</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
  WATERMARK <span class="token keyword">FOR</span> ts <span class="token keyword">AS</span> ts <span class="token operator">-</span> <span class="token keyword">INTERVAL</span> <span class="token string">'5'</span> <span class="token keyword">SECOND</span>
<span class="token punctuation">)</span> <span class="token keyword">WITH</span> <span class="token punctuation">(</span>
  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>这里我们把ts字段定义为事件时间属性，而且基于ts设置了5秒的水位线延迟。<br> 时间戳类型必须是 TIMESTAMP 或者TIMESTAMP_LTZ 类型。但是时间戳一般都是秒或者是毫秒（BIGINT 类型），这种情况可以通过如下方式转换</p> 
<pre><code class="prism language-sql">ts <span class="token keyword">BIGINT</span><span class="token punctuation">,</span>
time_ltz <span class="token keyword">AS</span> TO_TIMESTAMP_LTZ<span class="token punctuation">(</span>ts<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
</code></pre> 
<h3><a id="32__153"></a>3.2 处理时间</h3> 
<p>在定义处理时间属性时，必须要额外声明一个字段，专门用来保存当前的处理时间。<br> 在创建表的DDL（CREATE TABLE语句）中，可以增加一个额外的字段，通过调用系统内置的PROCTIME()函数来指定当前的处理时间属性。</p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> EventTable<span class="token punctuation">(</span>
  <span class="token keyword">user</span> STRING<span class="token punctuation">,</span>
  url STRING<span class="token punctuation">,</span>
  ts <span class="token keyword">AS</span> PROCTIME<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span> <span class="token keyword">WITH</span> <span class="token punctuation">(</span>
  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<h2><a id="4_DDLData_Definition_Language_166"></a>4. DDL（Data Definition Language）数据定义</h2> 
<h3><a id="41__168"></a>4.1 数据库</h3> 
<p><strong>1）创建数据库</strong><br> （1）语法</p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">DATABASE</span> <span class="token punctuation">[</span><span class="token keyword">IF</span> <span class="token operator">NOT</span> <span class="token keyword">EXISTS</span><span class="token punctuation">]</span> <span class="token punctuation">[</span>catalog_name<span class="token punctuation">.</span><span class="token punctuation">]</span>db_name
  <span class="token punctuation">[</span><span class="token keyword">COMMENT</span> database_comment<span class="token punctuation">]</span>
  <span class="token keyword">WITH</span> <span class="token punctuation">(</span>key1<span class="token operator">=</span>val1<span class="token punctuation">,</span> key2<span class="token operator">=</span>val2<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
</code></pre> 
<p>（2）案例</p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">DATABASE</span> db_flink<span class="token punctuation">;</span>
</code></pre> 
<p><strong>2）查询数据库</strong><br> （1）查询所有数据库</p> 
<pre><code class="prism language-sql"><span class="token keyword">SHOW</span> <span class="token keyword">DATABASES</span>
</code></pre> 
<p>（2）查询当前数据库</p> 
<pre><code class="prism language-sql"><span class="token keyword">SHOW</span> <span class="token keyword">CURRENT</span> <span class="token keyword">DATABASE</span>
</code></pre> 
<p><strong>3）修改数据库</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">DATABASE</span> <span class="token punctuation">[</span>catalog_name<span class="token punctuation">.</span><span class="token punctuation">]</span>db_name <span class="token keyword">SET</span> <span class="token punctuation">(</span>key1<span class="token operator">=</span>val1<span class="token punctuation">,</span> key2<span class="token operator">=</span>val2<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
</code></pre> 
<p><strong>4）删除数据库</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">DROP</span> <span class="token keyword">DATABASE</span> <span class="token punctuation">[</span><span class="token keyword">IF</span> <span class="token keyword">EXISTS</span><span class="token punctuation">]</span> <span class="token punctuation">[</span>catalog_name<span class="token punctuation">.</span><span class="token punctuation">]</span>db_name <span class="token punctuation">[</span> <span class="token punctuation">(</span><span class="token keyword">RESTRICT</span> <span class="token operator">|</span> <span class="token keyword">CASCADE</span><span class="token punctuation">)</span> <span class="token punctuation">]</span>
</code></pre> 
<ul><li>RESTRICT：删除非空数据库会触发异常。默认启用</li><li>CASCADE：删除非空数据库也会删除所有相关的表和函数。</li></ul> 
<pre><code class="prism language-sql"><span class="token keyword">DROP</span> <span class="token keyword">DATABASE</span> db_flink2<span class="token punctuation">;</span>
</code></pre> 
<p><strong>5）切换当前数据库</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">USE</span> database_name<span class="token punctuation">;</span>
</code></pre> 
<h3><a id="42__207"></a>4.2 表</h3> 
<p><strong>1）创建表</strong><br> （1）语法</p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> <span class="token punctuation">[</span><span class="token keyword">IF</span> <span class="token operator">NOT</span> <span class="token keyword">EXISTS</span><span class="token punctuation">]</span> <span class="token punctuation">[</span>catalog_name<span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">[</span>db_name<span class="token punctuation">.</span><span class="token punctuation">]</span>table_name
  <span class="token punctuation">(</span>
    { <span class="token operator">&lt;</span>physical_column_definition<span class="token operator">&gt;</span> <span class="token operator">|</span> <span class="token operator">&lt;</span>metadata_column_definition<span class="token operator">&gt;</span> <span class="token operator">|</span> <span class="token operator">&lt;</span>computed_column_definition<span class="token operator">&gt;</span> }<span class="token punctuation">[</span> <span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>n<span class="token punctuation">]</span>
    <span class="token punctuation">[</span> <span class="token operator">&lt;</span>watermark_definition<span class="token operator">&gt;</span> <span class="token punctuation">]</span>
    <span class="token punctuation">[</span> <span class="token operator">&lt;</span>table_constraint<span class="token operator">&gt;</span> <span class="token punctuation">]</span><span class="token punctuation">[</span> <span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>n<span class="token punctuation">]</span>
  <span class="token punctuation">)</span>
  <span class="token punctuation">[</span><span class="token keyword">COMMENT</span> table_comment<span class="token punctuation">]</span>
  <span class="token punctuation">[</span>PARTITIONED <span class="token keyword">BY</span> <span class="token punctuation">(</span>partition_column_name1<span class="token punctuation">,</span> partition_column_name2<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
  <span class="token keyword">WITH</span> <span class="token punctuation">(</span>key1<span class="token operator">=</span>val1<span class="token punctuation">,</span> key2<span class="token operator">=</span>val2<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
  <span class="token punctuation">[</span> <span class="token operator">LIKE</span> source_table <span class="token punctuation">[</span><span class="token punctuation">(</span> <span class="token operator">&lt;</span>like_options<span class="token operator">&gt;</span> <span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">|</span> <span class="token keyword">AS</span> select_query <span class="token punctuation">]</span>
</code></pre> 
<p>① physical_column_definition<br> 物理列是数据库中所说的常规列。其定义了物理介质中存储的数据中字段的名称、类型和顺序。其他类型的列可以在物理列之间声明，但不会影响最终的物理列的读取。</p> 
<p>② metadata_column_definition<br> 元数据列是 SQL 标准的扩展，允许访问数据源本身具有的一些元数据。元数据列由 METADATA 关键字标识。例如，我们可以使用元数据列从Kafka记录中读取和写入时间戳，用于基于时间的操作（这个时间戳不是数据中的某个时间戳字段，而是数据写入 Kafka 时，Kafka 引擎给这条数据打上的时间戳标记）。connector和format文档列出了每个组件可用的元数据字段。</p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> MyTable <span class="token punctuation">(</span>
  <span class="token identifier"><span class="token punctuation">`</span>user_id<span class="token punctuation">`</span></span> <span class="token keyword">BIGINT</span><span class="token punctuation">,</span>
  <span class="token identifier"><span class="token punctuation">`</span>name<span class="token punctuation">`</span></span> STRING<span class="token punctuation">,</span>
  <span class="token identifier"><span class="token punctuation">`</span>record_time<span class="token punctuation">`</span></span> TIMESTAMP_LTZ<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span> METADATA <span class="token keyword">FROM</span> <span class="token string">'timestamp'</span>
<span class="token punctuation">)</span> <span class="token keyword">WITH</span> <span class="token punctuation">(</span>
  <span class="token string">'connector'</span> <span class="token operator">=</span> <span class="token string">'kafka'</span>
  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>如果自定义的列名称和 Connector 中定义 metadata 字段的名称一样， FROM xxx 子句可省略</p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> MyTable <span class="token punctuation">(</span>
<span class="token identifier"><span class="token punctuation">`</span>user_id<span class="token punctuation">`</span></span> <span class="token keyword">BIGINT</span><span class="token punctuation">,</span>
<span class="token identifier"><span class="token punctuation">`</span>name<span class="token punctuation">`</span></span> STRING<span class="token punctuation">,</span>
<span class="token identifier"><span class="token punctuation">`</span>timestamp<span class="token punctuation">`</span></span> TIMESTAMP_LTZ<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span> METADATA
<span class="token punctuation">)</span> <span class="token keyword">WITH</span> <span class="token punctuation">(</span>
<span class="token string">'connector'</span> <span class="token operator">=</span> <span class="token string">'kafka'</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>如果自定义列的数据类型和 Connector 中定义的 metadata 字段的数据类型不一致，程序运行时会自动 cast强转，但是这要求两种数据类型是可以强转的。</p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> MyTable <span class="token punctuation">(</span>
<span class="token identifier"><span class="token punctuation">`</span>user_id<span class="token punctuation">`</span></span> <span class="token keyword">BIGINT</span><span class="token punctuation">,</span>
<span class="token identifier"><span class="token punctuation">`</span>name<span class="token punctuation">`</span></span> STRING<span class="token punctuation">,</span>
<span class="token comment">-- 将时间戳强转为 BIGINT</span>
<span class="token identifier"><span class="token punctuation">`</span>timestamp<span class="token punctuation">`</span></span> <span class="token keyword">BIGINT</span> METADATA
<span class="token punctuation">)</span> <span class="token keyword">WITH</span> <span class="token punctuation">(</span>
<span class="token string">'connector'</span> <span class="token operator">=</span> <span class="token string">'kafka'</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>默认情况下，Flink SQL planner 认为 metadata 列可以读取和写入。然而，在许多情况下，外部系统提供的只读元数据字段比可写字段多。因此，可以使用VIRTUAL关键字排除元数据列的持久化(表示只读)。</p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> MyTable <span class="token punctuation">(</span>
  <span class="token identifier"><span class="token punctuation">`</span>timestamp<span class="token punctuation">`</span></span> <span class="token keyword">BIGINT</span> METADATA<span class="token punctuation">,</span> 
  <span class="token identifier"><span class="token punctuation">`</span>offset<span class="token punctuation">`</span></span> <span class="token keyword">BIGINT</span> METADATA VIRTUAL<span class="token punctuation">,</span>
  <span class="token identifier"><span class="token punctuation">`</span>user_id<span class="token punctuation">`</span></span> <span class="token keyword">BIGINT</span><span class="token punctuation">,</span>
  <span class="token identifier"><span class="token punctuation">`</span>name<span class="token punctuation">`</span></span> STRING<span class="token punctuation">,</span>
<span class="token punctuation">)</span> <span class="token keyword">WITH</span> <span class="token punctuation">(</span>
  <span class="token string">'connector'</span> <span class="token operator">=</span> <span class="token string">'kafka'</span>
  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>③ computed_column_definition<br> 计算列是使用语法column_name AS computed_column_expression生成的虚拟列。<br> 计算列就是拿已有的一些列经过一些自定义的运算生成的新列，在物理上并不存储在表中，只能读不能写。列的数据类型从给定的表达式自动派生，无需手动声明。</p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> MyTable <span class="token punctuation">(</span>
  <span class="token identifier"><span class="token punctuation">`</span>user_id<span class="token punctuation">`</span></span> <span class="token keyword">BIGINT</span><span class="token punctuation">,</span>
  <span class="token identifier"><span class="token punctuation">`</span>price<span class="token punctuation">`</span></span> <span class="token keyword">DOUBLE</span><span class="token punctuation">,</span>
  <span class="token identifier"><span class="token punctuation">`</span>quantity<span class="token punctuation">`</span></span> <span class="token keyword">DOUBLE</span><span class="token punctuation">,</span>
  <span class="token identifier"><span class="token punctuation">`</span>cost<span class="token punctuation">`</span></span> <span class="token keyword">AS</span> price <span class="token operator">*</span> quanitity
<span class="token punctuation">)</span> <span class="token keyword">WITH</span> <span class="token punctuation">(</span>
  <span class="token string">'connector'</span> <span class="token operator">=</span> <span class="token string">'kafka'</span>
  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>④ 定义Watermark<br> Flink SQL 提供了几种 WATERMARK 生产策略：</p> 
<ul><li>严格升序：WATERMARK FOR rowtime_column AS rowtime_column。<br> Flink 任务认为时间戳只会越来越大，也<code>不存在相等的情况</code>，只要相等或者小于之前的，就认为是迟到的数据。</li><li>递增：WATERMARK FOR rowtime_column AS rowtime_column - INTERVAL ‘0.001’ SECOND 。<br> 一般基本不用这种方式。如果设置此类，则<code>允许有相同的时间戳</code>出现。</li><li>有界无序： WATERMARK FOR rowtime_column AS rowtime_column – INTERVAL ‘string’ timeUnit 。<br> 此类策略就可以用于设置最大乱序时间，假如设置为 WATERMARK FOR rowtime_column AS rowtime_column - INTERVAL ‘5’ SECOND ，则生成的是运行 5s 延迟的Watermark。一般都用这种 Watermark 生成策略，此类 Watermark 生成策略通常用于有数据乱序的场景中，而对应到实际的场景中，数据都是会存在乱序的，所以基本都使用此类策略。</li></ul> 
<p>⑤ PRIMARY KEY<br> 主键约束表明表中的一列或一组列是唯一的，并且它们不包含NULL值。主键唯一地标识表中的一行，只支持 not enforced。</p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> MyTable <span class="token punctuation">(</span>
<span class="token identifier"><span class="token punctuation">`</span>user_id<span class="token punctuation">`</span></span> <span class="token keyword">BIGINT</span><span class="token punctuation">,</span>
<span class="token identifier"><span class="token punctuation">`</span>name<span class="token punctuation">`</span></span> STRING<span class="token punctuation">,</span>
PARYMARY <span class="token keyword">KEY</span><span class="token punctuation">(</span>user_id<span class="token punctuation">)</span> <span class="token operator">not</span> enforced
<span class="token punctuation">)</span> <span class="token keyword">WITH</span> <span class="token punctuation">(</span>
<span class="token string">'connector'</span> <span class="token operator">=</span> <span class="token string">'kafka'</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>⑥ PARTITIONED BY<br> 创建分区表</p> 
<p>⑦ with语句<br> 用于创建表的表属性，用于指定外部存储系统的元数据信息。配置属性时，表达式key1=val1的键和值都应该是字符串字面值。如下是Kafka的映射表：</p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> KafkaTable <span class="token punctuation">(</span>
<span class="token identifier"><span class="token punctuation">`</span>user_id<span class="token punctuation">`</span></span> <span class="token keyword">BIGINT</span><span class="token punctuation">,</span>
<span class="token identifier"><span class="token punctuation">`</span>name<span class="token punctuation">`</span></span> STRING<span class="token punctuation">,</span>
<span class="token identifier"><span class="token punctuation">`</span>ts<span class="token punctuation">`</span></span> <span class="token keyword">TIMESTAMP</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span> METADATA <span class="token keyword">FROM</span> <span class="token string">'timestamp'</span>
<span class="token punctuation">)</span> <span class="token keyword">WITH</span> <span class="token punctuation">(</span>
<span class="token string">'connector'</span> <span class="token operator">=</span> <span class="token string">'kafka'</span><span class="token punctuation">,</span>
<span class="token string">'topic'</span> <span class="token operator">=</span> <span class="token string">'user_behavior'</span><span class="token punctuation">,</span>
<span class="token string">'properties.bootstrap.servers'</span> <span class="token operator">=</span> <span class="token string">'localhost:9092'</span><span class="token punctuation">,</span>
<span class="token string">'properties.group.id'</span> <span class="token operator">=</span> <span class="token string">'testGroup'</span><span class="token punctuation">,</span>
<span class="token string">'scan.startup.mode'</span> <span class="token operator">=</span> <span class="token string">'earliest-offset'</span><span class="token punctuation">,</span>
<span class="token string">'format'</span> <span class="token operator">=</span> <span class="token string">'csv'</span>
<span class="token punctuation">)</span>
</code></pre> 
<p>一般 with 中的配置项由 Flink SQL 的 Connector（链接外部存储的连接器） 来定义，每种 Connector 提供的with 配置项都是不同的。</p> 
<p>⑧ LIKE<br> 用于基于现有表的定义创建表。此外，用户可以扩展原始表或排除表的某些部分。<br> 可以使用该子句重用(可能还会覆盖)某些连接器属性，或者向外部定义的表添加水印。</p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> Orders <span class="token punctuation">(</span>
    <span class="token identifier"><span class="token punctuation">`</span>user<span class="token punctuation">`</span></span> <span class="token keyword">BIGINT</span><span class="token punctuation">,</span>
    product STRING<span class="token punctuation">,</span>
    order_time <span class="token keyword">TIMESTAMP</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span> <span class="token keyword">WITH</span> <span class="token punctuation">(</span> 
    <span class="token string">'connector'</span> <span class="token operator">=</span> <span class="token string">'kafka'</span><span class="token punctuation">,</span>
    <span class="token string">'scan.startup.mode'</span> <span class="token operator">=</span> <span class="token string">'earliest-offset'</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> Orders_with_watermark <span class="token punctuation">(</span>
    <span class="token comment">-- Add watermark definition</span>
    WATERMARK <span class="token keyword">FOR</span> order_time <span class="token keyword">AS</span> order_time <span class="token operator">-</span> <span class="token keyword">INTERVAL</span> <span class="token string">'5'</span> <span class="token keyword">SECOND</span> 
<span class="token punctuation">)</span> <span class="token keyword">WITH</span> <span class="token punctuation">(</span>
    <span class="token comment">-- Overwrite the startup-mode</span>
    <span class="token string">'scan.startup.mode'</span> <span class="token operator">=</span> <span class="token string">'latest-offset'</span>
<span class="token punctuation">)</span>
<span class="token operator">LIKE</span> Orders<span class="token punctuation">;</span>
</code></pre> 
<p>⑨ AS select_statement（CTAS）<br> 在一个create-table-as-select (CTAS)语句中，还可以通过查询的结果创建和填充表。CTAS是使用单个命令创建数据并向表中插入数据的最简单、最快速的方法。</p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> my_ctas_table
<span class="token keyword">WITH</span> <span class="token punctuation">(</span>
    <span class="token string">'connector'</span> <span class="token operator">=</span> <span class="token string">'kafka'</span><span class="token punctuation">,</span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token punctuation">)</span>
<span class="token keyword">AS</span> <span class="token keyword">SELECT</span> id<span class="token punctuation">,</span> name<span class="token punctuation">,</span> age <span class="token keyword">FROM</span> source_table <span class="token keyword">WHERE</span> <span class="token function">mod</span><span class="token punctuation">(</span>id<span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
</code></pre> 
<p>注意：CTAS有以下限制：</p> 
<ul><li>暂不支持创建临时表。</li><li>目前还不支持指定显式列。</li><li>还不支持指定显式水印。</li><li>目前还不支持创建分区表。</li><li>目前还不支持指定主键约束。</li></ul> 
<p>（2）简单建表示例</p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> test<span class="token punctuation">(</span>
    id <span class="token keyword">INT</span><span class="token punctuation">,</span> 
    ts <span class="token keyword">BIGINT</span><span class="token punctuation">,</span> 
    vc <span class="token keyword">INT</span>
<span class="token punctuation">)</span> <span class="token keyword">WITH</span> <span class="token punctuation">(</span>
<span class="token string">'connector'</span> <span class="token operator">=</span> <span class="token string">'print'</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> test1 <span class="token punctuation">(</span>
    <span class="token identifier"><span class="token punctuation">`</span>value<span class="token punctuation">`</span></span> STRING
<span class="token punctuation">)</span>
<span class="token operator">LIKE</span> test<span class="token punctuation">;</span>
</code></pre> 
<p><strong>2）查看表</strong><br> （1）查看所有表</p> 
<pre><code class="prism language-sql"><span class="token keyword">SHOW</span> <span class="token keyword">TABLES</span> <span class="token punctuation">[</span> <span class="token punctuation">(</span> <span class="token keyword">FROM</span> <span class="token operator">|</span> <span class="token operator">IN</span> <span class="token punctuation">)</span> <span class="token punctuation">[</span>catalog_name<span class="token punctuation">.</span><span class="token punctuation">]</span>database_name <span class="token punctuation">]</span> <span class="token punctuation">[</span> <span class="token punctuation">[</span><span class="token operator">NOT</span><span class="token punctuation">]</span> <span class="token operator">LIKE</span> <span class="token operator">&lt;</span>sql_like_pattern<span class="token operator">&gt;</span> <span class="token punctuation">]</span>
</code></pre> 
<p>如果没有指定数据库，则从当前数据库返回表。<br> LIKE子句中sql pattern的语法与MySQL方言的语法相同：</p> 
<ul><li>%匹配任意数量的字符，甚至零字符，%匹配一个’%'字符。</li><li><em>只匹配一个字符，_只匹配一个’</em>'字符</li></ul> 
<p>（2）查看表信息</p> 
<pre><code class="prism language-sql">{ <span class="token keyword">DESCRIBE</span> <span class="token operator">|</span> <span class="token keyword">DESC</span> } <span class="token punctuation">[</span>catalog_name<span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">[</span>db_name<span class="token punctuation">.</span><span class="token punctuation">]</span>table_name
</code></pre> 
<p><strong>3）修改表</strong><br> （1）修改表名</p> 
<pre><code class="prism language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> <span class="token punctuation">[</span>catalog_name<span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">[</span>db_name<span class="token punctuation">.</span><span class="token punctuation">]</span>table_name <span class="token keyword">RENAME</span> <span class="token keyword">TO</span> new_table_name
</code></pre> 
<p>（2）修改表属性</p> 
<pre><code class="prism language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> <span class="token punctuation">[</span>catalog_name<span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">[</span>db_name<span class="token punctuation">.</span><span class="token punctuation">]</span>table_name <span class="token keyword">SET</span> <span class="token punctuation">(</span>key1<span class="token operator">=</span>val1<span class="token punctuation">,</span> key2<span class="token operator">=</span>val2<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
</code></pre> 
<p><strong>4）删除表</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">DROP</span> <span class="token punctuation">[</span><span class="token keyword">TEMPORARY</span><span class="token punctuation">]</span> <span class="token keyword">TABLE</span> <span class="token punctuation">[</span><span class="token keyword">IF</span> <span class="token keyword">EXISTS</span><span class="token punctuation">]</span> <span class="token punctuation">[</span>catalog_name<span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">[</span>db_name<span class="token punctuation">.</span><span class="token punctuation">]</span>table_name
</code></pre> 
<h2><a id="5__413"></a>5. 查询</h2> 
<h3><a id="50_DataGen__Print_414"></a>5.0 DataGen &amp; Print</h3> 
<p><strong>1）创建数据生成器源表</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> source <span class="token punctuation">(</span> 
    id <span class="token keyword">INT</span><span class="token punctuation">,</span> 
    ts <span class="token keyword">BIGINT</span><span class="token punctuation">,</span> 
    vc <span class="token keyword">INT</span>
<span class="token punctuation">)</span> <span class="token keyword">WITH</span> <span class="token punctuation">(</span> 
    <span class="token string">'connector'</span> <span class="token operator">=</span> <span class="token string">'datagen'</span><span class="token punctuation">,</span> 
    <span class="token string">'rows-per-second'</span><span class="token operator">=</span><span class="token string">'1'</span><span class="token punctuation">,</span> 
    <span class="token string">'fields.id.kind'</span><span class="token operator">=</span><span class="token string">'random'</span><span class="token punctuation">,</span> 
    <span class="token string">'fields.id.min'</span><span class="token operator">=</span><span class="token string">'1'</span><span class="token punctuation">,</span> 
    <span class="token string">'fields.id.max'</span><span class="token operator">=</span><span class="token string">'10'</span><span class="token punctuation">,</span> 
    <span class="token string">'fields.ts.kind'</span><span class="token operator">=</span><span class="token string">'sequence'</span><span class="token punctuation">,</span> 
    <span class="token string">'fields.ts.start'</span><span class="token operator">=</span><span class="token string">'1'</span><span class="token punctuation">,</span> 
    <span class="token string">'fields.ts.end'</span><span class="token operator">=</span><span class="token string">'1000000'</span><span class="token punctuation">,</span> 
    <span class="token string">'fields.vc.kind'</span><span class="token operator">=</span><span class="token string">'random'</span><span class="token punctuation">,</span> 
    <span class="token string">'fields.vc.min'</span><span class="token operator">=</span><span class="token string">'1'</span><span class="token punctuation">,</span> 
    <span class="token string">'fields.vc.max'</span><span class="token operator">=</span><span class="token string">'100'</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> sink <span class="token punctuation">(</span>
    id <span class="token keyword">INT</span><span class="token punctuation">,</span> 
    ts <span class="token keyword">BIGINT</span><span class="token punctuation">,</span> 
    vc <span class="token keyword">INT</span>
<span class="token punctuation">)</span> <span class="token keyword">WITH</span> <span class="token punctuation">(</span>
<span class="token string">'connector'</span> <span class="token operator">=</span> <span class="token string">'print'</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p><strong>2）查询源表</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> source
</code></pre> 
<p><strong>3）插入sink表并查询</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">INSERT</span> <span class="token keyword">INTO</span> sink <span class="token keyword">select</span>  <span class="token operator">*</span> <span class="token keyword">from</span> source<span class="token punctuation">;</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> sink<span class="token punctuation">;</span>
</code></pre> 
<h3><a id="51_With_452"></a>5.1 With子句</h3> 
<p>WITH提供了一种编写辅助语句的方法，以便在较大的查询中使用。这些语句通常被称为公共表表达式(Common Table Expression, CTE)，可以认为它们定义了仅为一个查询而存在的临时视图。<br> <strong>1）语法</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">WITH</span> <span class="token operator">&lt;</span>with_item_definition<span class="token operator">&gt;</span> <span class="token punctuation">[</span> <span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token punctuation">]</span>
<span class="token keyword">SELECT</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token keyword">FROM</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">;</span>

<span class="token operator">&lt;</span>with_item_defintion<span class="token operator">&gt;</span>:
    with_item_name <span class="token punctuation">(</span>column_name<span class="token punctuation">[</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>n<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">AS</span> <span class="token punctuation">(</span> <span class="token operator">&lt;</span>select_query<span class="token operator">&gt;</span> <span class="token punctuation">)</span>
</code></pre> 
<p><strong>2）案例</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">WITH</span> source_with_total <span class="token keyword">AS</span> <span class="token punctuation">(</span>
    <span class="token keyword">SELECT</span> id<span class="token punctuation">,</span> vc<span class="token operator">+</span><span class="token number">10</span> <span class="token keyword">AS</span> total
    <span class="token keyword">FROM</span> source
<span class="token punctuation">)</span>

<span class="token keyword">SELECT</span> id<span class="token punctuation">,</span> <span class="token function">SUM</span><span class="token punctuation">(</span>total<span class="token punctuation">)</span>
<span class="token keyword">FROM</span> source_with_total
<span class="token keyword">GROUP</span> <span class="token keyword">BY</span> id<span class="token punctuation">;</span>
</code></pre> 
<h3><a id="52_SELECT__WHERE__474"></a>5.2 SELECT &amp; WHERE 子句</h3> 
<p><strong>1）语法</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">SELECT</span> select_list <span class="token keyword">FROM</span> table_expression <span class="token punctuation">[</span> <span class="token keyword">WHERE</span> boolean_expression <span class="token punctuation">]</span>
</code></pre> 
<p><strong>2）案例</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> source
<span class="token keyword">SELECT</span> id<span class="token punctuation">,</span> vc <span class="token operator">+</span> <span class="token number">10</span> <span class="token keyword">FROM</span> source

<span class="token comment">-- 自定义 Source 的数据</span>
<span class="token keyword">SELECT</span> id<span class="token punctuation">,</span> price <span class="token keyword">FROM</span> <span class="token punctuation">(</span><span class="token keyword">VALUES</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2.0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3.1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">AS</span> t <span class="token punctuation">(</span>order_id<span class="token punctuation">,</span> price<span class="token punctuation">)</span>

<span class="token keyword">SELECT</span> vc <span class="token operator">+</span> <span class="token number">10</span> <span class="token keyword">FROM</span> source <span class="token keyword">WHERE</span> id <span class="token operator">&gt;</span><span class="token number">10</span>
</code></pre> 
<h3><a id="53_SELECT_DISTINCT__489"></a>5.3 SELECT DISTINCT 子句</h3> 
<p>用作根据 key 进行数据去重</p> 
<pre><code class="prism language-sql"><span class="token keyword">SELECT</span> <span class="token keyword">DISTINCT</span> vc <span class="token keyword">FROM</span> source
</code></pre> 
<p>对于流查询，计算查询结果所需的状态可能无限增长。状态大小取决于不同行数。可以设置适当的状态生存时间(TTL)的查询配置，以防止状态过大。但是，这可能会影响查询结果的正确性。如某个 key 的数据过期从状态中删除了，那么下次再来这么一个 key，由于在状态中找不到，就又会输出一遍。</p> 
<h3><a id="54__496"></a>5.4 分组聚合</h3> 
<p>SQL中一般所说的聚合我们都很熟悉，主要是通过内置的一些聚合函数来实现的，比如SUM()、MAX()、MIN()、AVG()以及COUNT()。它们的特点是对多条输入数据进行计算，得到一个唯一的值，属于“多对一”的转换。比如我们可以通过下面的代码计算输入数据的个数：</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> <span class="token function">COUNT</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">)</span> <span class="token keyword">from</span> source<span class="token punctuation">;</span>
</code></pre> 
<p>而更多的情况下，我们可以通过GROUP BY子句来指定分组的键（key），从而对数据按照某个字段做一个分组统计。</p> 
<pre><code class="prism language-sql"><span class="token keyword">SELECT</span> vc<span class="token punctuation">,</span> <span class="token function">COUNT</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">)</span> <span class="token keyword">as</span> cnt <span class="token keyword">FROM</span> source <span class="token keyword">GROUP</span> <span class="token keyword">BY</span> vc<span class="token punctuation">;</span>
</code></pre> 
<p>这种聚合方式，就叫作“分组聚合”（group aggregation）。想要将结果表转换成流或输出到外部系统，必须采用撤回流（retract stream）或更新插入流（upsert stream）的编码方式；如果在代码中直接转换成DataStream打印输出，需要调用toChangelogStream()。</p> 
<p>分组聚合既是SQL原生的聚合查询，也是流处理中的聚合操作，这是实际应用中最常见的聚合方式。当然，使用的聚合函数一般都是系统内置的，如果希望实现特殊需求也可以进行自定义。</p> 
<p><strong>1）group聚合案例</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> source1 <span class="token punctuation">(</span>
dim STRING<span class="token punctuation">,</span>
user_id <span class="token keyword">BIGINT</span><span class="token punctuation">,</span>
price <span class="token keyword">BIGINT</span><span class="token punctuation">,</span>
row_time <span class="token keyword">AS</span> cast<span class="token punctuation">(</span><span class="token keyword">CURRENT_TIMESTAMP</span> <span class="token keyword">as</span> <span class="token keyword">timestamp</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
WATERMARK <span class="token keyword">FOR</span> row_time <span class="token keyword">AS</span> row_time <span class="token operator">-</span> <span class="token keyword">INTERVAL</span> <span class="token string">'5'</span> <span class="token keyword">SECOND</span>
<span class="token punctuation">)</span> <span class="token keyword">WITH</span> <span class="token punctuation">(</span>
<span class="token string">'connector'</span> <span class="token operator">=</span> <span class="token string">'datagen'</span><span class="token punctuation">,</span>
<span class="token string">'rows-per-second'</span> <span class="token operator">=</span> <span class="token string">'10'</span><span class="token punctuation">,</span>
<span class="token string">'fields.dim.length'</span> <span class="token operator">=</span> <span class="token string">'1'</span><span class="token punctuation">,</span>
<span class="token string">'fields.user_id.min'</span> <span class="token operator">=</span> <span class="token string">'1'</span><span class="token punctuation">,</span>
<span class="token string">'fields.user_id.max'</span> <span class="token operator">=</span> <span class="token string">'100000'</span><span class="token punctuation">,</span>
<span class="token string">'fields.price.min'</span> <span class="token operator">=</span> <span class="token string">'1'</span><span class="token punctuation">,</span>
<span class="token string">'fields.price.max'</span> <span class="token operator">=</span> <span class="token string">'100000'</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>


<span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> sink1 <span class="token punctuation">(</span>
dim STRING<span class="token punctuation">,</span>
pv <span class="token keyword">BIGINT</span><span class="token punctuation">,</span>
sum_price <span class="token keyword">BIGINT</span><span class="token punctuation">,</span>
max_price <span class="token keyword">BIGINT</span><span class="token punctuation">,</span>
min_price <span class="token keyword">BIGINT</span><span class="token punctuation">,</span>
uv <span class="token keyword">BIGINT</span><span class="token punctuation">,</span>
window_start <span class="token keyword">bigint</span>
<span class="token punctuation">)</span> <span class="token keyword">WITH</span> <span class="token punctuation">(</span>
<span class="token string">'connector'</span> <span class="token operator">=</span> <span class="token string">'print'</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>


<span class="token keyword">insert</span> <span class="token keyword">into</span> sink1
<span class="token keyword">select</span> dim<span class="token punctuation">,</span>
<span class="token function">count</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">)</span> <span class="token keyword">as</span> pv<span class="token punctuation">,</span>
<span class="token function">sum</span><span class="token punctuation">(</span>price<span class="token punctuation">)</span> <span class="token keyword">as</span> sum_price<span class="token punctuation">,</span>
<span class="token function">max</span><span class="token punctuation">(</span>price<span class="token punctuation">)</span> <span class="token keyword">as</span> max_price<span class="token punctuation">,</span>
<span class="token function">min</span><span class="token punctuation">(</span>price<span class="token punctuation">)</span> <span class="token keyword">as</span> min_price<span class="token punctuation">,</span>
<span class="token comment">-- 计算 uv 数</span>
<span class="token function">count</span><span class="token punctuation">(</span><span class="token keyword">distinct</span> user_id<span class="token punctuation">)</span> <span class="token keyword">as</span> uv<span class="token punctuation">,</span>
cast<span class="token punctuation">(</span><span class="token punctuation">(</span>UNIX_TIMESTAMP<span class="token punctuation">(</span>CAST<span class="token punctuation">(</span>row_time <span class="token keyword">AS</span> STRING<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">60</span> <span class="token keyword">as</span> <span class="token keyword">bigint</span><span class="token punctuation">)</span> <span class="token keyword">as</span> window_start
<span class="token keyword">from</span> source1
<span class="token keyword">group</span> <span class="token keyword">by</span>
dim<span class="token punctuation">,</span>
<span class="token comment">-- UNIX_TIMESTAMP得到秒的时间戳，将秒级别时间戳 / 60 转化为 1min， </span>
cast<span class="token punctuation">(</span><span class="token punctuation">(</span>UNIX_TIMESTAMP<span class="token punctuation">(</span>CAST<span class="token punctuation">(</span>row_time <span class="token keyword">AS</span> STRING<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">60</span> <span class="token keyword">as</span> <span class="token keyword">bigint</span><span class="token punctuation">)</span>
</code></pre> 
<p><strong>2）多维分析</strong><br> Group 聚合也支持 Grouping sets 、Rollup 、Cube，如下案例是Grouping sets：</p> 
<pre><code class="prism language-sql"><span class="token keyword">SELECT</span>
  supplier_id
<span class="token punctuation">,</span> rating
<span class="token punctuation">,</span> product_id
<span class="token punctuation">,</span> <span class="token function">COUNT</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">)</span>
<span class="token keyword">FROM</span> <span class="token punctuation">(</span>
<span class="token keyword">VALUES</span>
  <span class="token punctuation">(</span><span class="token string">'supplier1'</span><span class="token punctuation">,</span> <span class="token string">'product1'</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
  <span class="token punctuation">(</span><span class="token string">'supplier1'</span><span class="token punctuation">,</span> <span class="token string">'product2'</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
  <span class="token punctuation">(</span><span class="token string">'supplier2'</span><span class="token punctuation">,</span> <span class="token string">'product3'</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
  <span class="token punctuation">(</span><span class="token string">'supplier2'</span><span class="token punctuation">,</span> <span class="token string">'product4'</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>
<span class="token comment">-- 供应商id、产品id、评级</span>
<span class="token keyword">AS</span> Products<span class="token punctuation">(</span>supplier_id<span class="token punctuation">,</span> product_id<span class="token punctuation">,</span> rating<span class="token punctuation">)</span>  
<span class="token keyword">GROUP</span> <span class="token keyword">BY</span> GROUPING SETS<span class="token punctuation">(</span>
  <span class="token punctuation">(</span>supplier_id<span class="token punctuation">,</span> product_id<span class="token punctuation">,</span> rating<span class="token punctuation">)</span><span class="token punctuation">,</span>
  <span class="token punctuation">(</span>supplier_id<span class="token punctuation">,</span> product_id<span class="token punctuation">)</span><span class="token punctuation">,</span>
  <span class="token punctuation">(</span>supplier_id<span class="token punctuation">,</span> rating<span class="token punctuation">)</span><span class="token punctuation">,</span>
  <span class="token punctuation">(</span>supplier_id<span class="token punctuation">)</span><span class="token punctuation">,</span>
  <span class="token punctuation">(</span>product_id<span class="token punctuation">,</span> rating<span class="token punctuation">)</span><span class="token punctuation">,</span>
  <span class="token punctuation">(</span>product_id<span class="token punctuation">)</span><span class="token punctuation">,</span>
  <span class="token punctuation">(</span>rating<span class="token punctuation">)</span><span class="token punctuation">,</span>
  <span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<h3><a id="55__584"></a>5.5 分组窗口聚合</h3> 
<p>从1.13版本开始，分组窗口聚合已经标记为过时，鼓励使用更强大、更有效的窗口TVF聚合，在这里简单做个介绍。<br> 直接把窗口自身作为分组key放在GROUP BY之后的，所以也叫“分组窗口聚合”。SQL查询的分组窗口是通过 GROUP BY 子句定义的。类似于使用常规 GROUP BY 语句的查询，窗口分组语句的 GROUP BY 子句中带有一个窗口函数为每个分组计算出一个结果。<br> SQL中<code>只支持基于时间</code>的窗口，不支持基于元素个数的窗口。</p> 
<table><thead><tr><th align="center">分组窗口函数</th><th>描述</th></tr></thead><tbody><tr><td align="center">TUMBLE(time_attr, interval)</td><td>定义一个滚动窗口。滚动窗口把行分配到有固定持续时间（ interval ）的不重叠的连续窗口。比如，5 分钟的滚动窗口以 5 分钟为间隔对行进行分组。滚动窗口可以定义在事件时间（批处理、流处理）或处理时间（流处理）上。</td></tr><tr><td align="center">HOP(time_attr, interval, interval)</td><td>定义一个跳跃的时间窗口（在 Table API 中称为滑动窗口）。滑动窗口有一个固定的持续时间（ 第二个 interval 参数 ）以及一个滑动的间隔（第一个 interval 参数 ）。若滑动间隔小于窗口的持续时间，滑动窗口则会出现重叠；因此，行将会被分配到多个窗口中。比如，一个大小为 15 分组的滑动窗口，其滑动间隔为 5 分钟，将会把每一行数据分配到 3 个 15 分钟的窗口中。滑动窗口可以定义在事件时间（批处理、流处理）或处理时间（流处理）上。</td></tr><tr><td align="center">SESSION(time_attr, interval)</td><td>定义一个会话时间窗口。会话时间窗口没有一个固定的持续时间，但是它们的边界会根据 interval 所定义的不活跃时间所确定；即一个会话时间窗口在定义的间隔时间内没有时间出现，该窗口会被关闭。例如时间窗口的间隔时间是 30 分钟，当其不活跃的时间达到30分钟后，若观测到新的记录，则会启动一个新的会话时间窗口（否则该行数据会被添加到当前的窗口），且若在 30 分钟内没有观测到新纪录，这个窗口将会被关闭。会话时间窗口可以使用事件时间（批处理、流处理）或处理时间（流处理）。</td></tr></tbody></table> 
<p><img src="https://images2.imgbox.com/67/a7/RBoDh4zZ_o.png" alt="在这里插入图片描述"><br> <strong>1）准备数据</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> ws <span class="token punctuation">(</span>
  id <span class="token keyword">INT</span><span class="token punctuation">,</span>
  vc <span class="token keyword">INT</span><span class="token punctuation">,</span>
  pt <span class="token keyword">AS</span> PROCTIME<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment">--处理时间</span>
  et <span class="token keyword">AS</span> cast<span class="token punctuation">(</span><span class="token keyword">CURRENT_TIMESTAMP</span> <span class="token keyword">as</span> <span class="token keyword">timestamp</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment">--事件时间</span>
  WATERMARK <span class="token keyword">FOR</span> et <span class="token keyword">AS</span> et <span class="token operator">-</span> <span class="token keyword">INTERVAL</span> <span class="token string">'5'</span> <span class="token keyword">SECOND</span>   <span class="token comment">--watermark</span>
<span class="token punctuation">)</span> <span class="token keyword">WITH</span> <span class="token punctuation">(</span>
  <span class="token string">'connector'</span> <span class="token operator">=</span> <span class="token string">'datagen'</span><span class="token punctuation">,</span>
  <span class="token string">'rows-per-second'</span> <span class="token operator">=</span> <span class="token string">'10'</span><span class="token punctuation">,</span>
  <span class="token string">'fields.id.min'</span> <span class="token operator">=</span> <span class="token string">'1'</span><span class="token punctuation">,</span>
  <span class="token string">'fields.id.max'</span> <span class="token operator">=</span> <span class="token string">'3'</span><span class="token punctuation">,</span>
  <span class="token string">'fields.vc.min'</span> <span class="token operator">=</span> <span class="token string">'1'</span><span class="token punctuation">,</span>
  <span class="token string">'fields.vc.max'</span> <span class="token operator">=</span> <span class="token string">'100'</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p><strong>2）滚动窗口示例（时间属性字段，窗口长度）</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span>  
id<span class="token punctuation">,</span>
TUMBLE_START<span class="token punctuation">(</span>et<span class="token punctuation">,</span> <span class="token keyword">INTERVAL</span> <span class="token string">'5'</span> <span class="token keyword">SECOND</span><span class="token punctuation">)</span>  wstart<span class="token punctuation">,</span>
TUMBLE_END<span class="token punctuation">(</span>et<span class="token punctuation">,</span> <span class="token keyword">INTERVAL</span> <span class="token string">'5'</span> <span class="token keyword">SECOND</span><span class="token punctuation">)</span>  wend<span class="token punctuation">,</span>
<span class="token function">sum</span><span class="token punctuation">(</span>vc<span class="token punctuation">)</span> sumVc
<span class="token keyword">from</span> ws
<span class="token keyword">group</span> <span class="token keyword">by</span> id<span class="token punctuation">,</span> TUMBLE<span class="token punctuation">(</span>et<span class="token punctuation">,</span> <span class="token keyword">INTERVAL</span> <span class="token string">'5'</span> <span class="token keyword">SECOND</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p><strong>3）滑动窗口（时间属性字段，滑动步长，窗口长度）</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span>  
id<span class="token punctuation">,</span>
HOP_START<span class="token punctuation">(</span>pt<span class="token punctuation">,</span> <span class="token keyword">INTERVAL</span> <span class="token string">'3'</span> <span class="token keyword">SECOND</span><span class="token punctuation">,</span><span class="token keyword">INTERVAL</span> <span class="token string">'5'</span> <span class="token keyword">SECOND</span><span class="token punctuation">)</span>   wstart<span class="token punctuation">,</span>
HOP_END<span class="token punctuation">(</span>pt<span class="token punctuation">,</span> <span class="token keyword">INTERVAL</span> <span class="token string">'3'</span> <span class="token keyword">SECOND</span><span class="token punctuation">,</span><span class="token keyword">INTERVAL</span> <span class="token string">'5'</span> <span class="token keyword">SECOND</span><span class="token punctuation">)</span>  wend<span class="token punctuation">,</span>
   <span class="token function">sum</span><span class="token punctuation">(</span>vc<span class="token punctuation">)</span> sumVc
<span class="token keyword">from</span> ws
<span class="token keyword">group</span> <span class="token keyword">by</span> id<span class="token punctuation">,</span> HOP<span class="token punctuation">(</span>et<span class="token punctuation">,</span> <span class="token keyword">INTERVAL</span> <span class="token string">'3'</span> <span class="token keyword">SECOND</span><span class="token punctuation">,</span><span class="token keyword">INTERVAL</span> <span class="token string">'5'</span> <span class="token keyword">SECOND</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p><strong>4）会话窗口（时间属性字段，会话间隔）</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span>  
id<span class="token punctuation">,</span>
SESSION_START<span class="token punctuation">(</span>et<span class="token punctuation">,</span> <span class="token keyword">INTERVAL</span> <span class="token string">'5'</span> <span class="token keyword">SECOND</span><span class="token punctuation">)</span>  wstart<span class="token punctuation">,</span>
SESSION_END<span class="token punctuation">(</span>et<span class="token punctuation">,</span> <span class="token keyword">INTERVAL</span> <span class="token string">'5'</span> <span class="token keyword">SECOND</span><span class="token punctuation">)</span>  wend<span class="token punctuation">,</span>
<span class="token function">sum</span><span class="token punctuation">(</span>vc<span class="token punctuation">)</span> sumVc
<span class="token keyword">from</span> ws
<span class="token keyword">group</span> <span class="token keyword">by</span> id<span class="token punctuation">,</span> <span class="token keyword">SESSION</span><span class="token punctuation">(</span>et<span class="token punctuation">,</span> <span class="token keyword">INTERVAL</span> <span class="token string">'5'</span> <span class="token keyword">SECOND</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<h3><a id="56_TVF_642"></a>5.6 窗口表值函数（TVF）聚合</h3> 
<p>对比GroupWindow，TVF窗口更有效和强大。包括：</p> 
<ul><li>提供更多的性能优化手段</li><li>支持GroupingSets语法</li><li>可以在window聚合中使用TopN</li><li>提供累积窗口</li></ul> 
<p>对于窗口表值函数，窗口本身返回的是就是一个表，所以窗口会出现在FROM后面，GROUP BY后面的则是窗口新增的字段window_start和window_end</p> 
<pre><code class="prism language-sql"><span class="token keyword">FROM</span> <span class="token keyword">TABLE</span><span class="token punctuation">(</span>
窗口类型<span class="token punctuation">(</span><span class="token keyword">TABLE</span> 表名<span class="token punctuation">,</span> DESCRIPTOR<span class="token punctuation">(</span>时间字段<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token keyword">INTERVAL</span>时间…<span class="token punctuation">)</span>
<span class="token punctuation">)</span>
<span class="token keyword">GROUP</span> <span class="token keyword">BY</span> <span class="token punctuation">[</span>window_start<span class="token punctuation">,</span><span class="token punctuation">]</span><span class="token punctuation">[</span>window_end<span class="token punctuation">,</span><span class="token punctuation">]</span> <span class="token comment">--可选</span>
</code></pre> 
<p><strong>1）滚动窗口</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">SELECT</span> 
window_start<span class="token punctuation">,</span> 
window_end<span class="token punctuation">,</span> 
id <span class="token punctuation">,</span> <span class="token function">SUM</span><span class="token punctuation">(</span>vc<span class="token punctuation">)</span> 
sumVC
<span class="token keyword">FROM</span> <span class="token keyword">TABLE</span><span class="token punctuation">(</span>
  TUMBLE<span class="token punctuation">(</span><span class="token keyword">TABLE</span> ws<span class="token punctuation">,</span> DESCRIPTOR<span class="token punctuation">(</span>et<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">INTERVAL</span> <span class="token string">'5'</span> SECONDS<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">GROUP</span> <span class="token keyword">BY</span> window_start<span class="token punctuation">,</span> window_end<span class="token punctuation">,</span> id<span class="token punctuation">;</span>
</code></pre> 
<p><strong>2）滑动窗口</strong><br> 要求： 窗口长度=滑动步长的整数倍（底层会优化成多个小滚动窗口）</p> 
<pre><code class="prism language-sql"><span class="token keyword">SELECT</span> window_start<span class="token punctuation">,</span> window_end<span class="token punctuation">,</span> id <span class="token punctuation">,</span> <span class="token function">SUM</span><span class="token punctuation">(</span>vc<span class="token punctuation">)</span> sumVC
<span class="token keyword">FROM</span> <span class="token keyword">TABLE</span><span class="token punctuation">(</span>
  HOP<span class="token punctuation">(</span><span class="token keyword">TABLE</span> ws<span class="token punctuation">,</span> DESCRIPTOR<span class="token punctuation">(</span>et<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">INTERVAL</span> <span class="token string">'5'</span> SECONDS <span class="token punctuation">,</span> <span class="token keyword">INTERVAL</span> <span class="token string">'10'</span> SECONDS<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">GROUP</span> <span class="token keyword">BY</span> window_start<span class="token punctuation">,</span> window_end<span class="token punctuation">,</span> id<span class="token punctuation">;</span>
</code></pre> 
<p><strong>3）累积窗口</strong><br> <img src="https://images2.imgbox.com/77/2c/NQKvLaSM_o.png" alt="在这里插入图片描述"><br> 累积窗口会在一定的统计周期内进行累积计算。累积窗口中有两个核心的参数：最大窗口长度（max window size）和累积步长（step）。所谓的最大窗口长度其实就是我们所说的“统计周期”，最终目的就是统计这段时间内的数据。</p> 
<p>其实就是固定窗口间隔内提前触发的的滚动窗口 ，其实就是 Tumble Window + early-fire 的一个事件时间的版本。例如，从每日零点到当前这一分钟绘制累积 UV，其中 10:00 时的 UV 表示从 00:00 到 10:00 的 UV 总数。</p> 
<p>累积窗口可以认为是首先开一个最大窗口大小的滚动窗口，然后根据用户设置的触发的时间间隔将这个滚动窗口拆分为多个窗口，这些窗口具有相同的窗口起点和不同的窗口终点。<br> 注意： 窗口最大长度 = 累积步长的整数倍</p> 
<pre><code class="prism language-sql"><span class="token keyword">SELECT</span> 
window_start<span class="token punctuation">,</span> 
window_end<span class="token punctuation">,</span> 
id <span class="token punctuation">,</span> 
<span class="token function">SUM</span><span class="token punctuation">(</span>vc<span class="token punctuation">)</span> sumVC
<span class="token keyword">FROM</span> <span class="token keyword">TABLE</span><span class="token punctuation">(</span>
  CUMULATE<span class="token punctuation">(</span><span class="token keyword">TABLE</span> ws<span class="token punctuation">,</span> DESCRIPTOR<span class="token punctuation">(</span>et<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">INTERVAL</span> <span class="token string">'2'</span> SECONDS <span class="token punctuation">,</span> <span class="token keyword">INTERVAL</span> <span class="token string">'6'</span> SECONDS<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">GROUP</span> <span class="token keyword">BY</span> window_start<span class="token punctuation">,</span> window_end<span class="token punctuation">,</span> id<span class="token punctuation">;</span>
</code></pre> 
<p><strong>4）grouping sets多维分析</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">SELECT</span> 
window_start<span class="token punctuation">,</span> 
window_end<span class="token punctuation">,</span> 
id <span class="token punctuation">,</span> 
<span class="token function">SUM</span><span class="token punctuation">(</span>vc<span class="token punctuation">)</span> sumVC
<span class="token keyword">FROM</span> <span class="token keyword">TABLE</span><span class="token punctuation">(</span>
  TUMBLE<span class="token punctuation">(</span><span class="token keyword">TABLE</span> ws<span class="token punctuation">,</span> DESCRIPTOR<span class="token punctuation">(</span>et<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">INTERVAL</span> <span class="token string">'5'</span> SECONDS<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">GROUP</span> <span class="token keyword">BY</span> window_start<span class="token punctuation">,</span> window_end<span class="token punctuation">,</span>
rollup<span class="token punctuation">(</span> <span class="token punctuation">(</span>id<span class="token punctuation">)</span> <span class="token punctuation">)</span>
<span class="token comment">--  cube( (id) )</span>
<span class="token comment">--  grouping sets( (id),()  )</span>
<span class="token punctuation">;</span>
</code></pre> 
<h3><a id="57_Over__708"></a>5.7 Over 聚合</h3> 
<p>OVER聚合为一系列有序行的每个输入行计算一个聚合值。与GROUP BY聚合相比，OVER聚合不会将每个组的结果行数减少为一行。相反，OVER聚合为每个输入行生成一个聚合值。</p> 
<p>可以在事件时间或处理时间，以及指定为时间间隔、或行计数的范围内，定义Over windows。</p> 
<p><strong>1）语法</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">SELECT</span>
  agg_func<span class="token punctuation">(</span>agg_col<span class="token punctuation">)</span> <span class="token keyword">OVER</span> <span class="token punctuation">(</span>
    <span class="token punctuation">[</span><span class="token keyword">PARTITION</span> <span class="token keyword">BY</span> col1<span class="token punctuation">[</span><span class="token punctuation">,</span> col2<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
    <span class="token keyword">ORDER</span> <span class="token keyword">BY</span> time_col
    range_definition<span class="token punctuation">)</span><span class="token punctuation">,</span>
  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token keyword">FROM</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
</code></pre> 
<ul><li>ORDER BY：<code>必须是时间戳列</code>（事件时间、处理时间），<code>只能升序</code></li><li>PARTITION BY：标识了聚合窗口的聚合粒度</li><li>range_definition：这个标识聚合窗口的聚合数据范围，在 Flink 中有两种指定数据范围的方式。第一种为按照行数聚合，第二种为按照时间区间聚合</li></ul> 
<p><strong>2）案例</strong><br> （1）按照时间区间聚合<br> 统计每个传感器前10秒到现在收到的水位数据条数。</p> 
<pre><code class="prism language-sql"><span class="token keyword">SELECT</span> 
    id<span class="token punctuation">,</span> 
    et<span class="token punctuation">,</span> 
    vc<span class="token punctuation">,</span>
    <span class="token function">count</span><span class="token punctuation">(</span>vc<span class="token punctuation">)</span> <span class="token keyword">OVER</span> <span class="token punctuation">(</span>
        <span class="token keyword">PARTITION</span> <span class="token keyword">BY</span> id
        <span class="token keyword">ORDER</span> <span class="token keyword">BY</span> et
        RANGE <span class="token operator">BETWEEN</span> <span class="token keyword">INTERVAL</span> <span class="token string">'10'</span> <span class="token keyword">SECOND</span> <span class="token keyword">PRECEDING</span> <span class="token operator">AND</span> <span class="token keyword">CURRENT</span> <span class="token keyword">ROW</span>
  <span class="token punctuation">)</span> <span class="token keyword">AS</span> cnt
<span class="token keyword">FROM</span> ws
</code></pre> 
<p>也可以用WINDOW子句来在SELECT外部单独定义一个OVER窗口,可以多次使用：</p> 
<pre><code class="prism language-sql"><span class="token keyword">SELECT</span> 
    id<span class="token punctuation">,</span> 
    et<span class="token punctuation">,</span> 
    vc<span class="token punctuation">,</span>
<span class="token function">count</span><span class="token punctuation">(</span>vc<span class="token punctuation">)</span> <span class="token keyword">OVER</span> w <span class="token keyword">AS</span> cnt<span class="token punctuation">,</span>
<span class="token function">sum</span><span class="token punctuation">(</span>vc<span class="token punctuation">)</span> <span class="token keyword">OVER</span> w <span class="token keyword">AS</span> sumVC
<span class="token keyword">FROM</span> ws
WINDOW w <span class="token keyword">AS</span> <span class="token punctuation">(</span>
    <span class="token keyword">PARTITION</span> <span class="token keyword">BY</span> id
    <span class="token keyword">ORDER</span> <span class="token keyword">BY</span> et
    RANGE <span class="token operator">BETWEEN</span> <span class="token keyword">INTERVAL</span> <span class="token string">'10'</span> <span class="token keyword">SECOND</span> <span class="token keyword">PRECEDING</span> <span class="token operator">AND</span> <span class="token keyword">CURRENT</span> <span class="token keyword">ROW</span>
<span class="token punctuation">)</span>
</code></pre> 
<p>（2）按照行数聚合<br> 统计每个传感器前5条到现在数据的平均水位</p> 
<pre><code class="prism language-sql"><span class="token keyword">SELECT</span> 
    id<span class="token punctuation">,</span> 
    et<span class="token punctuation">,</span> 
    vc<span class="token punctuation">,</span>
    <span class="token function">avg</span><span class="token punctuation">(</span>vc<span class="token punctuation">)</span> <span class="token keyword">OVER</span> <span class="token punctuation">(</span>
    	<span class="token keyword">PARTITION</span> <span class="token keyword">BY</span> id
    	<span class="token keyword">ORDER</span> <span class="token keyword">BY</span> et
    	<span class="token keyword">ROWS</span> <span class="token operator">BETWEEN</span> <span class="token number">5</span> <span class="token keyword">PRECEDING</span> <span class="token operator">AND</span> <span class="token keyword">CURRENT</span> <span class="token keyword">ROW</span>
<span class="token punctuation">)</span> <span class="token keyword">AS</span> avgVC
<span class="token keyword">FROM</span> ws
</code></pre> 
<p>也可以用WINDOW子句来在SELECT外部单独定义一个OVER窗口：</p> 
<pre><code class="prism language-sql"><span class="token keyword">SELECT</span> 
    id<span class="token punctuation">,</span> 
    et<span class="token punctuation">,</span> 
    vc<span class="token punctuation">,</span>
<span class="token function">avg</span><span class="token punctuation">(</span>vc<span class="token punctuation">)</span> <span class="token keyword">OVER</span> w <span class="token keyword">AS</span> avgVC<span class="token punctuation">,</span>
<span class="token function">count</span><span class="token punctuation">(</span>vc<span class="token punctuation">)</span> <span class="token keyword">OVER</span> w <span class="token keyword">AS</span> cnt
<span class="token keyword">FROM</span> ws
WINDOW w <span class="token keyword">AS</span> <span class="token punctuation">(</span>
    <span class="token keyword">PARTITION</span> <span class="token keyword">BY</span> id
    <span class="token keyword">ORDER</span> <span class="token keyword">BY</span> et
    <span class="token keyword">ROWS</span> <span class="token operator">BETWEEN</span> <span class="token number">5</span> <span class="token keyword">PRECEDING</span> <span class="token operator">AND</span> <span class="token keyword">CURRENT</span> <span class="token keyword">ROW</span>
<span class="token punctuation">)</span>
</code></pre> 
<h3><a id="58___TOPN_786"></a>5.8 特殊语法 —— TOP-N</h3> 
<p>目前在Flink SQL中没有能够直接调用的TOP-N函数，而是提供了稍微复杂些的变通实现方法，是固定写法，特殊支持的over用法。</p> 
<p><strong>1）语法</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">SELECT</span> <span class="token punctuation">[</span>column_list<span class="token punctuation">]</span>
<span class="token keyword">FROM</span> <span class="token punctuation">(</span>
<span class="token keyword">SELECT</span> <span class="token punctuation">[</span>column_list<span class="token punctuation">]</span><span class="token punctuation">,</span>
ROW_NUMBER<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">OVER</span> <span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token keyword">PARTITION</span> <span class="token keyword">BY</span> col1<span class="token punctuation">[</span><span class="token punctuation">,</span> col2<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
<span class="token keyword">ORDER</span> <span class="token keyword">BY</span> col1 <span class="token punctuation">[</span><span class="token keyword">asc</span><span class="token operator">|</span><span class="token keyword">desc</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">,</span> col2 <span class="token punctuation">[</span><span class="token keyword">asc</span><span class="token operator">|</span><span class="token keyword">desc</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">AS</span> rownum
<span class="token keyword">FROM</span> table_name<span class="token punctuation">)</span>
<span class="token keyword">WHERE</span> rownum <span class="token operator">&lt;=</span> N <span class="token punctuation">[</span><span class="token operator">AND</span> conditions<span class="token punctuation">]</span>
</code></pre> 
<ul><li>ROW_NUMBER() ：标识 TopN 排序子句</li><li>PARTITION BY col1[, col2…] ：标识分区字段，代表按照这个 col 字段作为分区粒度对数据进行排序取 topN，比如下述案例中的 partition by key ，就是根据需求中的搜索关键词（key）做为分区</li><li>ORDER BY col1 [asc|desc][, col2 [asc|desc]…] ：标识 TopN 的排序规则，是按照哪些字段、顺序或逆序进行排序，<code>可以不是时间字段，也可以降序（TopN特殊支持）</code></li><li>WHERE rownum &lt;= N ：<code>这个子句是一定需要的，只有加上了这个子句，Flink 才能将其识别为一个TopN 的查询</code>，其中 N 代表 TopN 的条目数</li><li>[AND conditions] ：其他的限制条件也可以加上</li></ul> 
<p><strong>2）案例</strong><br> 取每个传感器最高的3个水位值</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> 
    id<span class="token punctuation">,</span>
    et<span class="token punctuation">,</span>
    vc<span class="token punctuation">,</span>
    rownum
<span class="token keyword">from</span> 
<span class="token punctuation">(</span>
    <span class="token keyword">select</span> 
        id<span class="token punctuation">,</span>
        et<span class="token punctuation">,</span>
        vc<span class="token punctuation">,</span>
        row_number<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">over</span><span class="token punctuation">(</span>
            <span class="token keyword">partition</span> <span class="token keyword">by</span> id 
            <span class="token keyword">order</span> <span class="token keyword">by</span> vc <span class="token keyword">desc</span> 
        <span class="token punctuation">)</span> <span class="token keyword">as</span> rownum
    <span class="token keyword">from</span> ws
<span class="token punctuation">)</span>
<span class="token keyword">where</span> rownum<span class="token operator">&lt;=</span><span class="token number">3</span><span class="token punctuation">;</span>
</code></pre> 
<h3><a id="59___Deduplication_827"></a>5.9 特殊语法 —— Deduplication去重</h3> 
<p>去重，也即上文介绍到的TopN 中 <code>row_number = 1</code> 的场景，但是这里有一点不一样在于其<code>排序字段一定是时间属性列，可以降序</code>，不能是其他非时间属性的普通列。</p> 
<p>在 row_number = 1 时，如果排序字段是普通列 planner 会翻译成 TopN 算子，如果是时间属性列 planner 会翻译成 Deduplication，这两者最终的执行算子是不一样的，Deduplication 相比 TopN 算子专门做了对应的优化，性能会有很大提升。可以从webui看出是翻译成哪种算子。<br> <img src="https://images2.imgbox.com/03/40/hViOA2XJ_o.png" alt="在这里插入图片描述"><br> 如果是按照时间属性字段降序，表示取最新一条，会造成不断的更新保存最新的一条。如果是升序，表示取最早的一条，不用去更新，性能更好。</p> 
<p><strong>1）语法</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">SELECT</span> <span class="token punctuation">[</span>column_list<span class="token punctuation">]</span>
<span class="token keyword">FROM</span> <span class="token punctuation">(</span>
<span class="token keyword">SELECT</span> <span class="token punctuation">[</span>column_list<span class="token punctuation">]</span><span class="token punctuation">,</span>
ROW_NUMBER<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">OVER</span> <span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token keyword">PARTITION</span> <span class="token keyword">BY</span> col1<span class="token punctuation">[</span><span class="token punctuation">,</span> col2<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
<span class="token keyword">ORDER</span> <span class="token keyword">BY</span> time_attr <span class="token punctuation">[</span><span class="token keyword">asc</span><span class="token operator">|</span><span class="token keyword">desc</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">AS</span> rownum
<span class="token keyword">FROM</span> table_name<span class="token punctuation">)</span>
<span class="token keyword">WHERE</span> rownum <span class="token operator">=</span> <span class="token number">1</span>
</code></pre> 
<p><strong>2）案例</strong><br> 对每个传感器的水位值去重</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> 
    id<span class="token punctuation">,</span>
    et<span class="token punctuation">,</span>
    vc<span class="token punctuation">,</span>
    rownum
<span class="token keyword">from</span> 
<span class="token punctuation">(</span>
    <span class="token keyword">select</span> 
        id<span class="token punctuation">,</span>
        et<span class="token punctuation">,</span>
        vc<span class="token punctuation">,</span>
        row_number<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">over</span><span class="token punctuation">(</span>
            <span class="token keyword">partition</span> <span class="token keyword">by</span> id<span class="token punctuation">,</span>vc 
            <span class="token keyword">order</span> <span class="token keyword">by</span> et 
        <span class="token punctuation">)</span> <span class="token keyword">as</span> rownum
    <span class="token keyword">from</span> ws
<span class="token punctuation">)</span>
<span class="token keyword">where</span> rownum<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">;</span>
</code></pre> 
<h3><a id="510_Join_867"></a>5.10 联结（Join）查询</h3> 
<p>在标准SQL中，可以将多个表连接合并起来，从中查询出想要的信息；这种操作就是表的联结（Join）。在Flink SQL中，同样支持各种灵活的联结（Join）查询，操作的对象是动态表。</p> 
<p>在流处理中，动态表的Join对应着两条数据流的Join操作。Flink SQL中的联结查询大体上也可以分为两类：SQL原生的联结查询方式，和流处理中特有的联结查询。</p> 
<h4><a id="5101__871"></a>5.10.1 常规联结查询</h4> 
<p>常规联结（Regular Join）是SQL中原生定义的Join方式，是最通用的一类联结操作。它的具体语法与标准SQL的联结完全相同，通过关键字JOIN来联结两个表，后面用关键字ON来指明联结条件。</p> 
<p>与标准SQL一致，Flink SQL的常规联结也可以分为内联结（INNER JOIN）和外联结（OUTER JOIN），区别在于结果中是否包含不符合联结条件的行。</p> 
<p>Regular Join 包含以下几种（以 L 作为左流中的数据标识， R 作为右流中的数据标识）：</p> 
<ul><li>Inner Join（Inner Equal Join）：流任务中，只有两条流 Join 到才输出，输出 +[L, R]</li><li>Left Join（Outer Equal Join）：流任务中，左流数据到达之后，无论有没有 Join 到右流的数据，都会输出（Join 到输出 +[L, R] ，没 Join 到输出 +[L, null] ），如果右流之后数据到达之后，发现左流之前输出过没有 Join 到的数据，则会发起回撤流，先输出 -[L, null] ，然后输出 +[L, R]</li><li>Right Join（Outer Equal Join）：有 Left Join 一样，左表和右表的执行逻辑完全相反</li><li>Full Join（Outer Equal Join）：流任务中，左流或者右流的数据到达之后，无论有没有 Join 到另外一条流的数据，都会输出（对右流来说：Join 到输出 +[L, R] ，没 Join 到输出 +[null, R] ；对左流来说：Join 到输出 +[L, R] ，没 Join 到输出 +[L, null] ）。如果一条流的数据到达之后，发现之前另一条流之前输出过没有 Join 到的数据，则会发起回撤流（左流数据到达为例：回撤 -[null, R] ，输出+[L, R] ，右流数据到达为例：回撤 -[L, null] ，输出 +[L, R]</li></ul> 
<p>Regular Join 的注意事项：</p> 
<ul><li>实时 Regular Join 可以不是 等值 join 。等值 join 和 非等值 join 区别在于， 等值 join数据 shuffle 策略是 Hash，会按照 Join on 中的等值条件作为 id 发往对应的下游； 非等值 join 数据 shuffle 策略是 Global，所有数据发往一个并发，按照非等值条件进行关联</li><li>流的上游是无限的数据，所以要做到关联的话，Flink 会将两条流的所有数据都存储在 State 中，所以 Flink 任务的 State 会无限增大，因此你需要为 State 配置合适的 TTL，以防止 State 过大。</li></ul> 
<p>再准备一张表用于join</p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> ws1 <span class="token punctuation">(</span>
  id <span class="token keyword">INT</span><span class="token punctuation">,</span>
  vc <span class="token keyword">INT</span><span class="token punctuation">,</span>
  pt <span class="token keyword">AS</span> PROCTIME<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment">--处理时间</span>
  et <span class="token keyword">AS</span> cast<span class="token punctuation">(</span><span class="token keyword">CURRENT_TIMESTAMP</span> <span class="token keyword">as</span> <span class="token keyword">timestamp</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment">--事件时间</span>
  WATERMARK <span class="token keyword">FOR</span> et <span class="token keyword">AS</span> et <span class="token operator">-</span> <span class="token keyword">INTERVAL</span> <span class="token string">'0.001'</span> <span class="token keyword">SECOND</span>   <span class="token comment">--watermark</span>
<span class="token punctuation">)</span> <span class="token keyword">WITH</span> <span class="token punctuation">(</span>
  <span class="token string">'connector'</span> <span class="token operator">=</span> <span class="token string">'datagen'</span><span class="token punctuation">,</span>
  <span class="token string">'rows-per-second'</span> <span class="token operator">=</span> <span class="token string">'1'</span><span class="token punctuation">,</span>
  <span class="token string">'fields.id.min'</span> <span class="token operator">=</span> <span class="token string">'3'</span><span class="token punctuation">,</span>
  <span class="token string">'fields.id.max'</span> <span class="token operator">=</span> <span class="token string">'5'</span><span class="token punctuation">,</span>
  <span class="token string">'fields.vc.min'</span> <span class="token operator">=</span> <span class="token string">'1'</span><span class="token punctuation">,</span>
  <span class="token string">'fields.vc.max'</span> <span class="token operator">=</span> <span class="token string">'100'</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p><strong>1）等值内联结（INNER Equi-JOIN）</strong><br> 内联结用INNER JOIN来定义，会返回两表中符合联接条件的所有行的组合，也就是所谓的笛卡尔积（Cartesian product）。目前仅支持等值联结条件。</p> 
<pre><code class="prism language-sql"><span class="token keyword">SELECT</span> <span class="token operator">*</span>
<span class="token keyword">FROM</span> ws
<span class="token keyword">INNER</span> <span class="token keyword">JOIN</span> ws1
<span class="token keyword">ON</span> ws<span class="token punctuation">.</span>id <span class="token operator">=</span> ws1<span class="token punctuation">.</span>id
</code></pre> 
<p><strong>2）等值外联结（OUTER Equi-JOIN）</strong><br> 与内联结类似，外联结也会返回符合联结条件的所有行的笛卡尔积；另外，还可以将某一侧表中找不到任何匹配的行也单独返回。Flink SQL支持左外（LEFT JOIN）、右外（RIGHT JOIN）和全外（FULL OUTER JOIN），分别表示会将左侧表、右侧表以及双侧表中没有任何匹配的行返回。</p> 
<p>具体用法如下：</p> 
<pre><code class="prism language-sql"><span class="token keyword">SELECT</span> <span class="token operator">*</span>
<span class="token keyword">FROM</span> ws
<span class="token keyword">LEFT</span> <span class="token keyword">JOIN</span> ws1
<span class="token keyword">ON</span> ws<span class="token punctuation">.</span>id <span class="token operator">=</span> ws1<span class="token punctuation">.</span>id

<span class="token keyword">SELECT</span> <span class="token operator">*</span>
<span class="token keyword">FROM</span> ws
<span class="token keyword">RIGHT</span> <span class="token keyword">JOIN</span> ws1
<span class="token keyword">ON</span> ws<span class="token punctuation">.</span>id <span class="token operator">=</span> ws1<span class="token punctuation">.</span>id

<span class="token keyword">SELECT</span> <span class="token operator">*</span>
<span class="token keyword">FROM</span> ws
<span class="token keyword">FULL</span> <span class="token keyword">OUTER</span> <span class="token keyword">JOIN</span> ws1
<span class="token keyword">ON</span> ws<span class="token punctuation">.</span>id <span class="token operator">=</span> ws<span class="token punctuation">.</span>id
</code></pre> 
<p>这部分知识与标准SQL中是完全一样的。</p> 
<h4><a id="5102__933"></a>5.10.2 间隔联结查询</h4> 
<p>我们曾经学习过DataStream API中的双流Join，包括窗口联结（window join）和间隔联结（interval join）。两条流的Join就对应着SQL中两个表的Join，这是流处理中特有的联结方式。目前Flink SQL还不支持窗口联结，而间隔联结则已经实现。</p> 
<p>间隔联结（Interval Join）返回的，同样是符合约束条件的两条中数据的笛卡尔积。只不过这里的“约束条件”除了常规的联结条件外，还多了一个时间间隔的限制。具体语法有以下要点：</p> 
<ul><li> <p>两表的联结<br> 间隔联结<code>不需要用JOIN关键字</code>，直接在FROM后将要联结的两表列出来就可以，用<code>逗号分隔</code>。这与标准SQL中的语法一致，表示一个“交叉联结”（Cross Join），会返回两表中所有行的笛卡尔积。</p> </li><li> <p>联结条件<br> <code>联结条件用WHERE子句来定义</code>，用一个等值表达式描述。交叉联结之后再用WHERE进行条件筛选，效果跟内联结INNER JOIN … ON …非常类似。</p> </li><li> <p>时间间隔限制<br> 我们可以在<code>WHERE子句中，联结条件后用AND追加一个时间间隔的限制条件</code>；做法是提取左右两侧表中的时间字段，然后用一个表达式来指明两者需要满足的间隔限制。具体定义方式有下面三种，这里分别用ltime和rtime表示左右表中的时间字段：</p> </li></ul> 
<p>（1）ltime = rtime<br> （2）ltime &gt;= rtime AND ltime &lt; rtime + INTERVAL ‘10’ MINUTE<br> （3）ltime BETWEEN rtime - INTERVAL ‘10’ SECOND AND rtime + INTERVAL ‘5’ SECOND<br> <img src="https://images2.imgbox.com/99/e1/KEQqeVnX_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-sql"><span class="token keyword">SELECT</span> <span class="token operator">*</span>
<span class="token keyword">FROM</span> ws<span class="token punctuation">,</span>ws1
<span class="token keyword">WHERE</span> ws<span class="token punctuation">.</span>id <span class="token operator">=</span> ws1<span class="token punctuation">.</span> id
<span class="token operator">AND</span> ws<span class="token punctuation">.</span>et <span class="token operator">BETWEEN</span> ws1<span class="token punctuation">.</span>et <span class="token operator">-</span> <span class="token keyword">INTERVAL</span> <span class="token string">'2'</span> <span class="token keyword">SECOND</span> <span class="token operator">AND</span> ws1<span class="token punctuation">.</span>et <span class="token operator">+</span> <span class="token keyword">INTERVAL</span> <span class="token string">'2'</span> <span class="token keyword">SECOND</span> 
</code></pre> 
<h4><a id="5103__958"></a>5.10.3 维表联结查询</h4> 
<p>Lookup Join 其实就是维表 Join，实时获取外部缓存的 Join，Lookup 的意思就是实时查找。<br> 上面说的这几种 Join 都是流与流之间的 Join，而 Lookup Join 是流与 Redis，Mysql，HBase 这种外部存储介质的 Join。<code>仅支持处理时间字段</code>。</p> 
<pre><code class="prism language-sql">表A
<span class="token keyword">JOIN</span> 维度表名 <span class="token keyword">FOR</span> SYSTEM_TIME <span class="token keyword">AS</span> <span class="token keyword">OF</span> 表A<span class="token punctuation">.</span>proc_time <span class="token keyword">AS</span> 别名
<span class="token keyword">ON</span> xx<span class="token punctuation">.</span>字段<span class="token operator">=</span>别名<span class="token punctuation">.</span>字段
</code></pre> 
<p>比如维表在mysql，维表join的写法如下：</p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> Customers <span class="token punctuation">(</span>
  id <span class="token keyword">INT</span><span class="token punctuation">,</span>
  name STRING<span class="token punctuation">,</span>
  country STRING<span class="token punctuation">,</span>
  zip STRING
<span class="token punctuation">)</span> <span class="token keyword">WITH</span> <span class="token punctuation">(</span>
  <span class="token string">'connector'</span> <span class="token operator">=</span> <span class="token string">'jdbc'</span><span class="token punctuation">,</span>
  <span class="token string">'url'</span> <span class="token operator">=</span> <span class="token string">'jdbc:mysql://hadoop102:3306/customerdb'</span><span class="token punctuation">,</span>
  <span class="token string">'table-name'</span> <span class="token operator">=</span> <span class="token string">'customers'</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- order表每来一条数据，都会去mysql的customers表查找维度数据</span>

<span class="token keyword">SELECT</span> o<span class="token punctuation">.</span>order_id<span class="token punctuation">,</span> o<span class="token punctuation">.</span>total<span class="token punctuation">,</span> c<span class="token punctuation">.</span>country<span class="token punctuation">,</span> c<span class="token punctuation">.</span>zip
<span class="token keyword">FROM</span> Orders <span class="token keyword">AS</span> o
  <span class="token keyword">JOIN</span> Customers <span class="token keyword">FOR</span> SYSTEM_TIME <span class="token keyword">AS</span> <span class="token keyword">OF</span> o<span class="token punctuation">.</span>proc_time <span class="token keyword">AS</span> c
    <span class="token keyword">ON</span> o<span class="token punctuation">.</span>customer_id <span class="token operator">=</span> c<span class="token punctuation">.</span>id<span class="token punctuation">;</span>
</code></pre> 
<h3><a id="511_Order_by__limit_987"></a>5.11 Order by 和 limit</h3> 
<p><strong>1）order by</strong><br> 支持 Batch\Streaming，但在实时任务中一般用的非常少。<br> 实时任务中，Order By 子句中<code>必须要有时间属性字段</code>，并且<code>必须写在最前面且为升序</code>。</p> 
<pre><code class="prism language-sql"><span class="token keyword">SELECT</span> <span class="token operator">*</span>
<span class="token keyword">FROM</span> ws
<span class="token keyword">ORDER</span> <span class="token keyword">BY</span> et<span class="token punctuation">,</span> id <span class="token keyword">desc</span>
</code></pre> 
<p><strong>2）limit</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">SELECT</span> <span class="token operator">*</span>
<span class="token keyword">FROM</span> ws
<span class="token keyword">LIMIT</span> <span class="token number">3</span>
</code></pre> 
<h3><a id="512_SQL_Hints_1002"></a>5.12 SQL Hints</h3> 
<p>在执行查询时，可以在表名后面添加SQL Hints来临时修改表属性，对当前job生效。</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> ws1<span class="token comment">/*+ OPTIONS('rows-per-second'='10')*/</span><span class="token punctuation">;</span>
</code></pre> 
<h3><a id="513__1007"></a>5.13 集合操作</h3> 
<p><strong>1）UNION 和 UNION ALL</strong><br> UNION：将集合合并并且去重<br> UNION ALL：将集合合并，不做去重。</p> 
<pre><code class="prism language-sql"><span class="token punctuation">(</span><span class="token keyword">SELECT</span> id <span class="token keyword">FROM</span> ws<span class="token punctuation">)</span> <span class="token keyword">UNION</span> <span class="token punctuation">(</span><span class="token keyword">SELECT</span> id <span class="token keyword">FROM</span> ws1<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">(</span><span class="token keyword">SELECT</span> id <span class="token keyword">FROM</span> ws<span class="token punctuation">)</span> <span class="token keyword">UNION</span> <span class="token keyword">ALL</span> <span class="token punctuation">(</span><span class="token keyword">SELECT</span> id <span class="token keyword">FROM</span> ws1<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p><strong>2）Intersect 和 Intersect All</strong><br> Intersect：交集并且去重<br> Intersect ALL：交集不做去重</p> 
<pre><code class="prism language-sql"><span class="token punctuation">(</span><span class="token keyword">SELECT</span> id <span class="token keyword">FROM</span> ws<span class="token punctuation">)</span> <span class="token keyword">INTERSECT</span> <span class="token punctuation">(</span><span class="token keyword">SELECT</span> id <span class="token keyword">FROM</span> ws1<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">(</span><span class="token keyword">SELECT</span> id <span class="token keyword">FROM</span> ws<span class="token punctuation">)</span> <span class="token keyword">INTERSECT</span> <span class="token keyword">ALL</span> <span class="token punctuation">(</span><span class="token keyword">SELECT</span> id <span class="token keyword">FROM</span> ws1<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p><strong>3）Except 和 Except All</strong><br> Except：差集并且去重<br> Except ALL：差集不做去重</p> 
<pre><code class="prism language-sql"><span class="token punctuation">(</span><span class="token keyword">SELECT</span> id <span class="token keyword">FROM</span> ws<span class="token punctuation">)</span> <span class="token keyword">EXCEPT</span> <span class="token punctuation">(</span><span class="token keyword">SELECT</span> id <span class="token keyword">FROM</span> ws1<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">(</span><span class="token keyword">SELECT</span> id <span class="token keyword">FROM</span> ws<span class="token punctuation">)</span> <span class="token keyword">EXCEPT</span> <span class="token keyword">ALL</span> <span class="token punctuation">(</span><span class="token keyword">SELECT</span> id <span class="token keyword">FROM</span> ws1<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>上述 SQL 在流式任务中，如果一条左流数据先来了，没有从右流集合数据中找到对应的数据时会直接输出，当右流对应数据后续来了之后，会下发回撤流将之前的数据給撤回。这也是一个回撤流</p> 
<p><strong>4）In 子查询</strong><br> In 子查询的结果集只能有一列</p> 
<pre><code class="prism language-sql"><span class="token keyword">SELECT</span> id<span class="token punctuation">,</span> vc
<span class="token keyword">FROM</span> ws
<span class="token keyword">WHERE</span> id <span class="token operator">IN</span> <span class="token punctuation">(</span>
<span class="token keyword">SELECT</span> id <span class="token keyword">FROM</span> ws1
<span class="token punctuation">)</span>
</code></pre> 
<p>上述 SQL 的 In 子句和之前介绍到的 Inner Join 类似。并且 In 子查询也会涉及到大状态问题，要注意设置 State 的 TTL。</p> 
<h3><a id="514__1043"></a>5.14 系统函数</h3> 
<p><a href="https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/dev/table/functions/systemfunctions/" rel="nofollow">系统函数（System Functions）</a>也叫内置函数（Built-in Functions），是在系统中预先实现好的功能模块。我们可以通过固定的函数名直接调用，实现想要的转换操作。Flink SQL提供了大量的系统函数，几乎支持所有的标准SQL中的操作，这为我们使用SQL编写流处理程序提供了极大的方便。</p> 
<p>Flink SQL中的系统函数又主要可以分为两大类：标量函数（Scalar Functions）和聚合函数（Aggregate Functions）。</p> 
<p><strong>1）标量函数（Scalar Functions）</strong><br> 标量函数指的就是只对输入数据做转换操作、返回一个值的函数。<br> 标量函数是最常见、也最简单的一类系统函数，数量非常庞大，很多在标准SQL中也有定义。所以我们这里只对一些常见类型列举部分函数，做一个简单概述，具体应用可以查看官网的完整函数列表。</p> 
<ul><li>比较函数（Comparison Functions）</li></ul> 
<p>比较函数其实就是一个比较表达式，用来判断两个值之间的关系，返回一个布尔类型的值。这个比较表达式可以是用 &lt;、&gt;、= 等符号连接两个值，也可以是用关键字定义的某种判断。例如：<br> （1）value1 = value2 判断两个值相等；<br> （2）value1 &lt;&gt; value2 判断两个值不相等<br> （3）value IS NOT NULL 判断value不为空</p> 
<ul><li>逻辑函数（Logical Functions）</li></ul> 
<p>逻辑函数就是一个逻辑表达式，也就是用与（AND）、或（OR）、非（NOT）将布尔类型的值连接起来，也可以用判断语句（IS、IS NOT）进行真值判断；返回的还是一个布尔类型的值。例如：<br> （1）boolean1 OR boolean2 布尔值boolean1与布尔值boolean2取逻辑或<br> （2）boolean IS FALSE 判断布尔值boolean是否为false<br> （3）NOT boolean 布尔值boolean取逻辑非</p> 
<ul><li>算术函数（Arithmetic Functions）</li></ul> 
<p>进行算术计算的函数，包括用算术符号连接的运算，和复杂的数学运算。例如：<br> （1）numeric1 + numeric2 两数相加<br> （2）POWER(numeric1, numeric2) 幂运算，取数numeric1的numeric2次方<br> （3）RAND() 返回（0.0, 1.0）区间内的一个double类型的伪随机数</p> 
<ul><li>字符串函数（String Functions）</li></ul> 
<p>进行字符串处理的函数。例如：<br> （1）string1 || string2 两个字符串的连接<br> （2）UPPER(string) 将字符串string转为全部大写<br> （3）CHAR_LENGTH(string) 计算字符串string的长度</p> 
<ul><li>时间函数（Temporal Functions）</li></ul> 
<p>进行与时间相关操作的函数。例如：<br> （1）DATE string 按格式"yyyy-MM-dd"解析字符串string，返回类型为SQL Date<br> （2）TIMESTAMP string 按格式"yyyy-MM-dd HH:mm:ss[.SSS]"解析，返回类型为SQL timestamp<br> （3）CURRENT_TIME 返回本地时区的当前时间，类型为SQL time（与LOCALTIME等价）<br> （4）INTERVAL string range 返回一个时间间隔。</p> 
<p><strong>2）聚合函数（Aggregate Functions）</strong><br> 聚合函数是以表中多个行作为输入，提取字段进行聚合操作的函数，会将唯一的聚合值作为结果返回。聚合函数应用非常广泛，不论分组聚合、窗口聚合还是开窗（Over）聚合，对数据的聚合操作都可以用相同的函数来定义。<br> 标准SQL中常见的聚合函数Flink SQL都是支持的，目前也在不断扩展，为流处理应用提供更强大的功能。例如：<br> （1）COUNT(*) 返回所有行的数量，统计个数。<br> （2）SUM([ ALL | DISTINCT ] expression) 对某个字段进行求和操作。默认情况下省略了关键字ALL，表示对所有行求和；如果指定DISTINCT，则会对数据进行去重，每个值只叠加一次。<br> （3）RANK() 返回当前值在一组值中的排名。<br> （4）ROW_NUMBER() 对一组值排序后，返回当前值的行号。<br> 其中，RANK()和ROW_NUMBER()一般用在OVER窗口中。</p> 
<h3><a id="515_Module_1096"></a>5.15 Module操作</h3> 
<p>Module 允许 Flink 扩展函数能力。它是可插拔的，Flink 官方本身已经提供了一些 Module，用户也可以编写自己的 Module。<br> 目前 Flink 包含了以下三种 Module：</p> 
<ul><li>CoreModule：CoreModule 是 Flink 内置的 Module，其包含了目前 Flink 内置的所有 UDF，Flink 默认开启的 Module 就是 CoreModule，我们可以直接使用其中的 UDF</li><li>HiveModule：HiveModule 可以将 Hive 内置函数作为 Flink 的系统函数提供给 SQL\Table API 用户进行使用，比如 get_json_object 这类 Hive 内置函数（Flink 默认的 CoreModule 是没有的）</li><li>用户自定义 Module：用户可以实现 Module 接口实现自己的 UDF 扩展 Module<br> 使用 LOAD 子句去加载 Flink SQL 体系内置的或者用户自定义的 Module，UNLOAD 子句去卸载 Flink SQL 体系内置的或者用户自定义的 Module。</li></ul> 
<p><strong>1）语法</strong></p> 
<pre><code class="prism language-sql"><span class="token comment">-- 加载</span>
<span class="token keyword">LOAD</span> MODULE module_name <span class="token punctuation">[</span><span class="token keyword">WITH</span> <span class="token punctuation">(</span><span class="token string">'key1'</span> <span class="token operator">=</span> <span class="token string">'val1'</span><span class="token punctuation">,</span> <span class="token string">'key2'</span> <span class="token operator">=</span> <span class="token string">'val2'</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
<span class="token comment">-- 卸载</span>
UNLOAD MODULE module_name

<span class="token comment">-- 查看</span>
<span class="token keyword">SHOW</span> MODULES<span class="token punctuation">;</span>
<span class="token keyword">SHOW</span> <span class="token keyword">FULL</span> MODULES<span class="token punctuation">;</span>
</code></pre> 
<p>在 Flink 中，Module 可以被 加载、启用 、禁用 、卸载 Module，当加载Module 之后，默认就是开启的。同时支持多个 Module 的，并且根据加载 Module 的顺序去按顺序查找和解析 UDF，先查到的先解析使用。<br> 此外，Flink 只会解析已经启用了的 Module。那么当两个 Module 中出现两个同名的函数且都启用时， Flink 会根据加载 Module 的顺序进行解析，结果就是会使用顺序为第一个的 Module 的 UDF，可以使用下面语法更改顺序：</p> 
<pre><code class="prism language-sql"><span class="token keyword">USE</span> MODULE hive<span class="token punctuation">,</span>core<span class="token punctuation">;</span>
</code></pre> 
<p>USE是启用module，没有被use的为禁用（禁用不是卸载），除此之外还可以实现调整顺序的效果。上面的语句会将 Hive Module 设为第一个使用及解析的 Module。</p> 
<p><strong>2）案例</strong><br> 加载官方已经提供的的 Hive Module，将 Hive 已有的内置函数作为 Flink 的内置函数。需要先引入 hive 的 connector。其中包含了 flink 官方提供的一个 HiveModule。</p> 
<p>（1）上传jar包到flink的lib中<br> 上传hive connector</p> 
<pre><code class="prism language-shell"><span class="token function">cp</span> flink-sql-connector-hive-3.1.3_2.12-1.17.0.jar /opt/module/flink-1.17.0/lib/
</code></pre> 
<p><code>注意</code>：拷贝hadoop的包，解决依赖冲突问题</p> 
<pre><code class="prism language-shell"><span class="token function">cp</span> /opt/module/hadoop-3.3.4/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar /opt/module/flink-1.17.0/lib/
</code></pre> 
<p>（2）重启flink集群和sql-client<br> （3）加载hive module</p> 
<pre><code class="prism language-sql"><span class="token comment">-- hive-connector内置了hive module，提供了hive自带的系统函数</span>
<span class="token keyword">load</span> module hive <span class="token keyword">with</span> <span class="token punctuation">(</span><span class="token string">'hive-version'</span><span class="token operator">=</span><span class="token string">'3.1.3'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">show</span> modules<span class="token punctuation">;</span>
<span class="token keyword">show</span> functions<span class="token punctuation">;</span>

<span class="token comment">-- 可以调用hive的split函数</span>
<span class="token keyword">select</span> split<span class="token punctuation">(</span><span class="token string">'a,b'</span><span class="token punctuation">,</span> <span class="token string">','</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<h2><a id="6__Connector__1145"></a>6. 常用 Connector 读写</h2> 
<p>12.5.0中的DataGen和Print都是一种connector，<a href="https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/connectors/table/overview/" rel="nofollow">其他connector</a>参考官网：</p> 
<h3><a id="61_Kafka_1147"></a>6.1 Kafka</h3> 
<p><strong>1）添加kafka连接器依赖</strong><br> （1）将flink-sql-connector-kafka-1.17.0.jar上传到flink的lib目录下<br> （2）重启yarn-session、sql-client</p> 
<p><strong>2）普通Kafka表</strong><br> （1）创建Kafka的映射表</p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> t1<span class="token punctuation">(</span> 
  <span class="token identifier"><span class="token punctuation">`</span>event_time<span class="token punctuation">`</span></span> <span class="token keyword">TIMESTAMP</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span> METADATA <span class="token keyword">FROM</span> <span class="token string">'timestamp'</span><span class="token punctuation">,</span>
  <span class="token comment">--列名和元数据名一致可以省略 FROM 'xxxx', VIRTUAL表示只读</span>
  <span class="token identifier"><span class="token punctuation">`</span>partition<span class="token punctuation">`</span></span> <span class="token keyword">BIGINT</span> METADATA VIRTUAL<span class="token punctuation">,</span>
  <span class="token identifier"><span class="token punctuation">`</span>offset<span class="token punctuation">`</span></span> <span class="token keyword">BIGINT</span> METADATA VIRTUAL<span class="token punctuation">,</span>
id <span class="token keyword">int</span><span class="token punctuation">,</span> 
ts <span class="token keyword">bigint</span> <span class="token punctuation">,</span> 
vc <span class="token keyword">int</span> <span class="token punctuation">)</span>
<span class="token keyword">WITH</span> <span class="token punctuation">(</span>
  <span class="token string">'connector'</span> <span class="token operator">=</span> <span class="token string">'kafka'</span><span class="token punctuation">,</span>
  <span class="token string">'properties.bootstrap.servers'</span> <span class="token operator">=</span> <span class="token string">'hadoop103:9092'</span><span class="token punctuation">,</span>
  <span class="token string">'properties.group.id'</span> <span class="token operator">=</span> <span class="token string">'atguigu'</span><span class="token punctuation">,</span>
<span class="token comment">-- 'earliest-offset', 'latest-offset', 'group-offsets', 'timestamp' and 'specific-offsets'</span>
  <span class="token string">'scan.startup.mode'</span> <span class="token operator">=</span> <span class="token string">'earliest-offset'</span><span class="token punctuation">,</span>
  <span class="token comment">-- fixed为flink实现的分区器，一个并行度只写往kafka一个分区</span>
<span class="token string">'sink.partitioner'</span> <span class="token operator">=</span> <span class="token string">'fixed'</span><span class="token punctuation">,</span>
  <span class="token string">'topic'</span> <span class="token operator">=</span> <span class="token string">'ws1'</span><span class="token punctuation">,</span>
  <span class="token string">'format'</span> <span class="token operator">=</span> <span class="token string">'json'</span>
<span class="token punctuation">)</span> 
</code></pre> 
<p>（2）插入Kafka表</p> 
<pre><code class="prism language-sql"><span class="token keyword">insert</span> <span class="token keyword">into</span> t1<span class="token punctuation">(</span>id<span class="token punctuation">,</span>ts<span class="token punctuation">,</span>vc<span class="token punctuation">)</span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> source
</code></pre> 
<p>（3）查询Kafka表</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> t1
</code></pre> 
<p><strong>3）upsert-kafka表</strong><br> 如果当前表存在<code>更新</code>操作，那么普通的kafka连接器将无法满足，此时可以使用<code>Upsert Kafka连接器</code>。</p> 
<p>Upsert Kafka 连接器支持以 upsert 方式从 Kafka topic 中读取数据并将数据写入 Kafka topic。</p> 
<p>作为 source，upsert-kafka 连接器生产 changelog 流，其中每条数据记录代表一个更新或删除事件。更准确地说，数据记录中的 value 被解释为同一 key 的最后一个 value 的 UPDATE，如果有这个 key（如果不存在相应的 key，则该更新被视为 INSERT）。用表来类比，changelog 流中的数据记录被解释为 UPSERT，也称为 INSERT/UPDATE，因为任何具有相同 key 的现有行都被覆盖。另外，value 为空的消息将会被视作为 DELETE 消息。</p> 
<p>作为 sink，upsert-kafka 连接器可以消费 changelog 流。它会将 INSERT/UPDATE_AFTER 数据作为正常的 Kafka 消息写入，并将 DELETE 数据以 value 为空的 Kafka 消息写入（表示对应 key 的消息被删除）。Flink 将根据主键列的值对数据进行分区，从而保证主键上的消息有序，因此同一主键上的更新/删除消息将落在同一分区中。</p> 
<p>（1）创建upsert-kafka的映射表(<code>必须定义主键</code>)</p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> t2<span class="token punctuation">(</span> 
    id <span class="token keyword">int</span> <span class="token punctuation">,</span> 
    sumVC <span class="token keyword">int</span> <span class="token punctuation">,</span>
    <span class="token keyword">primary</span> <span class="token keyword">key</span> <span class="token punctuation">(</span>id<span class="token punctuation">)</span> <span class="token operator">NOT</span> ENFORCED 
<span class="token punctuation">)</span>
<span class="token keyword">WITH</span> <span class="token punctuation">(</span>
  <span class="token string">'connector'</span> <span class="token operator">=</span> <span class="token string">'upsert-kafka'</span><span class="token punctuation">,</span>
  <span class="token string">'properties.bootstrap.servers'</span> <span class="token operator">=</span> <span class="token string">'hadoop102:9092'</span><span class="token punctuation">,</span>
  <span class="token string">'topic'</span> <span class="token operator">=</span> <span class="token string">'ws2'</span><span class="token punctuation">,</span>
  <span class="token string">'key.format'</span> <span class="token operator">=</span> <span class="token string">'json'</span><span class="token punctuation">,</span>
  <span class="token string">'value.format'</span> <span class="token operator">=</span> <span class="token string">'json'</span>
<span class="token punctuation">)</span>
</code></pre> 
<p>（2）插入upsert-kafka表</p> 
<pre><code class="prism language-sql"><span class="token keyword">insert</span> <span class="token keyword">into</span> t2 <span class="token keyword">select</span>  id<span class="token punctuation">,</span><span class="token function">sum</span><span class="token punctuation">(</span>vc<span class="token punctuation">)</span> sumVC  <span class="token keyword">from</span> source <span class="token keyword">group</span> <span class="token keyword">by</span> id
</code></pre> 
<p>（3）查询upsert-kafka表<br> upsert-kafka 无法从指定的偏移量读取，只会从主题的源读取。如此，才知道整个数据的更新过程。并且通过 -U，+U，+I 等符号来显示数据的变化过程。</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> t2
</code></pre> 
<h3><a id="62_File_1217"></a>6.2 File</h3> 
<p><strong>1）创建FileSystem映射表</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> t3<span class="token punctuation">(</span> id <span class="token keyword">int</span><span class="token punctuation">,</span> ts <span class="token keyword">bigint</span> <span class="token punctuation">,</span> vc <span class="token keyword">int</span> <span class="token punctuation">)</span>
<span class="token keyword">WITH</span> <span class="token punctuation">(</span>
  <span class="token string">'connector'</span> <span class="token operator">=</span> <span class="token string">'filesystem'</span><span class="token punctuation">,</span>
  <span class="token string">'path'</span> <span class="token operator">=</span> <span class="token string">'hdfs://hadoop102:8020/data/t3'</span><span class="token punctuation">,</span>
  <span class="token string">'format'</span> <span class="token operator">=</span> <span class="token string">'csv'</span>
<span class="token punctuation">)</span>
</code></pre> 
<p><strong>2）写入</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">insert</span> <span class="token keyword">into</span> t3 <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> source
</code></pre> 
<p><strong>3）查询</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> t3 <span class="token keyword">where</span> id <span class="token operator">=</span> <span class="token string">'1'</span>
</code></pre> 
<p><strong>4）报错问题</strong><br> <img src="https://images2.imgbox.com/17/ce/VbKL5CWb_o.png" alt="在这里插入图片描述"><br> 如上报错是因为之前lib下放了sql-hive的连接器jar包，解决方案有两种：</p> 
<ul><li>将hive的连接器jar包挪走，重启yarn-session、sql-client</li></ul> 
<pre><code class="prism language-shell"><span class="token function">mv</span> flink-sql-connector-hive-3.1.3_2.12-1.17.0.jar flink-sql-connector-hive-3.1.3_2.12-1.17.0.jar.bak
</code></pre> 
<ul><li>同10.8.3中的操作，替换planner的jar包</li></ul> 
<h3><a id="63_JDBCMySQL_1244"></a>6.3 JDBC（MySQL）</h3> 
<p>Flink在将数据写入外部数据库时使用DDL中定义的主键。<code>如果定义了主键，则连接器以upsert模式操作</code>，否则，连接器以追加模式操作。</p> 
<p>在upsert模式下，Flink会根据主键插入新行或更新现有行，Flink这样可以保证幂等性。为了保证输出结果符合预期，建议为表定义主键，并确保主键是底层数据库表的唯一键集或主键之一。在追加模式下，Flink将所有记录解释为INSERT消息，如果底层数据库中发生了主键或唯一约束违反，则INSERT操作可能会失败。</p> 
<p><strong>1）mysql的test库中建表</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> <span class="token identifier"><span class="token punctuation">`</span>ws2<span class="token punctuation">`</span></span> <span class="token punctuation">(</span>
  <span class="token identifier"><span class="token punctuation">`</span>id<span class="token punctuation">`</span></span> <span class="token keyword">int</span><span class="token punctuation">(</span><span class="token number">11</span><span class="token punctuation">)</span> <span class="token operator">NOT</span> <span class="token boolean">NULL</span><span class="token punctuation">,</span>
  <span class="token identifier"><span class="token punctuation">`</span>ts<span class="token punctuation">`</span></span> <span class="token keyword">bigint</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span> <span class="token keyword">DEFAULT</span> <span class="token boolean">NULL</span><span class="token punctuation">,</span>
  <span class="token identifier"><span class="token punctuation">`</span>vc<span class="token punctuation">`</span></span> <span class="token keyword">int</span><span class="token punctuation">(</span><span class="token number">11</span><span class="token punctuation">)</span> <span class="token keyword">DEFAULT</span> <span class="token boolean">NULL</span><span class="token punctuation">,</span>
  <span class="token keyword">PRIMARY</span> <span class="token keyword">KEY</span> <span class="token punctuation">(</span><span class="token identifier"><span class="token punctuation">`</span>id<span class="token punctuation">`</span></span><span class="token punctuation">)</span>
<span class="token punctuation">)</span> <span class="token keyword">ENGINE</span><span class="token operator">=</span><span class="token keyword">InnoDB</span> <span class="token keyword">DEFAULT</span> <span class="token keyword">CHARSET</span><span class="token operator">=</span>utf8
</code></pre> 
<p><strong>2）添加JDBC连接器依赖</strong></p> 
<p>由于目前1.17的连接器官方还未提供，我们从<a href="https://repository.apache.org/content/repositories/snapshots/org/apache/flink/flink-connector-jdbc/1.17-SNAPSHOT/" rel="nofollow">apache snapshot仓库</a>下载：</p> 
<p>上传jdbc连接器的jar包和mysql的连接驱动包到flink/lib下：</p> 
<ul><li>flink-connector-jdbc-1.17-20230109.003314-120.jar</li><li>mysql-connector-j-8.0.31.jar</li></ul> 
<p><strong>3）创建JDBC映射表</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> t4
<span class="token punctuation">(</span>
    id                      <span class="token keyword">INT</span><span class="token punctuation">,</span>
    ts                   <span class="token keyword">BIGINT</span><span class="token punctuation">,</span>
vc                     <span class="token keyword">INT</span><span class="token punctuation">,</span>
<span class="token keyword">PRIMARY</span> <span class="token keyword">KEY</span> <span class="token punctuation">(</span>id<span class="token punctuation">)</span> <span class="token operator">NOT</span> ENFORCED
<span class="token punctuation">)</span> <span class="token keyword">WITH</span> <span class="token punctuation">(</span>
    <span class="token string">'connector'</span><span class="token operator">=</span><span class="token string">'jdbc'</span><span class="token punctuation">,</span>
    <span class="token string">'url'</span> <span class="token operator">=</span> <span class="token string">'jdbc:mysql://hadoop102:3306/test?useUnicode=true&amp;characterEncoding=UTF-8'</span><span class="token punctuation">,</span>
    <span class="token string">'username'</span> <span class="token operator">=</span> <span class="token string">'root'</span><span class="token punctuation">,</span>
    <span class="token string">'password'</span> <span class="token operator">=</span> <span class="token string">'000000'</span><span class="token punctuation">,</span>
    <span class="token string">'connection.max-retry-timeout'</span> <span class="token operator">=</span> <span class="token string">'60s'</span><span class="token punctuation">,</span>
    <span class="token string">'table-name'</span> <span class="token operator">=</span> <span class="token string">'ws2'</span><span class="token punctuation">,</span>
    <span class="token string">'sink.buffer-flush.max-rows'</span> <span class="token operator">=</span> <span class="token string">'500'</span><span class="token punctuation">,</span>
    <span class="token string">'sink.buffer-flush.interval'</span> <span class="token operator">=</span> <span class="token string">'5s'</span><span class="token punctuation">,</span>
    <span class="token string">'sink.max-retries'</span> <span class="token operator">=</span> <span class="token string">'3'</span><span class="token punctuation">,</span>
    <span class="token string">'sink.parallelism'</span> <span class="token operator">=</span> <span class="token string">'1'</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p><strong>4）查询</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> t4
</code></pre> 
<p><strong>5）写入</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">insert</span> <span class="token keyword">into</span> t4 <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> source
</code></pre> 
<h2><a id="7_sqlclient__savepoint_1296"></a>7. sql-client 中使用 savepoint</h2> 
<p><strong>1）提交一个insert作业，可以给作业设置名称</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">INSERT</span> <span class="token keyword">INTO</span> sink <span class="token keyword">select</span>  <span class="token operator">*</span> <span class="token keyword">from</span> source<span class="token punctuation">;</span>
</code></pre> 
<p><strong>2）查看job列表</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">SHOW</span> JOBS<span class="token punctuation">;</span>
</code></pre> 
<p><strong>3）停止作业，触发savepoint</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">SET</span> state<span class="token punctuation">.</span>checkpoints<span class="token punctuation">.</span>dir<span class="token operator">=</span><span class="token string">'hdfs://hadoop102:8020/chk'</span><span class="token punctuation">;</span>
<span class="token keyword">SET</span> state<span class="token punctuation">.</span>savepoints<span class="token punctuation">.</span>dir<span class="token operator">=</span><span class="token string">'hdfs://hadoop102:8020/sp'</span><span class="token punctuation">;</span>

STOP JOB <span class="token string">'228d70913eab60dda85c5e7f78b5782c'</span> <span class="token keyword">WITH</span> <span class="token keyword">SAVEPOINT</span><span class="token punctuation">;</span>
</code></pre> 
<p><strong>4）从savepoint恢复</strong></p> 
<pre><code class="prism language-sql"><span class="token comment">-- 设置从savepoint恢复的路径 </span>
<span class="token keyword">SET</span> execution<span class="token punctuation">.</span><span class="token keyword">savepoint</span><span class="token punctuation">.</span>path<span class="token operator">=</span><span class="token string">'hdfs://hadoop102:8020/sp/savepoint-37f5e6-0013a2874f0a'</span><span class="token punctuation">;</span>  

<span class="token comment">-- 之后直接提交sql，就会从savepoint恢复</span>

<span class="token comment">--允许跳过无法还原的保存点状态</span>
<span class="token keyword">set</span> <span class="token string">'execution.savepoint.ignore-unclaimed-state'</span> <span class="token operator">=</span> <span class="token string">'true'</span><span class="token punctuation">;</span> 
</code></pre> 
<p><strong>5）恢复后重置路径</strong><br> 指定execution.savepoint.path后，将影响后面执行的所有DML语句，可以使用RESET命令重置这个配置选项。</p> 
<pre><code class="prism language-sql">RESET execution<span class="token punctuation">.</span><span class="token keyword">savepoint</span><span class="token punctuation">.</span>path<span class="token punctuation">;</span>
</code></pre> 
<p>如果出现reset没生效的问题，可能是个bug，我们可以退出sql-client，再重新进，不需要重启flink的集群。</p> 
<h2><a id="8_Catalog_1329"></a>8. Catalog</h2> 
<p>Catalog 提供了元数据信息，例如数据库、表、分区、视图以及数据库或其他外部系统中存储的函数和信息。</p> 
<p>数据处理最关键的方面之一是管理元数据。元数据可以是临时的，例如临时表、UDF。 元数据也可以是持久化的，例如 Hive MetaStore 中的元数据。Catalog 提供了一个统一的API，用于管理元数据，并使其可以从 Table API 和 SQL 查询语句中来访问。</p> 
<p>Catalog 允许用户引用其数据存储系统中现有的元数据，并自动将其映射到 Flink 的相应元数据。例如，Flink 可以直接使用 Hive MetaStore 中的表的元数据，不必在Flink中手动重写ddl，也可以将 Flink SQL 中的元数据存储到 Hive MetaStore 中。Catalog 极大地简化了用户开始使用 Flink 的步骤，并极大地提升了用户体验。</p> 
<h3><a id="81_Catalog_1336"></a>8.1 Catalog类型</h3> 
<p>目前 Flink 包含了以下四种 Catalog：</p> 
<ul><li>GenericInMemoryCatalog：基于内存实现的 Catalog，所有元数据只在session 的生命周期（即一个 Flink 任务一次运行生命周期内）内可用。默认自动创建，会有名为“default_catalog”的内存Catalog，这个Catalog默认只有一个名为“default_database”的数据库。</li><li>JdbcCatalog：JdbcCatalog 使得用户可以将 Flink 通过 JDBC 协议连接到关系数据库。Postgres Catalog和MySQL Catalog是目前仅有的两种JDBC Catalog实现，将元数据存储在数据库中。</li><li>HiveCatalog：有两个用途，一是单纯作为 Flink 元数据的持久化存储，二是作为读写现有 Hive 元数据的接口。注意：Hive MetaStore 以小写形式存储所有元数据对象名称。Hive Metastore以小写形式存储所有元对象名称，而 GenericInMemoryCatalog会区分大小写。</li><li>用户自定义 Catalog：用户可以实现 Catalog 接口实现自定义 Catalog。从Flink1.16开始引入了用户类加载器，通过CatalogFactory.Context#getClassLoader访问，否则会报错ClassNotFoundException。</li></ul> 
<h3><a id="82_JdbcCatalogMySQL_1343"></a>8.2 JdbcCatalog（MySQL）</h3> 
<p>JdbcCatalog不支持建表，只是打通flink与mysql的连接，可以去读写mysql现有的库表。</p> 
<p><strong>1）上传所需jar包到lib下</strong><br> 1.17的JDBC连接器还未发布到中央仓库，可以从<a href="https://repository.apache.org/content/repositories/snapshots/org/apache/flink/flink-connector-jdbc/1.17-SNAPSHOT/" rel="nofollow">apache snapshot</a>仓库下载：</p> 
<pre><code class="prism language-shell"><span class="token function">cp</span>	flink-connector-jdbc-1.17-20230109.003314-120.jar  /opt/module/flink-1.17.0/lib/
<span class="token function">cp</span> mysql-connector-j-8.0.31.jar /opt/module/flink-1.17.0/lib/
</code></pre> 
<p><strong>2）重启flink集群和sql-client</strong><br> <strong>3）创建Catalog</strong><br> JdbcCatalog支持以下选项：</p> 
<ul><li>name:必需，Catalog名称。</li><li>default-database:必需，连接到的默认数据库。</li><li>username: 必需，Postgres/MySQL帐户的用户名。</li><li>password:必需，该帐号的密码。</li><li>base-url:必需，数据库的jdbc url(不包含数据库名)</li></ul> 
<p>对于Postgres Catalog，是"jdbc:postgresql://:&lt;端口&gt;"<br> 对于MySQL Catalog，是"jdbc: mysql://:&lt;端口&gt;"</p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> CATALOG my_jdbc_catalog <span class="token keyword">WITH</span><span class="token punctuation">(</span>
    <span class="token string">'type'</span> <span class="token operator">=</span> <span class="token string">'jdbc'</span><span class="token punctuation">,</span>
    <span class="token string">'default-database'</span> <span class="token operator">=</span> <span class="token string">'test'</span><span class="token punctuation">,</span>
    <span class="token string">'username'</span> <span class="token operator">=</span> <span class="token string">'root'</span><span class="token punctuation">,</span>
    <span class="token string">'password'</span> <span class="token operator">=</span> <span class="token string">'000000'</span><span class="token punctuation">,</span>
    <span class="token string">'base-url'</span> <span class="token operator">=</span> <span class="token string">'jdbc:mysql://hadoop102:3306'</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p><strong>4）查看Catalog</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">SHOW</span> CATALOGS<span class="token punctuation">;</span>

<span class="token comment">--查看当前的CATALOG</span>
<span class="token keyword">SHOW</span> <span class="token keyword">CURRENT</span> CATALOG<span class="token punctuation">;</span>
</code></pre> 
<p><strong>5）使用指定Catalog</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">USE</span> CATALOG my_jdbc_catalog<span class="token punctuation">;</span>

<span class="token comment">--查看当前的CATALOG</span>
<span class="token keyword">SHOW</span> <span class="token keyword">CURRENT</span> CATALOG<span class="token punctuation">;</span>
</code></pre> 
<h3><a id="83_HiveCatalog_1386"></a>8.3 HiveCatalog</h3> 
<p><strong>1）上传所需jar包到lib下</strong></p> 
<pre><code class="prism language-shell"><span class="token function">cp</span> flink-sql-connector-hive-3.1.3_2.12-1.17.0.jar /opt/module/flink-1.17.0/lib/

<span class="token function">cp</span> mysql-connector-j-8.0.31.jar /opt/module/flink-1.17.0/lib/
</code></pre> 
<p><strong>2）更换planner依赖</strong></p> 
<p>只有在使用Hive方言或HiveServer2时才需要这样额外的计划器jar移动，但这是Hive集成的推荐设置。</p> 
<pre><code class="prism language-shell"><span class="token function">mv</span> /opt/module/flink-1.17.0/opt/flink-table-planner_2.12-1.17.0.jar /opt/module/flink-1.17.0/lib/flink-table-planner_2.12-1.17.0.jar

<span class="token function">mv</span> /opt/module/flink-1.17.0/lib/flink-table-planner-loader-1.17.0.jar /opt/module/flink-1.17.0/opt/flink-table-planner-loader-1.17.0.jar
</code></pre> 
<p><strong>3）重启flink集群和sql-client</strong></p> 
<p><strong>4）启动外置的hive metastore服务</strong><br> Hive metastore必须作为独立服务运行，也就是hive-site中必须配置hive.metastore.uris</p> 
<pre><code class="prism language-shell">hive <span class="token parameter variable">--service</span> metastore <span class="token operator">&amp;</span>
</code></pre> 
<p><strong>5）创建Catalog</strong></p> 
<table><thead><tr><th align="center">配置项</th><th>必需</th><th>默认值</th><th>类型</th><th>说明</th></tr></thead><tbody><tr><td align="center">type</td><td>Yes</td><td>(none)</td><td>String</td><td>Catalog类型，创建HiveCatalog时必须设置为’hive’。</td></tr><tr><td align="center">name</td><td>Yes</td><td>(none)</td><td>String</td><td>Catalog的唯一名称</td></tr><tr><td align="center">hive-conf-dir</td><td>No</td><td>(none)</td><td>String</td><td>包含hive -site.xml的目录,需要Hadoop文件系统支持。如果没指定hdfs协议，则认为是本地文件系统。如果不指定该选项，则在类路径中搜索hive-site.xml。</td></tr><tr><td align="center">default-database</td><td>No</td><td>default</td><td>String</td><td>Hive Catalog使用的默认数据库</td></tr><tr><td align="center">hive-version</td><td>No</td><td>(none)</td><td>String</td><td>HiveCatalog能够自动检测正在使用的Hive版本。建议不要指定Hive版本，除非自动检测失败。</td></tr><tr><td align="center">hadoop-conf-dir</td><td>No</td><td>(none)</td><td>String</td><td>Hadoop conf目录的路径。只支持本地文件系统路径。设置Hadoop conf的推荐方法是通过HADOOP_CONF_DIR环境变量。只有当环境变量不适合你时才使用该选项，例如，如果你想分别配置每个HiveCatalog。</td></tr></tbody></table> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> CATALOG myhive <span class="token keyword">WITH</span> <span class="token punctuation">(</span>
    <span class="token string">'type'</span> <span class="token operator">=</span> <span class="token string">'hive'</span><span class="token punctuation">,</span>
    <span class="token string">'default-database'</span> <span class="token operator">=</span> <span class="token string">'default'</span><span class="token punctuation">,</span>
    <span class="token string">'hive-conf-dir'</span> <span class="token operator">=</span> <span class="token string">'/opt/module/hive/conf'</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p><strong>6）查看Catalog</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">SHOW</span> CATALOGS<span class="token punctuation">;</span>

<span class="token comment">--查看当前的CATALOG</span>
<span class="token keyword">SHOW</span> <span class="token keyword">CURRENT</span> CATALOG<span class="token punctuation">;</span>
</code></pre> 
<p><strong>7）使用指定Catalog</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">USE</span> CATALOG myhive<span class="token punctuation">;</span>

<span class="token comment">--查看当前的CATALOG</span>
<span class="token keyword">SHOW</span> <span class="token keyword">CURRENT</span> CATALOG<span class="token punctuation">;</span>
</code></pre> 
<p>建表，退出sql-client重进，查看catalog和表还在。</p> 
<p><strong>8）读写Hive表</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">SHOW</span> <span class="token keyword">DATABASES</span><span class="token punctuation">;</span> <span class="token comment">-- 可以看到hive的数据库</span>

<span class="token keyword">USE</span> test<span class="token punctuation">;</span>  <span class="token comment">-- 可以切换到hive的数据库</span>

<span class="token keyword">SHOW</span> <span class="token keyword">TABLES</span><span class="token punctuation">;</span> <span class="token comment">-- 可以看到hive的表</span>

<span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">from</span> ws<span class="token punctuation">;</span> <span class="token comment">--可以读取hive表</span>

<span class="token keyword">INSERT</span> <span class="token keyword">INTO</span> ws <span class="token keyword">VALUES</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">-- 可以写入hive表</span>
</code></pre> 
<h2><a id="9_FlinkSQL_1452"></a>9. 代码中使用FlinkSQL</h2> 
<h3><a id="91__1453"></a>9.1 需要引入的依赖</h3> 
<p>我们想要在代码中使用Table API，必须引入相关的依赖。</p> 
<pre><code class="prism language-java"><span class="token generics"><span class="token punctuation">&lt;</span>dependency<span class="token punctuation">&gt;</span></span>
    <span class="token generics"><span class="token punctuation">&lt;</span>groupId<span class="token punctuation">&gt;</span></span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token operator">&lt;</span><span class="token operator">/</span>groupId<span class="token operator">&gt;</span>
    <span class="token generics"><span class="token punctuation">&lt;</span>artifactId<span class="token punctuation">&gt;</span></span>flink<span class="token operator">-</span>table<span class="token operator">-</span>api<span class="token operator">-</span>java<span class="token operator">-</span>bridge<span class="token operator">&lt;</span><span class="token operator">/</span>artifactId<span class="token operator">&gt;</span>
    <span class="token generics"><span class="token punctuation">&lt;</span>version<span class="token punctuation">&gt;</span></span>$<span class="token punctuation">{<!-- --></span>flink<span class="token punctuation">.</span>version<span class="token punctuation">}</span><span class="token operator">&lt;</span><span class="token operator">/</span>version<span class="token operator">&gt;</span>
<span class="token operator">&lt;</span><span class="token operator">/</span>dependency<span class="token operator">&gt;</span>
</code></pre> 
<p>这里的依赖是一个Java的“桥接器”（bridge），主要就是负责Table API和下层DataStream API的连接支持，按照不同的语言分为Java版和Scala版。</p> 
<p>如果我们希望在本地的集成开发环境（IDE）里运行Table API和SQL，还需要引入以下依赖：</p> 
<pre><code class="prism language-java"><span class="token generics"><span class="token punctuation">&lt;</span>dependency<span class="token punctuation">&gt;</span></span>
    <span class="token generics"><span class="token punctuation">&lt;</span>groupId<span class="token punctuation">&gt;</span></span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token operator">&lt;</span><span class="token operator">/</span>groupId<span class="token operator">&gt;</span>
    <span class="token generics"><span class="token punctuation">&lt;</span>artifactId<span class="token punctuation">&gt;</span></span>flink<span class="token operator">-</span>table<span class="token operator">-</span>planner<span class="token operator">-</span>loader<span class="token operator">&lt;</span><span class="token operator">/</span>artifactId<span class="token operator">&gt;</span>
    <span class="token generics"><span class="token punctuation">&lt;</span>version<span class="token punctuation">&gt;</span></span>$<span class="token punctuation">{<!-- --></span>flink<span class="token punctuation">.</span>version<span class="token punctuation">}</span><span class="token operator">&lt;</span><span class="token operator">/</span>version<span class="token operator">&gt;</span>
<span class="token operator">&lt;</span><span class="token operator">/</span>dependency<span class="token operator">&gt;</span>

<span class="token generics"><span class="token punctuation">&lt;</span>dependency<span class="token punctuation">&gt;</span></span>
    <span class="token generics"><span class="token punctuation">&lt;</span>groupId<span class="token punctuation">&gt;</span></span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token operator">&lt;</span><span class="token operator">/</span>groupId<span class="token operator">&gt;</span>
    <span class="token generics"><span class="token punctuation">&lt;</span>artifactId<span class="token punctuation">&gt;</span></span>flink<span class="token operator">-</span>table<span class="token operator">-</span>runtime<span class="token operator">&lt;</span><span class="token operator">/</span>artifactId<span class="token operator">&gt;</span>
    <span class="token generics"><span class="token punctuation">&lt;</span>version<span class="token punctuation">&gt;</span></span>$<span class="token punctuation">{<!-- --></span>flink<span class="token punctuation">.</span>version<span class="token punctuation">}</span><span class="token operator">&lt;</span><span class="token operator">/</span>version<span class="token operator">&gt;</span>
<span class="token operator">&lt;</span><span class="token operator">/</span>dependency<span class="token operator">&gt;</span>

<span class="token generics"><span class="token punctuation">&lt;</span>dependency<span class="token punctuation">&gt;</span></span>
    <span class="token generics"><span class="token punctuation">&lt;</span>groupId<span class="token punctuation">&gt;</span></span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token operator">&lt;</span><span class="token operator">/</span>groupId<span class="token operator">&gt;</span>
    <span class="token generics"><span class="token punctuation">&lt;</span>artifactId<span class="token punctuation">&gt;</span></span>flink<span class="token operator">-</span>connector<span class="token operator">-</span>files<span class="token operator">&lt;</span><span class="token operator">/</span>artifactId<span class="token operator">&gt;</span>
    <span class="token generics"><span class="token punctuation">&lt;</span>version<span class="token punctuation">&gt;</span></span>$<span class="token punctuation">{<!-- --></span>flink<span class="token punctuation">.</span>version<span class="token punctuation">}</span><span class="token operator">&lt;</span><span class="token operator">/</span>version<span class="token operator">&gt;</span>
<span class="token operator">&lt;</span><span class="token operator">/</span>dependency<span class="token operator">&gt;</span>
</code></pre> 
<h3><a id="92__1484"></a>9.2 创建表环境</h3> 
<p>对于Flink这样的流处理框架来说，数据流和表在结构上还是有所区别的。所以使用Table API和SQL需要一个特别的运行时环境，这就是所谓的“表环境”（TableEnvironment）。它主要负责：<br> （1）注册Catalog和表；<br> （2）执行 SQL 查询；<br> （3）注册用户自定义函数（UDF）；<br> （4）DataStream 和表之间的转换。</p> 
<p>每个表和SQL的执行，都必须绑定在一个表环境（TableEnvironment）中。TableEnvironment是Table API中提供的基本接口类，可以通过调用静态的create()方法来创建一个表环境实例。方法需要传入一个环境的配置参数EnvironmentSettings，它可以指定当前表环境的执行模式和计划器（planner）。执行模式有批处理和流处理两种选择，默认是流处理模式；计划器默认使用blink planner。</p> 
<pre><code class="prism language-java"><span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>table<span class="token punctuation">.</span>api<span class="token punctuation">.</span></span><span class="token class-name">EnvironmentSettings</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>table<span class="token punctuation">.</span>api<span class="token punctuation">.</span></span><span class="token class-name">TableEnvironment</span></span><span class="token punctuation">;</span>

<span class="token class-name">EnvironmentSettings</span> settings <span class="token operator">=</span> <span class="token class-name">EnvironmentSettings</span>
    <span class="token punctuation">.</span><span class="token function">newInstance</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">inStreamingMode</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment">// 使用流处理模式</span>
    <span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token class-name">TableEnvironment</span> tableEnv <span class="token operator">=</span> <span class="token class-name">TableEnvironment</span><span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span>setting<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>对于流处理场景，其实默认配置就完全够用了。所以我们也可以用另一种更加简单的方式来创建表环境：</p> 
<pre><code class="prism language-java"><span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>environment<span class="token punctuation">.</span></span><span class="token class-name">StreamExecutionEnvironment</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>table<span class="token punctuation">.</span>api<span class="token punctuation">.</span></span><span class="token class-name">EnvironmentSettings</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>table<span class="token punctuation">.</span>api<span class="token punctuation">.</span>bridge<span class="token punctuation">.</span>java<span class="token punctuation">.</span></span><span class="token class-name">StreamTableEnvironment</span></span><span class="token punctuation">;</span>

<span class="token class-name">StreamExecutionEnvironment</span> env <span class="token operator">=</span> <span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token class-name">StreamTableEnvironment</span> tableEnv <span class="token operator">=</span> <span class="token class-name">StreamTableEnvironment</span><span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span>env<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>这里我们引入了一个“流式表环境”（StreamTableEnvironment），它是继承自TableEnvironment的子接口。调用它的create()方法，只需要直接将当前的流执行环境（StreamExecutionEnvironment）传入，就可以创建出对应的流式表环境了。</p> 
<h3><a id="93__1514"></a>9.3 创建表</h3> 
<p>表（Table）是我们非常熟悉的一个概念，它是关系型数据库中数据存储的基本形式，也是SQL执行的基本对象。<br> 具体创建表的方式，有通过连接器（connector）和虚拟表（virtual tables）两种。</p> 
<p><strong>1）连接器表（Connector Tables）</strong><br> 最直观的创建表的方式，就是通过连接器（connector）连接到一个外部系统，然后定义出对应的表结构。<br> 在代码中，我们可以调用表环境的executeSql()方法，可以传入一个DDL作为参数执行SQL操作。这里我们传入一个CREATE语句进行表的创建，并通过WITH关键字指定连接到外部系统的连接器：</p> 
<pre><code class="prism language-java">tableEnv<span class="token punctuation">.</span><span class="token function">executeSql</span><span class="token punctuation">(</span><span class="token string">"CREATE [TEMPORARY] TABLE MyTable ... WITH ( 'connector' = ... )"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>这里的TEMPORARY关键字可以省略。</p> 
<p><strong>2）虚拟表（Virtual Tables）</strong><br> 在环境中注册之后，我们就可以在SQL中直接使用这张表进行查询转换了。</p> 
<pre><code class="prism language-java"><span class="token class-name">Table</span> newTable <span class="token operator">=</span> tableEnv<span class="token punctuation">.</span><span class="token function">sqlQuery</span><span class="token punctuation">(</span><span class="token string">"SELECT ... FROM MyTable... "</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>这里调用了表环境的sqlQuery()方法，直接传入一条SQL语句作为参数执行查询，得到的结果是一个Table对象。Table是Table API中提供的核心接口类，就代表了一个Java中定义的表实例。</p> 
<p>由于newTable是一个Table对象，并没有在表环境中注册；所以如果希望直接在SQL中使用，我们还需要将这个中间结果表注册到环境中：</p> 
<pre><code class="prism language-java">tableEnv<span class="token punctuation">.</span><span class="token function">createTemporaryView</span><span class="token punctuation">(</span><span class="token string">"NewTable"</span><span class="token punctuation">,</span> newTable<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>我们发现，这里的注册其实是创建了一个“虚拟表”（Virtual Table）。这个概念与SQL语法中的视图（View）非常类似，所以调用的方法也叫作创建“虚拟视图”（createTemporaryView）。</p> 
<h3><a id="94__1539"></a>9.4 表的查询</h3> 
<p>创建好了表，接下来自然就是对表进行查询转换了。对一个表的查询（Query）操作，就对应着流数据的转换（Transform）处理。<br> Flink为我们提供了两种查询方式：SQL，和Table API。</p> 
<p><strong>1）执行SQL进行查询</strong><br> 基于表执行SQL语句，是我们最为熟悉的查询方式。<br> 在代码中，我们只要调用表环境的sqlQuery()方法，传入一个字符串形式的SQL查询语句就可以了。执行得到的结果，是一个Table对象。</p> 
<pre><code class="prism language-java"><span class="token comment">// 创建表环境</span>
<span class="token class-name">TableEnvironment</span> tableEnv <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">;</span> 

<span class="token comment">// 创建表</span>
tableEnv<span class="token punctuation">.</span><span class="token function">executeSql</span><span class="token punctuation">(</span><span class="token string">"CREATE TABLE EventTable ... WITH ( 'connector' = ... )"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">// 查询用户Alice的点击事件，并提取表中前两个字段</span>
<span class="token class-name">Table</span> aliceVisitTable <span class="token operator">=</span> tableEnv<span class="token punctuation">.</span><span class="token function">sqlQuery</span><span class="token punctuation">(</span>
    <span class="token string">"SELECT user, url "</span> <span class="token operator">+</span>
    <span class="token string">"FROM EventTable "</span> <span class="token operator">+</span>
    <span class="token string">"WHERE user = 'Alice' "</span>
  <span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>目前Flink支持标准SQL中的绝大部分用法，并提供了丰富的计算函数。这样我们就可以把已有的技术迁移过来，像在MySQL、Hive中那样直接通过编写SQL实现自己的处理需求，从而大大降低了Flink上手的难度。<br> 例如，我们也可以通过GROUP BY关键字定义分组聚合，调用COUNT()、SUM()这样的函数来进行统计计算：</p> 
<pre><code class="prism language-java"><span class="token class-name">Table</span> urlCountTable <span class="token operator">=</span> tableEnv<span class="token punctuation">.</span><span class="token function">sqlQuery</span><span class="token punctuation">(</span>
    <span class="token string">"SELECT user, COUNT(url) "</span> <span class="token operator">+</span>
    <span class="token string">"FROM EventTable "</span> <span class="token operator">+</span>
    <span class="token string">"GROUP BY user "</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>上面的例子得到的是一个新的Table对象，我们可以再次将它注册为虚拟表继续在SQL中调用。另外，我们也可以直接将查询的结果写入到已经注册的表中，这需要调用表环境的executeSql()方法来执行DDL，传入的是一个INSERT语句：</p> 
<pre><code class="prism language-scala"><span class="token comment">// 注册表</span>
tableEnv<span class="token punctuation">.</span>executeSql<span class="token punctuation">(</span><span class="token string">"CREATE TABLE EventTable ... WITH ( 'connector' = ... )"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
tableEnv<span class="token punctuation">.</span>executeSql<span class="token punctuation">(</span><span class="token string">"CREATE TABLE OutputTable ... WITH ( 'connector' = ... )"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>


<span class="token comment">// 将查询结果输出到OutputTable中</span>
tableEnv<span class="token punctuation">.</span>executeSql <span class="token punctuation">(</span>
<span class="token string">"INSERT INTO OutputTable "</span> <span class="token operator">+</span>
    <span class="token string">"SELECT user, url "</span> <span class="token operator">+</span>
    <span class="token string">"FROM EventTable "</span> <span class="token operator">+</span>
    <span class="token string">"WHERE user = 'Alice' "</span>
  <span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p><strong>2）调用Table API进行查询</strong><br> 另外一种查询方式就是调用Table API。这是嵌入在Java和Scala语言内的查询API，核心就是Table接口类，通过一步步链式调用Table的方法，就可以定义出所有的查询转换操作。<br> 由于Table API是基于Table的Java实例进行调用的，因此我们首先要得到表的Java对象。基于环境中已注册的表，可以通过表环境的from()方法非常容易地得到一个Table对象：</p> 
<pre><code class="prism language-java"><span class="token class-name">Table</span> eventTable <span class="token operator">=</span> tableEnv<span class="token punctuation">.</span><span class="token function">from</span><span class="token punctuation">(</span><span class="token string">"EventTable"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>传入的参数就是注册好的表名。注意这里eventTable是一个Table对象，而EventTable是在环境中注册的表名。得到Table对象之后，就可以调用API进行各种转换操作了，得到的是一个新的Table对象：</p> 
<pre><code class="prism language-java"><span class="token class-name">Table</span> maryClickTable <span class="token operator">=</span> eventTable
        <span class="token punctuation">.</span><span class="token function">where</span><span class="token punctuation">(</span>$<span class="token punctuation">(</span><span class="token string">"user"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">isEqual</span><span class="token punctuation">(</span><span class="token string">"Alice"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">select</span><span class="token punctuation">(</span>$<span class="token punctuation">(</span><span class="token string">"url"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> $<span class="token punctuation">(</span><span class="token string">"user"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>这里每个方法的参数都是一个“表达式”（Expression），用方法调用的形式直观地说明了想要表达的内容；“$”符号用来指定表中的一个字段。上面的代码和直接执行SQL是等效的。</p> 
<p>Table API是嵌入编程语言中的DSL，SQL中的很多特性和功能必须要有对应的实现才可以使用，因此跟直接写SQL比起来肯定就要麻烦一些。目前Table API支持的功能相对更少，可以预见未来Flink社区也会以扩展SQL为主，为大家提供更加通用的接口方式；所以我们接下来也会以介绍SQL为主，简略地提及Table API。</p> 
<p><strong>3）两种API的结合使用</strong><br> 可以发现，无论是调用Table API还是执行SQL，得到的结果都是一个Table对象；所以这两种API的查询可以很方便地结合在一起。<br> （1）无论是那种方式得到的Table对象，都可以继续调用Table API进行查询转换；<br> （2）如果想要对一个表执行SQL操作（用FROM关键字引用），必须先在环境中对它进行注册。所以我们可以通过创建虚拟表的方式实现两者的转换：</p> 
<pre><code class="prism language-java">tableEnv<span class="token punctuation">.</span><span class="token function">createTemporaryView</span><span class="token punctuation">(</span><span class="token string">"MyTable"</span><span class="token punctuation">,</span> myTable<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>两种API殊途同归，实际应用中可以按照自己的习惯任意选择。不过由于结合使用容易引起混淆，而Table API功能相对较少、通用性较差，所以企业项目中往往会直接选择SQL的方式来实现需求。</p> 
<h3><a id="95__1609"></a>9.5 输出表</h3> 
<p>表的创建和查询，就对应着流处理中的读取数据源（Source）和转换（Transform）；而最后一个步骤Sink，也就是将结果数据输出到外部系统，就对应着表的输出操作。</p> 
<p>在代码上，输出一张表最直接的方法，就是调用Table的方法executeInsert()方法将一个 Table写入到注册过的表中，方法传入的参数就是注册的表名。</p> 
<pre><code class="prism language-java"><span class="token comment">// 注册表，用于输出数据到外部系统</span>
tableEnv<span class="token punctuation">.</span><span class="token function">executeSql</span><span class="token punctuation">(</span><span class="token string">"CREATE TABLE OutputTable ... WITH ( 'connector' = ... )"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">// 经过查询转换，得到结果表</span>
<span class="token class-name">Table</span> result <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>

<span class="token comment">// 将结果表写入已注册的输出表中</span>
result<span class="token punctuation">.</span><span class="token function">executeInsert</span><span class="token punctuation">(</span><span class="token string">"OutputTable"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>在底层，表的输出是通过将数据写入到TableSink来实现的。TableSink是Table API中提供的一个向外部系统写入数据的通用接口，可以支持不同的文件格式（比如CSV、Parquet）、存储数据库（比如JDBC、Elasticsearch）和消息队列（比如Kafka）。</p> 
<pre><code class="prism language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">SqlDemo</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
        <span class="token class-name">StreamExecutionEnvironment</span> env <span class="token operator">=</span> <span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">// TODO 1.创建表环境</span>
        <span class="token comment">// 1.1 写法一：</span>
<span class="token comment">//        EnvironmentSettings settings = EnvironmentSettings.newInstance()</span>
<span class="token comment">//                .inStreamingMode()</span>
<span class="token comment">//                .build();</span>
<span class="token comment">//        StreamTableEnvironment tableEnv = TableEnvironment.create(settings);</span>

        <span class="token comment">// 1.2 写法二</span>
        <span class="token class-name">StreamTableEnvironment</span> tableEnv <span class="token operator">=</span> <span class="token class-name">StreamTableEnvironment</span><span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span>env<span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">// TODO 2.创建表</span>
        tableEnv<span class="token punctuation">.</span><span class="token function">executeSql</span><span class="token punctuation">(</span><span class="token string">"CREATE TABLE source ( \n"</span> <span class="token operator">+</span>
                <span class="token string">"    id INT, \n"</span> <span class="token operator">+</span>
                <span class="token string">"    ts BIGINT, \n"</span> <span class="token operator">+</span>
                <span class="token string">"    vc INT\n"</span> <span class="token operator">+</span>
                <span class="token string">") WITH ( \n"</span> <span class="token operator">+</span>
                <span class="token string">"    'connector' = 'datagen', \n"</span> <span class="token operator">+</span>
                <span class="token string">"    'rows-per-second'='1', \n"</span> <span class="token operator">+</span>
                <span class="token string">"    'fields.id.kind'='random', \n"</span> <span class="token operator">+</span>
                <span class="token string">"    'fields.id.min'='1', \n"</span> <span class="token operator">+</span>
                <span class="token string">"    'fields.id.max'='10', \n"</span> <span class="token operator">+</span>
                <span class="token string">"    'fields.ts.kind'='sequence', \n"</span> <span class="token operator">+</span>
                <span class="token string">"    'fields.ts.start'='1', \n"</span> <span class="token operator">+</span>
                <span class="token string">"    'fields.ts.end'='1000000', \n"</span> <span class="token operator">+</span>
                <span class="token string">"    'fields.vc.kind'='random', \n"</span> <span class="token operator">+</span>
                <span class="token string">"    'fields.vc.min'='1', \n"</span> <span class="token operator">+</span>
                <span class="token string">"    'fields.vc.max'='100'\n"</span> <span class="token operator">+</span>
                <span class="token string">");\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>


        tableEnv<span class="token punctuation">.</span><span class="token function">executeSql</span><span class="token punctuation">(</span><span class="token string">"CREATE TABLE sink (\n"</span> <span class="token operator">+</span>
                <span class="token string">"    id INT, \n"</span> <span class="token operator">+</span>
                <span class="token string">"    sumVC INT \n"</span> <span class="token operator">+</span>
                <span class="token string">") WITH (\n"</span> <span class="token operator">+</span>
                <span class="token string">"'connector' = 'print'\n"</span> <span class="token operator">+</span>
                <span class="token string">");\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">// TODO 3.执行查询</span>
        <span class="token comment">// 3.1 使用sql进行查询</span>
<span class="token comment">//        Table table = tableEnv.sqlQuery("select id,sum(vc) as sumVC from source where id&gt;5 group by id ;");</span>
        <span class="token comment">// 把table对象，注册成表名</span>
<span class="token comment">//        tableEnv.createTemporaryView("tmp", table);</span>
<span class="token comment">//        tableEnv.sqlQuery("select * from tmp where id &gt; 7");</span>

        <span class="token comment">// 3.2 用table api来查询</span>
        <span class="token class-name">Table</span> source <span class="token operator">=</span> tableEnv<span class="token punctuation">.</span><span class="token function">from</span><span class="token punctuation">(</span><span class="token string">"source"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">Table</span> result <span class="token operator">=</span> source
                <span class="token punctuation">.</span><span class="token function">where</span><span class="token punctuation">(</span>$<span class="token punctuation">(</span><span class="token string">"id"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">isGreater</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">groupBy</span><span class="token punctuation">(</span>$<span class="token punctuation">(</span><span class="token string">"id"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">aggregate</span><span class="token punctuation">(</span>$<span class="token punctuation">(</span><span class="token string">"vc"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">as</span><span class="token punctuation">(</span><span class="token string">"sumVC"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">select</span><span class="token punctuation">(</span>$<span class="token punctuation">(</span><span class="token string">"id"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> $<span class="token punctuation">(</span><span class="token string">"sumVC"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>


        <span class="token comment">// TODO 4.输出表</span>
        <span class="token comment">// 4.1 sql用法</span>
<span class="token comment">//        tableEnv.executeSql("insert into sink select * from tmp");</span>
        <span class="token comment">// 4.2 tableapi用法</span>
        result<span class="token punctuation">.</span><span class="token function">executeInsert</span><span class="token punctuation">(</span><span class="token string">"sink"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<h3><a id="96__1690"></a>9.6 表和流的转换</h3> 
<p><strong>1）将流（DataStream）转换成表（Table）</strong><br> （1）调用fromDataStream()方法<br> 想要将一个DataStream转换成表很简单，可以通过调用表环境的fromDataStream()方法来实现，返回的就是一个Table对象。</p> 
<pre><code class="prism language-java"><span class="token class-name">StreamExecutionEnvironment</span> env <span class="token operator">=</span> <span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">// 获取表环境</span>
<span class="token class-name">StreamTableEnvironment</span> tableEnv <span class="token operator">=</span> <span class="token class-name">StreamTableEnvironment</span><span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span>env<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">// 读取数据源</span>
<span class="token class-name">SingleOutputStreamOperator</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">WaterSensor</span><span class="token punctuation">&gt;</span></span> sensorDS <span class="token operator">=</span> env<span class="token punctuation">.</span><span class="token function">fromSource</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>

<span class="token comment">// 将数据流转换成表</span>
<span class="token class-name">Table</span> sensorTable <span class="token operator">=</span> tableEnv<span class="token punctuation">.</span><span class="token function">fromDataStream</span><span class="token punctuation">(</span>sensorDS<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>由于流中的数据本身就是定义好的POJO类型WaterSensor，所以我们将流转换成表之后，每一行数据就对应着一个WaterSensor，而表中的列名就对应着WaterSensor中的属性。</p> 
<p>另外，我们还可以在fromDataStream()方法中增加参数，用来指定提取哪些属性作为表中的字段名，并可以任意指定位置：</p> 
<pre><code class="prism language-java"><span class="token comment">// 提取Event中的timestamp和url作为表中的列</span>
<span class="token class-name">Table</span> sensorTable <span class="token operator">=</span> tableEnv<span class="token punctuation">.</span><span class="token function">fromDataStream</span><span class="token punctuation">(</span>sensorDS<span class="token punctuation">,</span> $<span class="token punctuation">(</span><span class="token string">"id"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> $<span class="token punctuation">(</span><span class="token string">"vc"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>也可以通过表达式的as()方法对字段进行重命名：</p> 
<pre><code class="prism language-java"><span class="token comment">// 将timestamp字段重命名为ts</span>
<span class="token class-name">Table</span> sensorTable <span class="token operator">=</span> tableEnv<span class="token punctuation">.</span><span class="token function">fromDataStream</span><span class="token punctuation">(</span>sensorDS<span class="token punctuation">,</span> $<span class="token punctuation">(</span><span class="token string">"id"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">as</span><span class="token punctuation">(</span><span class="token string">"sid"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> $<span class="token punctuation">(</span><span class="token string">"vc"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>（2）调用createTemporaryView()方法<br> 调用fromDataStream()方法简单直观，可以直接实现DataStream到Table的转换；不过如果我们希望直接在SQL中引用这张表，就还需要调用表环境的createTemporaryView()方法来创建虚拟视图了。</p> 
<p>对于这种场景，也有一种更简洁的调用方式。我们可以直接调用createTemporaryView()方法创建虚拟表，传入的两个参数，第一个依然是注册的表名，而第二个可以直接就是DataStream。之后仍旧可以传入多个参数，用来指定表中的字段</p> 
<pre><code class="prism language-java">tableEnv<span class="token punctuation">.</span><span class="token function">createTemporaryView</span><span class="token punctuation">(</span><span class="token string">"sensorTable"</span><span class="token punctuation">,</span>sensorDS<span class="token punctuation">,</span> $<span class="token punctuation">(</span><span class="token string">"id"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>$<span class="token punctuation">(</span><span class="token string">"ts"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>$<span class="token punctuation">(</span><span class="token string">"vc"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>这样，我们接下来就可以直接在SQL中引用表sensorTable了。</p> 
<p><strong>2）将表（Table）转换成流（DataStream）</strong><br> （1）调用toDataStream()方法<br> 将一个Table对象转换成DataStream非常简单，只要直接调用表环境的方法toDataStream()就可以了。例如，我们可以将2.4小节经查询转换得到的表aliceClickTable转换成流打印输出：</p> 
<pre><code class="prism language-java">tableEnv<span class="token punctuation">.</span><span class="token function">toDataStream</span><span class="token punctuation">(</span>table<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>（2）调用toChangelogStream()方法<br> urlCountTable这个表中进行了分组聚合统计，所以表中的每一行是会“更新”的。对于这样有更新操作的表，我们不应该直接把它转换成DataStream打印输出，而是记录一下它的“更新日志”（change log）。这样一来，对于表的所有更新操作，就变成了一条更新日志的流，我们就可以转换成流打印输出了。<br> 代码中需要调用的是表环境的toChangelogStream()方法：</p> 
<pre><code class="prism language-java"><span class="token class-name">Table</span> table <span class="token operator">=</span> tableEnv<span class="token punctuation">.</span><span class="token function">sqlQuery</span><span class="token punctuation">(</span>
    <span class="token string">"SELECT id, sum(vc) "</span> <span class="token operator">+</span>
    <span class="token string">"FROM source "</span> <span class="token operator">+</span>
    <span class="token string">"GROUP BY id "</span>
  <span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">// 将表转换成更新日志流</span>
tableEnv<span class="token punctuation">.</span><span class="token function">toChangelogStream</span><span class="token punctuation">(</span>table<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p><strong>3）支持的数据类型</strong><br> 整体来看，DataStream中支持的数据类型，Table中也是都支持的，只不过在进行转换时需要注意一些细节。<br> （1）原子类型<br> 在Flink中，基础数据类型（Integer、Double、String）和通用数据类型（也就是不可再拆分的数据类型）统一称作“原子类型”。原子类型的DataStream，转换之后就成了只有一列的Table，列字段（field）的数据类型可以由原子类型推断出。另外，还可以在fromDataStream()方法里增加参数，用来重新命名列字段。</p> 
<pre><code class="prism language-java"><span class="token class-name">StreamTableEnvironment</span> tableEnv <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">;</span>

<span class="token class-name">DataStream</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Long</span><span class="token punctuation">&gt;</span></span> stream <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">;</span>

<span class="token comment">// 将数据流转换成动态表，动态表只有一个字段，重命名为myLong</span>
<span class="token class-name">Table</span> table <span class="token operator">=</span> tableEnv<span class="token punctuation">.</span><span class="token function">fromDataStream</span><span class="token punctuation">(</span>stream<span class="token punctuation">,</span> $<span class="token punctuation">(</span><span class="token string">"myLong"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>（2）Tuple类型<br> 当原子类型不做重命名时，默认的字段名就是“f0”，容易想到，这其实就是将原子类型看作了一元组Tuple1的处理结果。<br> Table支持Flink中定义的元组类型Tuple，对应在表中字段名默认就是元组中元素的属性名f0、f1、f2…。所有字段都可以被重新排序，也可以提取其中的一部分字段。字段还可以通过调用表达式的as()方法来进行重命名。</p> 
<pre><code class="prism language-java"><span class="token class-name">StreamTableEnvironment</span> tableEnv <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">;</span>

<span class="token class-name">DataStream</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">Long</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">&gt;</span><span class="token punctuation">&gt;</span></span> stream <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">;</span>

<span class="token comment">// 将数据流转换成只包含f1字段的表</span>
<span class="token class-name">Table</span> table <span class="token operator">=</span> tableEnv<span class="token punctuation">.</span><span class="token function">fromDataStream</span><span class="token punctuation">(</span>stream<span class="token punctuation">,</span> $<span class="token punctuation">(</span><span class="token string">"f1"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">// 将数据流转换成包含f0和f1字段的表，在表中f0和f1位置交换</span>
<span class="token class-name">Table</span> table <span class="token operator">=</span> tableEnv<span class="token punctuation">.</span><span class="token function">fromDataStream</span><span class="token punctuation">(</span>stream<span class="token punctuation">,</span> $<span class="token punctuation">(</span><span class="token string">"f1"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> $<span class="token punctuation">(</span><span class="token string">"f0"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">// 将f1字段命名为myInt，f0命名为myLong</span>
<span class="token class-name">Table</span> table <span class="token operator">=</span> tableEnv<span class="token punctuation">.</span><span class="token function">fromDataStream</span><span class="token punctuation">(</span>stream<span class="token punctuation">,</span> $<span class="token punctuation">(</span><span class="token string">"f1"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">as</span><span class="token punctuation">(</span><span class="token string">"myInt"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> $<span class="token punctuation">(</span><span class="token string">"f0"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">as</span><span class="token punctuation">(</span><span class="token string">"myLong"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>（3）POJO 类型<br> Flink也支持多种数据类型组合成的“复合类型”，最典型的就是简单Java对象（POJO 类型）。由于POJO中已经定义好了可读性强的字段名，这种类型的数据流转换成Table就显得无比顺畅了。</p> 
<p>将POJO类型的DataStream转换成Table，如果不指定字段名称，就会直接使用原始 POJO 类型中的字段名称。POJO中的字段同样可以被重新排序、提却和重命名。</p> 
<pre><code class="prism language-java"><span class="token class-name">StreamTableEnvironment</span> tableEnv <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">;</span>

<span class="token class-name">DataStream</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Event</span><span class="token punctuation">&gt;</span></span> stream <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">;</span>

<span class="token class-name">Table</span> table <span class="token operator">=</span> tableEnv<span class="token punctuation">.</span><span class="token function">fromDataStream</span><span class="token punctuation">(</span>stream<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token class-name">Table</span> table <span class="token operator">=</span> tableEnv<span class="token punctuation">.</span><span class="token function">fromDataStream</span><span class="token punctuation">(</span>stream<span class="token punctuation">,</span> $<span class="token punctuation">(</span><span class="token string">"user"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token class-name">Table</span> table <span class="token operator">=</span> tableEnv<span class="token punctuation">.</span><span class="token function">fromDataStream</span><span class="token punctuation">(</span>stream<span class="token punctuation">,</span> $<span class="token punctuation">(</span><span class="token string">"user"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">as</span><span class="token punctuation">(</span><span class="token string">"myUser"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> $<span class="token punctuation">(</span><span class="token string">"url"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">as</span><span class="token punctuation">(</span><span class="token string">"myUrl"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>（4）Row类型<br> Flink中还定义了一个在关系型表中更加通用的数据类型——行（Row），它是Table中数据的基本组织形式。<br> Row类型也是一种复合类型，它的长度固定，而且无法直接推断出每个字段的类型，所以在使用时必须指明具体的类型信息；我们在创建Table时调用的CREATE语句就会将所有的字段名称和类型指定，这在Flink中被称为表的“模式结构”（Schema）。</p> 
<p><strong>4）综合应用示例</strong><br> 现在，我们可以将介绍过的所有API整合起来，写出一段完整的代码。同样还是用户的一组点击事件，我们可以查询出某个用户（例如Alice）点击的url列表，也可以统计出每个用户累计的点击次数，这可以用两句SQL来分别实现。具体代码如下：</p> 
<pre><code class="prism language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TableStreamDemo</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">{<!-- --></span>
        <span class="token class-name">StreamExecutionEnvironment</span> env <span class="token operator">=</span> <span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>


        <span class="token class-name">DataStreamSource</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">WaterSensor</span><span class="token punctuation">&gt;</span></span> sensorDS <span class="token operator">=</span> env<span class="token punctuation">.</span><span class="token function">fromElements</span><span class="token punctuation">(</span>
                <span class="token keyword">new</span> <span class="token class-name">WaterSensor</span><span class="token punctuation">(</span><span class="token string">"s1"</span><span class="token punctuation">,</span> <span class="token number">1L</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token keyword">new</span> <span class="token class-name">WaterSensor</span><span class="token punctuation">(</span><span class="token string">"s1"</span><span class="token punctuation">,</span> <span class="token number">2L</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token keyword">new</span> <span class="token class-name">WaterSensor</span><span class="token punctuation">(</span><span class="token string">"s2"</span><span class="token punctuation">,</span> <span class="token number">2L</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token keyword">new</span> <span class="token class-name">WaterSensor</span><span class="token punctuation">(</span><span class="token string">"s3"</span><span class="token punctuation">,</span> <span class="token number">3L</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token keyword">new</span> <span class="token class-name">WaterSensor</span><span class="token punctuation">(</span><span class="token string">"s3"</span><span class="token punctuation">,</span> <span class="token number">4L</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token class-name">StreamTableEnvironment</span> tableEnv <span class="token operator">=</span> <span class="token class-name">StreamTableEnvironment</span><span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span>env<span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">// TODO 1. 流转表</span>
        <span class="token class-name">Table</span> sensorTable <span class="token operator">=</span> tableEnv<span class="token punctuation">.</span><span class="token function">fromDataStream</span><span class="token punctuation">(</span>sensorDS<span class="token punctuation">)</span><span class="token punctuation">;</span>
        tableEnv<span class="token punctuation">.</span><span class="token function">createTemporaryView</span><span class="token punctuation">(</span><span class="token string">"sensor"</span><span class="token punctuation">,</span> sensorTable<span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token class-name">Table</span> filterTable <span class="token operator">=</span> tableEnv<span class="token punctuation">.</span><span class="token function">sqlQuery</span><span class="token punctuation">(</span><span class="token string">"select id,ts,vc from sensor where ts&gt;2"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">Table</span> sumTable <span class="token operator">=</span> tableEnv<span class="token punctuation">.</span><span class="token function">sqlQuery</span><span class="token punctuation">(</span><span class="token string">"select id,sum(vc) from sensor group by id"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>


        <span class="token comment">// TODO 2. 表转流</span>
        <span class="token comment">// 2.1 追加流</span>
        tableEnv<span class="token punctuation">.</span><span class="token function">toDataStream</span><span class="token punctuation">(</span>filterTable<span class="token punctuation">,</span> <span class="token class-name">WaterSensor</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token string">"filter"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 2.2 changelog流(结果需要更新)</span>
        tableEnv<span class="token punctuation">.</span><span class="token function">toChangelogStream</span><span class="token punctuation">(</span>sumTable <span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token string">"sum"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>


        <span class="token comment">// 只要代码中调用了 DataStreamAPI，就需要 execute，否则不需要</span>
        env<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<h3><a id="97_UDF_1831"></a>9.7 自定义函数（UDF）</h3> 
<p>系统函数尽管庞大，也不可能涵盖所有的功能；如果有系统函数不支持的需求，我们就需要用自定义函数（User Defined Functions，UDF）来实现了。</p> 
<p>Flink的Table API和SQL提供了多种自定义函数的接口，以抽象类的形式定义。当前UDF主要有以下几类：</p> 
<ul><li>标量函数（Scalar Functions）：将输入的标量值转换成一个新的标量值；</li><li>表函数（Table Functions）：将标量值转换成一个或多个新的行数据，也就是扩展成一个表；</li><li>聚合函数（Aggregate Functions）：将多行数据里的标量值转换成一个新的标量值；</li><li>表聚合函数（Table Aggregate Functions）：将多行数据里的标量值转换成一个或多个新的行数据。</li></ul> 
<p><strong>1）整体调用流程</strong><br> 要想在代码中使用自定义的函数，我们需要首先自定义对应UDF抽象类的实现，并在表环境中注册这个函数，然后就可以在Table API和SQL中调用了。</p> 
<p>（1）注册函数<br> 注册函数时需要调用表环境的createTemporarySystemFunction()方法，传入注册的函数名以及UDF类的Class对象：</p> 
<pre><code class="prism language-java"><span class="token comment">// 注册函数</span>
tableEnv<span class="token punctuation">.</span><span class="token function">createTemporarySystemFunction</span><span class="token punctuation">(</span><span class="token string">"MyFunction"</span><span class="token punctuation">,</span> <span class="token class-name">MyFunction</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>我们自定义的UDF类叫作MyFunction，它应该是上面四种UDF抽象类中某一个的具体实现；在环境中将它注册为名叫MyFunction的函数。</p> 
<p>（2）使用Table API调用函数<br> 在Table API中，需要使用call()方法来调用自定义函数：</p> 
<pre><code class="prism language-java">tableEnv<span class="token punctuation">.</span><span class="token function">from</span><span class="token punctuation">(</span><span class="token string">"MyTable"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">select</span><span class="token punctuation">(</span><span class="token function">call</span><span class="token punctuation">(</span><span class="token string">"MyFunction"</span><span class="token punctuation">,</span> $<span class="token punctuation">(</span><span class="token string">"myField"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>这里call()方法有两个参数，一个是注册好的函数名MyFunction，另一个则是函数调用时本身的参数。这里我们定义MyFunction在调用时，需要传入的参数是myField字段。</p> 
<p>（3）在SQL中调用函数<br> 当我们将函数注册为系统函数之后，在SQL中的调用就与内置系统函数完全一样了：</p> 
<pre><code class="prism language-java">tableEnv<span class="token punctuation">.</span><span class="token function">sqlQuery</span><span class="token punctuation">(</span><span class="token string">"SELECT MyFunction(myField) FROM MyTable"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>可见，SQL的调用方式更加方便，我们后续依然会以SQL为例介绍UDF的用法。</p> 
<p><strong>2）标量函数（Scalar Functions）</strong><br> 自定义标量函数可以把0个、 1个或多个标量值转换成一个标量值，它对应的输入是一行数据中的字段，输出则是唯一的值。所以从输入和输出表中行数据的对应关系看，标量函数是“一对一”的转换。</p> 
<p>想要实现自定义的标量函数，我们需要自定义一个类来继承抽象类ScalarFunction，并实现叫作eval() 的求值方法。标量函数的行为就取决于求值方法的定义，它必须是公有的（public），而且名字必须是eval。求值方法eval可以重载多次，任何数据类型都可作为求值方法的参数和返回值类型。</p> 
<p>这里需要特别说明的是，ScalarFunction抽象类中并没有定义eval()方法，所以我们不能直接在代码中重写（override）；但Table API的框架底层又要求了求值方法必须名字为eval()。这是Table API和SQL目前还显得不够完善的地方，未来的版本应该会有所改进。</p> 
<p>下面我们来看一个具体的例子。我们实现一个自定义的哈希（hash）函数HashFunction，用来求传入对象的哈希值。</p> 
<pre><code class="prism language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">MyScalarFunctionDemo</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">{<!-- --></span>
        <span class="token class-name">StreamExecutionEnvironment</span> env <span class="token operator">=</span> <span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>


        <span class="token class-name">DataStreamSource</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">WaterSensor</span><span class="token punctuation">&gt;</span></span> sensorDS <span class="token operator">=</span> env<span class="token punctuation">.</span><span class="token function">fromElements</span><span class="token punctuation">(</span>
                <span class="token keyword">new</span> <span class="token class-name">WaterSensor</span><span class="token punctuation">(</span><span class="token string">"s1"</span><span class="token punctuation">,</span> <span class="token number">1L</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token keyword">new</span> <span class="token class-name">WaterSensor</span><span class="token punctuation">(</span><span class="token string">"s1"</span><span class="token punctuation">,</span> <span class="token number">2L</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token keyword">new</span> <span class="token class-name">WaterSensor</span><span class="token punctuation">(</span><span class="token string">"s2"</span><span class="token punctuation">,</span> <span class="token number">2L</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token keyword">new</span> <span class="token class-name">WaterSensor</span><span class="token punctuation">(</span><span class="token string">"s3"</span><span class="token punctuation">,</span> <span class="token number">3L</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token keyword">new</span> <span class="token class-name">WaterSensor</span><span class="token punctuation">(</span><span class="token string">"s3"</span><span class="token punctuation">,</span> <span class="token number">4L</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token class-name">StreamTableEnvironment</span> tableEnv <span class="token operator">=</span> <span class="token class-name">StreamTableEnvironment</span><span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span>env<span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token class-name">Table</span> sensorTable <span class="token operator">=</span> tableEnv<span class="token punctuation">.</span><span class="token function">fromDataStream</span><span class="token punctuation">(</span>sensorDS<span class="token punctuation">)</span><span class="token punctuation">;</span>
        tableEnv<span class="token punctuation">.</span><span class="token function">createTemporaryView</span><span class="token punctuation">(</span><span class="token string">"sensor"</span><span class="token punctuation">,</span> sensorTable<span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">// TODO 2.注册函数</span>
        tableEnv<span class="token punctuation">.</span><span class="token function">createTemporaryFunction</span><span class="token punctuation">(</span><span class="token string">"HashFunction"</span><span class="token punctuation">,</span> <span class="token class-name">HashFunction</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">// TODO 3.调用 自定义函数</span>
        <span class="token comment">// 3.1 sql用法</span>
<span class="token comment">//        tableEnv.sqlQuery("select HashFunction(id) from sensor")</span>
<span class="token comment">//                .execute()  // 调用了 sql的execute，就不需要 env.execute()</span>
<span class="token comment">//                .print();</span>

        <span class="token comment">// 3.2 table api用法</span>
        sensorTable
                <span class="token punctuation">.</span><span class="token function">select</span><span class="token punctuation">(</span><span class="token function">call</span><span class="token punctuation">(</span><span class="token string">"HashFunction"</span><span class="token punctuation">,</span>$<span class="token punctuation">(</span><span class="token string">"id"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>



    <span class="token punctuation">}</span>


    <span class="token comment">// TODO 1.定义 自定义函数的实现类</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span>  <span class="token keyword">class</span> <span class="token class-name">HashFunction</span> <span class="token keyword">extends</span> <span class="token class-name">ScalarFunction</span><span class="token punctuation">{<!-- --></span>

        <span class="token comment">// 接受任意类型的输入，返回 INT型输出</span>
        <span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">eval</span><span class="token punctuation">(</span><span class="token annotation punctuation">@DataTypeHint</span><span class="token punctuation">(</span>inputGroup <span class="token operator">=</span> <span class="token class-name">InputGroup</span><span class="token punctuation">.</span><span class="token constant">ANY</span><span class="token punctuation">)</span> <span class="token class-name">Object</span> o<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
            <span class="token keyword">return</span> o<span class="token punctuation">.</span><span class="token function">hashCode</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>这里我们自定义了一个ScalarFunction，实现了eval()求值方法，将任意类型的对象传入，得到一个Int类型的哈希值返回。当然，具体的求哈希操作就省略了，直接调用对象的hashCode()方法即可。</p> 
<p>另外注意，由于Table API在对函数进行解析时需要提取求值方法参数的类型引用，所以我们用DataTypeHint(inputGroup = InputGroup.ANY)对输入参数的类型做了标注，表示eval的参数可以是任意类型。</p> 
<p><strong>3）表函数（Table Functions）</strong><br> 跟标量函数一样，表函数的输入参数也可以是 0个、1个或多个标量值；不同的是，它可以返回任意多行数据。“多行数据”事实上就构成了一个表，所以“表函数”可以认为就是返回一个表的函数，这是一个“一对多”的转换关系。之前我们介绍过的窗口TVF，本质上就是表函数。</p> 
<p>类似地，要实现自定义的表函数，需要自定义类来继承抽象类TableFunction，内部必须要实现的也是一个名为 eval 的求值方法。与标量函数不同的是，TableFunction类本身是有一个泛型参数T的，这就是表函数返回数据的类型；而eval()方法没有返回类型，内部也没有return语句，是通过调用collect()方法来发送想要输出的行数据的。</p> 
<p>在SQL中调用表函数，需要使用LATERAL TABLE()来生成扩展的“侧向表”，然后与原始表进行联结（Join）。这里的Join操作可以是直接做交叉联结（cross join），在FROM后用逗号分隔两个表就可以；也可以是以ON TRUE为条件的左联结（LEFT JOIN）。</p> 
<p>下面是表函数的一个具体示例。我们实现了一个分隔字符串的函数SplitFunction，可以将一个字符串转换成（字符串，长度）的二元组。</p> 
<pre><code class="prism language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">MyTableFunctionDemo</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">{<!-- --></span>
        <span class="token class-name">StreamExecutionEnvironment</span> env <span class="token operator">=</span> <span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>


        <span class="token class-name">DataStreamSource</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> strDS <span class="token operator">=</span> env<span class="token punctuation">.</span><span class="token function">fromElements</span><span class="token punctuation">(</span>
                <span class="token string">"hello flink"</span><span class="token punctuation">,</span>
                <span class="token string">"hello world hi"</span><span class="token punctuation">,</span>
                <span class="token string">"hello java"</span>
        <span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token class-name">StreamTableEnvironment</span> tableEnv <span class="token operator">=</span> <span class="token class-name">StreamTableEnvironment</span><span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span>env<span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token class-name">Table</span> sensorTable <span class="token operator">=</span> tableEnv<span class="token punctuation">.</span><span class="token function">fromDataStream</span><span class="token punctuation">(</span>strDS<span class="token punctuation">,</span> $<span class="token punctuation">(</span><span class="token string">"words"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        tableEnv<span class="token punctuation">.</span><span class="token function">createTemporaryView</span><span class="token punctuation">(</span><span class="token string">"str"</span><span class="token punctuation">,</span> sensorTable<span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">// TODO 2.注册函数</span>
        tableEnv<span class="token punctuation">.</span><span class="token function">createTemporaryFunction</span><span class="token punctuation">(</span><span class="token string">"SplitFunction"</span><span class="token punctuation">,</span> <span class="token class-name">SplitFunction</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">// TODO 3.调用 自定义函数</span>
        <span class="token comment">// 3.1 交叉联结</span>
        tableEnv
                <span class="token comment">// 3.1 交叉联结</span>
<span class="token comment">//                .sqlQuery("select words,word,length from str,lateral table(SplitFunction(words))")</span>
                <span class="token comment">// 3.2 带 on  true 条件的 左联结</span>
<span class="token comment">//                .sqlQuery("select words,word,length from str left join lateral table(SplitFunction(words)) on true")</span>
                <span class="token comment">// 重命名侧向表中的字段</span>
                <span class="token punctuation">.</span><span class="token function">sqlQuery</span><span class="token punctuation">(</span><span class="token string">"select words,newWord,newLength from str left join lateral table(SplitFunction(words))  as T(newWord,newLength) on true"</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>



    <span class="token punctuation">}</span>


    <span class="token comment">// TODO 1.继承 TableFunction&lt;返回的类型&gt;</span>
    <span class="token comment">// 类型标注： Row包含两个字段：word和length</span>
    <span class="token annotation punctuation">@FunctionHint</span><span class="token punctuation">(</span>output <span class="token operator">=</span> <span class="token annotation punctuation">@DataTypeHint</span><span class="token punctuation">(</span><span class="token string">"ROW&lt;word STRING,length INT&gt;"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">class</span> <span class="token class-name">SplitFunction</span> <span class="token keyword">extends</span> <span class="token class-name">TableFunction</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Row</span><span class="token punctuation">&gt;</span></span> <span class="token punctuation">{<!-- --></span>

        <span class="token comment">// 返回是 void，用 collect方法输出</span>
        <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">eval</span><span class="token punctuation">(</span><span class="token class-name">String</span> str<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">String</span> word <span class="token operator">:</span> str<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
                <span class="token function">collect</span><span class="token punctuation">(</span><span class="token class-name">Row</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span>word<span class="token punctuation">,</span> word<span class="token punctuation">.</span><span class="token function">length</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>

<span class="token punctuation">}</span>
</code></pre> 
<p>这里我们直接将表函数的输出类型定义成了ROW，这就是得到的侧向表中的数据类型；每行数据转换后也只有一行。我们分别用交叉联结和左联结两种方式在SQL中进行了调用，还可以对侧向表的中字段进行重命名。</p> 
<p><strong>4）聚合函数（Aggregate Functions）</strong><br> 用户自定义聚合函数（User Defined AGGregate function，UDAGG）会把一行或多行数据（也就是一个表）聚合成一个标量值。这是一个标准的“多对一”的转换。</p> 
<p>聚合函数的概念我们之前已经接触过多次，如SUM()、MAX()、MIN()、AVG()、COUNT()都是常见的系统内置聚合函数。而如果有些需求无法直接调用系统函数解决，我们就必须自定义聚合函数来实现功能了。</p> 
<p>自定义聚合函数需要继承抽象类AggregateFunction。AggregateFunction有两个泛型参数&lt;T, ACC&gt;，T表示聚合输出的结果类型，ACC则表示聚合的中间状态类型。</p> 
<p>Flink SQL中的聚合函数的工作原理如下：<br> （1）首先，它需要创建一个累加器（accumulator），用来存储聚合的中间结果。这与DataStream API中的AggregateFunction非常类似，累加器就可以看作是一个聚合状态。调用createAccumulator()方法可以创建一个空的累加器。<br> （2）对于输入的每一行数据，都会调用accumulate()方法来更新累加器，这是聚合的核心过程。<br> （3）当所有的数据都处理完之后，通过调用getValue()方法来计算并返回最终的结果。<br> 所以，每个 AggregateFunction 都必须实现以下几个方法：</p> 
<ul><li>createAccumulator()<br> 这是创建累加器的方法。没有输入参数，返回类型为累加器类型ACC。</li><li>accumulate()<br> 这是进行聚合计算的核心方法，每来一行数据都会调用。它的第一个参数是确定的，就是当前的累加器，类型为ACC，表示当前聚合的中间状态；后面的参数则是聚合函数调用时传入的参数，可以有多个，类型也可以不同。这个方法主要是更新聚合状态，所以没有返回类型。需要注意的是，accumulate()与之前的求值方法eval()类似，也是底层架构要求的，必须为public，方法名必须为accumulate，且无法直接override、只能手动实现。</li><li>getValue()<br> 这是得到最终返回结果的方法。输入参数是ACC类型的累加器，输出类型为T。</li></ul> 
<p>在遇到复杂类型时，Flink 的类型推导可能会无法得到正确的结果。所以AggregateFunction也可以专门对累加器和返回结果的类型进行声明，这是通过 getAccumulatorType()和getResultType()两个方法来指定的。</p> 
<p>AggregateFunction 的所有方法都必须是 公有的（public），不能是静态的（static），而且名字必须跟上面写的完全一样。createAccumulator、getValue、getResultType 以及 getAccumulatorType 这几个方法是在抽象类 AggregateFunction 中定义的，可以override；而其他则都是底层架构约定的方法。</p> 
<p>下面举一个具体的示例，我们从学生的分数表ScoreTable中计算每个学生的加权平均分。</p> 
<pre><code class="prism language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">MyAggregateFunctionDemo</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">{<!-- --></span>
        <span class="token class-name">StreamExecutionEnvironment</span> env <span class="token operator">=</span> <span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>


        <span class="token comment">//  姓名，分数，权重</span>
        <span class="token class-name">DataStreamSource</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple3</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span><span class="token class-name">Integer</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">&gt;</span><span class="token punctuation">&gt;</span></span> scoreWeightDS <span class="token operator">=</span> env<span class="token punctuation">.</span><span class="token function">fromElements</span><span class="token punctuation">(</span>
                <span class="token class-name">Tuple3</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span><span class="token string">"zs"</span><span class="token punctuation">,</span><span class="token number">80</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token class-name">Tuple3</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span><span class="token string">"zs"</span><span class="token punctuation">,</span><span class="token number">90</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token class-name">Tuple3</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span><span class="token string">"zs"</span><span class="token punctuation">,</span><span class="token number">95</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token class-name">Tuple3</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span><span class="token string">"ls"</span><span class="token punctuation">,</span><span class="token number">75</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token class-name">Tuple3</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span><span class="token string">"ls"</span><span class="token punctuation">,</span><span class="token number">65</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token class-name">Tuple3</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span><span class="token string">"ls"</span><span class="token punctuation">,</span><span class="token number">85</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>

        <span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token class-name">StreamTableEnvironment</span> tableEnv <span class="token operator">=</span> <span class="token class-name">StreamTableEnvironment</span><span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span>env<span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token class-name">Table</span> scoreWeightTable <span class="token operator">=</span> tableEnv<span class="token punctuation">.</span><span class="token function">fromDataStream</span><span class="token punctuation">(</span>scoreWeightDS<span class="token punctuation">,</span> $<span class="token punctuation">(</span><span class="token string">"f0"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">as</span><span class="token punctuation">(</span><span class="token string">"name"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>$<span class="token punctuation">(</span><span class="token string">"f1"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">as</span><span class="token punctuation">(</span><span class="token string">"score"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> $<span class="token punctuation">(</span><span class="token string">"f2"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">as</span><span class="token punctuation">(</span><span class="token string">"weight"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        tableEnv<span class="token punctuation">.</span><span class="token function">createTemporaryView</span><span class="token punctuation">(</span><span class="token string">"scores"</span><span class="token punctuation">,</span> scoreWeightTable<span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">// TODO 2.注册函数</span>
        tableEnv<span class="token punctuation">.</span><span class="token function">createTemporaryFunction</span><span class="token punctuation">(</span><span class="token string">"WeightedAvg"</span><span class="token punctuation">,</span> <span class="token class-name">WeightedAvg</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">// TODO 3.调用 自定义函数</span>
        tableEnv
                <span class="token punctuation">.</span><span class="token function">sqlQuery</span><span class="token punctuation">(</span><span class="token string">"select name,WeightedAvg(score,weight)  from scores group by name"</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>


    <span class="token punctuation">}</span>


    <span class="token comment">// TODO 1.继承 AggregateFunction&lt; 返回类型，累加器类型&lt;加权总和，权重总和&gt; &gt;</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">class</span> <span class="token class-name">WeightedAvg</span> <span class="token keyword">extends</span> <span class="token class-name">AggregateFunction</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Double</span><span class="token punctuation">,</span> <span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">Integer</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">&gt;</span><span class="token punctuation">&gt;</span></span> <span class="token punctuation">{<!-- --></span>

        <span class="token annotation punctuation">@Override</span>
        <span class="token keyword">public</span> <span class="token class-name">Double</span> <span class="token function">getValue</span><span class="token punctuation">(</span><span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Integer</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">&gt;</span></span> integerIntegerTuple2<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
            <span class="token keyword">return</span> integerIntegerTuple2<span class="token punctuation">.</span>f0 <span class="token operator">*</span> <span class="token number">1D</span> <span class="token operator">/</span> integerIntegerTuple2<span class="token punctuation">.</span>f1<span class="token punctuation">;</span>
        <span class="token punctuation">}</span>

        <span class="token annotation punctuation">@Override</span>
        <span class="token keyword">public</span> <span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Integer</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">&gt;</span></span> <span class="token function">createAccumulator</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
            <span class="token keyword">return</span> <span class="token class-name">Tuple2</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>

        <span class="token comment">/**
         * 累加计算的方法，每来一行数据都会调用一次
         * @param acc 累加器类型
         * @param score 第一个参数：分数
         * @param weight 第二个参数：权重
         */</span>
        <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">accumulate</span><span class="token punctuation">(</span><span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Integer</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">&gt;</span></span> acc<span class="token punctuation">,</span><span class="token class-name">Integer</span> score<span class="token punctuation">,</span><span class="token class-name">Integer</span> weight<span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
            acc<span class="token punctuation">.</span>f0 <span class="token operator">+=</span> score <span class="token operator">*</span> weight<span class="token punctuation">;</span>  <span class="token comment">// 加权总和 =  分数1 * 权重1 + 分数2 * 权重2 +....</span>
            acc<span class="token punctuation">.</span>f1 <span class="token operator">+=</span> weight<span class="token punctuation">;</span>         <span class="token comment">// 权重和 = 权重1 + 权重2 +....</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
    
<span class="token punctuation">}</span>
</code></pre> 
<p>聚合函数的accumulate()方法有三个输入参数。第一个是WeightedAvgAccum类型的累加器；另外两个则是函数调用时输入的字段：要计算的值 ivalue 和 对应的权重 iweight。这里我们并不考虑其它方法的实现，只要有必须的三个方法就可以了。</p> 
<p><strong>5）表聚合函数（Table Aggregate Functions）</strong><br> 用户自定义表聚合函数（UDTAGG）可以把一行或多行数据（也就是一个表）聚合成另一张表，结果表中可以有多行多列。很明显，这就像表函数和聚合函数的结合体，是一个“多对多”的转换。</p> 
<p>自定义表聚合函数需要继承抽象类TableAggregateFunction。TableAggregateFunction的结构和原理与AggregateFunction非常类似，同样有两个泛型参数&lt;T, ACC&gt;，用一个ACC类型的累加器（accumulator）来存储聚合的中间结果。聚合函数中必须实现的三个方法，在TableAggregateFunction中也必须对应实现：</p> 
<ul><li>createAccumulator()<br> 创建累加器的方法，与AggregateFunction中用法相同。</li><li>accumulate()<br> 聚合计算的核心方法，与AggregateFunction中用法相同。</li><li>emitValue()<br> 所有输入行处理完成后，输出最终计算结果的方法。这个方法对应着AggregateFunction中的getValue()方法；区别在于emitValue没有输出类型，而输入参数有两个：第一个是ACC类型的累加器，第二个则是用于输出数据的“收集器”out，它的类型为Collect。另外，emitValue()在抽象类中也没有定义，无法override，必须手动实现。</li></ul> 
<p>表聚合函数相对比较复杂，它的一个典型应用场景就是TOP-N查询。比如我们希望选出一组数据排序后的前两名，这就是最简单的TOP-2查询。没有现成的系统函数，那么我们就可以自定义一个表聚合函数来实现这个功能。在累加器中应该能够保存当前最大的两个值，每当来一条新数据就在accumulate()方法中进行比较更新，最终在emitValue()中调用两次out.collect()将前两名数据输出。</p> 
<p>具体代码如下：</p> 
<pre><code class="prism language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">MyTableAggregateFunctionDemo</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">{<!-- --></span>
        <span class="token class-name">StreamExecutionEnvironment</span> env <span class="token operator">=</span> <span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>


        <span class="token comment">//  姓名，分数，权重</span>
        <span class="token class-name">DataStreamSource</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Integer</span><span class="token punctuation">&gt;</span></span> numDS <span class="token operator">=</span> env<span class="token punctuation">.</span><span class="token function">fromElements</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token class-name">StreamTableEnvironment</span> tableEnv <span class="token operator">=</span> <span class="token class-name">StreamTableEnvironment</span><span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span>env<span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token class-name">Table</span> numTable <span class="token operator">=</span> tableEnv<span class="token punctuation">.</span><span class="token function">fromDataStream</span><span class="token punctuation">(</span>numDS<span class="token punctuation">,</span> $<span class="token punctuation">(</span><span class="token string">"num"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">// TODO 2.注册函数</span>
        tableEnv<span class="token punctuation">.</span><span class="token function">createTemporaryFunction</span><span class="token punctuation">(</span><span class="token string">"Top2"</span><span class="token punctuation">,</span> <span class="token class-name">Top2</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">// TODO 3.调用 自定义函数: 只能用 Table API</span>
        numTable
                <span class="token punctuation">.</span><span class="token function">flatAggregate</span><span class="token punctuation">(</span><span class="token function">call</span><span class="token punctuation">(</span><span class="token string">"Top2"</span><span class="token punctuation">,</span> $<span class="token punctuation">(</span><span class="token string">"num"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">as</span><span class="token punctuation">(</span><span class="token string">"value"</span><span class="token punctuation">,</span> <span class="token string">"rank"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">select</span><span class="token punctuation">(</span> $<span class="token punctuation">(</span><span class="token string">"value"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> $<span class="token punctuation">(</span><span class="token string">"rank"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>


    <span class="token punctuation">}</span>


    <span class="token comment">// TODO 1.继承 TableAggregateFunction&lt; 返回类型，累加器类型&lt;加权总和，权重总和&gt; &gt;</span>
    <span class="token comment">// 返回类型 (数值，排名) =》 (12,1) (9,2)</span>
    <span class="token comment">// 累加器类型 (第一大的数，第二大的数) ===》 （12,9）</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">class</span> <span class="token class-name">Top2</span> <span class="token keyword">extends</span> <span class="token class-name">TableAggregateFunction</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">Integer</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">&gt;</span><span class="token punctuation">,</span> <span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">Integer</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">&gt;</span><span class="token punctuation">&gt;</span></span> <span class="token punctuation">{<!-- --></span>

        <span class="token annotation punctuation">@Override</span>
        <span class="token keyword">public</span> <span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Integer</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">&gt;</span></span> <span class="token function">createAccumulator</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
            <span class="token keyword">return</span> <span class="token class-name">Tuple2</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>


        <span class="token comment">/**
         * 每来一个数据调用一次，比较大小，更新 最大的前两个数到 acc中
         *
         * @param acc 累加器
         * @param num 过来的数据
         */</span>
        <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">accumulate</span><span class="token punctuation">(</span><span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Integer</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">&gt;</span></span> acc<span class="token punctuation">,</span> <span class="token class-name">Integer</span> num<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span>num <span class="token operator">&gt;</span> acc<span class="token punctuation">.</span>f0<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
                <span class="token comment">// 新来的变第一，原来的第一变第二</span>
                acc<span class="token punctuation">.</span>f1 <span class="token operator">=</span> acc<span class="token punctuation">.</span>f0<span class="token punctuation">;</span>
                acc<span class="token punctuation">.</span>f0 <span class="token operator">=</span> num<span class="token punctuation">;</span>
            <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>num <span class="token operator">&gt;</span> acc<span class="token punctuation">.</span>f1<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
                <span class="token comment">// 新来的变第二，原来的第二不要了</span>
                acc<span class="token punctuation">.</span>f1 <span class="token operator">=</span> num<span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span>


        <span class="token comment">/**
         * 输出结果： （数值，排名）两条最大的
         *
         * @param acc 累加器
         * @param out 采集器&lt;返回类型&gt;
         */</span>
        <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">emitValue</span><span class="token punctuation">(</span><span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Integer</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">&gt;</span></span> acc<span class="token punctuation">,</span> <span class="token class-name">Collector</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">Integer</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">&gt;</span><span class="token punctuation">&gt;</span></span> out<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span>acc<span class="token punctuation">.</span>f0 <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
                out<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token class-name">Tuple2</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span>acc<span class="token punctuation">.</span>f0<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span>acc<span class="token punctuation">.</span>f1 <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
                out<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token class-name">Tuple2</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span>acc<span class="token punctuation">.</span>f1<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>


<span class="token punctuation">}</span>
</code></pre> 
<p>目前SQL中没有直接使用表聚合函数的方式，所以需要使用Table API的方式来调用。</p> 
<p>这里使用了flatAggregate()方法，它就是专门用来调用表聚合函数的接口。统计num值最大的两个；并将聚合结果的两个字段重命名为value和rank，之后就可以使用select()将它们提取出来了。</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/50f15676ae0498de886e15c112d26da3/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Flink1.17实战教程（第六篇：容错机制）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/cad2d98e286f2bf3ea6d24fb64187195/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">StructuredTaskScope - JAVA 中的新并发模型</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程爱好者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151260"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>