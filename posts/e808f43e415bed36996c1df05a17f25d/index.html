<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>车载与体征/手势检测 毫米波雷达信号处理流程 - 编程爱好者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="车载与体征/手势检测 毫米波雷达信号处理流程" />
<meta property="og:description" content="说明 本篇博文旨在搭建一个车载毫米波雷达、体征检测(呼吸心跳检测)、手势识别信号处理的框架，介绍其流程，并尽可能多地给出一些流程中的细节处理(内容确实几乎都是文字内容..)，本篇博文不涉及各部分算法的具体原理与实现。本篇博文内容其实很简单，也会基于博主本人的积累以及读者的反馈不断更新内容，我们一起维护，我会定期完善。
Blog:
20221012博文第一次撰写
文章架构 目录
说明
文章架构
一、毫米波雷达信号处理概述
二、车载毫米波雷达的信号处理
三、体征检测与手势识别的雷达信号处理
四、总结
五、参考资料
一、毫米波雷达信号处理概述 应用于体征检测的雷达信号类型有很多，调频连续波(FMCW，chirp)是其中的一种，但现阶段应用于车载的基本就只有chirp的信号形式，后续对信号处理流程的说明都基于chirp的信号形式。
FMCW雷达的信号处理流程并不复杂，车载的：到从ADC数据到点云，体征检测的：从ADC数据到时间-相位的波形图，信号的处理流程和方法其实比较固定。各车载毫米波雷达厂家的信号处理方法也大同小异，正是基于此，加特兰在其芯片中甚至直接将得到点云之前信号处理过程硬化了，软件开发者只需要给硬件接口配置合适的参数即可，处理流程的硬化可以极大程度地提高处理速度、降低开发难度。
但是现阶段对雷达的信号处理已经不仅是限于对目标的定位和跟踪，越来越高的比如识别、分类乃至成像等要求都希望雷达可以实现，于是包括机器学习等方法开始被用到了雷达的信号处理中。此外，针对车载雷达的应用场景，各类ADAS报警功能的实现；针对体征检测的场景，病人的诊断报告以及一些应用场景下的报警功能的实现，连同这些更后端的功能实现都需要集中到雷达中做。
综合来看，雷达的信号处理流程虽然不复杂且比较固化，但是涉及的(可供研究和优化的)细节还是有很多的，此外，包括跟踪、分类、实际应用场景下的功能实现等也丰富了信号处理的内容，给信号处理工程师带来了更多的挑战，理清楚信号处理的流程，搭建一整个的知识框架是十分有必要的，这也是本篇博文想要做的事情。
博主本人现阶段对基于机器学习的方法做分类和识别，以及后端的应用功能的实现并不熟悉，相关原理和更细节的说明我会在往后进行补充。此外本人现阶段接触体征检测/手势识别还极少，有不当之处欢迎指正。
二、车载毫米波雷达的信号处理 车载和体征检测/手势识别雷达的射频前端基本一致：包括chirp的收发(当然车载的以及体征检测的对chirp的包括周期、带宽、斜率等的设置是不一样的)、混频、滤波、增益控制，直到ADC采集到原始的数据，现阶段的混频有两种方案：单路或IQ两路，这两种方案也都可以应用于车载以及体征检测，IQ两路可以减小对ADC采样率的要求，且距离维FFT后不需要丢掉多余的数据(单路在距离FFT后需要丢掉后面一半的数据)，当然其成本会高很多，关于射频前端以及这两种混频方案的区别与优劣可以参考之前的博文：毫米波雷达的硬件架构与射频前端_墨@#≯的博客-CSDN博客。
车载毫米波雷达的大体的信号处理框架大体如下：
车载毫米波雷达信号处理流程
对前述各个流程的细节说明：
对于雷达的单帧数据，ADC采集完成后，对应到各个通道的数据是一个N*M大小的数据矩阵，其中N为单个chirp下的采样点数，N也被称为快时间维，M为单帧下对应到该通道的chirp数，M也被称为慢时间维。假设一共有K个通道，则对应ADC数据(radar cube)大小为N*M*K。
对这K个N*M大小的矩阵做2D-FFT就完成了二维压缩，随后为了增加SNR，在做CFAR检测前有一个对K个二维压缩后的矩阵进行累加的过程，累加的方法有很多，常用的是非相干累加：把K个二维压缩后的矩阵取绝对值并累加，得到一个累加后的幅值矩阵【值得注意的是，可能是如果直接FFT后累加会超过32bit能装载值的上限？所以Ti在累加之前取了log2，关于整个数据处理过程中一些中间值的大小是否会超过限定bit数下的上限，是我们在产品研发的数据处理时需要考虑的，比如加特兰在其做FFT的过程中会对每一级的中间值进行右移的操作以减小值的大小。】；另外的一种累加方法是相干累加：给不同的通道加不同的权值再累加(类似波束成形，这些权值共同构成一个导向矢量)，这种相干累加可以通过设置的权值使雷达视场内其中一些方向的能量增加，从而增加这些区域的目标检测准确度，一般是会设置不同的权值，并对这些权值下得到的累加后的幅值矩阵分别做CFAR处理，再对这些CFAR的结果取并集。
累加完成后就是对累加得到的幅值矩阵做CFAR处理，CFAR算法有很多，比如CA-CFAR、OS-CFAR、GO/SO-CFAR等，做CFAR操作时，一种比较有意思的操作是分区CFAR，所谓的分区CFAR是指针对不同的距离区域使用不同的CFAR算法或者同一种CFAR使用不同的保护单元、参考单元以及阈值，分区CFAR的依据是：处在雷达不同距离门下的目标其能量一般不一样，为了减少虚警和漏警的情况发生，比如可以考虑在近处的位置将阈值设置得大一些，当然有基于距离的分区CFAR也就有基于速度的分区CFAR,一些更细节的东西可以参考加特兰芯片的Baseband User-guide 加特兰微电子 - Alps (calterah.com),里头有比较详细的说明。
CFAR完成后此时我们便可以基于被检测到的点在该二维矩阵中的横纵坐标索引得到该点对应的距离和速度的信息，但此时该速度信息还不能说是可信的，如果目标的速度超过了我们设计参数时的最大无模糊速度值：
式中，为该矩阵(该通道接收)前后两个chirp(两列)之间的时间间隔，事实上当发射通道增加时，该最大无模糊测速范围是很容易达到甚至超过的：举例来说，我们假设有3个发射天线按照TDM-MIMO的模式发射，相邻两天线发射的chirp间隔为40us(该值对于车载毫米波雷达来说不是很大),则这里的 = 120us,于是对应的最大无模糊测速范围约为8m/s，该值无疑是不够的，我们还是能检测到速度大于最大无模糊测速范围的目标，只是此值“藏在”了无模糊测速范围内，于是此时我们就需要进行速度解模糊，速度解模糊目的就是将目标的真实速度求出来，速度解模糊的方法很多，一般需要发射端帮忙，相关的具体的内容我会在后续的博文中作为一个专题给出(不只是速度模糊还有角度模糊等)。
做完速度解模糊后，我们得到的目标的真实速度，此时我们还需要知道目标的角度才能准确对目标进行定位，但是在测角之前，针对TDM-MIMO的发射模式我们还需要做相位补偿(这里的相位补偿也只需要针对TDM这种各天线不在同一时刻发射的情况，其它的发射情况并不需要，详情可以参考我之前的博文：车载毫米波雷达MIMO阵列的天线发射问题_墨@#≯的博客-CSDN博客)，相位补偿是针对当目标在运动以及天线是以时分的方式发射时的场景，这种情况下前后发射天线对应的通道会有因目标运动导致的相位差产生，该相位差值会影响测角，所以我们需要将该相位差补偿掉，且这一补偿的前提是测速的准确性！补偿的方法是以第一个发射天线为基准，对后续的发射天线对应各接收通道减去速度引起的相位差值： 2*pi*(V*P*Tc/λ)，式中P = 1,2,…S,对应后续各个发射天线(假设一共有S&#43;1个发射天线)。
CFAR检测的每个结果，我们其实并不知道在这个距离和速度门下藏有多少个目标，在完成相位补偿后就可以进行测角(DOA估计)操作了，该部分的测角操作后得到多少个目标，才是该距离和速度门下有多少个目标。值得注意的是，对于非4D毫米波雷达的实际应用场景(特别是针对动目标)，同距离和速度门下的目标数量其实很少(基本只有一个？)，特别是我们可以把距离和速度分辨率做得很高，这进一步减少了同一个距离和速度门下存在多个目标的可能性；但是对于4D毫米波雷达，雷达的角分辨率很高，我们需要测静止目标，且要求得到更多的点云信息，此时我们需要尽可能多且全地从该距离和速度门中拿到较多的目标点云信息。测角是车载雷达一个比较棘手但很重要的步骤，关于目标的DOA估计可以参看我后续会写的一篇关于车载毫米波雷达DOA估计的博文。
完成测角的操作后，我们此时便得到了目标作为一个点的所有信息：包括其距离、速度、角度(可以包括其水平和俯仰角)，还可以得到该点的SNR等信息，这些信息便可以帮助我们进行后续的聚类操作，适用于车载毫米波雷达的常用聚类方法为DBSCAN，聚类的目的在于将单个可能得到的诸多点汇集成一点以方便后续的跟踪等数据处理的操作。
随后我们再基于聚类得到的点云做跟踪处理，车载毫米波雷达实际应用时是随着车一同运动的，雷达自身也有速度，而我们之前计算得到的是雷达与目标之间的相对的径向速度，此时我们需要从CAN中获取车速以及车的转向角等信息将目标转成以大地为参考系的速度（关于车速转换及其与车辆方向的关系等这些细节我会在后续出一期专题以研究该问题），来辅助这里的跟踪操作，目标跟踪主要有两部分内容：数据关联算法&#43;滤波算法，数据关联可以使用比如最近邻算法等，滤波则有扩展卡尔曼滤波(EKF)等，这部分的算法细节不再本博文的讨论范围，博主本人对这些接触也比较少，后续随着积累的加深可以出一期相关的博文。
如果ADAS功能交给车内的域控去实现，此时对于雷达来说便完成了它的任务，但是现阶段ADAS功能更多的还是在雷达内部实现，ADAS功能比如包括ACC、AEB、BSD、LCA等，相关的介绍以及行业标准我会近期出一期博文做详细点的介绍，雷达需要基于点云信息使用算法对满足条件的情况发出预警信息。
补充说明1：
对于传统的车载毫米波雷达，其实还有一个细节：静态杂波滤除，该部分的处理一般放在2D-FFT之前，该方法一般是针对1D-FFT后的数据，每个数据减去同一个距离门下的速度维度的均值以达到去除静止目标的目的。因为传统的车载毫米波雷达由于不具备测高、识别能力，毫米波雷达无法判断检测到的物体在高空还是在地面（汽车是否能通过），也无法判断该物体是否能轧过（例如地面的易拉罐、窨井盖）。如果都判定为障碍物，则汽车会频繁减速刹车，严重影响驾驶体验。因此行业内采用“静态杂波滤除”，将所有静止物体信号过滤掉。但这种做法存在较大隐患，这也是Tesla前期几起事故的原因之一：摄像头没有识别出倾倒的白色货车车厢，毫米波雷达识别到，但是结果在决策中置信度太低，导致车辆没有触发自动紧急自动功能。
补充说明2：
前面提到有4D雷达，以及在雷达内部实现包括目标识别和分类的功能(或者说不限于雷达内部，而是基于4D雷达采集的数据实现目标识别和分类)，该话题是现阶段车载毫米波雷达领域十分热门的话题，虽然在产品上暂时还没有实现，但是得益于4D毫米波雷达极高的角分辨率，针对4D雷达所采集的数据使用各种方法(特别是机器学习)做目标识别和分类相关的文章近些年可谓层出不穷。
基于4D毫米波雷达的目标识别和分类，信息来源可以是4D雷达致密的点云(至少相较于传统的毫米波雷达，当然4D毫米波雷达其点云的密度相较激光雷达还是差很多的)，此时的点云应该是聚类前的点云。此外，从ADC数据直到点云数据这中间的数据处理其本质是一个信息筛选的过程，我们在获取我们想要的信息的同时其实也丢掉了很多可能有用的信息，这些信息可能我们人没法去使用，但是喂给深度学习算法是另外一回事了，所以很多的目标识别和分类方法是基于比如距离-多普勒图、距离-角度图去实现的，相关的内容博主本人现阶段也只是简单的了解，更多的我会随着个人积累和理解的加深在后续出相关的专题博文做更详细的介绍。
（最近又了解到，不只是4D毫米波雷达，包括角雷达和前向雷达其实OEM都希望雷达能给出目标对应的分类信息。）
补充说明3：
前面给出的车载毫米波雷达的信号处理流程可以说是完备的，但是实际实践起来不同的厂家(包括上游芯片厂家给的demo，以及毫米波雷达厂家其产品中的实践)可能会有一些差异，比如读者可以参考Ti相关的SDK中给的code和说明。但是总体而言大同小异，且读者在理清楚了前述框架的前提下再去看任何厂家的雷达信号处理对其流程的理解应该不再有困难。
三、体征检测与手势识别的雷达信号处理 这部分的内容博主现阶段也算是早期接触，想着一并做个总结，于是一起放在了这里。包括车载雷达、体征检测、手势识别，对应的雷达硬件架构可以说一样的，可以参考我之前写的博文：毫米波雷达的硬件架构与射频前端_墨@#≯的博客-CSDN博客，后两者对实时性也有要求但整体上没有车载那么高，此外后两者没有测速的要求，所以从雷达的发射与处理的角度来说后两者的要求会更低一些，另外，后两者其实可以归为消费电子产品，从包括法规在内的要求上也没有车规级的车载雷达的要求高。体征检测主要包括呼吸和心跳检测，体征检测与手势识别信号处理的方式不太一样，后文将分别介绍。
关于呼吸和心跳检测：
总体上来说：对采集的adc信号进行距离维度的fft后，找到目标的对应距离门，并提取该距离门的相位值，对多帧都进行该操作(中间还涉及到相位的解模糊等操作)，随后对得到的该时间-相位信息基于下述正常的频率范围做带通滤波，分别得到呼吸和心跳下的时域信息，随后对其做傅里叶变换得到目标的呼吸和心跳频率信息。
From front
From back
生命体征
频率
幅度
幅度
呼吸频率(成人)
0.1—0.5Hz
1---12mm
0.1---0.5mm" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bchobby.github.io/posts/e808f43e415bed36996c1df05a17f25d/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-05-23T16:38:39+08:00" />
<meta property="article:modified_time" content="2023-05-23T16:38:39+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程爱好者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程爱好者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">车载与体征/手势检测 毫米波雷达信号处理流程</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2 id="%E8%AF%B4%E6%98%8E" style="margin-left:.0001pt;text-align:center;"><strong>说明</strong></h2> 
<p style="margin-left:.0001pt;text-align:justify;">    本篇博文旨在搭建一个车载毫米波雷达、体征检测(呼吸心跳检测)、手势识别信号处理的框架，介绍其流程，并尽可能多地给出一些流程中的细节处理(内容确实几乎都是文字内容..)，本篇博文不涉及各部分算法的具体原理与实现。本篇博文内容其实很简单，也会基于博主本人的积累以及读者的反馈不断更新内容，我们一起维护，我会定期完善。</p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"><strong>Blog:</strong></p> 
<p style="margin-left:.0001pt;text-align:justify;">20221012博文第一次撰写</p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<h2 id="%E6%96%87%E7%AB%A0%E6%9E%B6%E6%9E%84" style="margin-left:.0001pt;text-align:center;"><strong>文章架构</strong></h2> 
<p></p> 
<p id="main-toc"><strong>目录</strong></p> 
<p id="%E8%AF%B4%E6%98%8E-toc" style="margin-left:0px;"><a href="#%E8%AF%B4%E6%98%8E" rel="nofollow">说明</a></p> 
<p id="%E6%96%87%E7%AB%A0%E6%9E%B6%E6%9E%84-toc" style="margin-left:0px;"><a href="#%E6%96%87%E7%AB%A0%E6%9E%B6%E6%9E%84" rel="nofollow">文章架构</a></p> 
<p id="%E4%B8%80%E3%80%81%E6%AF%AB%E7%B1%B3%E6%B3%A2%E9%9B%B7%E8%BE%BE%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86%E6%A6%82%E8%BF%B0-toc" style="margin-left:0px;"><a href="#%E4%B8%80%E3%80%81%E6%AF%AB%E7%B1%B3%E6%B3%A2%E9%9B%B7%E8%BE%BE%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86%E6%A6%82%E8%BF%B0" rel="nofollow">一、毫米波雷达信号处理概述</a></p> 
<p id="%E4%BA%8C%E3%80%81%E8%BD%A6%E8%BD%BD%E6%AF%AB%E7%B1%B3%E6%B3%A2%E9%9B%B7%E8%BE%BE%E7%9A%84%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86-toc" style="margin-left:0px;"><a href="#%E4%BA%8C%E3%80%81%E8%BD%A6%E8%BD%BD%E6%AF%AB%E7%B1%B3%E6%B3%A2%E9%9B%B7%E8%BE%BE%E7%9A%84%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86" rel="nofollow">二、车载毫米波雷达的信号处理</a></p> 
<p id="%E4%B8%89%E3%80%81%E4%BD%93%E5%BE%81%E6%A3%80%E6%B5%8B%E4%B8%8E%E6%89%8B%E5%8A%BF%E8%AF%86%E5%88%AB%E7%9A%84%E9%9B%B7%E8%BE%BE%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86-toc" style="margin-left:0px;"><a href="#%E4%B8%89%E3%80%81%E4%BD%93%E5%BE%81%E6%A3%80%E6%B5%8B%E4%B8%8E%E6%89%8B%E5%8A%BF%E8%AF%86%E5%88%AB%E7%9A%84%E9%9B%B7%E8%BE%BE%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86" rel="nofollow">三、体征检测与手势识别的雷达信号处理</a></p> 
<p id="%E5%9B%9B%E3%80%81%E6%80%BB%E7%BB%93-toc" style="margin-left:0px;"><a href="#%E5%9B%9B%E3%80%81%E6%80%BB%E7%BB%93" rel="nofollow">四、总结</a></p> 
<p id="%E4%BA%94%E3%80%81%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99-toc" style="margin-left:0px;"><a href="#%E4%BA%94%E3%80%81%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99" rel="nofollow">五、参考资料</a></p> 
<hr id="hr-toc"> 
<p></p> 
<h2 id="%E4%B8%80%E3%80%81%E6%AF%AB%E7%B1%B3%E6%B3%A2%E9%9B%B7%E8%BE%BE%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86%E6%A6%82%E8%BF%B0" style="text-align:justify;"><strong>一、毫米波雷达信号处理概述</strong></h2> 
<p style="margin-left:.0001pt;text-align:justify;">    应用于体征检测的雷达信号类型有很多，调频连续波(FMCW，chirp)是其中的一种，<strong>但现阶段应用于车载的基本就只有chirp的信号形式，后续对信号处理流程的说明都基于chirp的信号形式</strong>。</p> 
<p style="margin-left:.0001pt;text-align:justify;">    FMCW雷达的信号处理流程并不复杂，车载的：到从ADC数据到点云，体征检测的：从ADC数据到时间-相位的波形图，<strong>信号的处理流程和方法其实比较固定</strong>。各车载毫米波雷达厂家的信号处理方法也大同小异，正是基于此，加特兰在其芯片中甚至直接将得到点云之前信号处理过程硬化了，软件开发者只需要给硬件接口配置合适的参数即可，处理流程的硬化可以极大程度地提高处理速度、降低开发难度。</p> 
<p style="margin-left:.0001pt;text-align:justify;">    但是现阶段对雷达的信号处理已经不仅是限于对目标的定位和跟踪，<strong>越来越高的比如识别、分类乃至成像等要求都希望雷达可以实现，于是包括机器学习等方法开始被用到了雷达的信号处理中。此外，针对车载雷达的应用场景，各类ADAS报警功能的实现；针对体征检测的场景，病人的诊断报告以及一些应用场景下的报警功能的实现，连同这些更后端的功能实现都需要集中到雷达中做</strong>。</p> 
<p style="margin-left:.0001pt;text-align:justify;">    综合来看，雷达的信号处理流程虽然不复杂且比较固化，但是涉及的(可供研究和优化的)细节还是有很多的，此外，包括跟踪、分类、实际应用场景下的功能实现等也丰富了信号处理的内容，给信号处理工程师带来了更多的挑战，<strong>理清楚信号处理的流程，搭建一整个的知识框架是十分有必要的，这也是本篇博文想要做的事情</strong>。</p> 
<p style="margin-left:.0001pt;text-align:justify;">    博主本人现阶段对基于机器学习的方法做分类和识别，以及后端的应用功能的实现并不熟悉，相关原理和更细节的说明我会在往后进行补充。此外本人现阶段接触体征检测/手势识别还极少，有不当之处欢迎指正。</p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<h2 id="%E4%BA%8C%E3%80%81%E8%BD%A6%E8%BD%BD%E6%AF%AB%E7%B1%B3%E6%B3%A2%E9%9B%B7%E8%BE%BE%E7%9A%84%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86" style="margin-left:.0001pt;text-align:justify;"><strong>二、车载毫米波雷达的信号处理</strong></h2> 
<p style="margin-left:.0001pt;text-align:justify;">    车载和体征检测/手势识别雷达的<strong>射频前端基本一致</strong>：包括chirp的收发(当然车载的以及体征检测的对chirp的包括周期、带宽、斜率等的设置是不一样的)、混频、滤波、增益控制，直到ADC采集到原始的数据，现阶段的混频有两种方案：单路或IQ两路，这两种方案也都可以应用于车载以及体征检测，IQ两路可以减小对ADC采样率的要求，且距离维FFT后不需要丢掉多余的数据(单路在距离FFT后需要丢掉后面一半的数据)，当然其成本会高很多，关于射频前端以及这两种混频方案的区别与优劣可以参考之前的博文：<span style="color:#0000ff;"><u><a href="https://blog.csdn.net/xhblair/article/details/127229425?spm=1001.2014.3001.5501" title="毫米波雷达的硬件架构与射频前端_墨@#≯的博客-CSDN博客">毫米波雷达的硬件架构与射频前端_墨@#≯的博客-CSDN博客</a></u></span>。</p> 
<p style="margin-left:.0001pt;text-align:justify;">    车载毫米波雷达的大体的信号处理框架大体如下：</p> 
<p style="margin-left:.0001pt;text-align:center;"><img alt="" height="461" src="https://images2.imgbox.com/0b/cc/RcVBIhPI_o.png" width="1091"></p> 
<p style="margin-left:.0001pt;text-align:center;"><strong>车载毫米波雷达信号处理流程</strong></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"><strong><span style="background-color:#ffd900;">对前述各个流程的细节说明</span></strong>：</p> 
<p style="margin-left:.0001pt;text-align:justify;">    对于雷达的单帧数据，ADC采集完成后，对应到各个通道的数据是一个N*M大小的数据矩阵，其中N为单个chirp下的采样点数，N也被称为快时间维，M为单帧下对应到该通道的chirp数，M也被称为慢时间维。假设一共有K个通道，则对应<strong>ADC数据(radar cube)</strong>大小为N*M*K。</p> 
<p style="margin-left:.0001pt;text-align:justify;">    对这K个N*M大小的矩阵做<strong>2D-FFT</strong>就完成了<strong>二维压缩</strong>，随后为了增加SNR，在做CFAR检测前有一个对K个二维压缩后的矩阵进行<strong>累加</strong>的过程，累加的方法有很多，常用的是<strong>非相干累加</strong>：把K个二维压缩后的矩阵取绝对值并累加，得到一个累加后的幅值矩阵【<strong>值得注意的是</strong>，可能是如果直接FFT后累加会超过32bit能装载值的上限？所以Ti在累加之前取了log2，关于整个数据处理过程中一些中间值的大小是否会超过限定bit数下的上限，是我们在产品研发的数据处理时需要考虑的，比如加特兰在其做FFT的过程中会对每一级的中间值进行右移的操作以减小值的大小。】；另外的一种累加方法是<strong>相干累加</strong>：给不同的通道加不同的权值再累加(类似波束成形，这些权值共同构成一个导向矢量)，这种相干累加可以通过设置的权值使雷达视场内其中一些方向的能量增加，从而增加这些区域的目标检测准确度，一般是会设置不同的权值，并对这些权值下得到的累加后的幅值矩阵分别做CFAR处理，再对这些CFAR的结果取并集。</p> 
<p style="margin-left:.0001pt;text-align:justify;">    累加完成后就是对累加得到的幅值矩阵做<strong>CFAR处理</strong>，CFAR算法有很多，比如CA-CFAR、OS-CFAR、GO/SO-CFAR等，做CFAR操作时，一种比较有意思的操作是<strong>分区CFAR</strong>，所谓的分区CFAR是指针对不同的距离区域使用不同的CFAR算法或者同一种CFAR使用不同的保护单元、参考单元以及阈值，分区CFAR的依据是：处在雷达不同距离门下的目标其能量一般不一样，为了减少虚警和漏警的情况发生，比如可以考虑在近处的位置将阈值设置得大一些，当然有基于距离的分区CFAR也就有基于速度的分区CFAR,一些更细节的东西可以参考加特兰芯片的Baseband User-guide <span style="color:#0000ff;"><u><a href="https://www.calterah.com/producttypes/alps/" rel="nofollow" title="加特兰微电子 - Alps (calterah.com)">加特兰微电子 - Alps (calterah.com)</a></u></span>,里头有比较详细的说明。</p> 
<p style="margin-left:.0001pt;text-align:justify;">    CFAR完成后此时我们便可以基于被检测到的点在该二维矩阵中的横纵坐标索引得到该点对应的距离和速度的信息，但此时该速度信息还不能说是可信的，如果目标的速度超过了我们设计参数时的最大无模糊速度值：</p> 
<p style="margin-left:.0001pt;text-align:justify;"><img alt="" height="52" src="https://images2.imgbox.com/c6/b5/0K8Lxsmc_o.png" width="135"></p> 
<p style="margin-left:.0001pt;text-align:justify;">式中，<img alt="" height="26" src="https://images2.imgbox.com/02/24/mTpw3caz_o.png" width="18">为该矩阵(该通道接收)前后两个chirp(两列)之间的时间间隔，<strong>事实上当发射通道增加时，该最大无模糊测速范围是很容易达到甚至超过的</strong>：举例来说，我们假设有3个发射天线按照TDM-MIMO的模式发射，相邻两天线发射的chirp间隔为40us(该值对于车载毫米波雷达来说不是很大),则这里的<img alt="" height="26" src="https://images2.imgbox.com/a9/60/AmURmemW_o.png" width="18"> = 120us,于是对应的最大无模糊测速范围约为8m/s，该值无疑是不够的，我们还是能检测到速度大于最大无模糊测速范围的目标，只是此值“藏在”了无模糊测速范围内，于是此时我们就需要进行<strong>速度解模糊</strong>，速度解模糊目的就是将目标的真实速度求出来，速度解模糊的方法很多，一般需要发射端帮忙，相关的具体的内容我会在后续的博文中作为一个专题给出(不只是速度模糊还有角度模糊等)。</p> 
<p style="margin-left:.0001pt;text-align:justify;">    做完速度解模糊后，我们得到的目标的真实速度，此时我们还需要知道目标的角度才能准确对目标进行定位，但是在测角之前，<strong>针对TDM-MIMO的发射模式</strong>我们还需要做<strong>相位补偿</strong>(这里的相位补偿也只需要针对TDM这种各天线不在同一时刻发射的情况，其它的发射情况并不需要，详情可以参考我之前的博文：<span style="color:#0000ff;"><u><a href="https://blog.csdn.net/xhblair/article/details/126945669?spm=1001.2014.3001.5501" title="车载毫米波雷达MIMO阵列的天线发射问题_墨@#≯的博客-CSDN博客">车载毫米波雷达MIMO阵列的天线发射问题_墨@#≯的博客-CSDN博客</a></u></span>)，相位补偿是针对当目标在运动以及天线是以时分的方式发射时的场景，这种情况下前后发射天线对应的通道会有因目标运动导致的相位差产生，该相位差值会影响测角，所以我们需要将该相位差补偿掉，且这一补偿的前提是测速的准确性！补偿的方法是以第一个发射天线为基准，对后续的发射天线对应各接收通道减去速度引起的相位差值： 2*pi*(V*P*Tc/λ)，式中P = 1,2,…S,对应后续各个发射天线(假设一共有S+1个发射天线)。</p> 
<p style="margin-left:.0001pt;text-align:justify;">    CFAR检测的每个结果，我们其实并不知道在这个距离和速度门下藏有多少个目标，在完成相位补偿后就可以进行<strong>测角(DOA估计)操作</strong>了，该部分的测角操作后得到多少个目标，才是该距离和速度门下有多少个目标。值得注意的是，对于非4D毫米波雷达的实际应用场景(特别是针对动目标)，同距离和速度门下的目标数量其实很少(基本只有一个？)，特别是我们可以把距离和速度分辨率做得很高，这进一步减少了同一个距离和速度门下存在多个目标的可能性；但是对于4D毫米波雷达，雷达的角分辨率很高，我们需要测静止目标，且要求得到更多的点云信息，此时我们需要尽可能多且全地从该距离和速度门中拿到较多的目标点云信息。测角是车载雷达一个比较棘手但很重要的步骤，关于目标的DOA估计可以参看我后续会写的一篇关于车载毫米波雷达DOA估计的博文。</p> 
<p style="margin-left:.0001pt;text-align:justify;">    完成测角的操作后，我们此时便得到了目标作为一个点的所有信息：包括其距离、速度、角度(可以包括其水平和俯仰角)，还可以得到该点的SNR等信息，这些信息便可以帮助我们进行后续的<strong>聚类操作</strong>，适用于车载毫米波雷达的常用聚类方法为DBSCAN，聚类的目的在于将单个可能得到的诸多点汇集成一点以方便后续的跟踪等数据处理的操作。</p> 
<p style="margin-left:.0001pt;text-align:justify;">    随后我们再基于聚类得到的点云做<strong>跟踪处理</strong>，车载毫米波雷达实际应用时是随着车一同运动的，雷达自身也有速度，而我们之前计算得到的是雷达与目标之间的相对的径向速度，此时我们需要从CAN中获取车速以及车的转向角等信息将目标转成以大地为参考系的速度（关于车速转换及其与车辆方向的关系等这些细节我会在后续出一期专题以研究该问题），来辅助这里的跟踪操作，目标跟踪主要有两部分内容：<strong>数据关联算法+滤波算法</strong>，数据关联可以使用比如最近邻算法等，滤波则有扩展卡尔曼滤波(EKF)等，这部分的算法细节不再本博文的讨论范围，博主本人对这些接触也比较少，后续随着积累的加深可以出一期相关的博文。</p> 
<p style="margin-left:.0001pt;text-align:justify;">    如果<strong>ADAS功能</strong>交给车内的域控去实现，此时对于雷达来说便完成了它的任务，<strong>但是现阶段ADAS功能更多的还是在雷达内部实现</strong>，ADAS功能比如包括ACC、AEB、BSD、LCA等，相关的介绍以及行业标准我会近期出一期博文做详细点的介绍，雷达需要基于点云信息使用算法对满足条件的情况发出预警信息。</p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"><strong><span style="background-color:#ffff00;">补充说明1</span></strong>：</p> 
<p style="margin-left:.0001pt;text-align:justify;">    对于传统的车载毫米波雷达，其实还有一个细节：<strong>静态杂波滤除</strong>，该部分的处理一般放在2D-FFT之前，该方法一般是针对1D-FFT后的数据，每个数据减去同一个距离门下的速度维度的均值以达到去除静止目标的目的。因为传统的车载毫米波雷达由于不具备测高、识别能力，毫米波雷达无法判断检测到的物体在高空还是在地面（汽车是否能通过），也无法判断该物体是否能轧过（例如地面的易拉罐、窨井盖）。如果都判定为障碍物，则汽车会频繁减速刹车，严重影响驾驶体验。因此行业内采用“静态杂波滤除”，将所有静止物体信号过滤掉。但这种做法存在较大隐患，这也是Tesla前期几起事故的原因之一：摄像头没有识别出倾倒的白色货车车厢，毫米波雷达识别到，但是结果在决策中置信度太低，导致车辆没有触发自动紧急自动功能。</p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"><strong><span style="background-color:#ffff00;">补充说明2</span></strong>：</p> 
<p style="margin-left:.0001pt;text-align:justify;">    前面提到有4D雷达，以及在雷达内部实现包括<strong>目标识别和分类</strong>的功能(或者说不限于雷达内部，而是基于4D雷达采集的数据实现目标识别和分类)，该话题是现阶段车载毫米波雷达领域十分热门的话题，虽然在产品上暂时还没有实现，<strong>但是得益于4D毫米波雷达极高的角分辨率，针对4D雷达所采集的数据使用各种方法(特别是机器学习)做目标识别和分类相关的文章近些年可谓层出不穷</strong>。</p> 
<p style="margin-left:.0001pt;text-align:justify;"><strong>   基于4D毫米波雷达的目标识别和分类</strong>，信息来源可以是4D雷达致密的点云(至少相较于传统的毫米波雷达，当然4D毫米波雷达其点云的密度相较激光雷达还是差很多的)，此时的点云应该是聚类前的点云。此外，从ADC数据直到点云数据这中间的数据处理其本质是一个信息筛选的过程，我们在获取我们想要的信息的同时其实也丢掉了很多可能有用的信息，这些信息可能我们人没法去使用，但是喂给深度学习算法是另外一回事了，所以很多的目标识别和分类方法是基于比如距离-多普勒图、距离-角度图去实现的，相关的内容博主本人现阶段也只是简单的了解，更多的我会随着个人积累和理解的加深在后续出相关的专题博文做更详细的介绍。</p> 
<p style="margin-left:.0001pt;text-align:justify;">   （最近又了解到，不只是4D毫米波雷达，包括角雷达和前向雷达其实OEM都希望雷达能给出目标对应的分类信息。）</p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"><strong><span style="background-color:#ffff00;">补充说明3</span></strong>：</p> 
<p style="margin-left:.0001pt;text-align:justify;">    前面给出的车载毫米波雷达的信号处理流程可以说是完备的，但是实际实践起来不同的厂家(包括上游芯片厂家给的demo，以及毫米波雷达厂家其产品中的实践)可能会有一些差异，比如读者可以参考Ti相关的SDK中给的code和说明。但是总体而言大同小异，且读者在理清楚了前述框架的前提下再去看任何厂家的雷达信号处理对其流程的理解应该不再有困难。</p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<h2 id="%E4%B8%89%E3%80%81%E4%BD%93%E5%BE%81%E6%A3%80%E6%B5%8B%E4%B8%8E%E6%89%8B%E5%8A%BF%E8%AF%86%E5%88%AB%E7%9A%84%E9%9B%B7%E8%BE%BE%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86" style="text-align:justify;"><strong>三、体征检测与手势识别的雷达信号处理</strong></h2> 
<p style="margin-left:.0001pt;text-align:justify;">    这部分的内容博主现阶段也算是早期接触，想着一并做个总结，于是一起放在了这里。包括车载雷达、体征检测、手势识别，对应的雷达硬件架构可以说一样的，可以参考我之前写的博文：<a href="https://blog.csdn.net/xhblair/article/details/127229425?spm=1001.2014.3001.5501" title="毫米波雷达的硬件架构与射频前端_墨@#≯的博客-CSDN博客">毫米波雷达的硬件架构与射频前端_墨@#≯的博客-CSDN博客</a>，后两者对实时性也有要求但整体上没有车载那么高，此外后两者没有测速的要求，所以从雷达的发射与处理的角度来说后两者的要求会更低一些，另外，后两者其实可以归为消费电子产品，从包括法规在内的要求上也没有车规级的车载雷达的要求高。体征检测主要包括呼吸和心跳检测，体征检测与手势识别信号处理的方式不太一样，后文将分别介绍。</p> 
<p style="margin-left:.0001pt;text-align:justify;"><strong>关于呼吸和心跳检测</strong>：</p> 
<p style="margin-left:.0001pt;text-align:justify;">    总体上来说：对采集的adc信号进行距离维度的fft后，找到目标的对应距离门，并提取该距离门的相位值，对多帧都进行该操作(中间还涉及到相位的解模糊等操作)，随后对得到的该时间-相位信息基于下述正常的频率范围做带通滤波，分别得到呼吸和心跳下的时域信息，随后对其做傅里叶变换得到目标的呼吸和心跳频率信息。</p> 
<table border="1" cellspacing="0" style="width:430.3pt;"><tbody><tr><td style="border-color:#000000;vertical-align:top;width:107.55pt;"> <p style="margin-left:.0001pt;text-align:justify;"></p> </td><td style="border-color:#000000;vertical-align:top;width:107.55pt;"> <p style="margin-left:.0001pt;text-align:justify;"></p> </td><td style="border-color:#000000;vertical-align:top;width:107.6pt;"> <p style="margin-left:.0001pt;text-align:justify;">From front</p> </td><td style="border-color:#000000;vertical-align:top;width:107.6pt;"> <p style="margin-left:.0001pt;text-align:justify;">From back</p> </td></tr><tr><td style="border-color:#000000;vertical-align:top;width:107.55pt;"> <p style="margin-left:.0001pt;text-align:justify;">生命体征</p> </td><td style="vertical-align:top;width:107.55pt;"> <p style="margin-left:.0001pt;text-align:justify;">频率</p> </td><td style="vertical-align:top;width:107.6pt;"> <p style="margin-left:.0001pt;text-align:justify;">幅度</p> </td><td style="vertical-align:top;width:107.6pt;"> <p style="margin-left:.0001pt;text-align:justify;">幅度</p> </td></tr><tr><td style="border-color:#000000;vertical-align:top;width:107.55pt;"> <p style="margin-left:.0001pt;text-align:justify;">呼吸频率(成人)</p> </td><td style="vertical-align:top;width:107.55pt;"> <p style="margin-left:.0001pt;text-align:justify;">0.1—0.5Hz</p> </td><td style="vertical-align:top;width:107.6pt;"> <p style="margin-left:.0001pt;text-align:justify;">1---12mm</p> </td><td style="vertical-align:top;width:107.6pt;"> <p style="margin-left:.0001pt;text-align:justify;">0.1---0.5mm</p> </td></tr><tr><td style="border-color:#000000;vertical-align:top;width:107.55pt;"> <p style="margin-left:.0001pt;text-align:justify;">心跳频率(成人)</p> </td><td style="vertical-align:top;width:107.55pt;"> <p style="margin-left:.0001pt;text-align:justify;">0.8—2.0Hz</p> </td><td style="vertical-align:top;width:107.6pt;"> <p style="margin-left:.0001pt;text-align:justify;">0.1---0.5mm</p> </td><td style="vertical-align:top;width:107.6pt;"> <p style="margin-left:.0001pt;text-align:justify;">0.01---0.2mm</p> </td></tr></tbody></table> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"><strong><img alt="" height="458" src="https://images2.imgbox.com/c7/76/VRGYWYhf_o.png" width="1198"></strong></p> 
<p style="margin-left:.0001pt;text-align:center;"><strong>体征检测的信号处理流程</strong></p> 
<p style="margin-left:.0001pt;text-align:justify;">    相关的在Ti的官网教学视频以及文档里有很详细的介绍，我做说明的话可能只是翻译了没有太大意义，内容比较简单，看懂并入门并不难。(资料见随附参考资料)</p> 
<p style="margin-left:.0001pt;text-align:justify;"><strong>关于手势识别：</strong></p> 
<p style="margin-left:.0001pt;text-align:justify;">对ADC数据进行2D-FFT后有两种处理方法：</p> 
<p style="text-align:justify;">1、利用CFAR提取峰值作为散射中心点，然后捕捉散射点的统计信息和动态变化：雷达的帧周期很小(可高达10KHz)，手势的运动相较之下就很缓慢，可以认为散射中心在一个周期内的性质是稳定的，于是可以追踪散射中心并提取速度和空间分布的变化实现手势的追踪和分类。（了解到该方法国内上交的顾昌展老师主要在做相关的研究）</p> 
<p style="text-align:justify;">2、直接在叠加的距离-多普勒图上提取特征：将高维的距离-多普勒图投影到低维空间：通过在速度维上非相参累积可以得到距离像：散射中心在距离上的能量分布；通过在距离维上非相参累积可以得到多普勒像：散射中心在距离上的能量分布。随后通过时间维的积累，我们可以得到时间-距离图和时间-多普勒图(又称为微多普勒图)。如果采用了多发多收的雷达，还可以提取时间-角度图，从而更好地对不同方向的手势进行分类。(了解到基于这些图的特征提取，基于机器学习等方法的识别与分类走在前列的是谷歌，其Soli雷达算是这方面的鼻祖？)</p> 
<p style="margin-left:.0001pt;text-align:justify;">更多的信息读者可以去搜索其论文等信息。</p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<h2 id="%E5%9B%9B%E3%80%81%E6%80%BB%E7%BB%93" style="text-align:justify;"><strong>四、总结</strong></h2> 
<p style="margin-left:.0001pt;text-align:justify;">    本篇博文搭建了车载毫米波雷达、体征检测(呼吸心跳检测)、手势识别信号处理的框架，介绍了其主要的流程，并基于博主本人的积累给出一些流程中的细节处理的探讨。</p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<h2 id="%E4%BA%94%E3%80%81%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99" style="text-align:justify;"><strong>五、参考资料</strong></h2> 
<p style="margin-left:.0001pt;text-align:justify;"><a href="https://dev.ti.com/tirex/explore/node?node=A__AAS2iIa6eUZfJNAoxx6s8w__com.ti.mmwave_industrial_toolbox__VLyFKFf__LATEST" rel="nofollow" title="Vital Signs Xwr1443 Developers Guide (ti.com)">Vital Signs Xwr1443 Developers Guide (ti.com)</a></p> 
<p style="margin-left:.0001pt;text-align:justify;"><a href="https://training.ti.com/node/1146572" rel="nofollow" title="Vital Signs 驾驶员生理信号检测 | TI.com Video">Vital Signs 驾驶员生理信号检测 | TI.com Video</a></p> 
<p style="margin-left:.0001pt;text-align:justify;"><a href="https://mp.weixin.qq.com/s/49NyGJoT0D-eod0Md1SPuw" rel="nofollow" title="雷达资讯 | 深度解析谷歌Soli雷达：从手势识别到睡眠监控">雷达资讯 | 深度解析谷歌Soli雷达：从手势识别到睡眠监控</a> (手势识别，)</p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/d945c526361645cf178385afcb087aff/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">vue3.2 elementplus 中 popover组件指定按钮触发</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/8a822fcd94568340cadb6e63f46657d9/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">搭建 Python 开发环境</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程爱好者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151260"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>