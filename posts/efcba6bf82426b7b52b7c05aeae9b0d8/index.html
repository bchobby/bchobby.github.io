<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>用python生成词云图 --- 新手练手 - 编程爱好者博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="用python生成词云图 --- 新手练手" />
<meta property="og:description" content="类似生成各种形状的云图，我也会啦！
其实也就是针对新手吧，我估计老手分分钟，哈哈哈，我怕我忘了，随手记录下~
四个步骤吧：
读文件分词生成词云图显示词云图 1. 读文件 使用了下 codecs 库，读取内容更方便。
import codecs def get_file_content(filePath): with codecs.open(filePath, &#39;r&#39;, &#39;utf-8&#39;) as f: txt = f.read() return txt 2. 分词 jieba是一个分词库，可以将一段文本分割成词语。cut 是将文本精确切分开，不存在冗余词语。比如颜酱是一个厉害的厨师，会变成[&#39;颜酱&#39;, &#39;厉害&#39;, &#39;厨师&#39;]。 Counter是一个计数器，可以统计词语出现的次数，most_common 是取出最常用的词语。
import jieba from collections import Counter def get_words(txt): # 先分词，得到词语数组 seg_list = jieba.cut(txt) # 开始计数 c = Counter() for x in seg_list: if len(x)&gt;1 and x != &#39;\r\n&#39;: c[x] &#43;= 1 word_list = [] print(&#39;常用词频度统计结果&#39;) # 统计前99个词 for (k,v) in c." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bchobby.github.io/posts/efcba6bf82426b7b52b7c05aeae9b0d8/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-30T14:23:42+08:00" />
<meta property="article:modified_time" content="2023-12-30T14:23:42+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程爱好者博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程爱好者博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">用python生成词云图 --- 新手练手</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>类似生成各种形状的云图，我也会啦！</p> 
<p>其实也就是针对新手吧，我估计老手分分钟，哈哈哈，我怕我忘了，随手记录下~</p> 
<p>四个步骤吧：</p> 
<ol><li>读文件</li><li>分词</li><li>生成词云图</li><li>显示词云图</li></ol> 
<h3><a id="1__15"></a>1. 读文件</h3> 
<p>使用了下 codecs 库，读取内容更方便。</p> 
<pre><code>import codecs
def get_file_content(filePath):
  with codecs.open(filePath, 'r', 'utf-8') as f:
      txt = f.read()
  return txt

</code></pre> 
<h3><a id="2__29"></a>2. 分词</h3> 
<p><code>jieba</code>是一个分词库，可以将一段文本分割成词语。cut 是将文本精确切分开，不存在冗余词语。比如颜酱是一个厉害的厨师，会变成<code>['颜酱', '厉害', '厨师']</code>。 <code>Counter</code>是一个计数器，可以统计词语出现的次数，most_common 是取出最常用的词语。</p> 
<pre><code>import jieba
from collections import Counter
def get_words(txt):
    # 先分词，得到词语数组
    seg_list = jieba.cut(txt)
    # 开始计数
    c = Counter()
    for x in seg_list:
        if len(x)&gt;1 and x != '\r\n':
            c[x] += 1
    word_list = []
    print('常用词频度统计结果')
     # 统计前99个词
    for (k,v) in c.most_common(99):
        word_list.append(str(k))
    # 将词语生成文本文件
    file = open("./dist/out_words.txt", 'w').close()
    with open("./dist/out_words.txt",'a+',encoding='utf-8') as writeFile:
        for (k,v) in c.most_common(99):    # 统计前99个词
            writeFile.write(str(k))
            writeFile.write(str(v))
            writeFile.write('\n')
    print(word_list)
    # ['发展','平安']
    return word_list

</code></pre> 
<h3><a id="3__63"></a>3. 生成云图</h3> 
<p>wordcloud 是一个词云库，可以将词语生成词云图片。</p> 
<pre><code>import wordcloud;
def generate_cloud_image(file_path, shape_image_path):
  word_list = get_words(get_file_content(file_path))
  string = ' '.join(word_list)
  # 读取词云形状图片
  image = imageio.v2.imread(shape_image_path)
  # 先实例化一个词云对象
  wc = wordcloud.WordCloud(width=image.shape[0],     # 词云图宽度同原图片宽度
                          height=image.shape[1],
                          background_color='white',  # 背景颜色白色
                          font_path='Arial Unicode.ttf',    # 指定字体路径，微软雅黑，可从自带的字体库中找
                          mask=image,   # mask 指定词云形状图片，默认为矩形
                          scale=3)      # 默认为1，越大越清晰
  # 生成词云
  wc.generate(string)
  # 保存成文件,output_wordcloud.png，词云图
  wc.to_file('dist/output_wordcloud.png')
  # 弹出图片显示
  alert_image('dist/output_wordcloud.png')

</code></pre> 
<h3><a id="4__91"></a>4. 显示词云图</h3> 
<p><code>matplotlib</code>是一个绘图库，可以将图片显示出来，plt 用于显示图片，mpimg 用于读取图片。</p> 
<pre><code>#
# plt用于显示图片
import matplotlib.pyplot as plt
# mpimg 用于读取图片
import matplotlib.image as mpimg
def alert_image(image_path):
  # 这里是让词云图弹出来显示
  lena = mpimg.imread(image_path) # 读取和代码处于同一目录下的 lena.png
  # 此时 lena 就已经是一个 np.array 了，可以对它进行任意处理
  lena.shape #(512, 512, 3)
  plt.imshow(lena) # 显示图片
  plt.axis('off') # 不显示坐标轴
  plt.show()

</code></pre> 
<p>这就可以了！</p> 
<h3><a id="_115"></a>其他文件</h3> 
<p>准备好文件实验：</p> 
<h4><a id="inputtxt_120"></a>input.txt</h4> 
<p><a href="https://link.juejin.cn/?target=https%3A%2F%2Fblog-huahua.oss-cn-beijing.aliyuncs.com%2Fblog%2Fcode%2Finput.txt" rel="nofollow" title="https://blog-huahua.oss-cn-beijing.aliyuncs.com/blog/code/input.txt">input.txt</a></p> 
<h4><a id="cloudjpg_124"></a>cloud.jpg</h4> 
<h4><a id="generate_cloud_imagepy_128"></a>generate_cloud_image.py</h4> 
<p>generate_cloud_image.py:</p> 
<pre><code>import codecs
import jieba
import imageio
import wordcloud
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from collections import Counter
# def get_words(txt):...
# def get_file_content:...
# def alert_image(image_path):...
# def generate_cloud_image(file_path, shape_image_path):...
generate_cloud_image('input.txt', 'cloud.jpg')

</code></pre> 
<p>完整版：</p> 
<pre><code>import codecs
import jieba
import imageio
import wordcloud
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from collections import Counter
#  get_words函数用于统计词频，生成out.txt，展示词语和词频 如发展218 坚持170
def get_words(txt):
    seg_list = jieba.cut(txt)
    c = Counter()
    for x in seg_list:
        if len(x)&gt;1 and x != '\r\n':
            c[x] += 1
    word_list = []
    print('常用词频度统计结果')
     # 统计前99个词
    for (k,v) in c.most_common(99):
        word_list.append(str(k))

    file = open("./out_words.txt", 'w').close()
    with open("./out_words.txt",'a+',encoding='utf-8') as writeFile:
        for (k,v) in c.most_common(99):    # 统计前99个词
            writeFile.write(str(k))
            writeFile.write(str(v))
            writeFile.write('\n')
    print(word_list)
    # ['发展','平安']
    return word_list

def get_file_content(filePath):
    with codecs.open(filePath, 'r', 'utf-8') as f:
        txt = f.read()
    return txt
def alert_image(image_path):
    # 这里是让词云图弹出来显示
    lena = mpimg.imread(image_path) # 读取和代码处于同一目录下的 lena.png
    # 此时 lena 就已经是一个 np.array 了，可以对它进行任意处理
    lena.shape #(512, 512, 3)
    plt.imshow(lena) # 显示图片
    plt.axis('off') # 不显示坐标轴
    plt.show()

# 根据文件生成词云图，file_path是文本文件路径，shape_image_path是词云图的图片途径
def generate_cloud_image(file_path, shape_image_path):
    word_list = get_words(get_file_content(file_path))
    string = ' '.join(word_list)
    # 读取词云形状图片
    image = imageio.v2.imread(shape_image_path)
    # 生成词云图片，先实例化一个词云对象
    wc = wordcloud.WordCloud(width=image.shape[0],     # 词云图宽度同原图片宽度
                            height=image.shape[1],
                            background_color='white',  # 背景颜色白色
                            font_path='Arial Unicode.ttf',    # 指定字体路径，微软雅黑，可从win自带的字体库中找
                            mask=image,   # mask 指定词云形状图片，默认为矩形
                            scale=3)      # 默认为1，越大越清晰
    # 再给词云
    wc.generate(string)
    # 保存成文件,output_wordcloud.png，词云图
    wc.to_file('output_wordcloud.png')
    alert_image('output_wordcloud.png')

generate_cloud_image('input.txt', 'cloud.jpg')

</code></pre> 
<h3><a id="_217"></a>运行</h3> 
<p>记得先<code>pip3 install jieba imageio wordcloud matplotlib</code><br> 然后<code>python3 generate_cloud_image.py</code><br> 📢：文件在同一目录，进到这个目录下运行命令</p> 
<center> 
 <b>---------------------------END--------------------------- </b> 
</center> 
<h3><a id="_230"></a>题外话</h3> 
<p><img src="https://images2.imgbox.com/4d/f2/0H7IkfmZ_o.jpg" alt="在这里插入图片描述"></p> 
<p><font face="幼圆" size="4" color="red">感兴趣的小伙伴，赠送全套Python学习资料，包含面试题、简历资料等具体看下方。<br> </font></p> 
<p>👉<font color="red">CSDN大礼包🎁：</font><a href="https://blog.csdn.net/weixin_68789096/article/details/132275547?spm=1001.2014.3001.5502">全网最全《Python学习资料》免费赠送🆓！</a><font color="#66cc66">（安全链接，放心点击）</font></p> 
<p><strong>一、Python所有方向的学习路线</strong></p> 
<p>Python所有方向的技术点做的整理，形成各个领域的知识点汇总，它的用处就在于，你可以按照下面的知识点去找对应的学习资源，保证自己学得较为全面。</p> 
<p><img src="https://images2.imgbox.com/fc/62/W6W2QuKU_o.png" alt="img"></p> 
<p><strong>二、Python兼职渠道推荐</strong>*</p> 
<p>学的同时助你创收，每天花1-2小时兼职，轻松稿定生活费.<br> <img src="https://images2.imgbox.com/58/36/f2y2Dx7J_o.png" alt="在这里插入图片描述"></p> 
<p><strong>三、最新Python学习笔记</strong></p> 
<p>当我学到一定基础，有自己的理解能力的时候，会去阅读一些前辈整理的书籍或者手写的笔记资料，这些笔记详细记载了他们对一些技术点的理解，这些理解是比较独到，可以学到不一样的思路。</p> 
<p><img src="https://images2.imgbox.com/28/8f/v6RdNnxd_o.png" alt="img"></p> 
<p><strong>四、实战案例</strong></p> 
<p>纸上得来终觉浅，要学会跟着视频一起敲，要动手实操，才能将自己的所学运用到实际当中去，这时候可以搞点实战案例来学习。</p> 
<p><img src="https://images2.imgbox.com/e9/aa/kiZ8u9zu_o.png" alt="img"></p> 
<p>👉<font color="red">CSDN大礼包🎁：</font><a href="https://blog.csdn.net/weixin_68789096/article/details/132275547?spm=1001.2014.3001.5502">全网最全《Python学习资料》免费赠送🆓！</a><font color="#66cc66">（安全链接，放心点击）</font></p> 
<p>若有侵权，请联系删除</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/afdfab03560ec4c1ac0665d128cee8d3/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Python：爬虫获取微信公众号里面的表格内容&#43;整理数据导出表格</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/10c6ec68c5c3d06540781050c4041f44/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">7个罕见的Numpy函数！</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程爱好者博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151260"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>